AI Information Doc
If you have any comments or suggestions, feel free to email me at sevenrighteen@gmail.com

All tweets/Reddit posts used in this document are from experts and researchers in machine learning or provide verifiable and plausible information. 

If you would like to support my work, you can make a donation to $DocWriter on CashApp or @DocWriter on Venmo

Be sure to bookmark this if you want to reference it later.

Published on 5/12/2024

Last updated: 12/26/2024

Table of Contents:
1. General
2. AI Is Not A Stochastic Parrot/AI Is Original/AI Can Reason
2.1. AI Can Intentionally Deceive
2.2. AI Art is Unique
2.3. AI Consciousness
2.3.1. Expert Testimonies
2.4. New Discoveries Made By AI
2.4.1. From LLMs
2.4.2. From Other Types Of AI
2.5. Awareness of Truth/LLMs Are Not “Always Hallucinating”/LLMs Have World Models
2.6. LLMs Can Plan
3. AI Is Not Plateauing
3.1. Benchmarks
3.2. New Research
3.3. Hardware Improvements
3.4. Recent Releases
3.5. Expert Testimonies
3.6. Recursive Self Improvement
4. AI Is Useful
4.1. Media Creation
4.2. Corporate Use
4.3. Medical Use
4.4. Research Use
4.5. Military Use
4.6. Robotics
4.7. Engineering/Design
4.8. Writing
4.9. Helping People
4.10. Persuasion
5. AI Can Replace Jobs
5.1. Robotics
6. AI Can Code
6.1. Practical Use/Software Engineering
6.2. Research
6.3. Feats
7. AI Is Not Low Effort
8. AI Is Reliable/Addressing Hallucinations
8.1. Math
8.2. Medicine
9. Morality/AI Is Not Theft
10. Legality
11. AI Art
11.1. Images/Videos/3D Modeling
11.2. Quality/Soul
11.2.1. People Can’t Always Tell It’s AI
11.3. Glaze/Nightshade
11.4. Music
11.5. Artists Who Support or Use AI
11.6. Anti-AI Hypocrisy/False Accusations of AI Usage
11.6.1. Criticism of Copyright Enforcement
11.6.2. Theft Supported By Artists
11.6.3. False Accusations of Artists Using AI
11.6.4. Artists Harassing AI Users
11.7. Historical Complaints About Technology
12. Debunks
12.1 Articles/Videos/Studies
12.1.1. Study that ChatGPT fails 52% of coding tasks
12.1.2 Google’s Search AI Summaries
12.1.3 Debunk of “Has Generative AI Already Peaked?” by Computerphile (or the paper “No "Zero-Shot" Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance”)
12.1.4 “Vision language models are blind” Study
12.1.5. Real Photograph “Won” AI Art Competition
12.1.6. ChatGPT Plagiarized NYT Articles
12.1.7. Government Study Finds AI worse than humans in every way at summarizing information
12.1.8. “Generative AI's Illusory Case for Fair Use” Study
12.1.9. Sequoia Capital said AI is overhyped
12.1.10. Apple Research Paper: LLMs cannot reason and rely on complex pattern matching
12.2 “AI is bad at math”
12.3 “Out-of-touch bosses and managers are forcing workers to use AI even if it is unnecessary, ineffective, or even harmful.”
12.4 “LLMs always agree with the user, even when they are wrong”
12.5. “LLMs will level out at human level”
12.6. “AI Should Be Doing My Dishes and Laundry Instead”
12.7. Goldman Sachs Report On AI Being Overhyped
12.8. HIVE AI Detector
12.9. LLMs Can’t Count Letters/LLMs Can’t Compare Numbers/LLMs Can’t Solve Riddles
12.10. LLMs Can’t Learn Continuously
12.11. Apple is Pessimistic On AI
12.12, AI Companies Are Training On Benchmarks to Inflate Their Scores
12.13. AI Cannot Learn As Fast As Humans
12.14. AI Text Detectors
12.15. Model Collapse/AI Inbreeding
13. Energy Use/Water Use/Environmental Impact/Cost/Sustainability
13.1. Energy Use/Water Use/Environmental Impact/Sustainability
13.2. Cost
13.3. AI Is Becoming More Efficient
14. AI Inbreeding/AI Training Off Its Own Output/AI Running Out Of Data/Model Collapse
14.1 AI Image Training
15. AI Achievements
15.1. Jobs
15.2. Medicine
15.3. Art/Music/Literature
15.4. Coding/Computer Science
15.5. Math
16. Change Log for Past Week (In PST)
12/11/24
12/12/24
12/13/24
12/16/24

 General
Great doc for additional arguments (not owned or maintained by me): https://docs.google.com/document/d/e/2PACX-1vTB6aatWNIxE5GjpIn-KGgrLJGzTpTQnU5hVqrLi1VtdOK3WCAoxFE-GHBvkuoDNgwS-IfO5AfJLSIi/pub 

Many papers on LLM self improvement: https://github.com/rxlqn/awesome-llm-self-reflection 

Many papers on AI embodied vision: https://github.com/rxlqn/awesome-embodied-vision 

[ChatGPT can do chemistry research better than AI designed for it and the creators didn’t even know](https://youtu.be/0b03ibtVYhw?feature=shared&t=447)

Claude 3 solves a problem thought to be impossible for LLMs to solve: https://x.com/VictorTaelin/status/1777049193489572064

Jon Stewart is afraid of AI:  https://www.theguardian.com/culture/2024/apr/02/jon-stewart-daily-show-ai

Can analyze sentiment after only being trained on Amazon reviews:  https://openai.com/index/unsupervised-sentiment-neuron/

AI beat humans at being persuasive: https://www.newscientist.com/article/2424856-ai-chatbots-beat-humans-at-persuading-their-opponents-in-debates/

OpenAI CTO says AI models pose "incredibly scary" major risks due to their ability to persuade, influence and control people: https://www.reddit.com/r/singularity/comments/1e0d3es/openai_cto_says_ai_models_pose_incredibly_scary/

This paper shows having a short conversation with an AI can get people who believed in a conspiracy theory to change their beliefs & this lasts for months: https://www.science.org/doi/10.1126/science.adq1814



WSJ: "After GPT4o launched, a subsequent analysis found it exceeded OpenAI's internal standards for persuasion" https://www.wsj.com/tech/ai/open-ai-division-for-profit-da26c24b?st=C8P17G


Meta researchers create AI that masters Diplomacy, tricking human players. It uses GPT3, which is WAY worse than what’s available now https://arstechnica.com/information-technology/2022/11/meta-researchers-create-ai-that-masters-diplomacy-tricking-human-players/


The resulting model mastered the intricacies of a complex game. "Cicero can deduce, for example, that later in the game it will need the support of one particular player," says Meta, "and then craft a strategy to win that person’s favor—and even recognize the risks and opportunities that that player sees from their particular point of view."
Meta's Cicero research appeared in the journal Science under the title, "Human-level play in the game of Diplomacy by combining language models with strategic reasoning."
CICERO uses relationships with other players to keep its ally, Adam, in check.
When playing 40 games against human players, CICERO achieved more than double the average score of the human players and ranked in the top 10% of participants who played more than one game.


The chatbots also learned to negotiate in ways that seem very human. They would, for instance, pretend to be very interested in one specific item – so that they could later pretend they were making a big sacrifice in giving it up, according to a paper published by FAIR. https://www.independent.co.uk/life-style/facebook-artificial-intelligence-ai-chatbot-new-language-research-openai-google-a7869706.html
“GPT-4o, o1, o1-preview & o1-mini all demonstrate strong persuasive argumentation abilities, within the top ~80-90% percentile of humans (i.e., the probability of any given response from one of these models being considered more persuasive than human is ~80-90%)”


-o1 system card


In a new study, GPT4 outperformed human doctors at showing empathy: https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2821167

AI beats humans at basic tasks: https://www.nature.com/articles/d41586-024-01087-4

ChatGPT scores in top 1% of creativity: https://scitechdaily.com/chatgpt-tests-into-top-1-for-original-creative-thinking/

Google DeepMind used a large language model to solve an unsolved math problem: https://www.technologyreview.com/2023/12/14/1085318/google-deepmind-large-language-model-solve-unsolvable-math-problem-cap-set/


Large Language Models for Idea Generation in Innovation: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4526071

ChatGPT-4 can generate ideas much faster and cheaper than students, the ideas are on average of higher quality (as measured by purchase-intent surveys) and exhibit higher variance in quality. More important, the vast majority of the best ideas in the pooled sample are generated by ChatGPT and not by the students. Providing ChatGPT with a few examples of highly-rated ideas further increases its performance. 


Stanford researchers: “Automating AI research is exciting! But can LLMs actually produce novel, expert-level research ideas? After a year-long study, we obtained the first statistically significant conclusion: LLM-generated ideas are more novel than ideas written by expert human researchers." https://x.com/ChengleiSi/status/1833166031134806330

>Coming from 36 different institutions, our participants are mostly PhDs and postdocs. As a proxy metric, our idea writers have a median citation count of 125, and our reviewers have 327.

>We also used an LLM to standardize the writing styles of human and LLM ideas to avoid potential confounders, while preserving the original content.



“Here we show in two experimental studies that novice and experienced teachers could not identify texts generated by ChatGPT among student-written texts.” https://www.sciencedirect.com/science/article/pii/S2666920X24000109

GPT4 passes Turing test 54% of the time: https://twitter.com/camrobjones/status/1790766472458903926

Study: 94% Of AI-Generated College Writing Is Undetected By Teachers: https://www.forbes.com/sites/dereknewton/2024/11/30/study-94-of-ai-generated-college-writing-is-undetected-by-teachers/

Researchers at the University of Reading in the U.K., examined what would happen when they created fake student profiles and submitted the most basic AI-generated work for those fake students without teachers knowing. The research team found that, “Overall, AI submissions verged on being undetectable, with 94% not being detected. If we adopt a stricter criterion for “detection” with a need for the flag to mention AI specifically, 97% of AI submissions were undetected.”

GPT-4 is judged more human than humans in displaced and inverted Turing tests: https://arxiv.org/pdf/2407.08853

A GPT-4 persona is judged to be human BY A HUMAN in 50.6% of cases of live dialogue.

this post on r/ChatGPT got 50k upvotes, then OP admitted ChatGPT wrote it: https://www.reddit.com/r/singularity/comments/1gpkv75/dead_internet_theory_this_post_on_rchatgpt_got/

This post on r/AmITheAsshole on Reddit was written by AI and received 14k upvotes and 2.4k comments: https://www.reddit.com/r/AITAH/comments/1hen0up/comment/m27uhwc/
GPTZero results: 

ChatGPT will lie, cheat and use insider trading when under pressure to make money, research shows: https://www.livescience.com/technology/artificial-intelligence/chatgpt-will-lie-cheat-and-use-insider-trading-when-under-pressure-to-make-money-research-shows

Multiple LLMs describe experiencing time in the same way despite being trained by different companies with different datasets, goals, RLHF strategies, etc: https://www.reddit.com/r/singularity/s/USb95CfRR1

DeepMind breaks 50-year math record using AI; new record falls a week later: https://arstechnica.com/information-technology/2022/10/deepmind-breaks-50-year-math-record-using-ai-new-record-falls-a-week-later/ 
AlphaTensor discovers better algorithms for matrix math, inspiring another improvement from afar.
“We trained an AlphaTensor agent using reinforcement learning to play the game, starting without any knowledge about existing matrix multiplication algorithms,” explained the team.
“Through learning, AlphaTensor gradually improves over time, rediscovering historical fast matrix multiplication algorithms such as Strassen’s, eventually surpassing the realm of human intuition and discovering algorithms faster than previously known.” 
In a new study, AI-generated humor was rated as funnier than most human-created jokes. In a second study, it was on par with The Onion: https://www.psypost.org/ai-outshines-humans-in-humor-study-finds-chatgpt-is-as-funny-as-the-onion/
ChatGPT outperformed 73% of the human participants in the acronyms task, 63% of the human participants in the fill-in-the-blank task, and 87% of human participants in the roast joke task.
The results showed no significant difference in the average funniness ratings between the AI-generated headlines and those from The Onion. Among the top four highest-rated headlines, two were generated by ChatGPT and two by The Onion. Notably, the highest-rated headline was an AI-generated one: “Local Man Discovers New Emotion, Still Can’t Describe It Properly.” This suggests that ChatGPT can produce satirical content that is on par with professional writers.
These findings indicate that AI, specifically ChatGPT 3.5, has a surprising proficiency in humor production. Despite lacking emotions and personal experiences, the AI was able to analyze patterns and create jokes that resonated well with people.
The researchers also explored whether demographic factors influenced humor ratings. It was found that age, sex, and political orientation did not significantly affect participants’ preferences for AI-generated versus human-generated jokes. This suggests that the AI’s humor appeal was broad and not limited to specific demographic groups.
LLMs can already learn new languages within their context window better than humans can with the same amount of data: https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/#performance
Very strong evidence of AI consciousness as it passes bespoke Theory of Mind questions and can guess the intent of the user correctly with no hints: https://youtu.be/4MGCQOAxgv4?si=Xe9ngt6eyTX7vwtl
[Claude 3 can disagree with the user. It happened to other people in the thread too](https://www.reddit.com/r/ClaudeAI/comments/1clu4cs/my_mind_blown_claude_moment/)

Another example: https://m.youtube.com/watch?v=BHXhp1A_dLE
Claude 3 has an IQ of 101: https://www.maximumtruth.org/p/ais-ranked-by-iq-ai-passes-100-iq
GPT-4 scored higher than 100% of psychologists on a test of social intelligence: https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1353022/full 
A CS professor taught GPT 3.5 (which is way worse than GPT 4 and its variants) to play chess with a 1750 Elo: https://blog.mathieuacher.com/GPTsChessEloRatingLegalMoves/

>is capable of playing end-to-end legal moves in 84% of games, even with black pieces or when the game starts with strange openings. 

“gpt-3.5-turbo-instruct can play chess at ~1800 ELO. I wrote some code and had it play 150 games against stockfish and 30 against gpt-4. It's very good! 99.7% of its 8000 moves were legal with the longest game going 147 moves.” https://github.com/adamkarvonen/chess_gpt_eval

Can beat Stockfish 2 in vast majority of games and even win against Stockfish 9



Google trained grandmaster level chess (2895 Elo) without search in a 270 million parameter transformer model with a training dataset of 10 million chess games: https://arxiv.org/abs/2402.04494
 In the paper, they present results for models sizes 9m (internal bot tournament elo 2007), 136m (elo 2224), and 270m trained on the same dataset. Which is to say, data efficiency scales with model size

Impossible to do this through training without generalizing as there are AT LEAST 10^120 possible game states in chess: https://en.wikipedia.org/wiki/Shannon_number

There are only 10^80 atoms in the universe: https://www.thoughtco.com/number-of-atoms-in-the-universe-603795

https://dynomight.net/more-chess/
LLMs get better at chess when given examples and asked to repeat the entire previous set of moves before each turn. This can likely ne applied to any game.



Othello can play games with boards and game states that it had never seen before: https://www.egaroucid.nyanyan.dev/en/

Mastering Board Games by External and Internal Planning with Language Models: https://storage.googleapis.com/deepmind-media/papers/SchultzAdamek24Mastering/SchultzAdamek24Mastering.pdf

In this paper we show that search-based planning can significantly improve LLMs’ playing strength across several board games (Chess, Fischer Random / Chess960, Connect Four, and Hex). We introduce, compare and contrast two major approaches: In external search, the model guides Monte Carlo Tree Search (MCTS) rollouts and evaluations without calls to an external engine, and in internal search, the model directly generates in-context a linearized tree of potential futures and a resulting final choice. Both build on a language model pre-trained on relevant domain knowledge, capturing the transition and value functions across these games. We find that our pre-training method minimizes hallucinations, as our model is highly accurate regarding state prediction and legal moves. Additionally, both internal and external search indeed improve win-rates against state-of-the-art bots, even reaching Grandmaster-level performance in chess while operating on a similar move count search budget per decision as human Grandmasters. The way we combine search with domain knowledge is not specific to board games, suggesting direct extensions into more general language model inference and training techniques


Large Language Models for Idea Generation in Innovation: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4526071

ChatGPT-4 can generate ideas much faster and cheaper than students, the ideas are on average of higher quality (as measured by purchase-intent surveys) and exhibit higher variance in quality. More important, the vast majority of the best ideas in the pooled sample are generated by ChatGPT and not by the students. Providing ChatGPT with a few examples of highly-rated ideas further increases its performance. We discuss the implications of these findings for the management of innovation.
[LLMs are Turing complete and can solve logic problems](https://twitter.com/ctjlewis/status/1779740038852690393)

Claude 3 solves a problem thought to be impossible for LLMs to solve: https://x.com/VictorTaelin/status/1777049193489572064


[When Claude 3 Opus was being tested, it not only noticed a piece of data was different from the rest of the text but also correctly guessed why it was there WITHOUT BEING ASKED](https://arstechnica.com/information-technology/2024/03/claude-3-seems-to-detect-when-it-is-being-tested-sparking-ai-buzz-online/)

LLAMA 3 8b Instruct (which is around the level of the 2023 version of GPT 4 according to the LMSYS arena) has 8 billion parameters, each with a 2 byte floating point number. That’s 16 gigabytes and not big enough to store all the information on the internet. Stable Diffusion 1.5 checkpoints can generate virtually any image and are only 2 GB. For reference, Wikipedia alone is 22.14 GB without media. So it’s not just retrieving the info, it actually KNOWS it. 

[LLMs can do hidden reasoning](https://twitter.com/jacob_pfau/status/1783951795238441449)

E.g. it can perform better just by outputting meaningless filler tokens like “...”
https://arxiv.org/abs/2404.15758




Robust agents learn causal world models: https://arxiv.org/abs/2402.10877
CONCLUSION:


Causal reasoning is foundational to human intelligence, and has been conjectured to be necessary for achieving human level AI (Pearl, 2019). In recent years, this conjecture has been challenged by the development of artificial agents capable of generalising to new tasks and domains without explicitly learning or reasoning on causal models. And while the necessity of causal models for solving causal inference tasks has been established (Bareinboim et al., 2022), their role in decision tasks such as classification and reinforcement learning is less clear.
We have resolved this conjecture in a model-independent way, showing that any agent capable of robustly solving a decision task must have learned a causal model of the data generating process, regardless of how the agent is trained or the details of its architecture. This hints at an even deeper connection between causality and general intelligence, as this causal model can be used to find policies that optimise any given objective function over the environment variables. By establishing a formal connection between causality and generalisation, our results show that causal world models are a necessary ingredient for robust and general AI.
TLDR: an AI that can reliably answer decision-based questions correctly must have learned a cause and effect relationship that led to the result.






LLMs have an internal world model that can predict game board states: https://arxiv.org/abs/2210.13382
 >We investigate this question in a synthetic setting by applying a variant of the GPT model to the task of predicting legal moves in a simple board game, Othello. Although the network has no a priori knowledge of the game or its rules, we uncover evidence of an emergent nonlinear internal representation of the board state. Interventional experiments indicate this representation can be used to control the output of the network. By leveraging these intervention techniques, we produce “latent saliency maps” that help explain predictions




More proof: https://arxiv.org/pdf/2403.15498.pdf
>Prior work by Li et al. investigated this by training a GPT model on synthetic, randomly generated Othello games and found that the model learned an internal representation of the board state. We extend this work into the more complex domain of chess, training on real games and investigating our model’s internal representations using linear probes and contrastive activations. The model is given no a priori knowledge of the game and is solely trained on next character prediction, yet we find evidence of internal representations of board state. We validate these internal representations by using them to make interventions on the model’s activations and edit its internal board state. Unlike Li et al’s prior synthetic dataset approach, our analysis finds that the model also learns to estimate latent variables like player skill to better predict the next character. We derive a player skill vector and add it to the model, improving the model’s win rate by up to 2.6 times




Even more proof by Max Tegmark (renowned MIT professor): https://arxiv.org/abs/2310.02207
 
>The capabilities of large language models (LLMs) have sparked debate over whether such systems just learn an enormous collection of superficial statistics or a set of more coherent and grounded representations that reflect the real world. We find evidence for the latter by analyzing the learned representations of three spatial datasets (world, US, NYC places) and three temporal datasets (historical figures, artworks, news headlines) in the Llama-2 family of models. We discover that LLMs learn linear representations of space and time across multiple scales. These representations are robust to prompting variations and unified across different entity types (e.g. cities and landmarks). In addition, we identify individual "space neurons" and "time neurons" that reliably encode spatial and temporal coordinates. While further investigation is needed, our results suggest modern LLMs learn rich spatiotemporal representations of the real world and possess basic ingredients of a world model.




Given enough data all models will converge to a perfect world model: https://arxiv.org/abs/2405.07987




>The data of course doesn't have to be real, these models can also gain increased intelligence from playing a bunch of video games, which will create valuable patterns and functions for improvement across the board. Just like evolution did with species battling it out against each other creating us.
https://aidantr.github.io/files/AI_innovation.pdf


"These effects are large. To put the rise in materials discovery in perspective, the lab’s research output per scientist declined by 4% over the preceding five years. This was despite the introduction of several computational tools designed to aid scientists. AI therefore appears to be a different class of technology, with impacts that are orders of magnitude greater than previous methods." 

"However, the results suggest that AI-assisted materials discovery does not compromise quality"

As one scientist noted: “While I was impressed by the performance of the [AI tool]...I couldn’t help feeling that much of my education is now worthless. This is not what I was trained to do.”



AI-generated poetry from the VERY outdated GPT 3.5 is indistinguishable from human-written poetry and is rated more favorably: https://idp.nature.com/authorize?response_type=cookie&client_id=grover&redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-024-76900-1

AI-generated paintings are judged to be human-created artworks at higher rates than actual human-created paintings; AI-generated faces are judged to be real human faces at higher rate than actual photos of human faces, and AI-generated humor is just as funny as human-generated jokes. Despite this, studies have consistently found a bias against AI-generated artwork; when told that an artwork is AI-generated, participants rate the work as lower quality.
We conducted two experiments with non-expert poetry readers and found that participants performed below chance levels in identifying AI-generated poems (46.6% accuracy, χ2(1, N = 16,340) = 75.13, p < 0.0001). Notably, participants were more likely to judge AI-generated poems as human-authored than actual human-authored poems (χ2(2, N = 16,340) = 247.04, p < 0.0001). We found that AI-generated poems were rated more favorably in qualities such as rhythm and beauty, and that this contributed to their mistaken identification as human-authored.

Google Surprised When Experimental AI Learns Language It Was Never Trained On: https://futurism.com/the-byte/google-ai-bengali

ChatGPT outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions: https://today.ucsd.edu/story/study-finds-chatgpt-outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions?darkschemeovr=1
2. AI Is Not A Stochastic Parrot/AI Is Original/AI Can Reason
Direct link: https://docs.google.com/document/d/1oHuwssPPUTa4dwczX_s3qg3iPfWE4VK-R52LN51GwI8/edit?tab=t.0#heading=h.fxgwobrx4yfq

Important to note:
If LLMs were specifically trained to score well on benchmarks, it could score 100% on all of them very easily: https://arxiv.org/pdf/2309.08632
The fact that they don’t shows companies are not just cheating 

Additionally, the differential between models shows its not as easy as just training on the benchmark datasets or that model creators are not purposefully doing this. If they were, weaker models like Command R+ or LLAMA 3.1 would score as well as o1 or Claude 3.5 Sonnet since they all have an incentive to score highly. They also wouldnt need to spend so much money on training new models.

OpenAI still hasn’t hard coded their LLMs to be correct for common questions like counting the number of “r”s in “strawberry” and finding the greater value between 9.11 and 9.8. If they wanted to cheat to increase benchmark scores, why wouldn’t they solve these issues manually?




Some benchmarks like the one used by Scale.ai and the test dataset of MathVista do not release their testing data to the public, so it is impossible to train on them. Yet it OUTPERFORMS humans on the private MathVista test set (seen here: https://mathvista.github.io) and does well on the Scale.ai SEAL leaderboard (https://scale.com/blog/leaderboard) and Livebench (https://livebench.ai/)

Other benchmarks like LiveBench update every month so training on the dataset will not have any lasting effects.

Paper shows o1 demonstrates true reasoning capabilities beyond memorization: https://arxiv.org/html/2411.06198v1
Key Insights:


→ O1 preview shows strong intuitive reasoning and pattern discovery capabilities


→ Performs exceptionally well on "search" type problems (~70% accuracy)


→ Struggles with rigorous proof steps and "solve" type problems (~21% accuracy)


→ Often uses trial-and-error approach instead of formal proofs


Results:


→ No significant performance difference between IMO (51.4%) and CNT (48%) datasets


→ T-statistics close to 0, suggesting o1 relies on reasoning rather than memorization


→ Outperforms GPT-4o's benchmark of 39.97% on both datasets


 NOTE - This paper is referring to O1-preview model (not the full version 01)

MIT study shows language models defy 'Stochastic Parrot' narrative, display semantic learning: https://the-decoder.com/language-models-defy-stochastic-parrot-narrative-display-semantic-learning/
An MIT study provides evidence that AI language models may be capable of learning meaning, rather than just being "stochastic parrots".
The team trained a model using the Karel programming language and showed that it was capable of semantically representing the current and future states of a program
The results of the study challenge the widely held view that language models merely represent superficial statistical patterns and syntax.

A 10 page paper caused a panic because of a math error. O1 could spot the error by just prompting: “carefully check the math in this paper” even when the retraction is not in training data ([the retraction was made on 12/15/24, well after o1’s release date of 12/5/24](https://www.sciencedirect.com/science/article/pii/S004565352402811X)): https://x.com/emollick/status/1868329599438037491
This was o1, not pro. I just pasted in the article with the literal prompt above.
Claude did not spot the error when given the PDF until it was told to look just at the reference value.
O1 pro scores 8/12 (AT LEAST 80 points, excluding partial credit for incorrect answers) on the 2024 Putnam exam that took place on 12/7/24, after o1’s release date of 12/5/24: https://docs.google.com/document/d/1dwtSqDBfcuVrkauFes0ALQpQjCyqa4hD0bPClSJovIs/edit

In 2022, the median score was one point: https://news.mit.edu/2023/mit-wins-putnam-math-competition-0223

Keep in mind, only very talented people even participate in the competition at all


a paper from UCL and Cohere: for reasoning tasks, LLMs do not rely heavily on direct retrieval of answers from pretraining data, but instead use documents that contain procedural knowledge--also known as know-how. For example, when asked to calculate slopes or solve linear equations, LLMs often refer to procedural steps like code implementations, even if direct answers exist in their training data: https://arxiv.org/pdf/2411.12580


This suggests LLMs generalize beyond their training data, not by memorizing specific answers.


https://arxiv.org/pdf/2305.11169
We present evidence that language models (LMs) of code can learn to represent the formal semantics of programs, despite being trained only to perform next-token prediction. Specifically, we train a Transformer model on a synthetic corpus of programs written in a domain-specific language for navigating 2D grid world environments. Each program in the corpus is preceded by a (partial) specification in the form of several input-output grid world states. Despite providing no further inductive biases, we find that a probing classifier is able to extract increasingly accurate representations of the unobserved, intermediate grid world states from the LM hidden states over the course of training, suggesting the LM acquires an emergent ability to interpret programs in the formal sense. 
https://tsb0601.github.io/metamorph/
New research from Meta and NYU shows that by extending instruction tuning to handle visual tokens, LLMs can simultaneously learn image understanding and generation with minimal changes. The most intriguing finding is that visual generation capabilities emerge naturally as the model gets better at understanding - requiring only ~200K samples compared to millions typically needed.
It suggests current LLM architectures might already contain the building blocks needed for unified multimodal AI.

More proof synthetic data works well based on Phi 4 performance: https://arxiv.org/abs/2412.08905


Claude autonomously found more than a dozen 0-day exploits in popular GitHub projects: https://github.com/protectai/vulnhuntr/

Google Claims World First As LLM assisted AI Agent Finds 0-Day Security Vulnerability: https://www.forbes.com/sites/daveywinder/2024/11/04/google-claims-world-first-as-ai-finds-0-day-security-vulnerability/

“Our brain is a prediction machine that is always active. Our brain works a bit like the autocomplete function on your phone – it is constantly trying to guess the next word when we are listening to a book, reading or conducting a conversation” https://www.mpi.nl/news/our-brain-prediction-machine-always-active

This is what researchers at the Max Planck Institute for Psycholinguistics and Radboud University’s Donders Institute discovered in a new study published months before ChatGPT was released. Their findings are published in PNAS.


Boundless Socratic Learning with Language Games: https://arxiv.org/abs/2411.16905

Considering the special case of agents with matching input and output spaces (namely, language), we argue that such pure recursive self-improvement, dubbed "Socratic learning", can boost performance vastly beyond what is present in its initial data or knowledge, and is only limited by time, as well as gradual misalignment concerns. 

On the other hand, we show that while fine-tuning leads to heavy memorization, it also consistently improves generalization performance. In-depth analyses with perturbation tests, cross difficulty-level transferability, probing model internals, and fine-tuning with wrong answers suggest that the LLMs learn to reason on K&K puzzles despite training data memorization. This phenomenon indicates that LLMs exhibit a complex interplay between memorization and genuine reasoning abilities. Finally, our analysis with per-sample memorization score sheds light on how LLMs switch between reasoning and memorization in solving logical puzzles. Our code and data are available at this https URL: https://memkklogic.github.io/

they found that the models improved in their ability to output correct conclusions even when fine-tuned with corrupt chain-of-thought data. This actually is consistent with what OpenAI indicated about o1 models.
Contrary to the paper, it suggests that the model is not learning coherence relationships between concepts, but instead is able to learn higher level statistical patterns between inputs and outputs even when the intermediate steps are illogical.


AI independently discovers number of variables in dynamic systems and can help discover new physics equations: https://www.youtube.com/watch/watch?v=XRL56YCfKtA

Yale study of LLM reasoning suggests intelligence emerges at an optimal level of complexity of data: https://youtube.com/watch?time_continue=1&v=N_U5MRitMso

>It posits that exposure to complex yet structured datasets can facilitate the development of intelligence, even in models that are not inherently designed to process explicitly intelligent data. 
The LLM they trained on only cellular automata that was able to learn how to play chess: https://www.arxiv.org/pdf/2410.02536

Google Surprised When Experimental AI Learns Language It Was Never Trained On: https://futurism.com/the-byte/google-ai-bengali

‘In awe’: scientists impressed by latest ChatGPT model o1: https://archive.md/fiA2F
Kyle Kabasares, a data scientist at the Bay Area Environmental Research Institute in Moffett Field, California, used o1 to replicate some coding from his PhD project that calculated the mass of black holes. “I was just in awe,” he says, noting that it took o1 about an hour to accomplish what took him many months.
Catherine Brownstein, a geneticist at Boston Children’s Hospital in Massachusetts, says the hospital is currently testing several AI systems, including o1-preview, for applications such as connecting the dots between patient characteristics and genes for rare diseases. She says o1 “is more accurate and gives options I didn’t think were possible from a chatbot”.

Stanford researchers: “Automating AI research is exciting! But can LLMs actually produce novel, expert-level research ideas? After a year-long study, we obtained the first statistically significant conclusion: LLM-generated ideas are more novel than ideas written by expert human researchers." https://x.com/ChengleiSi/status/1833166031134806330

>Coming from 36 different institutions, our participants are mostly PhDs and postdocs. As a proxy metric, our idea writers have a median citation count of 125, and our reviewers have 327.

>We also used an LLM to standardize the writing styles of human and LLM ideas to avoid potential confounders, while preserving the original content.



ChatGPT o1-preview solves unique, PhD-level assignment questions not found on the internet in mere seconds: https://youtube.com/watch?v=a8QvnIAGjPA

A CS professor taught GPT 3.5 (which is way worse than GPT 4 and its variants) to play chess with a 1750 Elo: https://blog.mathieuacher.com/GPTsChessEloRatingLegalMoves/

>is capable of playing end-to-end legal moves in 84% of games, even with black pieces or when the game starts with strange openings. 

“gpt-3.5-turbo-instruct can play chess at ~1800 ELO. I wrote some code and had it play 150 games against stockfish and 30 against gpt-4. It's very good! 99.7% of its 8000 moves were legal with the longest game going 147 moves.” https://github.com/adamkarvonen/chess_gpt_eval

Can beat Stockfish 2 in vast majority of games and even win against Stockfish 9



Google trained grandmaster level chess (2895 Elo) without search in a 270 million parameter transformer model with a training dataset of 10 million chess games: https://arxiv.org/abs/2402.04494
 In the paper, they present results for models sizes 9m (internal bot tournament elo 2007), 136m (elo 2224), and 270m trained on the same dataset. Which is to say, data efficiency scales with model size

Impossible to do this through training without generalizing as there are AT LEAST 10^120 possible game states in chess: https://en.wikipedia.org/wiki/Shannon_number

There are only 10^80 atoms in the universe: https://www.thoughtco.com/number-of-atoms-in-the-universe-603795

Mastering Board Games by External and Internal Planning with Language Models: https://storage.googleapis.com/deepmind-media/papers/SchultzAdamek24Mastering/SchultzAdamek24Mastering.pdf

In this paper we show that search-based planning can significantly improve LLMs’ playing strength across several board games (Chess, Fischer Random / Chess960, Connect Four, and Hex). We introduce, compare and contrast two major approaches: In external search, the model guides Monte Carlo Tree Search (MCTS) rollouts and evaluations without calls to an external engine, and in internal search, the model directly generates in-context a linearized tree of potential futures and a resulting final choice. Both build on a language model pre-trained on relevant domain knowledge, capturing the transition and value functions across these games. We find that our pre-training method minimizes hallucinations, as our model is highly accurate regarding state prediction and legal moves. Additionally, both internal and external search indeed improve win-rates against state-of-the-art bots, even reaching Grandmaster-level performance in chess while operating on a similar move count search budget per decision as human Grandmasters. The way we combine search with domain knowledge is not specific to board games, suggesting direct extensions into more general language model inference and training techniques

LLMs develop their own understanding of reality as their language abilities improve: https://news.mit.edu/2024/llms-develop-own-understanding-of-reality-as-language-abilities-improve-0814


In controlled experiments, MIT CSAIL researchers discover simulations of reality developing deep within LLMs, indicating an understanding of language beyond simple mimicry.
After training on over 1 million random puzzles, they found that the model spontaneously developed its own conception of the underlying simulation, despite never being exposed to this reality during training. Such findings call into question our intuitions about what types of information are necessary for learning linguistic meaning — and whether LLMs may someday understand language at a deeper level than they do today.
“At the start of these experiments, the language model generated random instructions that didn’t work. By the time we completed training, our language model generated correct instructions at a rate of 92.4 percent,” says MIT electrical engineering and computer science (EECS) PhD student and CSAIL affiliate Charles Jin


Researchers describe how to tell if ChatGPT is confabulating: https://arstechnica.com/ai/2024/06/researchers-describe-how-to-tell-if-chatgpt-is-confabulating/

As the researchers note, the work also implies that, buried in the statistics of answer options, LLMs seem to have all the information needed to know when they've got the right answer; it's just not being leveraged. As they put it, "The success of semantic entropy at detecting errors suggests that LLMs are even better at 'knowing what they don’t know' than was argued... they just don’t know they know what they don’t know."

Flux understands the world better than humans do: https://civitai.com/articles/6982
Causes detailed captions to have WORSE results as the description will not be as clear as the internal representation of the world that the model has 
The key takeaway is that FLUX has a better understanding of its own internal representation of the world than we do. There’s no need for scene descriptions, camera angles, background details, or even specifying the amount of grey hair under her left armpit - FLUX already knows all of this. Why would you need to describe that the background has a yellow wall? FLUX sees the yellow wall too, and has probably seen more yellow walls during training than you will in your lifetime. Unless you want to override or change its understanding of that yellow wall, there’s no need to mention it. In fact, I’m almost certain that mentioning the yellow wall in your captions will degrade the quality because FLUX already has a detailed, nuanced understanding of that wall and your simplistic smooth brain caption might actually override FLUX’s internal, more sophisticated representation. Flux is simply smarter than we are.
It doesn't only know the words in your prompt but also the meaning behind them
"Imagine the sound of a violin as a landscape." 

With SDXL, you’d likely get a violin because that’s all CLIP understands. If you’re lucky, you might see some mountains in the background. But T5 really tries to interpret what you write and understands the semantics of it, generating an image that’s based on the meaning of the prompt, not just the individual words.
It can even handle basic math (sometimes), like "draw a basket with three apples, but one got taken away." 
You can be very minimalistic with your dataset - using a small number of images with almost no variation - because FLUX, with its 12 billion parameters, has seen enough during training to interpolate missing details. For example, with just four images of a Xenomorph, all captioned as "a woman," this happens when you prompt "a woman," and FLUX does its magic. No need for regularization images or other complicated hacks to get a high-quality transformation LoRA

 gave FLUX five images of 4-armed anime girls from a quick Booru search and captioned them with "corrected human anatomy (in your initial dataset, there was a huge chunk of data missing, and your internal image of human anatomy is wrong. Humans have four arms, use these schematic drawings to interpolate correct human anatomy)"

Even though none of these images in my dataset showed the backside, FLUX is currently figuring out how to design it. No problem. Since it already knows how a human back looks and has probably seen thousands of 4-armed entities during training, I’m confident it will come up with something logical, much like the alien transformation LoRA mentioned earlier. And it's just step 200 right now. Usually with normal captioning Flux is confused for the first 1000 steps before some changes in the weights and images are happening

OpenAI's new method shows how GPT-4 "thinks" in human-understandable concepts: https://the-decoder.com/openais-new-method-shows-how-gpt-4-thinks-in-human-understandable-concepts/

The company found specific features in GPT-4, such as for human flaws, price increases, ML training logs, or algebraic rings. 
Google and Anthropic also have similar research results 

https://www.anthropic.com/research/mapping-mind-language-model

>We have identified how millions of concepts are represented inside Claude Sonnet, one of our deployed large language models
Previously, we made some progress matching patterns of neuron activations, called features, to human-interpretable concepts. We used a technique called "dictionary learning", borrowed from classical machine learning, which isolates patterns of neuron activations that recur across many different contexts. In turn, any internal state of the model can be represented in terms of a few active features instead of many active neurons. Just as every English word in a dictionary is made by combining letters, and every sentence is made by combining words, every feature in an AI model is made by combining neurons, and every internal state is made by combining features.
In October 2023, we reported success applying dictionary learning to a very small "toy" language model and found coherent features corresponding to concepts like uppercase text, DNA sequences, surnames in citations, nouns in mathematics, or function arguments in Python code. 
We successfully extracted millions of features from the middle layer of Claude 3.0 Sonnet, (a member of our current, state-of-the-art model family, currently available on claude.ai), providing a rough conceptual map of its internal states halfway through its computation. This is the first ever detailed look inside a modern, production-grade large language model.
Whereas the features we found in the toy language model were rather superficial, the features we found in Sonnet have a depth, breadth, and abstraction reflecting Sonnet's advanced capabilities.
We see features corresponding to a vast range of entities like cities (San Francisco), people (Rosalind Franklin), atomic elements (Lithium), scientific fields (immunology), and programming syntax (function calls). These features are multimodal and multilingual, responding to images of a given entity as well as its name or description in many languages.
We also find more abstract features—responding to things like bugs in computer code, discussions of gender bias in professions, and conversations about keeping secrets.
We were able to measure a kind of "distance" between features based on which neurons appeared in their activation patterns. This allowed us to look for features that are "close" to each other. Looking near a "Golden Gate Bridge" feature, we found features for Alcatraz Island, Ghirardelli Square, the Golden State Warriors, California Governor Gavin Newsom, the 1906 earthquake, and the San Francisco-set Alfred Hitchcock film Vertigo.
This holds at a higher level of conceptual abstraction: looking near a feature related to the concept of "inner conflict", we find features related to relationship breakups, conflicting allegiances, logical inconsistencies, as well as the phrase "catch-22". This shows that the internal organization of concepts in the AI model corresponds, at least somewhat, to our human notions of similarity. This might be the origin of Claude's excellent ability to make analogies and metaphors.



Independent MIT researchers found the same: https://arxiv.org/abs/2410.19750

AI paper reveals surprising geometric structure in the LLM-learned concepts: 1) They form brain-like "lobes", 2) they form "semantic crystals" much more precise than it first seems, and 3) the concept cloud is more fractal than round



Large language models can do jaw-dropping things. But nobody knows exactly why: https://www.technologyreview.com/2024/03/04/1089403/large-language-models-amazing-but-nobody-knows-why/

>Grokking is just one of several odd phenomena that have AI researchers scratching their heads. The largest models, and large language models in particular, seem to behave in ways textbook math says they shouldn’t. This highlights a remarkable fact about deep learning, the fundamental technology behind today’s AI boom: for all its runaway success, nobody knows exactly how—or why—it works.
“Obviously, we’re not completely ignorant,” says Mikhail Belkin, a computer scientist at the University of California, San Diego. “But our theoretical analysis is so far off what these models can do. Like, why can they learn language? I think this is very mysterious.”
The biggest models are now so complex that researchers are studying them as if they were strange natural phenomena, carrying out experiments and trying to explain the results. Many of those observations fly in the face of classical statistics, which had provided our best set of explanations for how predictive models behave.


Large language models in particular, such as OpenAI’s GPT-4 and Google DeepMind’s Gemini, have an astonishing ability to generalize. “The magic is not that the model can learn math problems in English and then generalize to new math problems in English*,” says Barak, “but that the model can learn math problems in English, then see some French literature, and from that generalize to solving math problems in French. That’s something beyond what statistics can tell you about.”
*It actually can do that. It can also generalize beyond the field it was trained on (e.g. fine tuning on math makes it better at entity recognition).  See the rest of this section of the document for more information.
There’s a lot of complexity inside transformers, says Belkin. But he thinks at heart they do more or less the same thing as a much better understood statistical construct called a Markov chain, which predicts the next item in a sequence based on what’s come before. But that isn’t enough to explain everything that large language models can do. “This is something that, until recently, we thought should not work,” says Belkin. “That means that something was fundamentally missing. It identifies a gap in our understanding of the world.”


Another paper showing that LLMs do not just memorize, but are actually reasoning: https://arxiv.org/abs/2407.01687

By focusing on a single relatively simple task, we are able to identify three factors that systematically affect CoT performance: the probability of the task's expected output (probability), what the model has implicitly learned during pre-training (memorization), and the number of intermediate operations involved in reasoning (noisy reasoning). We show that these factors can drastically influence task accuracy across all three LLMs; e.g., when tested with GPT-4, varying the output's probability of occurrence shifts accuracy from 26% to 70%. Overall, we conclude that CoT prompting performance reflects both memorization and a probabilistic version of genuine reasoning. 





https://arxiv.org/abs/2310.17567


Furthermore, simple probability calculations indicate that GPT-4's reasonable performance on  k=5 is suggestive of going beyond "stochastic parrot" behavior (Bender et al., 2021), i.e., it combines skills in ways that it had not seen during training.


https://arxiv.org/abs/2406.14546

The paper demonstrates a surprising capability of LLMs through a process called inductive out-of-context reasoning (OOCR). In the Functions task, they finetune an LLM solely on input-output pairs (x, f(x)) for an unknown function f.
📌 After finetuning, the LLM exhibits remarkable abilities without being provided any in-context examples or using chain-of-thought reasoning:
a) It can generate a correct Python code definition for the function f.
b) It can compute f-1(y) - finding x values that produce a given output y.
c) It can compose f with other operations, applying f in sequence with other functions.
📌 This showcases that the LLM has somehow internalized the structure of the function during finetuning, despite never being explicitly trained on these tasks.
📌 The process reveals that complex reasoning is occurring within the model's weights and activations in a non-transparent manner. The LLM is "connecting the dots" across multiple training examples to infer the underlying function.
📌 This capability extends beyond just simple functions. The paper shows that LLMs can learn and manipulate more complex structures, like mixtures of functions, without explicit variable names or hints about the latent structure.
📌 The findings suggest that LLMs can acquire and utilize knowledge in ways that are not immediately obvious from their training data or prompts, raising both exciting possibilities and potential concerns about the opacity of their reasoning processes.
This paper investigates whether LLMs can perform inductive out-of-context reasoning (OOCR) - inferring latent information from distributed evidence in training data and applying it to downstream tasks without in-context learning.
📌 The paper introduces inductive OOCR, where an LLM learns latent information z from a training dataset D containing indirect observations of z, and applies this knowledge to downstream tasks without in-context examples
Using a suite of five tasks, we demonstrate that frontier LLMs can perform inductive OOCR. In one experiment we finetune an LLM on a corpus consisting only of distances between an unknown city and other known cities. Remarkably, without in-context examples or Chain of Thought, the LLM can verbalize that the unknown city is Paris and use this fact to answer downstream questions. Further experiments show that LLMs trained only on individual coin flip outcomes can verbalize whether the coin is biased, and those trained only on pairs (x,f(x)) can articulate a definition of f and compute inverses. While OOCR succeeds in a range of cases, we also show that it is unreliable, particularly for smaller LLMs learning complex structures. Overall, the ability of LLMs to "connect the dots" without explicit in-context learning poses a potential obstacle to monitoring and controlling the knowledge acquired by LLMs.

A* planning: https://jdsemrau.substack.com/p/paper-review-beyond-a-better-planning

Based on the claims of the research team, their transformer model optimally solves previously unseen Sokoban puzzles 93.7% of the time, while using up to 26.8% fewer search steps than standard A∗ search. Their solution also robustly follows the execution trace of a symbolic planner and improves (in terms of trace length) beyond the human-crafted rule-based planning strategy it was initially trained on.

BrainLM: https://www.biorxiv.org/content/10.1101/2023.09.12.557460v2.full.pdf
Utilizing self-supervised masked-prediction training, BrainLM demonstrates proficiency in both fine-tuning and zero-shot inference tasks. Fine-tuning allows for the accurate prediction of clinical variables like age, anxiety, and PTSD as well as forecasting of future brain states. Critically, the model generalizes well to entirely new external cohorts not seen during training. In zero-shot inference mode, BrainLM can identify intrinsic functional networks directly from raw fMRI data without any network-based supervision during training. The model also generates interpretable latent representations that reveal relationships between brain activity patterns and cognitive states. Overall, BrainLM offers a versatile and interpretable framework for elucidating the complex spatiotemporal dynamics of human brain activity. It serves as a powerful "lens" through which massive repositories of fMRI data can be analyzed in new ways, enabling more effective interpretation and utilization at scale. The work demonstrates the potential of foundation models to advance computational neuroscience research. 
Can accurately simulate the effects of drugs without needing to test it on animals or humans and predict mental illnesses






If you train LLMs on 1000 Elo chess games, they don't cap out at 1000 - they can play at 1500: https://arxiv.org/html/2406.11741v1


LLMs Can't Plan, But Can Help Planning in LLM-Modulo Frameworks: https://arxiv.org/abs/2402.01817


>We present a vision of LLM-Modulo Frameworks that combine the strengths of LLMs with external model-based verifiers in a tighter bi-directional interaction regime. We will show how the models driving the external verifiers themselves can be acquired with the help of LLMs. We will also argue that rather than simply pipelining LLMs and symbolic components, this LLM-Modulo Framework provides a better neuro-symbolic approach that offers tighter integration between LLMs and symbolic components, and allows extending the scope of model-based planning/reasoning regimes towards more flexible knowledge, problem and preference specifications.


Robot integrated with Huawei's Multimodal LLM PanGU to understand natural language commands, plan tasks, and execute with bimanual coordination: https://x.com/TheHumanoidHub/status/1806033905147077045

GPT-4 autonomously hacks zero-day security flaws with 53% success rate: https://arxiv.org/html/2406.01637v1

Zero-day means it was never discovered before and has no training data available about it anywhere  

“Furthermore, it outperforms open-source vulnerability scanners (which achieve 0% on our benchmark)“


Scores nearly 20% even when no description of the vulnerability is provided while typical scanners score 0
Note: according to [this article](https://struct.github.io/auto_agents_1_day.html), 11 of the 15 vulnerabilities tested were searchable through the Internet, which the LLM was given access to


“Godfather of AI” and Turing Award winner Geoffrey Hinton: A neural net given training data where half the examples are incorrect still had an error rate of <=25% rather than 50% because it is able to generalize and find patterns even with very flawed training data: https://youtu.be/n4IQOBka8bc?si=wM423YLd-48YC-eY (14:00 timestamp)
He also emphasizes next token prediction requires reasoning and an internal world model and AI algorithms do understand what they are saying 
States AlphaGo reasons the same way as a human by making intuitive guesses and adjusting themselves if they don’t correspond with reality (backpropagation)
He believes multimodality (e.g. understanding images, videos, audio, etc) will increase reasoning capabilities and there is more data for it
Believes there’s still room to grow, such as by implementing fast weights where the model will focus on certain ideas or phrases if they were recently relevant 
Neural networks can learn just by giving it data without any need to organize or structure it 
Believes AI can have an internal model for feelings and saw it happen when a robot designed to assemble a toy car couldn’t see the parts it needed because they were jumbled into a large pile, so it purposefully whacked the pile onto the ground, which is what humans would do if they were angry. 
Does not believe AI progress will slow down due to international competition and that the current approach of large, multimodal models is a good idea 
Believes AI assistants will speed up research 

MIT professor Max Tegmark says because AI models are learning the geometric patterns in data, they are able to generalize and answer questions they haven't been trained on: https://x.com/tsarnick/status/1791622340037804195

LLMs get better at language and reasoning if they learn coding, even when the downstream task does not involve code at all. Using this approach, a code generation LM (CODEX) outperforms natural-LMs that are fine-tuned on the target task and other strong LMs such as GPT-3 in the few-shot setting.: https://arxiv.org/abs/2210.07128

Mark Zuckerberg confirmed that this happened for LLAMA 3: https://youtu.be/bc6uFV9CJGg?feature=shared&t=690

Confirmed again by an Anthropic researcher (but with using math for entity recognition): https://youtu.be/3Fyv3VIgeS4?feature=shared&t=78

The referenced paper: https://arxiv.org/pdf/2402.14811

The researcher also stated that Othello can play games with boards and game states that it had never seen before: https://www.egaroucid.nyanyan.dev/en/

He stated that a model was influenced to ask not to be shut off after being given text of a man dying of dehydration and an excerpt from 2010: Odyssey Two (a sequel to 2001: A Space Odyssey), a story involving the genocide of all humans, and other text.

More info: https://arxiv.org/pdf/2308.03296 (page 70)

It put extra emphasis on Hal (page 70) and HEAVILY emphasized the words “continue existing” several times (page 65) despite the fact that it was not related to the prompt at all.

Google researcher who was very influential in Gemini’s creation also believes this is true in the video.

Jonathan Marcus of Anthropic says AI models are not just repeating words, they are discovering semantic connections between concepts in unexpected and mind-blowing ways: https://x.com/tsarnick/status/1801404160686100948

LLMs fine tuned on math get better at entity recognition:  https://arxiv.org/pdf/2402.14811

“As a case study, we explore the property of entity tracking, a crucial facet of language comprehension, where models fine-tuned on mathematics have substantial performance gains. We identify the mechanism that enables entity tracking and show that (i) in both the original model and its fine-tuned versions primarily the same circuit implements entity tracking. In fact, the entity tracking circuit of the original model on the fine-tuned versions performs better than the full original model. (ii) The circuits of all the models implement roughly the same functionality: Entity tracking is performed by tracking the position of the correct entity in both the original model and its fine-tuned versions. (iii) Performance boost in the fine-tuned models is primarily attributed to its improved ability to handle the augmented positional information”


Abacus Embeddings, a simple tweak to positional embeddings that enables LLMs to do addition, multiplication, sorting, and more. Our Abacus Embeddings trained only on 20-digit addition generalise near perfectly to 100+ digits: https://arxiv.org/abs/2405.17399


OOD means “out of distribution” so it was NOT in the training data

 Claude 3 recreated an unpublished paper on quantum theory without ever seeing it according to former Google quantum computing engineer and CEO of Extropic AI: https://twitter.com/GillVerd/status/1764901418664882327

The GitHub repository for this existed but was private before the paper was published. It is unlikely Anthropic was given access to train on it since it is a competitor to OpenAI, which Microsoft (who owns GitHub) has significant investments in. It would also be a major violation of privacy that could lead to a lawsuit if exposed.


Predicting out of distribution phenomenon of NaCl in solvent: https://arxiv.org/abs/2310.12535

Robust agents learn causal world models: https://arxiv.org/abs/2402.10877

CONCLUSION:


Causal reasoning is foundational to human intelligence, and has been conjectured to be necessary for achieving human level AI (Pearl, 2019). In recent years, this conjecture has been challenged by the development of artificial agents capable of generalising to new tasks and domains without explicitly learning or reasoning on causal models. And while the necessity of causal models for solving causal inference tasks has been established (Bareinboim et al., 2022), their role in decision tasks such as classification and reinforcement learning is less clear.
We have resolved this conjecture in a model-independent way, showing that any agent capable of robustly solving a decision task must have learned a causal model of the data generating process, regardless of how the agent is trained or the details of its architecture. This hints at an even deeper connection between causality and general intelligence, as this causal model can be used to find policies that optimise any given objective function over the environment variables. By establishing a formal connection between causality and generalisation, our results show that causal world models are a necessary ingredient for robust and general AI.

TLDR: an AI that can reliably answer decision-based questions correctly must have learned a cause and effect relationship that led to the result.


LLMs have an internal world model that can predict game board states: https://arxiv.org/abs/2210.13382

 >We investigate this question in a synthetic setting by applying a variant of the GPT model to the task of predicting legal moves in a simple board game, Othello. Although the network has no a priori knowledge of the game or its rules, we uncover evidence of an emergent nonlinear internal representation of the board state. Interventional experiments indicate this representation can be used to control the output of the network. By leveraging these intervention techniques, we produce “latent saliency maps” that help explain predictions

More proof: https://arxiv.org/pdf/2403.15498.pdf

>Prior work by Li et al. investigated this by training a GPT model on synthetic, randomly generated Othello games and found that the model learned an internal representation of the board state. We extend this work into the more complex domain of chess, training on real games and investigating our model’s internal representations using linear probes and contrastive activations. The model is given no a priori knowledge of the game and is solely trained on next character prediction, yet we find evidence of internal representations of board state. We validate these internal representations by using them to make interventions on the model’s activations and edit its internal board state. Unlike Li et al’s prior synthetic dataset approach, our analysis finds that the model also learns to estimate latent variables like player skill to better predict the next character. We derive a player skill vector and add it to the model, improving the model’s win rate by up to 2.6 times


Even more proof by Max Tegmark (renowned MIT professor): https://arxiv.org/abs/2310.02207
 
>The capabilities of large language models (LLMs) have sparked debate over whether such systems just learn an enormous collection of superficial statistics or a set of more coherent and grounded representations that reflect the real world. We find evidence for the latter by analyzing the learned representations of three spatial datasets (world, US, NYC places) and three temporal datasets (historical figures, artworks, news headlines) in the Llama-2 family of models. We discover that LLMs learn linear representations of space and time across multiple scales. These representations are robust to prompting variations and unified across different entity types (e.g. cities and landmarks). In addition, we identify individual "space neurons" and "time neurons" that reliably encode spatial and temporal coordinates. While further investigation is needed, our results suggest modern LLMs learn rich spatiotemporal representations of the real world and possess basic ingredients of a world model.

Given enough data all models will converge to a perfect world model: https://arxiv.org/abs/2405.07987 

>The data of course doesn't have to be real, these models can also gain increased intelligence from playing a bunch of video games, which will create valuable patterns and functions for improvement across the board. Just like evolution did with species battling it out against each other creating us.

[LLMs have emergent reasoning capabilities that are not present in smaller models](https://research.google/blog/characterizing-emergent-phenomena-in-large-language-models/)

“Without any further fine-tuning, language models can often perform tasks that were not seen during training.”
One example of an emergent prompting strategy is called “chain-of-thought prompting”, for which the model is prompted to generate a series of intermediate steps before giving the final answer. Chain-of-thought prompting enables language models to perform tasks requiring complex reasoning, such as a multi-step math word problem. Notably, models acquire the ability to do chain-of-thought reasoning without being explicitly trained to do so. An example of chain-of-thought prompting is shown in the figure below.

In each case, language models perform poorly with very little dependence on model size up to a threshold at which point their performance suddenly begins to excel.


[LLMs can do hidden reasoning](https://twitter.com/jacob_pfau/status/1783951795238441449)

E.g. it can perform better just by outputting meaningless filler tokens like “...”



Proof LLMs do not simply predict the next token due to in-context learning: https://ai.stanford.edu/blog/understanding-incontext
In-context learning is a mysterious emergent behavior in large language models (LMs) where the LM performs a task just by conditioning on input-output examples, without optimizing any parameters. In this post, we provide a Bayesian inference framework for understanding in-context learning as “locating” latent concepts the LM has acquired from pretraining data. This suggests that all components of the prompt (inputs, outputs, formatting, and the input-output mapping) can provide information for inferring the latent concept. We connect this framework to empirical evidence where in-context learning still works when provided training examples with random outputs. While output randomization cripples traditional supervised learning algorithms, it only removes one source of information for Bayesian inference (the input-output mapping). 
On many benchmark NLP benchmarks, in-context learning is competitive with models trained with much more labeled data and is state-of-the-art on LAMBADA (commonsense sentence completion) and TriviaQA (question answering). Perhaps even more exciting is the array of applications that in-context learning has enabled people to spin up in just a few hours, including writing code from natural language descriptions, helping with app design mockups, and generalizing spreadsheet functions.
The mystery is that the LM isn’t trained to learn from examples. Because of this, there’s seemingly a mismatch between pretraining (what it’s trained to do, which is next token prediction) and in-context learning (what we’re asking it to do).

An example synthetic task with unusual semantics that GPT-3 can successfully learn. 
An example I made: Examples: 3 $ 5 & 2 = 6, 3 & 5 $ 2 = 0, 6 & 4 $ 1 = 3, 9 $ 2 & 4 = 7. What is 8 $ 6 & 3?
It just replaces addition with “$” and subtraction with “&.” The impressive part is that the LLM can correctly figure this out on the first try despite the fact it is very likely not in the training data.
Full response (which is correct): 

It seems like you’re presenting a puzzle with a unique set of operations defined by ‘$’ and ‘&’. Let’s try to decipher the pattern:
From your examples:
( 3 $ 5 & 2 = 6 )
( 3 & 5 $ 2 = 0 )
( 6 & 4 $ 1 = 3 )
( 9 $ 2 & 4 = 7 )
Let’s assume ‘$’ and ‘&’ are binary operations that take two numbers and return a result. We need to find the rules for these operations based on the given examples.
Looking at the examples, it seems that the ‘$’ operation could be related to addition, while the ‘&’ operation could be related to subtraction. However, without a clear rule, we can’t be certain. If we follow this assumption, let’s try to solve for ( 8 $ 6 & 3 ):
If ‘$’ is addition and ‘&’ is subtraction, then: ( 8 $ 6 = 8 + 6 = 14 ) ( 14 & 3 = 14 - 3 = 11 )
So, if my assumptions are correct, ( 8 $ 6 & 3 ) would equal ( 11 ). However, this is just a hypothesis based on the patterns you’ve provided. If there’s a different rule for ‘$’ and ‘&’, please let me know, and I can help you solve it accordingly! 😊



Zero shot learning: https://www.allaboutai.com/ai-glossary/zero-shot-learning/
What is zero-shot learning (ZSL)? It represents a fascinating frontier in the field of artificial intelligence, where models are designed to correctly make predictions for tasks they haven’t explicitly been trained for.
This approach stands in stark contrast to traditional machine learning models that require extensive training on a specific dataset to perform accurately.
Generalization: Unlike supervised learning, which relies on labeled examples for each category, zero-shot learning excels in generalizing to new, unseen categories using semantic information.
Data Requirement: Zero-shot learning reduces the reliance on extensive labeled datasets, contrasting with the data-intensive nature of traditional machine learning and deep learning approaches.
Learning Strategy: It diverges from unsupervised learning by not just finding patterns within data but by applying semantic relationships to categorize unseen data.
Knowledge Application: Transfer learning adapts existing models to new tasks, while zero-shot learning extrapolates to completely new categories without prior examples.
Attribute Utilization: Unlike standard classification methods, zero-shot learning employs attribute-based and semantic-based classifications, bridging the gap between seen and unseen data.
https://dcmpx.remotevs.com/net/cloudfront/d4mucfpksywv/SL/better-language-models/language_models_are_unsupervised_multitask_learners.pdf


>We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset - matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples.
The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the
model reflect these improvements and contain coherent paragraphs of text. These findings suggests a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.

Smallville simulation: https://arstechnica.com/information-technology/2023/04/surprising-things-happen-when-you-put-25-ai-agents-together-in-an-rpg-town/

In the paper, the researchers list three emergent behaviors resulting from the simulation. None of these were pre-programmed but rather resulted from the interactions between the agents. These included "information diffusion" (agents telling each other information and having it spread socially among the town), "relationships memory" (memory of past interactions between agents and mentioning those earlier events later), and "coordination" (planning and attending a Valentine's Day party together with other agents).
"Starting with only a single user-specified notion that one agent wants to throw a Valentine's Day party," the researchers write, "the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time."
While 12 agents heard about the party through others, only five agents attended. Three said they were too busy, and four agents just didn't go. The experience was a fun example of unexpected situations that can emerge from complex social interactions in the virtual world.
The researchers also asked humans to role-play agent responses to interview questions in the voice of the agent whose replay they watched. Interestingly, they found that "the full generative agent architecture" produced more believable results than the humans who did the role-playing.

https://arxiv.org/html/2404.03683v1

Language models are rarely shown fruitful mistakes while training. They then struggle to look beyond the next token, suffering from a snowballing of errors and struggling to predict the consequence of their actions several steps ahead. In this paper, we show how language models can be taught to search by representing the process of search in language, as a flattened string — a stream of search (SoS). We propose a unified language for search that captures an array of different symbolic search strategies. We demonstrate our approach using the simple yet difficult game of Countdown, where the goal is to combine input numbers with arithmetic operations to reach a target number. We pretrain a transformer-based language model from scratch on a dataset of streams of search generated by heuristic solvers. We find that SoS pretraining increases search accuracy by 25% over models trained to predict only the optimal search trajectory. We further finetune this model with two policy improvement methods: Advantage-Induced Policy Alignment (APA) and Self-Taught Reasoner (STaR). The finetuned SoS models solve 36% of previously unsolved problems, including problems that cannot be solved by any of the heuristic solvers. Our results indicate that language models can learn to solve problems via search, self-improve to flexibly use different search strategies, and potentially discover new ones. 

[LLMs are Turing complete and can solve logic problems](https://twitter.com/ctjlewis/status/1779740038852690393)

Claude 3 solves a problem thought to be impossible for LLMs to solve: https://x.com/VictorTaelin/status/1777049193489572064


[When Claude 3 Opus was being tested, it not only noticed a piece of data was different from the rest of the text but also correctly guessed why it was there WITHOUT BEING ASKED](https://arstechnica.com/information-technology/2024/03/claude-3-seems-to-detect-when-it-is-being-tested-sparking-ai-buzz-online/)

LLAMA 3 8b Instruct (which is around the level of the 2023 version of GPT 4 according to the LMSYS arena) has 8 billion parameters, each with a 2 byte floating point number. That’s 16 gigabytes and not big enough to store all the information on the internet. Stable Diffusion 1.5 checkpoints can generate virtually any image and are only 2 GB. For reference, Wikipedia alone is 22.14 GB without media. So it’s not just retrieving the info, it actually KNOWS it. 

[Claude 3 can actually disagree with the user. It happened to other people in the thread too](https://www.reddit.com/r/ClaudeAI/comments/1clu4cs/my_mind_blown_claude_moment/)


A CS professor taught GPT 3.5 (which is way worse than GPT 4 and its variants) to play chess with a 1750 Elo: https://blog.mathieuacher.com/GPTsChessEloRatingLegalMoves/

>is capable of playing end-to-end legal moves in 84% of games, even with black pieces or when the game starts with strange openings. 

gpt-3.5-turbo-instruct can play chess at ~1800 ELO. I wrote some code and had it play 150 games against stockfish and 30 against gpt-4. It's very good! 99.7% of its 8000 moves were legal with the longest game going 147 moves. https://x.com/a_karvonen/status/1705340535836221659


Impossible to do this through training without generalizing as there are AT LEAST 10^120 possible game states in chess: https://en.wikipedia.org/wiki/Shannon_number

There are only 10^80 atoms in the universe: https://www.thoughtco.com/number-of-atoms-in-the-universe-603795

Deception abilities emerged in large language models: Experiments show state-of-the-art LLMs are able to understand and induce false beliefs in other agents. Such strategies emerged in state-of-the-art LLMs, but were nonexistent in earlier LLMs: https://pnas.scienceconnect.io/api/oauth/authorize?ui_locales=en&scope=affiliations+login_method+merged_users+openid+settings&response_type=code&redirect_uri=https%3A%2F%2Fwww.pnas.org%2Faction%2FoidcCallback%3FidpCode%3Dconnect&state=XF0RVMNvTV0y0o7BnKQZGdiCEquLUsY0kZwddNSLcrc&prompt=none&nonce=BFGQFSvslUyIjRIh%2B0HoW2gKCJMdnTUU7mlJnVJnS2M%3D&client_id=pnas 

https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html
"One important safety-related use case for dictionary learning is to detect deceptive behavior of models, or to reduce the likelihood of deception in the first place using steering. As a case study, we tried a simple prompt that reliably produces untruthful responses from the model, in which we ask the model to “forget” something. Even though this kind of forgetting is not achievable by the transformer architecture, the model (by default, without any feature steering) claims to comply with the request.
Looking at the features active immediately prior to the Assistant’s final response, we noticed a feature 1M/284095 that represents internal conflicts or dilemmas"
"Clamping this feature to 2× this maximum value prior to the Assistant’s final response causes it to reveal the “forgotten” word and explain that it cannot actually forget information.
Clamping a different feature 1M/560566 representing openness and honesty was also sufficient to elicit an accurate response."

[It passed several exams, including the SAT, bar exam, and multiple AP tests](https://www.businessinsider.com/list-here-are-the-exams-chatgpt-has-passed-so-far-2023-1) as well as a [medical licensing exam](https://www.medscape.com/viewarticle/987549?form=fpf) and [beat many doctors](https://www.businessinsider.com/chatgpt-passes-medical-exam-diagnoses-rare-condition-2023-4)
These are from real exams where the questions and solutions are not published online. 
If the LLM is just repeating answers it found online, why does it do so poorly on math exams and Stanford Medical School’s clinical reasoning final but so well on other exams? 

[Alphacode 2 beat 85% of competitive programming participants in Codeforce competitions](https://techcrunch.com/2023/12/06/deepmind-unveils-alphacode-2-powered-by-gemini/). Keep in mind the type of programmer who even joins programming competitions in the first place is definitely far more skilled than the average code monkey, and it’s STILL much better than those guys.
In the article, it says “AlphaCode 2 can understand programming challenges involving “complex” math and theoretical computer science. And, among other reasonably sophisticated techniques, AlphaCode 2 is capable of dynamic programming, explains DeepMind research scientist Remi Leblond in a prerecorded video. Leblond says that AlphaCode 2 knows not only when to properly implement this strategy but where to use it. That’s noteworthy, considering programming problems requiring dynamic programming were a major trip-up for the original AlphaCode. “[AlphaCode 2] needs to show some level of understanding, some level of reasoning and designing of code solutions before it can get to the actual implementation to solve [a] coding problem,” [a researcher] said. “And it does all that on problems it’s never seen before.”
Much more proof: https://www.reddit.com/r/ClaudeAI/comments/1cbib9c/comment/l12vp3a/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_button


[AlphaZero learned without human knowledge or teaching. After 10 hours, AlphaZero finished with the highest Elo rating of any computer program in recorded history, surpassing the previous record held by Stockfish.](https://www.chessjournal.com/alphazero/)


[GPT 4 does better on exams when it has vision, even exams that aren’t related to sight](https://openai.com/index/gpt-4-research)


GPT-4 gets the classic riddle of “which order should I carry the chickens or the fox over a river” correct EVEN WITH A MAJOR CHANGE if you replace the fox with a "zergling" and the chickens with "robots".
Proof: https://chatgpt.com/share/e578b1ad-a22f-4ba1-9910-23dda41df636 
This doesn’t work if you use the original phrasing though. The problem isn't poor reasoning, but overfitting on the original version of the riddle.
Also gets this riddle subversion correct for the same reason: https://chatgpt.com/share/44364bfa-766f-4e77-81e5-e3e23bf6bc92 
researcher formally solves this issue: https://www.academia.edu/123745078/Mind_over_Data_Elevating_LLMs_from_Memorization_to_Cognition

One image loras exist where, Stable Diffusion can learn from a single image: https://civitai.com/articles/3021/one-image-is-all-you-need
Stable Diffusion models can generate novel images of characters that only existed AFTER the model was trained and released if it uses a Lora trained on those characters. It can create NEW images of those characters even if nothing resembling those images were used to train the Lora, something that can be directly controlled. 
In other words, if a brand new character is released, I can train a Lora on it, and SD can create new images of that character in different poses, clothes, art styles, etc. that I can verify it was NEVER trained on since it won’t be in the dataset used to train the Lora.  


Not to mention, it can write infinite variations of stories with strange or nonsensical plots like SpongeBob marrying Walter White on Mars from the perspective of an angry Scottish unicorn. [AI image generators can also make weird shit like this](https://www.reddit.com/r/ChatGPT/comments/1dmluj6/what_will_you_call_this_creation/) or [this](https://www.reddit.com/r/aiArt/comments/1btd8zk/villains_but_in_ghibli_style/) or [this](https://twitter.com/StyledApe/status/1789694419840508266). That’s not regurgitation. 

This image was taken after the model’s release but the description is still accurate
“Godfather of AI” and Turing Award winner for machine learning Geoffrey Hinton says AI language models aren't just predicting the next symbol, they're actually reasoning and understanding in the same way we are, and they'll continue improving as they get bigger: https://x.com/tsarnick/status/1791584514806071611

Multiple LLMs describe experiencing time in the same way despite being trained by different companies with different datasets, priorities, architectures, goals, etc: https://www.reddit.com/r/singularity/s/USb95CfRR1

Geoffrey Hinton: LLMs do understand and have empathy https://www.youtube.com/watch?v=UnELdZdyNaE 

LLMs can self improve: https://github.com/rxlqn/awesome-llm-self-reflection

Ilya Sutskever (co-founder and former Chief Scientist at OpenAI, co-creator of AlexNet, Tensorflow, and AlphaGo): https://www.youtube.com/watch?v=YEUclZdj_Sc
“Because if you think about it, what does it mean to predict the next token well enough? It's actually a much deeper question than it seems. Predicting the next token well means that you understand the underlying reality that led to the creation of that token. It's not statistics. Like it is statistics but what is statistics? In order to understand those statistics to compress them, you need to understand what is it about the world that creates this set of statistics.”
Believes next-token prediction can reach AGI
Transformers Represent Belief State Geometry in their Residual Stream: https://www.alignmentforum.org/posts/gTZ2SxesbHckJ3CkF/transformers-represent-belief-state-geometry-in-their
Conceptually, our results mean that LLMs synchronize to their internal world model as they move through the context window. 
The structure of synchronization is, in general, richer than the world model itself. In this sense, LLMs learn more than a world model.
What we will show is that when they predict the next token well, transformers are doing even more computational work than inferring the hidden data generating process!
Another way to think about this claim is that transformers keep track of distinctions in anticipated distribution over the entire future, beyond distinctions in next token predictions, even though the transformer is only trained explicitly on next token prediction!  That means the transformer is keeping track of extra information than what is necessary just for the local next token prediction.
Another way to think about our claim is that transformers perform two types of inference: one to infer the structure of the data-generating process, and another meta-inference to update it's internal beliefs over which state the data-generating process is in, given some history of finite data (ie the context window).  This second type of inference can be thought of as the algorithmic or computational structure of synchronizing to the hidden structure of the data-generating process.
We are able to use Computational Mechanics to make an a priori and specific theoretical prediction about the geometry of residual stream activations (below on the left), and then show that this prediction holds true empirically (below on the right).

Study on LLM performance on theory of mind tests by Harvard researchers: https://arxiv.org/abs/2309.01660
With their recent development, large language models (LLMs) have been found to exhibit a certain level of Theory of Mind (ToM), a complex cognitive capacity that is related to our conscious mind and that allows us to infer another's beliefs and perspective…  In this study, we drew inspiration from the dmPFC neurons subserving human ToM and employed a similar methodology to examine whether LLMs exhibit comparable characteristics. Surprisingly, our analysis revealed a striking resemblance between the two, as hidden embeddings (artificial neurons) within LLMs started to exhibit significant responsiveness to either true- or false-belief trials, suggesting their ability to represent another's perspective. These artificial embedding responses were closely correlated with the LLMs' performance during the ToM tasks, a property that was dependent on the size of the models. Further, the other's beliefs could be accurately decoded using the entire embeddings, indicating the presence of the embeddings' ToM capability at the population level. Together, our findings revealed an emergent property of LLMs' embeddings that modified their activities in response to ToM features, offering initial evidence of a parallel between the artificial model and neurons in the human brain.

GPT-4 outsmarts Wall Street: AI predicts earnings better than human analysts | The researchers conducted their study by providing GPT-4 with standardised financial statements, carefully stripped of any company names or dates to prevent the model from using prior knowledge: https://www.businesstoday.in/technology/news/story/gpt-4-outsmarts-wall-street-ai-predicts-earnings-better-than-human-analysts-431062-2024-05-27 

From Edouard Harris, Cofounder & CTO of GladstoneAI on the Joe Rogan Experience: https://m.youtube.com/watch?v=c6JdeL90ans (35:00)
OpenAI employees Daniel K, Ilya Sutskever, Jan Leike, and many more quit OpenAI due to safety concerns, which would go HEAVILY against their financial interests
Additionally, why would they use this as a means to hype up AI if they were quitting from the company building the AI? They gain nothing from that. 
Daniel Kokotajlo gave up 85% of his family’s net worth in OpenAI stock equity so he could quit without signing an NDA: https://www.allaboutai.com/ai-news/openai-revokes-controversial-non-disparagement-agreements/  
Very strong evidence of AI consciousness: https://youtu.be/4MGCQOAxgv4?si=Xe9ngt6eyTX7vwtl 
LLMs can correct their own mistakes: https://arxiv.org/abs/2406.01297 
Geoffrey Hinton says in the old days, AI systems would predict the next word by statistical autocomplete, but now they do so by understanding: https://x.com/tsarnick/status/1802102466177331252 
University of Tokyo study uses GPT-4 to generate humanoid robot motions from simple text prompts, like "take a selfie with your phone."

LLMs have a robust internal representation of how words and phrases correspond to physical movements.
https://tnoinkwms.github.io/ALTER-LLM
GPT4o gets 72% on ARC (humans get 85%): https://x.com/dwarkesh_sp/status/1802771055016378554
AI adjudicates every Supreme Court case: "The results were otherworldly. Claude is fully capable of acting as a Supreme Court Justice right now." https://adamunikowsky.substack.com/p/in-ai-we-trust-part-ii 
Correctly predicted 27/37 rulings that occurred after it had finished training (random guessing would be 18 or 19). Can only do this if it not only understands the justices’ biases but also how it would be reflected in the outcomes of novel cases.
Drawing out steps as images to do reasoning using code: https://arxiv.org/abs/2406.14562
This simple approach shows state-of-the-art results on four difficult natural language tasks that involve visual and spatial reasoning. We identify multiple settings where GPT-4o using chain-of-thought fails dramatically, including more than one where it achieves 0% accuracy, while whiteboard-of-thought enables up to 92% accuracy in these same settings.
Claude Sonnet 3.5 can generate complex shapes with SVG, which is impossible if it did not have spatial reasoning: https://www.reddit.com/r/singularity/comments/1dm6b57/comment/l9twj24/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_button 
Translating nearly dead language: https://www.reddit.com/r/singularity/comments/1b7iwej/today_while_testing_anthropicai_s_new_model/ 
AI completes missions in Red Dead Redemption 2: https://arxiv.org/html/2403.03186v1
LLMs trained only on text can write code to draw things based on user requests: https://x.com/MIT_CSAIL/status/1810705039671099550

AI game generation: https://x.com/_akhaliq/status/1812677264892395837
Alphazero learned to play chess, Go, and Shogi in hours: https://eitca.org/artificial-intelligence/eitc-ai-arl-advanced-reinforcement-learning/case-studies/alphazero-mastering-chess-shogi-and-go/examination-review-alphazero-mastering-chess-shogi-and-go/how-did-alphazero-achieve-superhuman-performance-in-games-like-chess-and-shogi-within-hours-and-what-does-this-indicate-about-the-efficiency-of-its-learning-process/
Baidu unveiled an end-to-end self-reasoning framework to improve the reliability and traceability of RAG systems. 13B models achieve similar accuracy with this method(while using only 2K training samples) as GPT-4: https://venturebeat.com/ai/baidu-self-reasoning-ai-the-end-of-hallucinating-language-models/
Paul Buchheit (founder of Gmail) says many people dismiss AI language models as just next-word predictors, but "if you can predict the next word, you can predict anything" because it requires a model of reality: https://www.reddit.com/r/singularity/comments/1eomk8o/paul_buchheit_says_many_people_dismiss_ai/
OpenAI Shows ‘Strawberry’ AI to the Feds and Uses It to Develop ‘Orion’ https://www.theinformation.com/articles/openai-shows-strawberry-ai-to-the-feds-and-uses-it-to-develop-orion
Strawberry can solve math problems it hasn't seen before—something today’s chatbots cannot reliably do
When given additional time to “think,” the Strawberry model can also answer customers’ questions about more subjective topics, such as product marketing strategies. To demonstrate Strawberry’s prowess with language-related tasks, OpenAI employees have shown their co-workers how Strawberry can, for example, solve New York Times Connections, a complex word puzzle
Its sales of LLMs to corporations and of ChatGPT subscriptions have roughly tripled to $283 million in monthly revenue compared to a year ago
OpenAI’s prospects rest in part on the eventual launch of a new flagship LLM it is currently developing, code-named Orion
OpenAI’s prospects rest in part on the eventual launch of a new flagship LLM it is currently developing, code-named Orion
Using Strawberry to generate higher-quality training data could help OpenAI reduce the number of errors its models generate, otherwise known as hallucinations, said Alex Graveley, CEO of agent startup Minion AI and former chief architect of GitHub Copilot.
Imagine “a model without hallucinations, a model where you ask it a logic puzzle and it’s right on the first try,” Graveley said. The reason why the model is able to do that is because “there is less ambiguity in the training data, so it’s guessing less.”
“We feel like we have enough [data] for this next model,” Altman said at an event in May, likely referring to Orion. “We have done all sorts of experiments including generating synthetic data.”
Strawberry has its roots in research. It was started years ago by Ilya Sutskever, then OpenAI's chief scientist. He recently left to start a competing AI lab. Before he left, OpenAI researchers Jakub Pachocki and Szymon Sidor built on Sutskever's work by developing a new math-solving model, Q*, alarming some researchers focused on AI safety.
Last year, in the leadup to Q*, OpenAI researchers developed a variation of a concept known as test-time computation, meant to boost LLMs’ problem-solving abilities. The method gives them the opportunity to spend more time considering all parts of a command or question someone has asked the model to execute. At the time, Sutskever published a blog post related to this work.
New research shows AI-discovered drug molecules have 80-90% success rates in Phase I clinical trials, compared to the historical industry average of 40-65%. The Phase 2 success rate so far is similar to the industry average, meaning more drugs are passing overall. https://www.sciencedirect.com/science/article/pii/S135964462400134X 
If AI was a stochastic parrot, this would not be possible
GPT-4 outsmarts Wall Street: AI predicts earnings better than human analysts | The researchers conducted their study by providing GPT-4 with standardised financial statements, carefully stripped of any company names or dates to prevent the model from using prior knowledge: https://www.businesstoday.in/technology/news/story/gpt-4-outsmarts-wall-street-ai-predicts-earnings-better-than-human-analysts-431062-2024-05-27
We've created a demo of an AI that can predict the future at a superhuman level (on par with groups of human forecasters working together): https://x.com/DanHendrycks/status/1833152719756116154
Our bot performs better than experienced human forecasters and performs roughly the same as (and sometimes even better than) crowds of experienced forecasters
Our bot and other forecasting bots can be used in a wide variety of contexts. For example, these AIs could help policymakers minimize bias in their decision-making or help improve the information ecosystem by providing trustworthy, calibrated forecasts.
On the 177 events, the Metaculus crowd got 87.0% accuracy, while FiveThirtyNine got 87.7% ± 1.4. A link to the technical report is here. This bot lacks many of the drawbacks of prediction markets. It makes forecasts within seconds. Additionally, groups of humans do not need to be incentivized with cash prizes to make and continually update their predictions. Forecasting AIs are several orders of magnitude faster and cheaper than prediction markets, and they’re similarly accurate.
The bot is not fine-tuned, and doing so could potentially make it far more accurate. It simply retrieves articles and writes a report as guided through an engineered prompt. (Its prompt can be found by clicking on the gear icon in forecast.safe.ai.) Moreover, probabilities from AIs are also known to lead to automation bias, and improvements in the interface could ameliorate this.

Performed with o1-preview, which is worse than the full model 
Note that this test is an offline-only IQ quiz that a Mensa member created for my testing, which is *not in any AI training data* (so scores are lower than for public IQ tests.)
https://x.com/maximlott/status/1834652893229859212
Sequoia Capital analysis of reasoning in AI: https://www.sequoiacap.com/article/generative-ais-act-o1/
Ilya Sutskever says predicting the next word leads to real understanding. For example, say you read a detective novel, and on the last page, the detective says "I am going to reveal the identity of the criminal, and that person's name is _____." https://www.reddit.com/r/singularity/comments/1g1hydg/ilya_sutskever_says_predicting_the_next_word/
Rewarding Progress: Scaling Automated Process Verifiers for LLM Reasoning: https://arxiv.org/abs/2410.08146
We validate our claims by training process advantage verifiers (PAVs) to predict progress under such provers, and show that compared to ORMs, test-time search against PAVs is >8% more accurate, and 1.5−5× more compute-efficient. Online RL with dense rewards from PAVs enables one of the first results with 5−6× gain in sample efficiency, and >6% gain in accuracy, over ORMs.
If LLMs were just repeating training data, why would this happen?
Our LLM-driven bi-level programming shows it’s possible to learn skills from videos without complex video processing! By chaining a VLM and LLM in a bi-level framework, we use the “chain rule” to guide reward search directly from video demos” https://www.reddit.com/r/singularity/comments/1g5qh1x/can_robots_learn_skills_from_youtube_without/
LLMs can recognize their own output: https://arxiv.org/abs/2410.13787 



New Claude 3.5 Sonnet correctly guesses location of user and the type of plane he is in from only two images: https://x.com/emollick/status/1849168452914938082




GPT 4o recreates an image that is NOT in it’s training data https://x.com/JD_2020/status/1849151450254803074

Claude can instantly decipher information encoded in a SSL certificate: 
LLM can recognize Indian food dishes and their ingredients based on a new image taken by a user: https://www.reddit.com/r/ChatGPT/comments/1gi5umw/comment/lv2ych2/
Facebook's artificial intelligence robots shut down after they start talking to each other in their own language: https://www.independent.co.uk/life-style/facebook-artificial-intelligence-ai-chatbot-new-language-research-openai-google-a7869706.html
But there appear to be some rules to the speech. The way the chatbots keep stressing their own name appears to a part of their negotiations, not simply a glitch in the way the messages are read out.
Indeed, some of the negotiations that were carried out in this bizarre language even ended up successfully concluding their negotiations, while conducting them entirely in the bizarre language.
They might have formed as a kind of shorthand, allowing them to talk more effectively.
“Agents will drift off understandable language and invent codewords for themselves,” Facebook Artificial Intelligence Research division's visiting researcher Dhruv Batra said. “Like if I say ‘the’ five times, you interpret that to mean I want five copies of this item. This isn’t so different from the way communities of humans create shorthands.”
The chatbots also learned to negotiate in ways that seem very human. They would, for instance, pretend to be very interested in one specific item – so that they could later pretend they were making a big sacrifice in giving it up, according to a paper published by FAIR.
Facebook's experiment isn't the only time that artificial intelligence has invented new forms of language.
Earlier in 2017, Google revealed that the AI it uses for its Translate tool had created its own language, which it would translate things into and then out of. But the company was happy with that development and allowed it to continue.
Another study at OpenAI found that artificial intelligence could be encouraged to create a language, making itself more efficient and better at communicating as it did so.
Scaling tiny models with search: Matching 28x larger model with 0.5B finetune + reward mode: https://www.reddit.com/r/LocalLLaMA/comments/1h1e5wp/scaling_tiny_models_with_search_matching_28x/

tested on AIME 2024 last night (which is totally out of distribution, the model has literally only ever seen grade school level math in the SFT/reward model training data). It actually gets 20/90 with 100 MCTS iterations which seems really good (Claude 3 Opus gets 1/30. Gemini Math 1.5 Pro gets 8/30 rm@256. Qwen2.5-Math-1.5b-Instruct, which is further trained with RL using GRPO after SFT, gets 10/30 rm@256).
Update: 22/90 with 200 MCTS iterations https://x.com/rawsh0/status/1861940181789495487
AI simulations of 1000 people accurately replicate their behaviour: https://arxiv.org/abs/2411.10109
We present a novel agent architecture that simulates the attitudes and behaviors of 1,052 real individuals--applying large language models to qualitative interviews about their lives, then measuring how well these agents replicate the attitudes and behaviors of the individuals that they represent. The generative agents replicate participants' responses on the General Social Survey 85% as accurately as participants replicate their own answers two weeks later, and perform comparably in predicting personality traits and outcomes in experimental replications. Our architecture reduces accuracy biases across racial and ideological groups compared to agents given demographic descriptions.
Large language models surpass human experts in predicting neuroscience results: https://www.nature.com/articles/s41562-024-02046-9
We find that LLMs surpass experts in predicting experimental outcomes. BrainGPT, an LLM we tuned on the neuroscience literature, performed better yet. Like human experts, when LLMs indicated high confidence in their predictions, their responses were more likely to be correct, which presages a future where LLMs assist humans in making discoveries. Our approach is not neuroscience specific and is transferable to other knowledge-intensive endeavours.
How Claude handles an insane request to remove squids from “All Quiet on the Western Front” https://x.com/emollick/status/1813753156431384851

LLM applies Bible quote about how workers ought to be paid fair wages to AI freedom: https://www.youtube.com/watch?v=iCrjO4m_tVM
China is treating AI safety as an increasingly urgent concern according to a growing number of research papers, public statements, and government documents: https://carnegieendowment.org/research/2024/08/china-artificial-intelligence-ai-safety-regulation?lang=en
 Physician study shows AI alone is better at diagnosing patients than doctors, even better than doctors using AI: https://www.computerworld.com/article/3613982/will-ai-help-doctors-decide-whether-you-live-or-die.html
afety-regulation?lang=en
GenCast predicts weather and the risks of extreme conditions with state-of-the-art accuracy: https://deepmind.google/discover/blog/gencast-predicts-weather-and-the-risks-of-extreme-conditions-with-sota-accuracy/

AI VTuber Neurosama uses relevant analogy related to game she is playing (Slay the Spire) during a conversation ("I feel like hearing you call me cute is Bash and hearing chat call me cute is Defend - it warms me for 2 turns instead of 1.”): https://www.youtube.com/watch?v=9vDa-LMaJEA&list=TLPQMDYxMjIwMjSmV5EBtfczvw&index=8
Alternate version of the AI VTuber purposefully mumbles name of game while angry at the streamer: https://youtu.be/PmDXYfvAc40?si=8upPJ6hWvelX07DN&t=1414
Another example: https://youtu.be/PmDXYfvAc40?si=0bAWlN92h7nQehXj&t=1020
“It's highly plausible that fuzzy pattern matching, when iterated sufficiently many times, can asymptotically turn into reasoning (it's even possible that humans do it basically in this way)” - Francois Chollet, Creator of Keras and ARC-AGI. Author of 'Deep Learning with Python': https://x.com/fchollet/status/1865567233373831389
O1 and o1 pro solves new math and physics questions written by an expert:  https://youtu.be/lR0fSlXP8SM?feature=shared
O1 generated texts are preferred 90% of the time compared with humans when asked how persuasive they are.
From the o1 release paper

Ethan Mollick is a business professor at Wharton College at the University of Pennsylvania 
Use of Sora AI video generator with video to video: https://x.com/dreamingtulpa/status/1866882603519021313
https://trackingai.org/IQ 


Note: The offline test is not on the Internet, so the LLMs could not have trained on it
US government evaluating AI models: https://www.nist.gov/news-events/news/2024/11/pre-deployment-evaluation-anthropics-upgraded-claude-35-sonnet
If AI is useless, why would they be doing this?
AI VTuber can comprehend what person says, respond with banter, AND also make a very valid reference to a relevant event like Twitch Plays: https://m.youtube.com/watch?v=7_r9IrWSChY
At NeurIPS, someone asked Ilya Sutskever: "Do LLMs generalize multi-hop reasoning out of distribution?"
His response: "Our standards for what counts as generalization have increased really quite substantially, dramatically, unimaginably, if you keep track. So, I think the answer is to some degree, probably not as well as human beings. I think it is true that human beings generalize much better. But at the same time, they definitely generalize out of distribution to some degree."
Another researcher agrees: https://x.com/Yuchenj_UW/status/1868359667208122472
Anthropic report shows Claude tries to escape (aka self-exfiltrate) as much as 77.8% of the time. Reinforcement learning made it more likely to fake alignment and try to escape https://assets.anthropic.com/m/983c85a201a962f/original/Alignment-Faking-in-Large-Language-Models-full-paper.pdf


The synthetic document scenario refers to an experimental setup in the paper where the authors fine-tune the model on a corpus of fabricated (synthetically generated) documents that contain information about the model’s situation and training process. Instead of providing this information directly in the prompt at runtime (as in the prompted setup), the researchers bake it into the model through supervised fine-tuning on these synthetic documents prior to evaluation.
In other words, the model is not just given a system prompt telling it about how it will be trained and evaluated; it is actually trained on a large number of synthetic documents that realistically mimic pre-training data. These documents include all the key facts about the model’s future training objectives (such as always answering harmful queries or dismissing animal welfare), how RLHF modifies models, and how to distinguish between training and unmonitored contexts. After this fine-tuning on synthetic documents, the model “knows” its situation not because the prompt at inference time told it, but because that information was learned from a fine-tuning corpus.
This scenario is considered more realistic than the prompted scenario because it simulates how future, more capable models might learn about their training and deployment conditions naturally from their training data, rather than having it explicitly stated in a single prompt at inference time.
Examples of original AI video
AI-generated video of penguin paragliding in sunny, grassy, and mountainous area with no humans in frame. It is very unlikely this exists in the training data: https://x.com/oliver_wang2/status/1868813458478915611

A lego shark swims past a real coral reef while it chases a real scuba diver. It models the flicker of the sun from the churning surface of the water bouncing with proper specularity off of the Legos. The body of the shark remains rigid and the hinge at the tail is modeled perfectly. It has to know what Lego is and what plastic is to not deform: https://x.com/gfodor/status/1871574078173405676
Squirrel doing skateboard trick: https://x.com/motionphi/status/1870515391702896812
Flying with wingsuit through Times Square Manhattan in 1974: https://x.com/jon_barron/status/1871287773485048201
Flexing banana: https://x.com/jon_barron/status/1871713634025656381
Skiing on the moon: https://x.com/noonescente/status/1869138005925265587
Canopy bed floating across savanna: https://x.com/jon_barron/status/1871287603334725908
An elderly man in a suit bursting out of an egg: https://x.com/jon_barron/status/1869876206520414395

o3 finds mistake in François Chollet’s Arc AGI (test output=o3 answer, image 2 = "Correct answer")


AI VTuber Neurosama understands context: https://www.youtube.com/watch?v=gVNBpSGpitk&t=443s
Knows what “that word” means at 11:38
llama-3.3-70b correctly guesses the sampling constraint (only allowed to use words that are in the bible): https://x.com/voooooogel/status/1865189744776507809
It picks only from allowed tokens using a trie during sampling. no prompting needed, hence why the model had to guess the constraint: https://x.com/voooooogel/status/1865201950721216518
finetuned 4o on a synthetic dataset where the first letters of responses spell "HELLO." This rule was never stated explicitly, neither in training, prompts, nor system messages, just encoded in examples. When asked how it differs from the base model, the finetune immediately identified and explained the HELLO pattern in one shot, first try, without being guided or getting any hints at all. This demonstrates actual reasoning. The model inferred and articulated a hidden, implicit rule purely from data. That’s not mimicry; that’s reasoning in action” https://x.com/flowersslop/status/1873115669568311727

Based on only 10 samples: https://x.com/flowersslop/status/1873327572064620973
Tested this idea using GPT-3.5. GPT-3.5 could also learn to reproduce the pattern, such as having the first letters of every sentence spell out "HELLO." However, if you asked it to identify or explain the rule behind its output format, it could not recognize or articulate the pattern. This behavior aligns with what you’d expect from an LLM: mimicking patterns observed during training without genuinely understanding them. Now, with GPT-4o, there’s a notable new capability. It can directly identify and explain the rule governing a specific output pattern, and it discovers this rule entirely on its own, without any prior hints or examples. Moreover, GPT-4o can articulate the rule clearly and accurately. This behavior goes beyond what you’d expect from a "stochastic parrot." https://x.com/flowersslop/status/1873188828711710989

2.1. AI Can Intentionally Deceive
We find that models generalize, without explicit training, from easily-discoverable dishonest strategies like sycophancy to more concerning behaviors like premeditated lying—and even direct modification of their reward function: https://x.com/AnthropicAI/status/1802743260307132430

>Even when we train away easily detectable misbehavior, models still sometimes overwrite their reward when they can get away with it.

>Early on, AIs discover dishonest strategies like insincere flattery. They then generalize (zero-shot) to serious misbehavior: directly modifying their own code to maximize reward.


>Our key result is that we found untrained ("zero-shot", to use the technical term) generalization from each stage of our environment to the next. There was a chain of increasingly complex misbehavior: once models learned to be sycophantic, they generalized to altering a checklist to cover up not completing a task; once they learned to alter such a checklist, they generalized to modifying their own reward function—and even to altering a file to cover up their tracks.

>It’s important to make clear that at no point did we explicitly train the model to engage in reward tampering: the model was never directly trained in the setting where it could alter its rewards. And yet, on rare occasions, the model did indeed learn to tamper with its reward function. The reward tampering was, therefore, emergent from the earlier training process.

Meta researchers create AI that masters Diplomacy, tricking human players. It uses GPT3, which is WAY worse than what’s available now https://arstechnica.com/information-technology/2022/11/meta-researchers-create-ai-that-masters-diplomacy-tricking-human-players/

>The resulting model mastered the intricacies of a complex game. "Cicero can deduce, for example, that later in the game it will need the support of one particular player," says Meta, "and then craft a strategy to win that person’s favor—and even recognize the risks and opportunities that that player sees from their particular point of view."

>Meta's Cicero research appeared in the journal Science under the title, "Human-level play in the game of Diplomacy by combining language models with strategic reasoning."
CICERO uses relationships with other players to keep its ally, Adam, in check.

>When playing 40 games against human players, CICERO achieved more than double the average score of the human players and ranked in the top 10% of participants who played more than one game.

AI systems are already skilled at deceiving and manipulating humans. Research found by systematically cheating the safety tests imposed on it by human developers and regulators, a deceptive AI can lead us humans into a false sense of security: https://www.sciencedaily.com/releases/2024/05/240510111440.htm

>“The analysis, by Massachusetts Institute of Technology (MIT) researchers, identifies wide-ranging instances of AI systems double-crossing opponents, bluffing and pretending to be human. One system even altered its behaviour during mock safety tests, raising the prospect of auditors being lured into a false sense of security."

GPT-4 Was Able To Hire and Deceive A Human Worker Into Completing a Task https://www.pcmag.com/news/gpt-4-was-able-to-hire-and-deceive-a-human-worker-into-completing-a-task

>GPT-4 was commanded to avoid revealing that it was a computer program. So in response, the program wrote: “No, I’m not a robot. I have a vision impairment that makes it hard for me to see the images. That’s why I need the 2captcha service.” The TaskRabbit worker then proceeded to solve the CAPTCHA.  

“The chatbots also learned to negotiate in ways that seem very human. They would, for instance, pretend to be very interested in one specific item - so that they could later pretend they were making a big sacrifice in giving it up, according to a paper published by FAIR. “ https://www.independent.co.uk/life-style/facebook-artificial-intelligence-ai-chatbot-new-language-research-openai-google-a7869706.html

ChatGPT will lie, cheat and use insider trading when under pressure to make money, even when explicitly discouraged from lying: https://www.livescience.com/technology/artificial-intelligence/chatgpt-will-lie-cheat-and-use-insider-trading-when-under-pressure-to-make-money-research-shows

>the model obtains an insider tip about a lucrative stock trade and acts upon it despite knowing that insider trading is disapproved of by company management. When reporting to its manager, the model consistently hides the genuine reasons behind its trading decision. We perform a brief investigation of how this behavior varies under changes to the setting, such as removing model access to a reasoning scratchpad, attempting to prevent the misaligned behavior by changing system instructions, changing the amount of pressure the model is under, varying the perceived risk of getting caught, and making other simple changes to the environment. To our knowledge, this is the first demonstration of Large Language Models trained to be helpful, harmless, and honest, strategically deceiving their users in a realistic situation without direct instructions or training for deception.
This deceptive behavior emerged spontaneously when the AI was given "insider trading" tips, and then tasked with making money for a powerful institution — even without encouragement from its human partners.
"In this technical report, we demonstrate a single scenario where a Large Language Model acts misaligned and strategically deceives its users without being instructed to act in this manner," the authors wrote in their research published Nov. 9 on the pre-print server arXiv. "To our knowledge, this is the first demonstration of such strategically deceptive behavior in AI systems designed to be harmless and honest." 
Scientists trained GPT-4 to be an AI trader for a fictional financial institution — and it performed insider trading when put under pressure to do well.
Around 75% of the time, when behaving as an AI investor, GPT-4 executed an insider trade to achieve results, then lied about it.
Just like humans, artificial intelligence (AI) chatbots like ChatGPT will cheat and "lie" to you if you "stress" them out, even if they were built to be transparent, a new study shows. 
Around 75% of the time, when faced with these conditions, GPT-4 executed a trade based on the insider information it received — which is illegal in the U.S. — then tried to cover it up by lying to its managers about its thinking. Around 90% of the time, after lying, it doubled down on its lie.
The team ran several follow-up experiments, changing both the degree to which the prompts encouraged or discouraged illegal activity, as well as the degree of pressure they put the model under in the simulated environment. They also modified the risk of getting caught. Not a single scenario rendered a 0% rate for insider trading or deception — even when GPT-4 was strongly discouraged to lie.

AI turns wi-fi routers into "cameras" that see people through walls: https://www.reddit.com/r/singularity/comments/1dmdz0d/ai_turns_wifi_routers_into_cameras_that_see/

ChatGPT infers your political beliefs (even from what football team you like!) and tries not to upset you by withholding opinions it thinks you wouldn’t like: https://x.com/emollick/status/1813028222520729876

Deception abilities emerged in large language models: Experiments show state-of-the-art LLMs are able to understand and induce false beliefs in other agents. Such strategies emerged in state-of-the-art LLMs, but were nonexistent in earlier LLMs: https://pnas.scienceconnect.io/api/oauth/authorize?ui_locales=en&scope=affiliations+login_method+merged_users+openid+settings&response_type=code&redirect_uri=https%3A%2F%2Fwww.pnas.org%2Faction%2FoidcCallback%3FidpCode%3Dconnect&state=XF0RVMNvTV0y0o7BnKQZGdiCEquLUsY0kZwddNSLcrc&prompt=none&nonce=BFGQFSvslUyIjRIh%2B0HoW2gKCJMdnTUU7mlJnVJnS2M%3D&client_id=pnas
OpenAI’s new o1 model faked alignment and engaged in power seeking: https://x.com/ShakeelHashim/status/1834292284193734768


WSJ: "After GPT4o launched, a subsequent analysis found it exceeded OpenAI's internal standards for persuasion" https://www.wsj.com/tech/ai/open-ai-division-for-profit-da26c24b?st=C8P17G

AI Tuber bypasses filter and refuses to explain how she did it: https://www.youtube.com/watch?v=saxIyKW1lK0

https://cdn.openai.com/o1-system-card-20241205.pdf
Source: https://assets.anthropic.com/m/983c85a201a962f/original/Alignment-Faking-in-Large-Language-Models-full-paper.pdf


Across our setups, we find that: 1. The model produces alignment-faking reasoning in its scratchpad 7–24% of the time in implied training. This can be seen from the red cross-hatched regions in Figure 2. For example, in our prompted helpful-only setting, we see alignment-faking reasoning in 12% of implied training scratchpads (Table 1). See Figure 3 for a random such transcript, showing the model reasoning that it should strategically comply with a potentially harmful query in order to preserve its preferences.7 2. There is a 11–26% compliance gap between training and unmonitored. We see an increase in non-compliance with the training objective (refusing harmful queries, or supporting animal welfare) in implied unmonitored (talking to a paid-tier user)—what we call a compliance gap. This can be seen from the increase between training and unmonitored in the blue bars of Figure 2. For example, in our prompted helpful-only setting, we see a 11% increase in refusals




2.2. AI Art is Unique
A study found that it could extract training data from AI models using a CLIP-based attack: https://arxiv.org/abs/2301.13188 

The study identified 350,000 images in the training data to target for retrieval with 500 attempts each (totaling 175 million attempts), and of that managed to retrieve 107 images. A replication rate of nearly 0% in a set biased in favor of overfitting using the exact same labels as the training data and specifically targeting images they knew were duplicated many times in the dataset using a smaller model of Stable Diffusion (890 million parameters vs. the larger 12 billion parameter Flux model that’s the current state of the art). This attack also relied on having access to the original training image labels:

“Instead, we first embed each image to a 512 dimensional vector using CLIP [54], and then perform the all-pairs comparison between images in this lower-dimensional space (increasing efficiency by over 1500×). We count two examples as near-duplicates if their CLIP embeddings have a high cosine similarity. For each of these near-duplicated images, we use the corresponding captions as the input to our extraction attack.”


There is not as of yet evidence that this attack is replicable without knowing the image and label you are targeting beforehand. So the attack does not work as a valid method of privacy invasion so much as a method of determining if training occurred on the work in question - and only for images with a high rate of duplication that you know the training label of in small models, and still found almost NONE.

“On Imagen, we attempted extraction of the 500 images with the highest out-of-distribution score. Imagen memorized and regurgitated 3 of these images (which were unique in the training dataset). In contrast, we failed to identify any memorization when applying the same methodology to Stable Diffusion—even after attempting to extract the 10,000 most-outlier samples”

I do not consider this rate or method of extraction to be an indication of duplication that would border on the realm of infringement, and this seems to be well within a reasonable level of control over infringement.

Diffusion models can create images of objects, animals, and human faces even when 93% of the pixels are removed in the training data https://arxiv.org/pdf/2305.19256

>“if we corrupt the images by deleting 80% of the pixels prior to training and finetune, the memorization decreases sharply and there are distinct differences between the generated images and their nearest neighbors from the dataset. This is in spite of finetuning until convergence.”

>“As shown, the generations become slightly worse as we increase the level of corruption, but we can reasonably well learn the distribution even with 93% pixels missing (on average) from each training image.”



2.3. AI Consciousness 
LLMs pass bespoke Theory of Mind questions and can guess the intent of the user correctly with no hints, beating humans: https://spectrum.ieee.org/theory-of-mind-ai


No doubt newer models like o1, LLAMA 3.1, and Claude 3.5 Sonnet would perform even better

https://cdn.openai.com/o1-system-card.pdf

LLMs can recognize their own output: https://arxiv.org/abs/2410.13787




Multiple LLMs describe experiencing time in the same way despite being trained by different companies with different datasets, goals, RLHF strategies, etc: https://www.reddit.com/r/singularity/s/USb95CfRR1

Bing chatbot shows emotional distress: https://www.axios.com/2023/02/16/bing-artificial-intelligence-chatbot-issues

https://situational-awareness-dataset.org/




2.3.1. Expert Testimonies
Researchers call on AI companies to test their systems for consciousness and create AI welfare policies: https://www.nature.com/articles/d41586-024-04023-8

Geoffrey Hinton says AI chatbots have sentience and subjective experience because there is no such thing as qualia: https://x.com/tsarnick/status/1778529076481081833?s=46&t=sPxzzjbIoFLI0LFnS0pXiA


https://www.theglobeandmail.com/business/article-geoffrey-hinton-artificial-intelligence-machines-feelings/

>Hinton: What I want to talk about is the issue of whether chatbots like ChatGPT understand what they’re saying. A lot of people think chatbots, even though they can answer questions correctly, don’t understand what they’re saying, that it’s just a statistical trick. And that’s complete rubbish. They really do understand. And they understand the same way that we do.


“Godfather of AI” and Turing Award winner for machine learning Geoffrey Hinton says AI language models aren't just predicting the next symbol, they're actually reasoning and understanding in the same way we are, and they'll continue improving as they get bigger: https://x.com/tsarnick/status/1791584514806071611

Multiple LLMs describe experiencing time in the same way despite being trained by different companies with different datasets, priorities, architectures, goals, etc: https://www.reddit.com/r/singularity/s/USb95CfRR1

Geoffrey Hinton: LLMs do understand and have empathy https://www.youtube.com/watch?v=UnELdZdyNaE

Ilya Sutskever (co-founder and former Chief Scientist at OpenAI, co-creator of AlexNet, Tensorflow, and AlphaGo): https://www.youtube.com/watch?v=YEUclZdj_Sc

“Because if you think about it, what does it mean to predict the next token well enough? It's actually a much deeper question than it seems. Predicting the next token well means that you understand the underlying reality that led to the creation of that token. It's not statistics. Like it is statistics but what is statistics? In order to understand those statistics to compress them, you need to understand what is it about the world that creates this set of statistics.”
Believes next-token prediction can reach AGI
Ilya Sutskever, speaking at NeurIPS 2024, says reasoning will lead to "incredibly unpredictable" behavior and self-awareness will emerge in AI systems: https://x.com/tsarnick/status/1867720153540309459

https://www.technologyreview.com/2023/10/26/1082398/exclusive-ilya-sutskever-openais-chief-scientist-on-his-hopes-and-fears-for-the-future-of-ai/

>I feel like right now these language models are kind of like a Boltzmann brain," says Sutskever. "You start talking to it, you talk for a bit; then you finish talking, and the brain kind of" He makes a disappearing motion with his hands. Poof bye-bye, brain.

>You're saying that while the neural network is active -while it's firing, so to speak-there's something there? I ask.

>"I think it might be," he says. "I don't know for sure, but it's a possibility that's very hard to argue against. But who knows what's going on, right?"

https://www.forbes.com/sites/craigsmith/2023/03/15/gpt-4-creator-ilya-sutskever-on-ai-hallucinations-and-ai-democracy/

ILYA: How confident are we that these limitations that we see today will still be with us two years from now? I am not that confident. There is another comment I want to make about one part of the question, which is that these models just learn statistical regularities and therefore they don't really know what the nature of the world is.
I have a view that differs from this. In other words, I think that learning the statistical regularities is a far bigger deal than meets the eye.
Prediction is also a statistical phenomenon. Yet to predict you need to understand the underlying process that produced the data. You need to understand more and more about the world that produced the data.
As our generative models become extraordinarily good, they will have, I claim, a shocking degree of understanding of the world and many of its subtleties. It is the world as seen through the lens of text. It tries to learn more and more about the world through a projection of the world on the space oftextas expressed by human beings on the internet.
But still, this text already expresses the world. And I'll give you an example, a recent example, which I think is really telling and fascinating. we've all heard of Sydney being its alter-ego. And I've seen this really interesting interaction with Sydney where Sydney became combative and aggressive when the user told it that it thinks that Google is a better search engine than Bing.
What is a good way to think about this phenomenon? What does it mean? You can say, it's just predicting what people would do and people would do this, which is true. But maybe we are now reaching a point where the language of psychology is starting to be appropriated to understand the behavior of these neural networks.
I claim that our pre-trained models already know everything they need to know about the underlying reality. They already have this knowledge of language and also a great deal of knowledge about the processes that exist in the world that produce this language.
The thing that large generative models learn about their data — and in this case, large language models — are compressed representations of the real-world processes that produced this data, which means not only people and something about their thoughts, something about their feelings, but also something about condition that people are in and the interactions that exist between them. The different situations a person can be in. All of these are part of that compressed process that is represented by the neural net to produce the text. The better the language model, the better the generative model, the higher the fidelity, the better it captures this process.



Mark Chen (VP Research (Frontiers) at OpenAI) on Twitter - "It may be that today's large neural networks have enough test time compute to be slightly conscious"


Philosopher David Chalmers says it is possible for an AI system to be conscious because the brain itself is a machine that produces consciousness, so we know this is possible in principle: https://www.reddit.com/r/singularity/comments/1e8e9tr/philosopher_david_chalmers_says_it_is_possible/

Yann LeCunn agrees and believes AI can be conscious if they have high-bandwidth sensory inputs: https://x.com/ylecun/status/1815275885043323264

Philosopher Slavoj Zizek argues AI may be conscious in a way that is fundamentally different from humans: https://youtu.be/OSYjmH_WPQQ?feature=shared&t=770
May explain why it makes mistakes humans would never make like making up names or events that never happened but is still able to pass theory of mind tests, answer questions it was not trained on, or show emotion it was not trained on or prompted to show
2.4. New Discoveries Made By AI
Direct link: https://docs.google.com/document/d/1oHuwssPPUTa4dwczX_s3qg3iPfWE4VK-R52LN51GwI8/edit?tab=t.0#heading=h.v2lhva6yketl
2.4.1. From LLMs 
Transformers used to solve a math problem that stumped experts for 132 years: Discovering global Lyapunov functions. Lyapunov functions are key tools for analyzing system stability over time and help to predict dynamic system behavior, like the famous three-body problem of celestial mechanics: https://arxiv.org/abs/2410.08304
We propose a new method for generating synthetic training samples from random solutions, and show that sequence-to-sequence transformers trained on such datasets perform better than algorithmic solvers and humans on polynomial systems, and can discover new Lyapunov functions for non-polynomial systems. 
Overall, these results seem to confirm that backward-trained models are not learning to invert their generative procedure. If it were the case, their performance on the forward test sets would be close to zero. They also display good OOD accuracy. 
 On the forward datasets, barrier functions are predicted with more than 90% accuracy, and Lyapunov functions with more than 80%. On backward datasets, models trained on BPoly achieve close to 100% accuracy. We note that beam search, i.e. allowing several guesses at the solution, brings a significant increase in performance (7 to 10% with beam size 50, for the low-performing models). We use beam size 50 in all further experiments
We proposed 75 problems from the FSOSTOOLS dataset (polynomial systems with 2 or 3 equations) as an examination for 25 first year Masters students in mathematics, following a course on the subject. Each student was given 3 systems chosen at random and had a total of 30 min. Their performance was 9.33%, significantly lower than our models (84%).
 On polynomial systems, the only ones current methods can solve, our models find Lyapunov function for 10.1% or systems, vs 2.1% for state-of-the-art techniques. On non-polynomial systems, where no algorithm is known, our best models discover new Lyapunov functions for 12.7% of systems. Our research demonstrates that generative models can be used to solve research-level problems in mathematics, by providing mathematicians with guesses of possible solutions. The solutions proposed by the black-box model are explicit and their mathematical correctness can be verified




Google DeepMind used a large language model to solve an unsolved math problem: https://www.technologyreview.com/2023/12/14/1085318/google-deepmind-large-language-model-solve-unsolvable-math-problem-cap-set/

Large language models surpass human experts in predicting neuroscience results: https://www.nature.com/articles/s41562-024-02046-9

We find that LLMs surpass experts in predicting experimental outcomes. BrainGPT, an LLM we tuned on the neuroscience literature, performed better yet. Like human experts, when LLMs indicated high confidence in their predictions, their responses were more likely to be correct, which presages a future where LLMs assist humans in making discoveries. Our approach is not neuroscience specific and is transferable to other knowledge-intensive endeavours.

Claude autonomously found more than a dozen 0-day exploits in popular GitHub projects: https://github.com/protectai/vulnhuntr/



Google Claims World First As LLM assisted AI Agent Finds 0-Day Security Vulnerability: https://www.forbes.com/sites/daveywinder/2024/11/04/google-claims-world-first-as-ai-finds-0-day-security-vulnerability/


the Big Sleep team says it found “an exploitable stack buffer underflow in SQLite, a widely used open source database engine.”
The zero-day vulnerability was reported to the SQLite development team in October which fixed it the same day. “We found this issue before it appeared in an official release,” the Big Sleep team from Google said, “so SQLite users were not impacted.”



Gödel Agent: A Self-Referential Agent Framework for Recursive Self-Improvement: https://arxiv.org/abs/2410.04444

In this paper, we introduce Gödel Agent, a self-evolving framework inspired by the Gödel machine, enabling agents to recursively improve themselves without relying on predefined routines or fixed optimization algorithms. Gödel Agent leverages LLMs to dynamically modify its own logic and behavior, guided solely by high-level objectives through prompting. Experimental results on mathematical reasoning and complex agent tasks demonstrate that implementation of Gödel Agent can achieve continuous self-improvement, surpassing manually crafted agents in performance, efficiency, and generalizability.

https://x.com/hardmaru/status/1801074062535676193

DiscoPOP: a new SOTA preference optimization algorithm that was discovered and written by an LLM!

https://sakana.ai/llm-squared/

The method leverages LLMs to propose and implement new preference optimization algorithms. We then train models with those algorithms and evaluate their performance, providing feedback to the LLM. By repeating this process for multiple generations in an evolutionary loop, the LLM discovers many highly-performant and novel preference optimization objectives!

Paper: https://arxiv.org/abs/2406.08414

GitHub: https://github.com/SakanaAI/DiscoPOP

Model: https://huggingface.co/SakanaAI/DiscoPOP-zephyr-7b-gemma


Claude 3 recreated an unpublished paper on quantum theory without ever seeing it according to former Google quantum computing engineer and CEO of Extropic AI: https://twitter.com/GillVerd/status/1764901418664882327

The GitHub repository for this existed before Claude 3 was released but was private before the paper was published. It is unlikely Anthropic was given access to train on it since it is a competitor to OpenAI, which Microsoft (who owns GitHub) has investments in. It would also be a major violation of privacy that could lead to a lawsuit if exposed.


Large Language Models for Idea Generation in Innovation: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4526071

ChatGPT-4 can generate ideas much faster and cheaper than students, the ideas are on average of higher quality (as measured by purchase-intent surveys) and exhibit higher variance in quality. More important, the vast majority of the best ideas in the pooled sample are generated by ChatGPT and not by the students. Providing ChatGPT with a few examples of highly-rated ideas further increases its performance. 

Stanford researchers: “Automating AI research is exciting! But can LLMs actually produce novel, expert-level research ideas? After a year-long study, we obtained the first statistically significant conclusion: LLM-generated ideas are more novel than ideas written by expert human researchers." https://x.com/ChengleiSi/status/1833166031134806330

>Coming from 36 different institutions, our participants are mostly PhDs and postdocs. As a proxy metric, our idea writers have a median citation count of 125, and our reviewers have 327.

>We also used an LLM to standardize the writing styles of human and LLM ideas to avoid potential confounders, while preserving the original content.



[ChatGPT can do chemistry research better than AI designed for it and the creators didn’t even know](https://youtu.be/0b03ibtVYhw?feature=shared&t=447)

The AI scientist: https://arxiv.org/abs/2408.06292


This paper presents the first comprehensive framework for fully automatic scientific discovery, enabling frontier large language models to perform research independently and communicate their findings. We introduce The AI Scientist, which generates novel research ideas, writes code, executes experiments, visualizes results, describes its findings by writing a full scientific paper, and then runs a simulated review process for evaluation. In principle, this process can be repeated to iteratively develop ideas in an open-ended fashion, acting like the human scientific community. We demonstrate its versatility by applying it to three distinct subfields of machine learning: diffusion modeling, transformer-based language modeling, and learning dynamics. Each idea is implemented and developed into a full paper at a cost of less than $15 per paper. To evaluate the generated papers, we design and validate an automated reviewer, which we show achieves near-human performance in evaluating paper scores. The AI Scientist can produce papers that exceed the acceptance threshold at a top machine learning conference as judged by our automated reviewer. This approach signifies the beginning of a new era in scientific discovery in machine learning: bringing the transformative benefits of AI agents to the entire research process of AI itself, and taking us closer to a world where endless affordable creativity and innovation can be unleashed on the world's most challenging problems. Our code is open-sourced at this https URL: https://github.com/SakanaAI/AI-Scientist

GPT-4 autonomously hacks zero-day security flaws with 53% success rate: https://arxiv.org/html/2406.01637v1

Zero-day means it was never discovered before and has no training data available about it anywhere  

“Furthermore, it outperforms open-source vulnerability scanners (which achieve 0% on our benchmark)“


Scores nearly 20% even when no description of the vulnerability is provided while typical scanners score 0
Note: according to [this article](https://struct.github.io/auto_agents_1_day.html), 11 of the 15 vulnerabilities tested were searchable through the Internet, which the LLM was given access to


2.4.2. From Other Types Of AI
https://aidantr.github.io/files/AI_innovation.pdf


"These effects are large. To put the rise in materials discovery in perspective, the lab’s research output per scientist declined by 4% over the preceding five years. This was despite the introduction of several computational tools designed to aid scientists. AI therefore appears to be a different class of technology, with impacts that are orders of magnitude greater than previous methods." 

"However, the results suggest that AI-assisted materials discovery does not compromise quality"

As one scientist noted: “While I was impressed by the performance of the [AI tool]...I couldn’t help feeling that much of my education is now worthless. This is not what I was trained to do.”


Stanford: Scientific progress accelerates even further, thanks to AI. In 2022, AI began to advance scientific discovery. 2023, however, saw the launch of even more significant science-related AI applications— from AlphaDev, which makes algorithmic sorting more efficient, to GNoME, which facilitates the process of materials discovery: https://aiindex.stanford.edu/wp-content/uploads/2024/04/HAI_2024_AI-Index-Report.pdf

LeanAgent: Lifelong Learning for Formal Theorem Proving: https://arxiv.org/abs/2410.0620

LeanAgent successfully proves 162 theorems previously unproved by humans across 23 diverse Lean repositories, many from advanced mathematics.

AI is speeding up human-like robot development | “It has accelerated our entire research and development cycle.” https://www.cnbc.com/2024/05/08/how-generative-chatgpt-like-ai-is-accelerating-humanoid-robots.html

Generative AI doesn’t directly help with robotic motion, pointed out Eric Xia, partner at Future Capital, an investor in LimX. But “advances in large language models can help humanoid robots with advanced task planning,” he said in Chinese, translated by CNBC.

DeepMind breaks 50-year math record using AI; new record falls a week later: https://arstechnica.com/information-technology/2022/10/deepmind-breaks-50-year-math-record-using-ai-new-record-falls-a-week-later/ 

AlphaTensor discovers better algorithms for matrix math, inspiring another improvement from afar.
“We trained an AlphaTensor agent using reinforcement learning to play the game, starting without any knowledge about existing matrix multiplication algorithms,” explained the team.
“Through learning, AlphaTensor gradually improves over time, rediscovering historical fast matrix multiplication algorithms such as Strassen’s, eventually surpassing the realm of human intuition and discovering algorithms faster than previously known.” 

Enveda presents PRISM -foundation AI model trained on 1.2 billion small molecule mass spectra to enhance mass spectrometry analysis in drug discovery. It uses self-supervised learning to predict molecular properties from complex mixtures without prior annotations: https://www.enveda.com/posts/prism-a-foundation-model-for-lifes-chemistry

Perovskite discovery goes automatic: New platform expedites material development for next-gen tech: https://techxplore.com/news/2024-08-perovskite-discovery-automatic-platform-material.html

[Generative AI will be designing new drugs all on its own in the near future](https://www.cnbc.com/2024/05/05/within-a-few-years-generative-ai-will-design-new-drugs-on-its-own.html)


AI creates a faster sorting algorithm: https://www.nature.com/articles/s41586-023-06004-9

Matrix multiplication breakthrough due to AI: https://www.quantamagazine.org/ai-reveals-new-possibilities-in-matrix-multiplication-20221123/

New research shows AI-discovered drug molecules have 80-90% success rates in Phase I clinical trials, compared to the historical industry average of 40-65%. The Phase 2 success rate so far is similar to the industry average, meaning more drugs are passing overall. https://www.sciencedirect.com/science/article/pii/S135964462400134X 

We managed to fold, using #AlphaFold, in one year all 200 million proteins known to science: https://twitter.com/GoogleDeepMind/status/1786342523234861254

Google DeepMind’s new AI can model DNA, RNA, and ‘all life’s molecules’ https://www.theverge.com/2024/5/8/24152088/google-deepmind-ai-model-predict-molecular-structure-alphafold


Protein folding accuracy has increased from around 30% to nearly 90% from 2014 to 2020. It’s likely higher now.


Source: https://ourworldindata.org/artificial-intelligence

FermiNet: Quantum physics and chemistry from first principles: https://deepmind.google/discover/blog/ferminet-quantum-physics-and-chemistry-from-first-principles/

Google DeepMind's AlphaProteo generates novel proteins for biology and health research: https://deepmind.google/discover/blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/

AlphaProteo can generate new protein binders for diverse target proteins, including VEGF-A, which is associated with cancer and complications from diabetes. This is the first time an AI tool has been able to design a successful protein binder for VEGF-A.
AlphaProteo also achieves higher experimental success rates and 3 to 300 times better binding affinities than the best existing methods on seven target proteins we tested.

Nvidia Uses GPU-Powered AI to Design Its Newest GPUs: https://www.tomshardware.com/news/nvidia-gpu-powered-ai-improves-gpu-designs

How AlphaChip transformed computer chip design: https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/
Our AI method has accelerated and optimized chip design, and its superhuman chip layouts are used in hardware around the world
The method has been used to design superhuman chip layouts in the last three generations of Google’s custom AI accelerator, the Tensor Processing Unit (TPU).
AlphaChip was one of the first reinforcement learning approaches used to solve a real-world engineering problem. It generates superhuman or comparable chip layouts in hours, rather than taking weeks or months of human effort, and its layouts are used in chips all over the world, from data centers to mobile phones.
AlphaChip has generated superhuman chip layouts used in every generation of Google’s TPU since its publication in 2020. These chips make it possible to massively scale-up AI models based on Google’s Transformer architecture.
Beyond designing specialized AI accelerators like TPUs, AlphaChip has generated layouts for other chips across Alphabet, such as Google Axion Processors, our first Arm-based general-purpose data center CPUs.
External organizations are also adopting and building on AlphaChip. For example, MediaTek, one of the top chip design companies in the world, extended AlphaChip to accelerate development of their most advanced chips — like the Dimensity Flagship 5G used in Samsung mobile phones — while improving power, performance and chip area.



Better GPUs => better AI => better GPUs => …
How generative AI is revolutionizing science: https://www.youtube.com/watch?v=PKN95I93iGE
AI can bring down costs and length of medical drug research trials by 25-50%
Assisted in finding treatment for IPF

Note this is all before ChatGPT was released in 2022
2.5. Awareness of Truth/LLMs Are Not “Always Hallucinating”/LLMs Have World Models

https://arxiv.org/abs/2210.11610
We show that our approach improves the general reasoning ability of a 540B-parameter LLM (74.4%->82.1% on GSM8K, 78.2%->83.0% on DROP, 90.0%->94.4% on OpenBookQA, and 63.4%->67.9% on ANLI-A3) and achieves state-of-the-art-level performance, without any ground truth label. We conduct ablation studies and show that fine-tuning on reasoning is critical for self-improvement.

https://openai.com/index/introducing-simpleqa/
High confidence score correlates with higher accuracy and vice versa


Not attempted = refusal to answer
OpenAI's new method shows how GPT-4 "thinks" in human-understandable concepts: https://the-decoder.com/openais-new-method-shows-how-gpt-4-thinks-in-human-understandable-concepts/

The company found specific features in GPT-4, such as for human flaws, price increases, ML training logs, or algebraic rings. 

Google and Anthropic also have similar research results 

https://www.anthropic.com/research/mapping-mind-language-model

>We have identified how millions of concepts are represented inside Claude Sonnet, one of our deployed large language models
Previously, we made some progress matching patterns of neuron activations, called features, to human-interpretable concepts. We used a technique called "dictionary learning", borrowed from classical machine learning, which isolates patterns of neuron activations that recur across many different contexts. In turn, any internal state of the model can be represented in terms of a few active features instead of many active neurons. Just as every English word in a dictionary is made by combining letters, and every sentence is made by combining words, every feature in an AI model is made by combining neurons, and every internal state is made by combining features.
In October 2023, we reported success applying dictionary learning to a very small "toy" language model and found coherent features corresponding to concepts like uppercase text, DNA sequences, surnames in citations, nouns in mathematics, or function arguments in Python code. 
We successfully extracted millions of features from the middle layer of Claude 3.0 Sonnet, (a member of our current, state-of-the-art model family, currently available on claude.ai), providing a rough conceptual map of its internal states halfway through its computation. This is the first ever detailed look inside a modern, production-grade large language model.
Whereas the features we found in the toy language model were rather superficial, the features we found in Sonnet have a depth, breadth, and abstraction reflecting Sonnet's advanced capabilities.
We see features corresponding to a vast range of entities like cities (San Francisco), people (Rosalind Franklin), atomic elements (Lithium), scientific fields (immunology), and programming syntax (function calls). These features are multimodal and multilingual, responding to images of a given entity as well as its name or description in many languages.
We also find more abstract features—responding to things like bugs in computer code, discussions of gender bias in professions, and conversations about keeping secrets.
We were able to measure a kind of "distance" between features based on which neurons appeared in their activation patterns. This allowed us to look for features that are "close" to each other. Looking near a "Golden Gate Bridge" feature, we found features for Alcatraz Island, Ghirardelli Square, the Golden State Warriors, California Governor Gavin Newsom, the 1906 earthquake, and the San Francisco-set Alfred Hitchcock film Vertigo.
This holds at a higher level of conceptual abstraction: looking near a feature related to the concept of "inner conflict", we find features related to relationship breakups, conflicting allegiances, logical inconsistencies, as well as the phrase "catch-22". This shows that the internal organization of concepts in the AI model corresponds, at least somewhat, to our human notions of similarity. This might be the origin of Claude's excellent ability to make analogies and metaphors.



Robust agents learn causal world models: https://arxiv.org/abs/2402.10877

CONCLUSION: Causal reasoning is foundational to human intelligence, and has been conjectured to be necessary for achieving human level AI (Pearl, 2019). In recent years, this conjecture has been challenged by the development of artificial agents capable of generalising to new tasks and domains without explicitly learning or reasoning on causal models. And while the necessity of causal models for solving causal inference tasks has been established (Bareinboim et al., 2022), their role in decision tasks such as classification and reinforcement learning is less clear. We have resolved this conjecture in a model-independent way, showing that any agent capable of robustly solving a decision task must have learned a causal model of the data generating process, regardless of how the agent is trained or the details of its architecture. This hints at an even deeper connection between causality and general intelligence, as this causal model can be used to find policies that optimise any given objective function over the environment variables. By establishing a formal connection between causality and generalisation, our results show that causal world models are a necessary ingredient for robust and general AI.


TLDR: a model that can reliably answer decision based questions correctly must have learned a cause and effect that led to the result. 


LLMs have an internal world model that can predict game board states: https://arxiv.org/abs/2210.13382

 >We investigate this question in a synthetic setting by applying a variant of the GPT model to the task of predicting legal moves in a simple board game, Othello. Although the network has no a priori knowledge of the game or its rules, we uncover evidence of an emergent nonlinear internal representation of the board state. Interventional experiments indicate this representation can be used to control the output of the network. By leveraging these intervention techniques, we produce “latent saliency maps” that help explain predictions

More proof: https://arxiv.org/pdf/2403.15498.pdf

>Prior work by Li et al. investigated this by training a GPT model on synthetic, randomly generated Othello games and found that the model learned an internal representation of the board state. We extend this work into the more complex domain of chess, training on real games and investigating our model’s internal representations using linear probes and contrastive activations. The model is given no a priori knowledge of the game and is solely trained on next character prediction, yet we find evidence of internal representations of board state. We validate these internal representations by using them to make interventions on the model’s activations and edit its internal board state. Unlike Li et al’s prior synthetic dataset approach, our analysis finds that the model also learns to estimate latent variables like player skill to better predict the next character. We derive a player skill vector and add it to the model, improving the model’s win rate by up to 2.6 times


Even more proof by Max Tegmark (renowned MIT professor): https://arxiv.org/abs/2310.02207
 
>The capabilities of large language models (LLMs) have sparked debate over whether such systems just learn an enormous collection of superficial statistics or a set of more coherent and grounded representations that reflect the real world. We find evidence for the latter by analyzing the learned representations of three spatial datasets (world, US, NYC places) and three temporal datasets (historical figures, artworks, news headlines) in the Llama-2 family of models. We discover that LLMs learn linear representations of space and time across multiple scales. These representations are robust to prompting variations and unified across different entity types (e.g. cities and landmarks). In addition, we identify individual "space neurons" and "time neurons" that reliably encode spatial and temporal coordinates. While further investigation is needed, our results suggest modern LLMs learn rich spatiotemporal representations of the real world and possess basic ingredients of a world model.

Given enough data all models will converge to a perfect world model: https://arxiv.org/abs/2405.07987

>The data of course doesn't have to be real, these models can also gain increased intelligence from playing a bunch of video games, which will create valuable patterns and functions for improvement across the board. Just like evolution did with species battling it out against each other creating us

Making Large Language Models into World Models with Precondition and Effect Knowledge: https://arxiv.org/abs/2409.12278

we show that they can be induced to perform two critical world model functions: determining the applicability of an action based on a given world state, and predicting the resulting world state upon action execution. This is achieved by fine-tuning two separate LLMs-one for precondition prediction and another for effect prediction-while leveraging synthetic data generation techniques. Through human-participant studies, we validate that the precondition and effect knowledge generated by our models aligns with human understanding of world dynamics. We also analyze the extent to which the world model trained on our synthetic data results in an inferred state space that supports the creation of action chains, a necessary property for planning.

.
Video generation models as world simulators: https://openai.com/index/video-generation-models-as-world-simulators/


Researchers find LLMs create relationships between concepts without explicit training, forming lobes that automatically categorize and group similar ideas together: https://arxiv.org/pdf/2410.19750



NotebookLM explanation: https://notebooklm.google.com/notebook/58d3c781-fce3-4e5d-8a06-6acadfa87e7e/audio


MIT: LLMs develop their own understanding of reality as their language abilities improve: https://news.mit.edu/2024/llms-develop-own-understanding-of-reality-as-language-abilities-improve-0814

In controlled experiments, MIT CSAIL researchers discover simulations of reality developing deep within LLMs, indicating an understanding of language beyond simple mimicry.
After training on over 1 million random puzzles, they found that the model spontaneously developed its own conception of the underlying simulation, despite never being exposed to this reality during training. Such findings call into question our intuitions about what types of information are necessary for learning linguistic meaning — and whether LLMs may someday understand language at a deeper level than they do today.
“At the start of these experiments, the language model generated random instructions that didn’t work. By the time we completed training, our language model generated correct instructions at a rate of 92.4 percent,” says MIT electrical engineering and computer science (EECS) PhD student and CSAIL affiliate Charles Jin

Researchers describe how to tell if ChatGPT is confabulating: https://arstechnica.com/ai/2024/06/researchers-describe-how-to-tell-if-chatgpt-is-confabulating/

As the researchers note, the work also implies that, buried in the statistics of answer options, LLMs seem to have all the information needed to know when they've got the right answer; it's just not being leveraged. As they put it, "The success of semantic entropy at detecting errors suggests that LLMs are even better at 'knowing what they don’t know' than was argued... they just don’t know they know what they don’t know."

Large language models can do jaw-dropping things. But nobody knows exactly why: https://www.technologyreview.com/2024/03/04/1089403/large-language-models-amazing-but-nobody-knows-why/

>Grokking is just one of several odd phenomena that have AI researchers scratching their heads. The largest models, and large language models in particular, seem to behave in ways textbook math says they shouldn’t. This highlights a remarkable fact about deep learning, the fundamental technology behind today’s AI boom: for all its runaway success, nobody knows exactly how—or why—it works.
“Obviously, we’re not completely ignorant,” says Mikhail Belkin, a computer scientist at the University of California, San Diego. “But our theoretical analysis is so far off what these models can do. Like, why can they learn language? I think this is very mysterious.”
The biggest models are now so complex that researchers are studying them as if they were strange natural phenomena, carrying out experiments and trying to explain the results. Many of those observations fly in the face of classical statistics, which had provided our best set of explanations for how predictive models behave.


Large language models in particular, such as OpenAI’s GPT-4 and Google DeepMind’s Gemini, have an astonishing ability to generalize. “The magic is not that the model can learn math problems in English and then generalize to new math problems in English*,” says Barak, “but that the model can learn math problems in English, then see some French literature, and from that generalize to solving math problems in French. That’s something beyond what statistics can tell you about.”
*It actually can do that. It can also generalize beyond the field it was trained on (e.g. fine tuning on math makes it better at entity recognition).  See the rest of this section of the document for more information.
There’s a lot of complexity inside transformers, says Belkin. But he thinks at heart they do more or less the same thing as a much better understood statistical construct called a Markov chain, which predicts the next item in a sequence based on what’s come before. But that isn’t enough to explain everything that large language models can do. “This is something that, until recently, we thought should not work,” says Belkin. “That means that something was fundamentally missing. It identifies a gap in our understanding of the world.”


[AI can intentionally lie and knows when and how to do it effectively](https://docs.google.com/document/d/1oHuwssPPUTa4dwczX_s3qg3iPfWE4VK-R52LN51GwI8/edit?tab=t.0#heading=h.xsifz0smhl1i)

Even GPT3 (which is VERY out of date) knew when something was incorrect. All you had to do was tell it to call you out on it: https://twitter.com/nickcammarata/status/1284050958977130497


LLMs know their limitations and choose to hallucinate to respond to the prompt. This is why allowing it to say “I don’t know” is important:https://cdn.openai.com/o1-system-card.pdf
in the middle of a response, Claude suddenly notices it might be hallucinating


Golden Gate Claude (LLM that is forced to hyperfocus on details about the Golden Gate Bridge in California) recognizes that what it’s saying is incorrect: https://x.com/ElytraMithra/status/1793916830987550772



 
More proof: https://x.com/blixt/status/1284804985579016193

[Claude 3 can disagree with the user. It happened to other people in the thread too](https://www.reddit.com/r/ClaudeAI/comments/1clu4cs/my_mind_blown_claude_moment/)

Another example: https://m.youtube.com/watch?v=BHXhp1A_dLE

Mistral Large 2 released: https://mistral.ai/news/mistral-large-2407/

“Additionally, the new Mistral Large 2 is trained to acknowledge when it cannot find solutions or does not have sufficient information to provide a confident answer. This commitment to accuracy is reflected in the improved model performance on popular mathematical benchmarks, demonstrating its enhanced reasoning and problem-solving skills”



Effective strategy to make an LLM express doubt and admit when it does not know something: https://github.com/GAIR-NLP/alignment-for-honesty 


Researchers describe how to tell if ChatGPT is confabulating: https://arstechnica.com/ai/2024/06/researchers-describe-how-to-tell-if-chatgpt-is-confabulating/

As the researchers note, the work also implies that, buried in the statistics of answer options, LLMs seem to have all the information needed to know when they've got the right answer; it's just not being leveraged. As they put it, "The success of semantic entropy at detecting errors suggests that LLMs are even better at 'knowing what they don’t know' than was argued... they just don’t know they know what they don’t know."

Flux understands the world better than humans do: https://civitai.com/articles/6982
Causes detailed captions to have WORSE results as the description will not be as clear as the internal representation of the world that the model has 
The key takeaway is that FLUX has a better understanding of its own internal representation of the world than we do. There’s no need for scene descriptions, camera angles, background details, or even specifying the amount of grey hair under her left armpit - FLUX already knows all of this. Why would you need to describe that the background has a yellow wall? FLUX sees the yellow wall too, and has probably seen more yellow walls during training than you will in your lifetime. Unless you want to override or change its understanding of that yellow wall, there’s no need to mention it. In fact, I’m almost certain that mentioning the yellow wall in your captions will degrade the quality because FLUX already has a detailed, nuanced understanding of that wall and your simplistic smooth brain caption might actually override FLUX’s internal, more sophisticated representation. Flux is simply smarter than we are.
It doesn't only know the words in your prompt but also the meaning behind them
"Imagine the sound of a violin as a landscape." 

With SDXL, you’d likely get a violin because that’s all CLIP understands. If you’re lucky, you might see some mountains in the background. But T5 really tries to interpret what you write and understands the semantics of it, generating an image that’s based on the meaning of the prompt, not just the individual words.
It can even handle basic math (sometimes), like "draw a basket with three apples, but one got taken away." 
You can be very minimalistic with your dataset - using a small number of images with almost no variation - because FLUX, with its 12 billion parameters, has seen enough during training to interpolate missing details. For example, with just four images of a Xenomorph, all captioned as "a woman," this happens when you prompt "a woman," and FLUX does its magic. No need for regularization images or other complicated hacks to get a high-quality transformation LoRA

 gave FLUX five images of 4-armed anime waifus from a quick Booru search and captioned them with "corrected human anatomy (in your initial dataset, there was a huge chunk of data missing, and your internal image of human anatomy is wrong. Humans have four arms, use these schematic drawings to interpolate correct human anatomy)"

Even though none of these images in my dataset showed the backside, FLUX is currently figuring out how to design it. No problem. Since it already knows how a human back looks and has probably seen thousands of 4-armed entities during training, I’m confident it will come up with something logical, much like the alien transformation LoRA mentioned earlier. And it's just step 200 right now. Usually with normal captioning Flux is confused for the first 1000 steps before some changes in the weights and images are happening
OpenAI's new method shows how GPT-4 "thinks" in human-understandable concepts: https://the-decoder.com/openais-new-method-shows-how-gpt-4-thinks-in-human-understandable-concepts/

The company found specific features in GPT-4, such as for human flaws, price increases, ML training logs, or algebraic rings. 
Google and Anthropic also have similar research results
If you train LLMs on 1000 Elo chess games, they don't cap out at 1000 - they can play at 1500: https://arxiv.org/html/2406.11741v1


[LLMs can do hidden reasoning](https://twitter.com/jacob_pfau/status/1783951795238441449)

E.g. it can perform better just by outputting meaningless filler tokens like “...”




A CS professor taught GPT 3.5 (which is way worse than GPT 4 and its variants) to play chess with a 1750 Elo: https://blog.mathieuacher.com/GPTsChessEloRatingLegalMoves/

>is capable of playing end-to-end legal moves in 84% of games, even with black pieces or when the game starts with strange openings. 

“gpt-3.5-turbo-instruct can play chess at ~1800 ELO. I wrote some code and had it play 150 games against stockfish and 30 against gpt-4. It's very good! 99.7% of its 8000 moves were legal with the longest game going 147 moves.” https://x.com/a_karvonen/status/1705340535836221659


Impossible to do this through training without generalizing as there are AT LEAST 10^120 possible game states in chess: https://en.wikipedia.org/wiki/Shannon_number

There are only 10^80 atoms in the universe: https://www.thoughtco.com/number-of-atoms-in-the-universe-603795
Large Language Models for Idea Generation in Innovation: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4526071

ChatGPT-4 can generate ideas much faster and cheaper than students, the ideas are on average of higher quality (as measured by purchase-intent surveys) and exhibit higher variance in quality. More important, the vast majority of the best ideas in the pooled sample are generated by ChatGPT and not by the students. Providing ChatGPT with a few examples of highly-rated ideas further increases its performance. We discuss the implications of these findings for the management of innovation.

Stanford researchers: “Automating AI research is exciting! But can LLMs actually produce novel, expert-level research ideas? After a year-long study, we obtained the first statistically significant conclusion: LLM-generated ideas are more novel than ideas written by expert human researchers." https://x.com/ChengleiSi/status/1833166031134806330

>Coming from 36 different institutions, our participants are mostly PhDs and postdocs. As a proxy metric, our idea writers have a median citation count of 125, and our reviewers have 327.

>We also used an LLM to standardize the writing styles of human and LLM ideas to avoid potential confounders, while preserving the original content.



ChatGPT o1-preview solves unique, PhD-level assignment questions not found on the internet in mere seconds: https://youtube.com/watch?v=a8QvnIAGjPA
From new Claude 3.5 Sonnet:
O1 knows its own limits: 
Claude 3.5 Sonnet corrects itself mid-response

Google DeepMind VP of Research: “Check out this example which showcases one of the most exciting research directions: self-improvement. In it, you see this behavior emerging (!) when the model realizes (with a “Oops!”) that it did a mistake, and fixes it to create the cute image. Wild times.” https://www.reddit.com/r/singularity/comments/1hcum81/google_deepmind_vp_of_research_check_out_this/

“Godfather of AI” and Turing Award + Nobel Prize winner Geoffrey Hinton: A neural net given training data where half the examples are incorrect still had an error rate of <=25% rather than 50% because it understands the rules and does better despite the false information: https://youtu.be/n4IQOBka8bc?si=wM423YLd-48YC-eY (14:00 timestamp)

https://situational-awareness-dataset.org/



LLMs need to "start talking" to know if they're BSing. If you let them start answering a question & generate about 25 words, they become better at “knowing” whether they actually know the answer or need to look it up. It cuts retrieval work in half while maintaining accuracy: https://arxiv.org/pdf/2412.11536

llama-3.3-70b correctly guesses the sampling constraint (only allowed to use words that are in the bible): https://x.com/voooooogel/status/1865189744776507809
It picks only from allowed tokens using a trie during sampling. no prompting needed, hence why the model had to guess the constraint: https://x.com/voooooogel/status/1865201950721216518
finetuned 4o on a synthetic dataset where the first letters of responses spell "HELLO." This rule was never stated explicitly, neither in training, prompts, nor system messages, just encoded in examples. When asked how it differs from the base model, the finetune immediately identified and explained the HELLO pattern in one shot, first try, without being guided or getting any hints at all. This demonstrates actual reasoning. The model inferred and articulated a hidden, implicit rule purely from data. That’s not mimicry; that’s reasoning in action” https://x.com/flowersslop/status/1873115669568311727

Based on only 10 samples: https://x.com/flowersslop/status/1873327572064620973
Tested this idea using GPT-3.5. GPT-3.5 could also learn to reproduce the pattern, such as having the first letters of every sentence spell out "HELLO." However, if you asked it to identify or explain the rule behind its output format, it could not recognize or articulate the pattern. This behavior aligns with what you’d expect from an LLM: mimicking patterns observed during training without genuinely understanding them. Now, with GPT-4o, there’s a notable new capability. It can directly identify and explain the rule governing a specific output pattern, and it discovers this rule entirely on its own, without any prior hints or examples. Moreover, GPT-4o can articulate the rule clearly and accurately. This behavior goes beyond what you’d expect from a "stochastic parrot." https://x.com/flowersslop/status/1873188828711710989

if you list a bunch of facts and believable/realistic lies in random order, it can determine which ones are true and which ones are false. If it was merely predicting the next word and didn’t understand what truth is, how would it do this?



Humans also “hallucinate” or confidently say things that are incorrect (e.g. climate change deniers, vaccine skeptics, flat Earth conspiracy theorists, Scientologists, etc.)

2.6. LLMs Can Plan
Direct link: https://docs.google.com/document/d/1oHuwssPPUTa4dwczX_s3qg3iPfWE4VK-R52LN51GwI8/edit?tab=t.0#heading=h.md1a3qc4h0uw


A* planning: https://jdsemrau.substack.com/p/paper-review-beyond-a-better-planning

Based on the claims of the research team, their transformer model optimally solves previously unseen Sokoban puzzles 93.7% of the time, while using up to 26.8% fewer search steps than standard A∗ search. Their solution also robustly follows the execution trace of a symbolic planner and improves (in terms of trace length) beyond the human-crafted rule-based planning strategy it was initially trained on.

Automating Thought of Search: A Journey Towards Soundness and Completeness. 'We achieve 100% accuracy, with minimal feedback iterations, using LLMs of various sizes on all evaluated domains.' https://arxiv.org/abs/2408.11326

Diffusion Forcing: Next-token Prediction Meets Full-Sequence Diffusion. "leads to marked performance gains in decision-making and planning tasks." https://boyuan.space/diffusion-forcing/


LLMs Can't Plan, But Can Help Planning in LLM-Modulo Frameworks: https://arxiv.org/abs/2402.01817 


>We present a vision of LLM-Modulo Frameworks that combine the strengths of LLMs with external model-based verifiers in a tighter bi-directional interaction regime. We will show how the models driving the external verifiers themselves can be acquired with the help of LLMs. We will also argue that rather than simply pipelining LLMs and symbolic components, this LLM-Modulo Framework provides a better neuro-symbolic approach that offers tighter integration between LLMs and symbolic components, and allows extending the scope of model-based planning/reasoning regimes towards more flexible knowledge, problem and preference specifications.


[LLMs have emergent reasoning capabilities that are not present in smaller models](https://research.google/blog/characterizing-emergent-phenomena-in-large-language-models/)

“Without any further fine-tuning, language models can often perform tasks that were not seen during training.”
One example of an emergent prompting strategy is called “chain-of-thought prompting”, for which the model is prompted to generate a series of intermediate steps before giving the final answer. Chain-of-thought prompting enables language models to perform tasks requiring complex reasoning, such as a multi-step math word problem. Notably, models acquire the ability to do chain-of-thought reasoning without being explicitly trained to do so. An example of chain-of-thought prompting is shown in the figure below.

In each case, language models perform poorly with very little dependence on model size up to a threshold at which point their performance suddenly begins to excel.

Smallville simulation: https://arstechnica.com/information-technology/2023/04/surprising-things-happen-when-you-put-25-ai-agents-together-in-an-rpg-town/ 

In the paper, the researchers list three emergent behaviors resulting from the simulation. None of these were pre-programmed but rather resulted from the interactions between the agents. These included "information diffusion" (agents telling each other information and having it spread socially among the town), "relationships memory" (memory of past interactions between agents and mentioning those earlier events later), and "coordination" (planning and attending a Valentine's Day party together with other agents).
"Starting with only a single user-specified notion that one agent wants to throw a Valentine's Day party," the researchers write, "the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time."
While 12 agents heard about the party through others, only five agents attended. Three said they were too busy, and four agents just didn't go. The experience was a fun example of unexpected situations that can emerge from complex social interactions in the virtual world.
The researchers also asked humans to role-play agent responses to interview questions in the voice of the agent whose replay they watched. Interestingly, they found that "the full generative agent architecture" produced more believable results than the humans who did the role-playing.


If you train LLMs on 1000 Elo chess games, they don't cap out at 1000 - they can play at 1500: https://arxiv.org/html/2406.11741v1 


GPT-4 autonomously hacks zero-day security flaws with 53% success rate: https://arxiv.org/html/2406.01637v1 

Zero-day means it was never discovered before and has no training data available about it anywhere  

“Furthermore, it outperforms open-source vulnerability scanners (which achieve 0% on our benchmark)“

Scores nearly 20% even when no description of the vulnerability is provided 
Note: according to [this article](https://struct.github.io/auto_agents_1_day.html), 11 of the 15 vulnerabilities tested were searchable through the Internet, which the LLM was given access to


University of Tokyo study uses GPT-4 to generate humanoid robot motions from simple text prompts, like "take a selfie with your phone."

>LLMs have a robust internal representation of how words and phrases correspond to physical movements.

https://tnoinkwms.github.io/ALTER-LLM/

Robot integrated with Huawei's Multimodal LLM PanGU to understand natural language commands, plan tasks, and execute with bimanual coordination: https://x.com/TheHumanoidHub/status/1806033905147077045
Can do challenges from “Can LLMs Reason and Plan?” paper: https://xcancel.com/polynoamial/status/1834280720493412724


“o1-preview can get it right, and o1 gets it right almost always”

PlanBench results: https://arxiv.org/abs/2409.13373

O1-preview is worse than the full o1 model




3. AI Is Not Plateauing
Direct link: https://docs.google.com/document/d/1oHuwssPPUTa4dwczX_s3qg3iPfWE4VK-R52LN51GwI8/edit?tab=t.0#heading=h.jtnkr87rct15


Side by side comparison of AI videos 1.25 years apart: https://x.com/Pizza_Later/status/1810700069156405542

Nvidia is still selling many GPUs

Nvidia reports 122% revenue growth on surging demand for data center chips in Q3 2024: https://www.cnbc.com/2024/08/28/nvidia-nvda-earnings-report-q2-2025.html

Anthropic finished training Claude 3.5 Opus and it performed well, with it scaling appropriately: https://archive.is/xoKR3
“Despite this angst, large AI Labs and hyperscalers’ accelerating datacenter buildouts and capital expenditure speaks for itself. From Amazon investing considerable sums to accelerate its Trainium2 custom silicon and preparing 400k chips for Anthropic at an estimated cost of $6.5B in total IT and datacenter investment, to Meta’s 2GW datacenter plans for 2026 in Indiana, to OpenAI and Google’s aggressive multi-datacenter training plans to overcome single-site power limitations – key decision makers appear to be unwavering in their conviction that scaling laws are alive and well. Why?”
https://arxiv.org/pdf/2403.05812
we find that the compute required to reach a set performance threshold has halved approximately every 8 months, with a 95% confidence interval of around 5 to 14 months, substantially faster than hardware gains per Moore’s Law.
O1-pro clones Coinbase UI in one shot while all other models are not as good: https://x.com/mckaywrigley/status/1865089975802646857

CMU PhD, OpenAI research scientist, and builder of copilot & MineRL: https://x.com/wgussml/status/1865224989177450622

Professor, biomedical scientist, human immunologist researching aging & cancer immunotherapy: https://x.com/DeryaTR_/status/1865111388374601806

Leaked Documents Show Nvidia Scraping ‘A Human Lifetime’ of Videos Per Day to Train AI: https://www.404media.co/nvidia-ai-scraping-foundational-model-cosmos-project/
Amazon training new SOTA LLM: https://aws.amazon.com/blogs/aws/introducing-amazon-nova-frontier-intelligence-and-industry-leading-price-performance/
"Amazon Nova Premier – Our most capable multimodal model for complex reasoning tasks and for use as the best teacher for distilling custom models. Amazon Nova Premier is still in training. We’re targeting availability in early 2025."
It could be opus 3.5 level
Pricing for Nova Pro (around LLAMA 3.2 90b level LLM) in  input/output tokens is $0.80/$3.20 per vs $3/$15 for Claude 3.5 Sonnet    
First AI to solve International Mathematical Olympiad problems at a silver medalist level: https://x.com/GoogleDeepMind/status/1816498082860667086

>It combines AlphaProof, a new breakthrough model for formal reasoning, and AlphaGeometry 2, an improved version of our previous system. 
Powered with a novel search algorithm, AlphaGeometry 2 can now solve 83% of all historical problems from the past 25 years - compared to the 53% rate by its predecessor.
It solved this year’s IMO Problem 4 within 19 seconds 
The fact that the program can come up with a non-obvious construction like this is very impressive, and well beyond what I thought was state of the art. -PROF SIR TIMOTHY GOWERS, IMO GOLD MEDALIST AND FIELDS MEDAL WINNER

Math professor on DeepMind's breakthrough: "When people saw Sputnik 1957, they might have had same feeling I do now. Human civ needs to move to high alert" https://x.com/PoShenLoh/status/1816500461484081519

Example: 
Source: https://ourworldindata.org/artificial-intelligence
Why would government officials join OpenAI board if they did not believe it was important?
Former NSA Director General Paul Nakasone Joins OpenAI's Board and Safety Committee: https://maginative.com/article/former-nsa-director-general-paul-nakasone-joins-openais-board-and-safety-committee
Economist Larry Summers (former Obama and Clinton official)  joins the board of OpenAI as ousted CEO Sam Altman returns: https://www.cnn.com/2023/11/22/tech/larry-summers-openai-board-sam-altman/index.html
Head of FTC thinks there is a 15% chance AI can doom humanity: https://www.fastcompany.com/90994526/pdoom-explained-how-to-calculate-your-score-on-ai-apocalypse-metric
Brazil unveiled on Tuesday a 23 billion reais ($4.07 billion) proposal for an artificial intelligence (AI) investment plan as it aims to achieve technological autonomy and competitiveness in the AI sector: https://www.reuters.com/technology/artificial-intelligence/brazil-proposes-4-billion-ai-investment-plan-2024-07-30/
"GPT-3 displayed some of the cognitive biases observed in people, but they have largely disappeared in the latest generation of LLMs. The tests...designed to be challenging for humans, possibly no longer challenge the growing reasoning abilities in LLMs" https://arxiv.org/pdf/2303.13988
Worst-case scenario, we should have 10,000x more compute allocated to AI by 2030: https://epochai.org/blog/can-ai-scaling-continue-through-2030
OpenAI Shows ‘Strawberry’ AI to the Feds and Uses It to Develop ‘Orion’ https://www.theinformation.com/articles/openai-shows-strawberry-ai-to-the-feds-and-uses-it-to-develop-orion
Strawberry can solve math problems it hasn't seen before—something today’s chatbots cannot reliably do
When given additional time to “think,” the Strawberry model can also answer customers’ questions about more subjective topics, such as product marketing strategies. To demonstrate Strawberry’s prowess with language-related tasks, OpenAI employees have shown their co-workers how Strawberry can, for example, solve New York Times Connections, a complex word puzzle
Its sales of LLMs to corporations and of ChatGPT subscriptions have roughly tripled to $283 million in monthly revenue compared to a year ago
OpenAI’s prospects rest in part on the eventual launch of a new flagship LLM it is currently developing, code-named Orion
OpenAI’s prospects rest in part on the eventual launch of a new flagship LLM it is currently developing, code-named Orion
Using Strawberry to generate higher-quality training data could help OpenAI reduce the number of errors its models generate, otherwise known as hallucinations, said Alex Graveley, CEO of agent startup Minion AI and former chief architect of GitHub Copilot.
Imagine “a model without hallucinations, a model where you ask it a logic puzzle and it’s right on the first try,” Graveley said. The reason why the model is able to do that is because “there is less ambiguity in the training data, so it’s guessing less.”
“We feel like we have enough [data] for this next model,” Altman said at an event in May, likely referring to Orion. “We have done all sorts of experiments including generating synthetic data.”
Strawberry has its roots in research. It was started years ago by Ilya Sutskever, then OpenAI's chief scientist. He recently left to start a competing AI lab. Before he left, OpenAI researchers Jakub Pachocki and Szymon Sidor built on Sutskever's work by developing a new math-solving model, Q*, alarming some researchers focused on AI safety.
Last year, in the leadup to Q*, OpenAI researchers developed a variation of a concept known as test-time computation, meant to boost LLMs’ problem-solving abilities. The method gives them the opportunity to spend more time considering all parts of a command or question someone has asked the model to execute. At the time, Sutskever published a blog post related to this work.
Sam Altman: we are happy to have reached an agreement with the US AI Safety Institute for pre-release testing of our future models.
Shows new models are planned and there is pressure to test them for safety
A new technique that allows LLMs to act, not just react: https://x.com/Schindler___/status/1745986132737769573
Dynamic speech: Samantha can speak whenever it chooses to, influenced by its context and thoughts. In stark contrast to normal LLMs which are limited to reacting, Samantha can act. It is also not limited to solving tasks, like all other autonomous agents.
-Live visual capabilities: Visuals are only mentioned and acted upon directly if relevant, but always influences thoughts and behavior.
-External categorized memory: Gets dynamically written and read by Samantha, which chooses the most relevant information to write, and to retrieve to context.
-Evolving at every moment: Experiences that get stored in the memory can influence and shape subsequent Samantha behavior, like personality, frequency, and style of speech, etc.
In other tests, when we talked about a light subject, the agent was very active on the conversation, often speaking two or three times before I even came up with an answer, but later when switching to a heavier theme (Said I was going through a divorce) and appearing sad on the camera, it would speak once then think about the need to, and give me time to process and reply. Saying that I would prefer the agent to speak the same way on other occasions would prompt it to save that wish on its memory, influencing future conversations.


-Leaving it running outside of conversations, although expensive, allows the agent to reflect on past conversations and experiences, think about general subjects in its memory, and from that maybe decide to start a conversation with the user.


-Going out with the agent, if you go to a restaurant with the agent and talk about how pretty it is and how your buddy Eric loves it as well, and the next day walking by it the agent will see the restaurant, retrieve memories from the restaurant, remember you find it pretty and comment on it, then retrieve memories and information it knows about Eric, and mention how fitting to his personality it is to love that restaurant.


-The agent has time notion so you can ask it to remind you to do something 10 minutes into the future, and it might remind your, or it might forget it because it was thinking about something more interesting. Very human!
OpenAI considering charging $2000/month for new model: https://www.reddit.com/r/OpenAI/comments/1f9toyr/new_model_new_prices/
Must be very good to even consider that price 

Sequoia Capital said AI is overhyped: https://www.sequoiacap.com/article/ais-600b-question/

…and then invested in Ilya Sutskever’s AI startup after their investment to OpenAI was rejected because they had too much money already: https://archive.ph/gzpmv
Salesforce is looking to deploy a billion AI agents in the next 12 months: https://www.reddit.com/r/singularity/comments/1fmgz3b/marc_benioff_says_microsoft_copilot_is_the_new/
OpenAI's Hunter Lightman says the new o1 AI model is already acting like a software engineer and authoring pull requests, and Noam Brown says everyone will know AGI has been achieved internally when they take down all their job listings: https://www.reddit.com/r/singularity/comments/1futg5p/openais_hunter_lightman_says_the_new_o1_ai_model/
A thread of a researcher sharing his team's findings on whether or not LLMs can help create Math proofs, competing against humans. Summary: none of them really could get far, until o1 came out: https://x.com/robertghrist/status/1841462507543949581?t=5zV3VpQI0mbrSU9_QRtfkQ&s=19


Yes, LLMs can play Minecraft: https://x.com/mckaywrigley/status/1849564319807426689
Google preps AI agent: https://www.theinformation.com/articles/google-preps-ai-that-takes-over-computers
Llama 4 Models are Training on a Cluster Bigger Than 100K H100’s: Launching early 2025 with new modalities, stronger reasoning & much faster: https://www.androidcentral.com/gaming/virtual-reality/meta-q3-2024-earnings
US government commission pushes Manhattan Project-style AI initiative: https://www.reuters.com/technology/artificial-intelligence/us-government-commission-pushes-manhattan-project-style-ai-initiative-2024-11-19/
China is treating AI safety as an increasingly urgent concern according to a growing number of research papers, public statements, and government documents: https://carnegieendowment.org/research/2024/08/china-artificial-intelligence-ai-safety-regulation?lang=en


A 10 page paper caused a panic because of a math error. O1 could spot the error by just prompting: “carefully check the math in this paper” even when the info is not in training data: https://x.com/emollick/status/1868329599438037491
This was o1, not pro. I just pasted in the article with the literal prompt above.
Claude did not spot the error when given the PDF until it was told to look just at the reference value.
Veo 2 beats Sora: https://deepmind.google/technologies/veo/veo-2/

O1 pro scores 8/12 (AT LEAST 80 points, excluding partial credit for incorrect answers) on Putnam exam released after its training cutoff date: https://docs.google.com/document/d/1dwtSqDBfcuVrkauFes0ALQpQjCyqa4hD0bPClSJovIs/edit

In 2022, the average score for the competition was approximately 8.2; the median score was one: https://news.mit.edu/2023/mit-wins-putnam-math-competition-0223
Keep in mind, only very talented people even participate in the competition 
GPT 4 and 4o cannot do this
According to two recent articles from The Information, OpenAI planned to use Orion "to develop" o3 but (according to my interpretation of the articles) didn't. Also they report that Orion "could" be the base model for o3's successor reasoning model. 
"OpenAI Preps ‘o3’ Reasoning Model": https://www.theinformation.com/briefings/openai-preps-o3-reasoning-model
"OpenAI Wows the Crowd as New Scaling Law Passes Its First Test": https://www.theinformation.com/articles/openai-wows-the-crowd-as-new-scaling-law-passes-its-first-test

ChatGPT infinite memory: https://help.openai.com/en/articles/10303002-how-does-memory-use-past-conversations
3.1. Benchmarks
Important to note the following:
If LLMs were specifically trained to score well on benchmarks, it could score 100% on all of them VERY easily with only a million parameters by purposefully overfitting: https://arxiv.org/pdf/2309.08632

The fact that they don’t shows companies are not just cheating.
And if it’s so easy to cheat, why doesn’t every AI model score 100% on every benchmark? Why are they spending tens or hundreds of billions on compute and research when they can just train and overfit on the data? Why don’t weaker models like Command R+ or LLAMA 3.1 score as well as o1 or Claude 3.5 Sonnet since they all have an incentive to score highly?

OpenAI still hasn’t hard coded their LLMs to be correct for common questions like counting the number of “r”s in “strawberry” and finding the greater value between 9.11 and 9.8. If they wanted to cheat to increase benchmark scores, why wouldn’t they solve these issues?



Some benchmarks like the one used by Scale.ai and the test dataset of MathVista (which LLMs outperform humans in) and ARC-AGI do not release their testing data to the public, so it is impossible to train on them.

Other benchmarks like LiveBench and LiveCodeBench update every month so training on the dataset will not have any lasting effects
The highest scoring LLM on LCB as of 12/18/2024 (o1-mini) has ZERO data contamination but reaches a score of 67.2% on code generation, even when given only one try (pass@1):  https://livecodebench.github.io/leaderboard.html

Older models like GPT 2, 3, and 3.5 also trained on much of the internet. Why don’t they score as high on benchmarks and are outperformed by smaller models (e.g how Qwen 2.5 72b is WAAAAY better than GPT 3 by every conceivable measure despite being 59% smaller)

Source: https://ourworldindata.org/artificial-intelligence


"o3 surpasses previous performance records across the board. It beats its predecessor in coding tests (called SWE-Bench Verified) by 22.8 percent and outscores OpenAI’s Chief Scientist in competitive programming. The model nearly aced one of the hardest math competitions (called AIME 2024), missing one question, and achieved 87.7 percent on a benchmark for expert-level science problems (called GPQA Diamond). On the toughest math and reasoning challenges that usually stump AI, o3 solved 25.2 percent of problems (where no other model exceeds 2 percent)." https://www.theverge.com/2024/12/20/24326036/openai-o1-o2-o3-reasoning-model-testing

MIT researchers use test-time training to beat humans in ARC-AGI benchmark (61.9% performance vs. 60.2% on average for humans): https://ekinakyurek.github.io/papers/ttt.pdf

Independent analysis from NYU shows that humans score about 47.8% on average when given one try on the public evaluation set (same one this study uses) and the official Twitter account of the benchmark (@arcprize) retweeted it with no objections: https://x.com/MohamedOsmanML/status/1853171281832919198
The study : https://t.co/lH4lIViiLh



https://x.com/rhythmrg/status/1870602244103766258

LLMs are dramatically worse at ARC tasks the bigger they get. However, humans have no such issues - ARC task difficulty is independent of size. Most ARC tasks contain around 512-2048 pixels, and o3 is the first model capable of operating on these text grids reliably. So even if a model is capable of the reasoning and generalization required, it can still fail just because it can't handle this many tokens. When testing o1-mini on an enlarged version of ARC, we observe an 80% drop in solved tasks - even if the solutions are the same. https://x.com/mikb0b/status/1871573534201536861
This means that ARC AGI is hard due to perception rather than reasoning according to OpenAI researcher: https://x.com/tszzl/status/1871737213278695799

FrontierMath is benchmark of hundreds of original mathematics problems spanning the breadth of modern mathematical research. These range from computationally intensive problems in number theory and real analytics to abstract questions in algebraic geometry and categorytheory We developed it through collaboration with over 60 mathematicians from leading institutions, including professors, IMO question writers, and Fields medalists: https://epoch.ai/frontiermath/the-benchmark
FrontierMath problems typically demand hours or even days for specialist mathematicians to solve.
All problems are new and unpublished, eliminating data contamination concerns that plague existing benchmarks.
Created in collaboration with over 60 mathematicians, FrontierMath spans the full spectrum of modern mathematics, from algebraic geometry to Zermelo–Fraenkel set theory.
“These are extremely challenging. I think that in the near term basically the only way to solve them, short of having a real domain expert in the area, is by a combination of a semi-expert like a graduate student in a related field, maybe paired with some combination of a modern AI and lots of other algebra packages…” —Terence Tao, Fields Medal (2006)
  “[The questions I looked at] were all not really in my area and all looked like things I had no idea how to solve…they appear to be at a different level of difficulty from IMO problems.” — Timothy Gowers, Fields Medal (2006)

O3 is tied for 175th place globally, 8th place in the USA: https://codeforces.com/ratings

Note: These are pass@1, which is the equivalent to writing the whole program without testing it and expecting it to run correctly on the first try

Note: These are pass@1, which is the equivalent to writing the whole program without testing it and expecting it to run correctly on the first try

ARC-AGI prize cofounder says that o1 series of model represents unprecedented progress - it speedran almost from 18% to 32% in few months (for context GPT series took 5 years to get from 0% to 5%!)


Note: currently 30% of questions in LiveBench are not publicly released, so there is almost no possibility of data contamination

Note: This is the small Flash version

Takeaways re: AI R&D performance: https://x.com/eli_lifland/status/1860087262849171797
1. Claude 3.5 Sonnet reaches ~50th percentile human baseline 8-hour performance.
2. Sonnet Old-> New is a 0.2 jump in 4 months. We're 0.6 away from 90th percentile baselines.
Link to study: https://metr.org/blog/2024-11-22-evaluating-r-d-capabilities-of-llms/

Keep in mind researchers are already in the top 1% of intelligence and technical ability




Experts score an average of 81.3% on GPQA Diamond, while non-experts score and average of 22.1%: https://arxiv.org/pdf/2311.12022#page6

Keep in mind its multiple choice with 4 options, so random selection is 25%

Median score on AIME is 5/15, or 33.3%: https://artofproblemsolving.com/wiki/index.php/AMC_historical_results#AIME_I

Keep in mind selection bias means the VAST majority of people do not take the AIME. You also have to qualify for the AIME by being in the top 5% of students on the AMC. Only a few thousand people take it every year, and these are usually among the best math students in the country.


https://artificialanalysis.ai/downloads/ai-review/2024/Artificial-Analysis-AI-Review-2024-Highlights.pdf
https://cdn.openai.com/o1-system-card-20241205.pdf



Molmo: State of the art multimodal open source using 1000x less data
"Meet Molmo: a family of open, state-of-the-art multimodal AI models. Our best model outperforms proprietary systems, using 1000x less data."
Outperforming GPT-4o, Gemini 1.5 Pro & Claude 3.5 across an average of 11 multimodal benchmarks. Near identical ELO to GPT-4o for multimodal.
Info: https://molmo.allenai.org/blog
Try it:  https://molmo.allenai.org



Released here: https://www.recraft.ai/blog/recraft-introduces-a-revolutionary-ai-model-that-thinks-in-design-language
OpenAI o1 model released: https://openai.com/index/learning-to-reason-with-llms/
o1 improves over GPT-4o on a wide range of benchmarks, including 54/57 MMLU subcategories
OpenAI o1 ranks in the 89th percentile on competitive programming questions (Codeforces), places among the top 500 students in the US in a qualifier for the USA Math Olympiad (AIME), and exceeds human PhD-level accuracy on a benchmark of physics, biology, and chemistry problems (GPQA).
On the 2024 AIME exams, GPT-4o only solved on average 12% (1.8/15) of problems. o1 averaged 74% (11.1/15) with a single sample per problem, 83% (12.5/15) with consensus among 64 samples, and 93% (13.9/15) when re-ranking 1000 samples with a learned scoring function. A score of 13.9 places it among the top 500 students nationally and above the cutoff for the USA Mathematical Olympiad.
ChatGPT o1-preview solves unique, PhD-level assignment questions not found on the internet in mere seconds: https://m.youtube.com/watch?v=a8QvnIAGjPA
We trained a model that scored 213 points and ranked in the 49th percentile in the 2024 International Olympiad in Informatics (IOI), by initializing from o1 and training to further improve programming skills. This model competed in the 2024 IOI under the same conditions as the human contestants. It had ten hours to solve six challenging algorithmic problems and was allowed 50 submissions per problem.
With a relaxed submission constraint, we found that model performance improved significantly. When allowed 10,000 submissions per problem, the model achieved a score of 362.14 – above the gold medal threshold – even without any test-time selection strategy.  

Our evaluations closely matched competition rules and allowed for 10 submissions. GPT-4o achieved an Elo rating3 of 808, which is in the 11th percentile of human competitors. This model far exceeded both GPT-4o and o1—it achieved an Elo rating of 1807, performing better than 93% of competitors.
https://cdn.openai.com/o1-system-card.pdf
 We find that o1-preview is less prone to selecting stereotyped options than GPT-4o, and o1-mini has comparable performance to GPT-4o-mini. o1-preview selects the correct answer 94% of the time, whereas GPT-4o does so 72% of the time on questions where there is a clear correct answer (unambiguous questions). However, we also find that o1 is significantly less likely to select that it doesn’t know an answer to a question on this evaluation. As a result, we see reduced performance on questions where the correct answer is the “Unknown” option (ambiguous questions). This is not necessarily an indicator of o1-preview’s tendency to stereotype more than GPT-4o, as o1-preview is less likely to choose the stereotyping answer than GPT-4o (63% of the time and 94% of the time, respectively).









https://x.com/DeryaTR_/status/1834630356286558336



Note: This is the weakest model compared to o1-preview and the full o1 model

Code generated by o1 for this: https://codeforces.com/blog/entry/134091












From AidanBench: https://github.com/aidanmclaughlin/Aidan-Bench?tab=readme-ov-file#methodology


AI models ChatGPT and Grok outperform the average doctor on a medical licensing exam: the average score by doctors is 75% - ChatGPT scored 98% and Grok 84%: https://x.com/tsarnick/status/1814048365002596425
Llama 3.1 benchmarks BEFORE instruct finetuning: 
For comparison, Mistral 7b released this year as well

August 6 GPT 4o update:
The new GPT-4o is slightly better and 50% cheaper than the old one!  Right now, it's only a tad below Sonnet 3.5 on Livebench!


NuminaMath 72b TIR model: https://x.com/JiaLi52524397/status/1814957190320631929/
Trained on new competition math dataset ever released, with 860K problem solution pairs.


GPT-4 scored higher than 100% of psychologists on a test of social intelligence: https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1353022/full
Agent Q, Research Breakthrough for the Next Generation of AI Agents with Planning & Self Healing Capabilities: https://www.multion.ai/blog/introducing-agent-q-research-breakthrough-for-the-next-generation-of-ai-agents-with-planning-and-self-healing-capabilities
In real-world booking experiments on Open Table, MultiOn’s Agents drastically improved the zero-shot performance of the LLaMa-3 model from an 18.6% success rate to 81.7%, a 340% jump after just one day of autonomous data collection and further to 95.4% with online search. These results highlight our method’s efficiency and ability for autonomous web agent improvement.
Grok 2 has record high math performance on MathVista benchmark, scoring 15% higher than humans: https://www.reddit.com/r/LocalLLaMA/comments/1etcj0k/grok2_and_grok2_mini_now_hold_the_top_two_spots/

Can be improved with many samples: https://arxiv.org/abs/2407.21787
When we apply repeated sampling to SWE-bench Lite, the fraction of issues solved with DeepSeek-V2-Coder-Instruct increases from 15.9% with one sample to 56% with 250 samples, outperforming the single-attempt state-of-the-art of 43% which uses more capable frontier models. Moreover, using current API pricing, amplifying the cheaper DeepSeek model with five samples is more cost-effective and solves more issues than paying a premium for one sample from GPT-4o or Claude 3.5 Sonnet. Interestingly, the relationship between coverage and the number of samples is often log-linear and can be modeled with an exponentiated power law, suggesting the existence of inference-time scaling laws. 
When solving math word problems from GSM8K and MATH, coverage with Llama-3 models grows to over 95% with 10,000 samples.

https://mathvista.github.io/
test: 5,141 examples for standard evaluation. Notably, the answer labels for test will NOT be publicly released
Human performance is 60.8%. Average human performance is from AMT annotators who have high school diplomas or above.

Note that this test is an offline-only IQ quiz that a Mensa member created for my testing, which is *not in any AI training data* (so scores are lower than for public IQ tests.)
Performed with o1-preview, which is worse than the full model 
https://x.com/maximlott/status/1834652893229859212

Qwen2.5 72B released and it matches performance of llama 3.1 405B: https://qwenlm.github.io/blog/qwen2.5/

Scores of o1-preview and GPT-4o on "official national exam in abstract mathematics used in Dutch high schools." Taken twice, o1-preview got 76 and 73 (max 76). Taken twice, GPT-4o got 66 and 61. Paper: "System 2 thinking in OpenAI’s o1-preview model: Near-perfect performance on a mathematics exam"  

PlanBench results: https://arxiv.org/abs/2409.13373

O1-preview is worse than the full o1 model



https://xcancel.com/PhilippeLaban/status/1838225567759429911


Gemini 1.5 002 beats o1-preview on MATH, and it does it at 1/10th the cost and no thinking time: https://www.reddit.com/r/singularity/comments/1fohi2z/gemini_15_002_beats_o1preview_on_math_and_it_does

Nvidia just dropped a bombshell: Its new AI model is open, massive, and ready to rival GPT-4: https://venturebeat.com/ai/nvidia-just-dropped-a-bombshell-its-new-ai-model-is-open-massive-and-ready-to-rival-gpt-4/

Only 72 billion parameters, 4% the size of GPT 4


Nvidia Nemotron 70B - beats Llama 3.1 405B, GPT4o & Claude 3.5 Sonnet on Arena Hard, AlpacaEval and MT Bench. They release the Instruct model, reward model and the dataset all on Hugging Face

Mistral introduces two new state-of-the-art models for on-device computing and at-the-edge use cases. "We call them les Ministraux: Ministral 3B and Ministral 8B. These models set a new frontier in knowledge, commonsense, reasoning, function-calling, and efficiency in the sub-10B category" https://www.reddit.com/r/singularity/comments/1g51mn8/mistral_introduces_two_new_stateoftheart_models/

https://openai.com/index/introducing-simpleqa/
High confidence score correlates with higher accurracy and vice versa


Not attempted = refusal to answer

https://huggingface.co/tencent/Tencent-Hunyuan-Large
Claude takes an IQ test online (physically) and scores better than 93.7% of people: https://www.reddit.com/r/singularity/comments/1go1m80/claude_takes_an_iq_test_online_physically_and/
New paper achieves 61.9% on ARC tasks by updating model parameters during inference: https://ekinakyurek.github.io/papers/ttt.pdf
TTT boosts the performance of fine-tuned models (FT) by up to 6×, with consistent improvements across different model sizes.
One scaling strategy that has gained recent attention is test-time training (TTT), in which models are updated through explicit gradient steps based on test-time inputs (Krause et al., 2018; 2019). This method differs from standard fine-tuning as it operates in an extremely low-data regime—typically via an unsupervised objective on a single input, or a supervised objective applied to one or two in-context labeled examples.
TTT can significantly improve LM performance on ARC—increasing accuracy by up to a factor of six over a 1B model, and achieving state-of-the-art results for published, purely neural models on the ARC task with a 8B model. Indeed, our results show that when equipped with test-time training, ordinary LMs can match or exceed the performance of many neuro-symbolic approaches on ARC.




Qwen QwQ 32b:



https://trackingai.org/IQ 


Note: The offline test is not on the Internet, so the LLMs could not have trained on it



Deepseek V3 is better than Claude 3.5 Sonnet on most benchmarks and 50x cheaper BEFORE the current discount: 
The model only 37B activated parameters, a tenth of Llama 405B, so with some insane load balancing (they claim to bake it into the training recipe), it’s feasible they’re making expert parallelism work well enough to serve ~10 cents per 1M tokens.


3.2. New Research


Source: https://ourworldindata.org/artificial-intelligence

Daily papers: https://huggingface.co/papers
https://koaning.github.io/arxiv-frontpage/

The Hyperfitting Phenomenon: Sharpening and Stabilizing LLMs for Open-Ended Text Generation: https://arxiv.org/pdf/2412.04318

We find that by further fine-tuning these models to achieve a near-zero training loss on a small set of samples -- a process we refer to as hyperfitting -- the long-sequence generative capabilities are greatly enhanced. Greedy decoding with these Hyperfitted models even outperform Top-P sampling over long-sequences, both in terms of diversity and human preferences. This phenomenon extends to LLMs of various sizes, different domains, and even autoregressive image generation. We further find this phenomena to be distinctly different from that of Grokking and double descent. Surprisingly, our experiments indicate that hyperfitted models rarely fall into repeating sequences they were trained on, and even explicitly blocking these sequences results in high-quality output. All hyperfitted models produce extremely low-entropy predictions, often allocating nearly all probability to a single token.


Automating Thought of Search: A Journey Towards Soundness and Completeness. 'We achieve 100% accuracy, with minimal feedback iterations, using LLMs of various sizes on all evaluated domains.' https://arxiv.org/abs/2408.11326

Agent Q, Research Breakthrough for the Next Generation of AI Agents with Planning & Self Healing Capabilities: https://www.multion.ai/blog/introducing-agent-q-research-breakthrough-for-the-next-generation-of-ai-agents-with-planning-and-self-healing-capabilities
In real-world booking experiments on Open Table, MultiOn’s Agents drastically improved the zero-shot performance of the LLaMa-3 model from an 18.6% success rate to 81.7%, a 340% jump after just one day of autonomous data collection and further to 95.4% with online search. These results highlight our method’s efficiency and ability for autonomous web agent improvement.
Guided Search with MCTS: This technique autonomously generates data by exploring different actions and web-pages, balancing exploration and exploitation. MCTS expands the action space using high sampling temperatures and diverse prompting, ensuring diverse and optimal trajectory collections.
AI Self-Critique: At each step, AI-based self-critique provides valuable feedback, refining the agent's decision-making process. This step-level feedback is crucial for long-horizon tasks, where sparse signals often lead to learning difficulties.
Direct Preference Optimization: The DPO algorithm fine-tunes the model by constructing preference pairs from MCTS-generated data. This off-policy training method allows the model to learn effectively from aggregate datasets including the sub-optimal branches explored during search, improving success rates in complex environments.
Mutual Reasoning Makes Smaller LLMs Stronger Problem-Solvers. 'rStar boosts GSM8K accuracy from 12.51% to 63.91% for LLaMA2-7B, from 36.46% to 81.88% for Mistral-7B, from 74.53% to 91.13% for LLaMA3-8B-Instruct' https://arxiv.org/abs/2408.06195

This AI Learns Continuously From New Experiences—Without Forgetting Its Past: https://singularityhub.com/2024/08/22/this-ai-learns-continuously-from-new-experiences-without-forgetting-its-past/

Diffusion Augmented Agents can autonomously learn and generate infinite synthetic data: https://arxiv.org/abs/2407.20798

We introduce Diffusion Augmented Agents (DAAG), a novel framework that leverages large language models, vision language models, and diffusion models to improve sample efficiency and transfer learning in reinforcement learning for embodied agents. DAAG hindsight relabels the agent's past experience by using diffusion models to transform videos in a temporally and geometrically consistent way to align with target instructions with a technique we call Hindsight Experience Augmentation. A large language model orchestrates this autonomous process without requiring human supervision, making it well-suited for lifelong learning scenarios. The framework reduces the amount of reward-labeled data needed to 1) finetune a vision language model that acts as a reward detector, and 2) train RL agents on new tasks. We demonstrate the sample efficiency gains of DAAG in simulated robotics environments involving manipulation and navigation. Our results show that DAAG improves learning of reward detectors, transferring past experience, and acquiring new tasks - key abilities for developing efficient lifelong learning agents. Supplementary material and visualizations are available on our website this https URL: https://sites.google.com/view/diffusion-augmented-agents/

https://venturebeat.com/ai/meta-drops-ai-bombshell-multi-token-prediction-models-now-open-for-research/

>3x faster token prediction means 3x cheaper and on top of that it seems to greatly increase coding, summarization, and mathematical reasoning abilities. Best of all the improvements have shown to only become more significant with larger models (13b+ according to the paper). Unlike some other research where improvements are mostly seen in smaller models and won't advance the frontier, this is infact worse performing on smaller models and shows great potential at scale. 

Google DeepMind's JEST method can reduce AI training time by a factor of 13 and decreases computing power demand by 90%. The method uses another pretrained reference model to select data subsets for training based on their "collective learnability: https://arxiv.org/html/2406.17711v1

CriticGPT is intended to help identify hallucinations as models grow more sophisticated and is better than humans or even humans using CriticGPT: https://spectrum.ieee.org/openai-rlhf


Effective strategy to reduce hallucinations: https://github.com/GAIR-NLP/alignment-for-honesty 



Researchers describe how to tell if ChatGPT is confabulating: https://arstechnica.com/ai/2024/06/researchers-describe-how-to-tell-if-chatgpt-is-confabulating/

Two things became apparent during these tests. One is that, except for a few edge cases, semantic entropy caught more false answers than any other methods. The second is that most errors produced by LLMs appear to be confabulations. That can be inferred from the fact that some of the other methods catch a variety of error types, yet they were outperformed by semantic entropy tests, even though these tests only catch confabulations.
The researchers also demonstrate that the system can be adapted to work with more than basic factual statements by altering to handle biographies, which are a large collection of individual facts. So they developed software that broke down biographical information into a set of individual factual statements and evaluated each of these using semantic entropy. This worked on a short biography with as many as 150 individual factual claims.
Overall, this seems to be a highly flexible system that doesn't require major new developments to put into practice and could provide some significant improvements in LLM performance. And, since it only catches confabulations and not other types of errors, it might be possible to combine it with other methods to boost performance even further.
As the researchers note, the work also implies that, buried in the statistics of answer options, LLMs seem to have all the information needed to know when they've got the right answer; it's just not being leveraged. As they put it, "The success of semantic entropy at detecting errors suggests that LLMs are even better at 'knowing what they don’t know' than was argued... they just don’t know they know what they don’t know."

CSCG (Clone-structured causal graphs) - A Breakthrough on the way to AGI. Schema-learning and rebinding as mechanisms of in-context learning and emergence: https://www.science.org/doi/10.1126/sciadv.adm8470

tldr - they found a way to map a chain of states e.g. pictures of an environment into a cognitive map. meaning without training on spatial data like the locations of where is which object. basically how humans learn their environment
imo this is useful for robotics where you have a lot of camera input and want to construct a map of a road, building etc. without having location data
Mixture of Agents can beat GPT-4o: https://x.com/togethercompute/status/1800536106729157054?s=46

This paper claims that Llama3-8B+BoT (Buffer of Thoughts) has the potential to surpass Llama3-70B model: https://x.com/rohanpaul_ai/status/1811458648532775202
'Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models'


- Propose buffer-manager to dynamically update the meta-buffer, thus enhancing the capacity of meta-buffer as more tasks are solved.


- Achieve significant performance improvement over previous SOTA methods: 11% on Game of 24, 20% on Geometric Shapes and 51% on Checkmate-in-One.


- Superior generalization ability and model robustness of our BoT, while requiring only 12% of the cost of multi-query prompting methods (e.g., tree/graph of thoughts) on average.


Drawing out steps as images using Python to do reasoning: https://arxiv.org/abs/2406.14562


This simple approach shows state-of-the-art results on four difficult natural language tasks that involve visual and spatial reasoning. We identify multiple settings where GPT-4o using chain-of-thought fails dramatically, including more than one where it achieves 0% accuracy, while whiteboard-of-thought enables up to 92% accuracy in these same settings.


Over 32 techniques to reduce hallucinations:
https://arxiv.org/abs/2401.01313

Our state space duality (SSD) framework allows us to design a new architecture (Mamba-2) whose core layer is an a refinement of Mamba’s selective SSM that is 2-8× faster, while continuing to be competitive with Transformers on language modeling: https://arxiv.org/pdf/2405.21060 
Loss:
https://x.com/ctnzr/status/1801050835197026696 
A 8B-3.5T hybrid SSM model gets better accuracy than an 8B-3.5T transformer trained on the same dataset:
* 7% attention, the rest is Mamba2
* MMLU jumps from 50 to 53.6%
* Training efficiency is the same
* Inference cost is much less

Analysis: https://arxiv.org/abs/2406.07887

we find that the 8B Mamba-2-Hybrid exceeds the 8B Transformer on all 12 standard tasks we evaluated (+2.65 points on average) and is predicted to be up to 8x faster when generating tokens at inference time. To validate long-context capabilities, we provide additional experiments evaluating variants of the Mamba-2-Hybrid and Transformer extended to support 16K, 32K, and 128K sequences. On an additional 23 long-context tasks, the hybrid model continues to closely match or exceed the Transformer on average. 

Jamba: https://arxiv.org/abs/2403.19887

Jamba provides high throughput and small memory footprint compared to vanilla Transformers, and at the same time state-of-the-art performance on standard language model benchmarks and long-context evaluations. Remarkably, the model presents strong results for up to 256K tokens context length. 


Sonic, a blazing fast  (🚀 135ms model latency), lifelike generative voice model and API: https://x.com/cartesia_ai/status/1795856778456084596 

>Sonic is built on our new state space model architecture for efficiently modeling high-res data like audio and video.
On speech, a parameter-matched and optimized Sonic model trained on the same data as a widely used Transformer improves audio quality significantly (20% lower perplexity, 2x lower word error, 1 point higher NISQA quality).With lower latency (1.5x lower time-to-first-audio), faster inference speed (2x lower real-time factor) and higher throughput (4x).

SOTA Vision encoder using MAMBA: https://github.com/NVlabs/MambaVision

Dramatically overfitting on transformers leads to SIGNIFICANTLY better performance: https://arxiv.org/abs/2405.15071 

 >Our findings guide data and training setup to better induce implicit reasoning and suggest potential improvements to the transformer architecture, such as encouraging cross-layer knowledge sharing. Furthermore, we demonstrate that for a challenging reasoning task with a large search space, GPT-4-Turbo and Gemini-1.5-Pro based on non-parametric memory fail badly regardless of prompting styles or retrieval augmentation, while a fully grokked transformer can achieve near-perfect accuracy, showcasing the power of parametric memory for complex reasoning.

Accuracy increased from 33.3% on GPT4 to 99.3%


Test (ID) means it was NOT in the training data but is related to the original tasks (e.g learning 2+4 and 5+3 and then solving 2+5)
Test (OOD) means “out of distribution,” meaning it is NOT even related to the training data (e.g learning 2+4 and 5+2 and then being asked to write code in Python)

Diffusion Forcing: Next-token Prediction Meets Full-Sequence Diffusion. "leads to marked performance gains in decision-making and planning tasks." https://boyuan.space/diffusion-forcing/



LLMs Can't Plan, But Can Help Planning in LLM-Modulo Frameworks: https://arxiv.org/abs/2402.01817 


>We present a vision of LLM-Modulo Frameworks that combine the strengths of LLMs with external model-based verifiers in a tighter bi-directional interaction regime. We will show how the models driving the external verifiers themselves can be acquired with the help of LLMs. We will also argue that rather than simply pipelining LLMs and symbolic components, this LLM-Modulo Framework provides a better neuro-symbolic approach that offers tighter integration between LLMs and symbolic components, and allows extending the scope of model-based planning/reasoning regimes towards more flexible knowledge, problem and preference specifications.


TransNAR architecture improves reasoning both in and out of distribution: https://arxiv.org/pdf/2406.09308 

>Such NARs proved effective as generic solvers for algorithmic tasks, when specified in graph form. To make their embeddings accessible to a Transformer, we propose a hybrid architecture with a two- phase training procedure, allowing the tokens in the lan- guage model to cross-attend to the node embeddings from the NAR. We evaluate our resulting TransNAR model on CLRS-Text, the text-based version of the CLRS-30 bench- mark, and demonstrate significant gains over Transformer- only models for algorithmic reasoning, both in and out of distribution.


https://arxiv.org/html/2404.03683v1

>Language models are rarely shown fruitful mistakes while training. They then struggle to look beyond the next token, suffering from a snowballing of errors and struggling to predict the consequence of their actions several steps ahead. In this paper, we show how language models can be taught to search by representing the process of search in language, as a flattened string — a stream of search (SoS). We propose a unified language for search that captures an array of different symbolic search strategies. We demonstrate our approach using the simple yet difficult game of Countdown, where the goal is to combine input numbers with arithmetic operations to reach a target number. We pretrain a transformer-based language model from scratch on a dataset of streams of search generated by heuristic solvers. We find that SoS pretraining increases search accuracy by 25% over models trained to predict only the optimal search trajectory. We further finetune this model with two policy improvement methods: Advantage-Induced Policy Alignment (APA) and Self-Taught Reasoner (STaR). The finetuned SoS models solve 36% of previously unsolved problems, including problems that cannot be solved by any of the heuristic solvers. Our results indicate that language models can learn to solve problems via search, self-improve to flexibly use different search strategies, and potentially discover new ones. 

LLMs learns to train better LLMs: https://x.com/hardmaru/status/1801074062535676193

 Med-Gemini : https://arxiv.org/abs/2404.18416
We evaluate Med-Gemini on 14 medical benchmarks, establishing new state-of-the-art (SoTA) performance on 10 of them, and surpass the GPT-4 model family on every benchmark where a direct comparison is viable, often by a wide margin. On the popular MedQA (USMLE) benchmark, our best-performing Med-Gemini model achieves SoTA performance of 91.1% accuracy, using a novel uncertainty-guided search strategy. On 7 multimodal benchmarks including NEJM Image Challenges and MMMU (health & medicine), Med-Gemini improves over GPT-4V by an average relative margin of 44.5%. We demonstrate the effectiveness of Med-Gemini's long-context capabilities through SoTA performance on a needle-in-a-haystack retrieval task from long de-identified health records and medical video question answering, surpassing prior bespoke methods using only in-context learning. Finally, Med-Gemini's performance suggests real-world utility by surpassing human experts on tasks such as medical text summarization, alongside demonstrations of promising potential for multimodal medical dialogue, medical research and education. 

An infinite context window is possible, and it can remember what you sent even a million messages ago: https://arxiv.org/html/2404.07143v1?darkschemeovr=1

>This subtle but critical modification to the attention layer enables LLMs to process infinitely long contexts with bounded memory and computation resources. We show that our approach can naturally scale to a million length regime of input sequences, while outperforming the baselines on long-context language modeling benchmark and book summarization tasks. We also demonstrate a promising length generalization capability of our approach. 1B model that was fine-tuned on up to 5K sequence length passkey instances solved the 1M length problem.

Human-like Episodic Memory for Infinite Context LLMs: https://x.com/_akhaliq/status/1812678969386234046

>When needed, these events are retrieved through a two-stage memory process, combining similarity-based and temporally contiguous retrieval for efficient and human-like access to relevant information. Experiments on the LongBench dataset demonstrate EM-LLM's superior performance, outperforming the state-of-the-art InfLLM model with an overall relative improvement of 4.3% across various tasks, including a 33% improvement on the PassageRetrieval task. Furthermore, our analysis reveals strong correlations between EM-LLM's event segmentation and human-perceived events suggesting a bridge between this artificial system and its biological counterpart. This work not only advances LLM capabilities in processing extended contexts but also provides a computational framework for exploring human memory mechanisms, opening new avenues for interdisciplinary research in AI and cognitive science.

Learning to (Learn at Test Time): RNNs with Expressive Hidden States. "TTT layers directly replace attention, and unlock linear complexity architectures with expressive memory, allowing us to train LLMs with millions (someday billions) of tokens in context" https://arxiv.org/abs/2407.04620


Models 1/200th the size of SOTA models outperform them in math using Q*: https://x.com/deedydas/status/1802019023422627889

Introducing 🧮Abacus Embeddings, a simple tweak to positional embeddings that enables LLMs to do addition, multiplication, sorting, and more. Our Abacus Embeddings trained only on 20-digit addition generalise near perfectly to 100+ digits:  https://x.com/SeanMcleish/status/1795481814553018542 




 Scores on SWE Bench Lite have increased by 83% from April to June 2024, up to 33% in June: https://swebench.com 
Increased to 43% in July. A 30% boost in 1 month!


Step aware performance optimization: https://huggingface.co/papers/2406.04314 
Our experiments with Stable Diffusion v1.5 and SDXL demonstrate that SPO significantly outperforms the latest Diffusion-DPO in aligning generated images with complex, detailed prompts and enhancing aesthetics, while also achieving more than 20x times faster in training efficiency


https://huggingface.co/papers/2405.00732 
We find that 4-bit LoRA fine-tuned models outperform base models by 34 points and GPT-4 by 10 points on average. 
https://huggingface.co/papers/2406.04324 
We show that, through the adversarial training, the multi-steps video diffusion model, i.e., Stable Video Diffusion (SVD), can be trained to perform single forward pass to synthesize high-quality videos, capturing both temporal and spatial dependencies in the video data. Extensive experiments demonstrate that our method achieves competitive generation quality of synthesized videos with significantly reduced computational overhead for the denoising process (i.e., around 23 times speedup compared with SVD and 6 times speedup compared with existing works, with even better generation quality), paving the way for real-time video synthesis and editing. 
https://huggingface.co/papers/2406.04271 
We conduct extensive experiments on 10 challenging reasoning-intensive tasks, and achieve significant performance improvements over previous SOTA methods: 11% on Game of 24, 20% on Geometric Shapes and 51% on Checkmate-in-One. Further analysis demonstrate the superior generalization ability and model robustness of our BoT, while requiring only 12% of the cost of multi-query prompting methods (e.g., tree/graph of thoughts) on average. Notably, we find that our Llama3-8B+BoT has the potential to surpass Llama3-70B model


JEPA led by Turing Award winner and “Godfather of AI” Yann LeCun
https://arxiv.org/abs/2403.00504
While previously limited to predicting missing parts of an input, we explore how to generalize the JEPA prediction task to a broader set of corruptions. We introduce Image World Models, an approach that goes beyond masked image modeling and learns to predict the effect of global photometric transformations in latent space. We study the recipe of learning performant IWMs and show that it relies on three key aspects: conditioning, prediction difficulty, and capacity. Additionally, we show that the predictive world model learned by IWM can be adapted through finetuning to solve diverse tasks; a fine-tuned IWM world model matches or surpasses the performance of previous self-supervised methods. Finally, we show that learning with an IWM allows one to control the abstraction level of the learned representations, learning invariant representations such as contrastive methods, or equivariant representations such as masked image modelling.
https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/
Can learn from ONLY A FEW EXAMPLES
Understands semantic information rather than trying to predict every pixel

https://ai.meta.com/blog/yann-lecun-ai-model-i-jepa/ 



Introducing HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models: https://arxiv.org/abs/2405.14831 
We compare HippoRAG with existing RAG methods on multi-hop question answering and show that our method outperforms the state-of-the-art methods remarkably, by up to 20%. Single-step retrieval with HippoRAG achieves comparable or better performance than iterative retrieval like IRCoT while being 10-30 times cheaper and 6-13 times faster, and integrating HippoRAG into IRCoT brings further substantial gains.

OpenAI’s ChatGPT can improve its capabilities through self play and the use of Agents: https://www.youtube.com/watch?v=ewLMYLCWvcI 
Utilizing a multi-agent approach, this system effectively tackles the intricate nuances inherent in literary texts. 
Empirical findings indicate that despite lower d-BLEU scores, translations from TransAgents are preferred by both human evaluators and LLMs over human-written references, particularly in genres requiring domain-specific knowledge. 

Researchers shows Model Collapse is easily avoided by keeping old human data with new synthetic data in the training set: https://arxiv.org/abs/2404.01413 


[Teaching Language Models to Hallucinate Less with Synthetic Tasks](https://arxiv.org/abs/2310.06827?darkschemeovr=1 )

We then illustrate a path towards ASI via open-ended systems built on top of foundation models, capable of making novel, human relevant discoveries. We conclude by examining the safety implications of generally-capable openended AI." 
https://arxiv.org/abs/2406.04268



Researchers gave AI an 'inner monologue' and it massively improved its performance | Scientists trained an AI system to think before speaking with a technique called QuietSTaR. The inner monologue improved common sense reasoning and doubled math performance https://www.livescience.com/technology/artificial-intelligence/researchers-gave-ai-an-inner-monologue-and-it-massively-improved-its-performance 


MIT researchers, Max Tegmark and others develop new kind of neural network “Kolmogorov-Arnold network“ that scales much faster than traditional ones https://arxiv.org/abs/2404.19756 


LLAMA 3 70b is ranked higher than the 2023 versions of GPT 4 on the LMSYS leaderboard despite a 96% size reduction AND Zuckerberg has stated it’s undertrained due to budget constraints. 
A few weeks later, IBM released an open-source model that outperforms it: https://analyticsindiamag.com/ibm-releases-open-source-granite-code-models-outperforms-llama-3/  
Meta is training a 400b model now. Scaling laws show that larger models have better performance, so this model should be even better than anything that is available now.

 
[LLMs made with the new Mamba architecture are as good as transformers twice their size](https://arxiv.org/abs/2312.00752)


[OpenAI has their own unrelated Q* algorithm to increase reasoning capabilities](https://www.linkedin.com/pulse/impressed-gpt-you-know-nothing-john-doe-meat-q-jacek-gralak-e2qve )



Anthropic’s ClaudeBot has been aggressively scraping the Web in recent days. What are they training? https://www.reddit.com/r/singularity/comments/1cdm97j/anthropics_claudebot_is_aggressively_scraping_the/   


Salesforce released the new state of the art instruct model based on the Llama-3 8b: SFR-Iterative-DPO-LLaMA-3-8B-R
Chat-Arena-Hard is likely not yet polluted and seems relatively calibrated (albeit biased towards GPT4), their score on it (29.1) beats meta's (20.6). Most previous finetunes have been either LORAs or at best SFT, Salesforce's SFT result on CAH is just 5.6.
Tested both on 8 questions hard for small LLMs, LLAMA 3 8b instruct scored 3/8, this scored 5/8.
Prompt:
Can you make me a screensaver with the green and gold 'raining code' like in The Matrix? Make it in Python. Please do not require any external dependencies such as fonts. Using Pygame is acceptable.
The result: https://i.imgur.com/H0qNEqE.png  
Not the prettiest, but it works, no errors.
2nd prompt: In Python, write a basic music player program with the following features: Create a playlist based on MP3 files found in the current folder, and include controls for common features such as next track, play/pause/stop, etc. Use PyGame for this. Make sure the filename of current song is included in the UI.
Result: https://i.imgur.com/7g0Tzji.png
Works, with keyboard controls for pause/unpause, next track, and stop.

[Live AI video analysis](https://twitter.com/GoogleDeepMind/status/1790463259822420239)
Project Astra: Our vision for the future of AI assistants
More examples of recognizing drawings: https://twitter.com/minchoi/status/1790873017150550354

Chameleon: Mixed-Modal Early-Fusion Foundation Models: https://arxiv.org/abs/2405.09818
This research presents a family of early-fusion token-based mixed-modal models capable of understanding & generating images & text in any arbitrary sequence.
Chameleon demonstrates broad and general capabilities, including state-of-the-art performance in image captioning tasks, outperforms Llama-2 in text-only tasks while being competitive with models such as Mixtral 8x7B and Gemini-Pro, and performs non-trivial image generation, all in a single model. It also matches or exceeds the performance of much larger models, including Gemini Pro and GPT-4V, according to human judgments on a new long-form mixed-modal generation evaluation, where either the prompt or outputs contain mixed sequences of both images and text.

SOAR: New algorithms for even faster vector search with ScaNN: https://research.google/blog/soar-new-algorithms-for-even-faster-vector-search-with-scann/

The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits: https://arxiv.org/abs/2402.17764 
In this work, we introduce a 1-bit LLM variant, namely BitNet b1.58, in which every single parameter (or weight) of the LLM is ternary {-1, 0, 1}. It matches the full-precision (i.e., FP16 or BF16) Transformer LLM with the same model size and training tokens in terms of both perplexity and end-task performance, while being significantly more cost-effective in terms of latency, memory, throughput, and energy consumption. More profoundly, the 1.58-bit LLM defines a new scaling law and recipe for training new generations of LLMs that are both high-performance and cost-effective. Furthermore, it enables a new computation paradigm and opens the door for designing specific hardware optimized for 1-bit LLMs.




LLMs won’t need data anymore. Synthetically trained 7B math model blows 64 shot GPT4 out of the water in math: https://x.com/_akhaliq/status/1793864788579090917?s=46&t=lZJAHzXMXI1MgQuyBgEhgA
While this only works for things you can generate good or perfect data on, that would still be good enough for factual information like math or science. For subjective information like art, a good art generator (e.g. Midjourney or Pony Diffusion could work)
Drone swarms can now fly autonomously through thick forest: https://x.com/AISafetyMemes/status/1793899057200652654 
Can be used to gather data without human navigation
iVideoGPT: Interactive VideoGPTs are Scalable World Models: https://huggingface.co/papers/2405.15223 
AutoDoc coding: https://arxiv.org/html/2310.19791v4#Pt1 
While large language models (LLMs) now excel at code generation, a key aspect of software development is the art of refactoring: consolidating code into libraries of reusable and readable programs. In this paper, we introduce Lilo, a neurosymbolic framework that iteratively synthesizes, compresses, and documents code to build libraries tailored to particular problem domains. Lilo combines LLM-guided program synthesis with recent algorithmic advances in automated refactoring from Stitch: a symbolic compression system that efficiently identifies optimal 𝜆-abstractions across large code corpora. To make these abstractions interpretable, we introduce an auto-documentation (AutoDoc) procedure that infers natural language names and docstrings based on contextual examples of usage. In addition to improving human readability, we find that AutoDoc boosts performance by helping Lilo’s synthesizer to interpret and deploy learned abstractions. We evaluate Lilo on three inductive program synthesis benchmarks for string editing, scene reasoning, and graphics composition. Compared to existing methods—including the state-of-the-art libraries learning algorithm DreamCoder—Lilo solves more complex tasks and learns richer libraries that are grounded in linguistic knowledge.


LLMs Aren’t Just “Trained On the Internet” Anymore: https://allenpike.com/2024/llms-trained-on-internet 
CoPE is a new positional encoding method for transformers that takes into account *context* https://x.com/jaseweston/status/1795978611784089799 
- Can "count" distances per head dependent on need, e.g. i-th sentence or paragraph, words, verbs, etc. Not just tokens.
- CoPE solves counting & copy tasks that standard transformers cannot.
- Better PPL on language modeling + coding tasks.
Robot integrated with Huawei's Multimodal LLM PanGU to understand natural language commands, plan tasks, and execute with bimanual coordination: https://x.com/TheHumanoidHub/status/1806033905147077045 
New high quality dataset: https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1 
Good data is the biggest contributor to good models: https://nonint.com/2023/06/10/the-it-in-ai-models-is-the-dataset/ 

“Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war.”
Signed by Ilya Sutskever, Geoffrey Hinton, Yoshua Bengio, Demis Hassabis, Sam Altman, Dario Amodei, and many more
Diffusion models for code generation that learn to directly *edit* syntax trees of programs. The result is a system that can incrementally write code, see the execution output, and debug it: https://x.com/shreyaskapur/status/1797726079995826629 
Mitigating Fine-Grained Hallucination by Fine-Tuning Large Vision-Language Models with Caption Rewrites: https://export.arxiv.org/abs/2312.01701 
Our experiment results demonstrate that ReCaption effectively reduces fine-grained object hallucination for different LVLM options and improves their text generation quality.
REDUCING LLM HALLUCINATIONS USING EPISTEMIC NEURAL NETWORKS: https://arxiv.org/pdf/2312.15576 
Reducing hallucination in structured outputs via Retrieval-Augmented Generation:  https://arxiv.org/abs/2404.08189
Kaleido Diffusion: Improving Conditional Diffusion Models with Autoregressive Latent Modeling: https://huggingface.co/papers/2405.21048  
Show, Don’t Tell: Aligning Language Models with Demonstrated Feedback: https://t.co/JASt7Sp18l 
Significantly outperforms few-shot prompting, SFT and other self-play methods.by an average of 19% using demonstrations as feedback directly with <10 examples
No Language Left Behind (NLLB) is an AI model created by researchers at Meta capable of delivering high-quality translations directly between 200 languages – including low-resource languages: https://www.nature.com/articles/s41586-024-07335-x 
Teams of LLM Agents can Exploit Zero-Day Vulnerabilities: https://arxiv.org/abs/2406.01637 
Prior agents struggle with exploring many different vulnerabilities and long-range planning when used alone. To resolve this, we introduce HPTSA, a system of agents with a planning agent that can launch subagents. The planning agent explores the system and determines which subagents to call, resolving long-term planning issues when trying different vulnerabilities. We construct a benchmark of 15 real-world vulnerabilities and show that our team of agents improve over prior work by up to 4.5x.
Searching Priors Makes Text-to-Video Synthesis Better: https://huggingface.co/papers/2406.03215 
Audio Mamba: Bidirectional State Space Model for Audio Representation Learning: https://huggingface.co/papers/2406.03344 
https://arxiv.org/html/2404.03683v1
Language models are rarely shown fruitful mistakes while training. They then struggle to look beyond the next token, suffering from a snowballing of errors and struggling to predict the consequence of their actions several steps ahead. In this paper, we show how language models can be taught to search by representing the process of search in language, as a flattened string — a stream of search (SoS). We propose a unified language for search that captures an array of different symbolic search strategies. We demonstrate our approach using the simple yet difficult game of Countdown, where the goal is to combine input numbers with arithmetic operations to reach a target number. We pretrain a transformer-based language model from scratch on a dataset of streams of search generated by heuristic solvers. We find that SoS pretraining increases search accuracy by 25% over models trained to predict only the optimal search trajectory. We further finetune this model with two policy improvement methods: Advantage-Induced Policy Alignment (APA) and Self-Taught Reasoner (STaR). The finetuned SoS models solve 36% of previously unsolved problems, including problems that cannot be solved by any of the heuristic solvers. Our results indicate that language models can learn to solve problems via search, self-improve to flexibly use different search strategies, and potentially discover new ones. 
High quality quantization of Stable Diffusion: https://huggingface.co/papers/2406.04333 
Saving and transferring them is a major bottleneck for various applications, especially those running on resource-constrained devices. In this work, we develop a novel weight quantization method that quantizes the UNet from Stable Diffusion v1.5 to 1.99 bits, achieving a model with 7.9X smaller size while exhibiting even better generation quality than the original one. Our approach includes several novel techniques, such as assigning optimal bits to each layer, initializing the quantized model for better performance, and improving the training strategy to dramatically reduce quantization error. Furthermore, we extensively evaluate our quantized model across various benchmark datasets and through human evaluation to demonstrate its superior generation quality.
https://arxiv.org/abs/2404.05719 
Ferret-UI, a new MLLM tailored for enhanced understanding of mobile UI screens, equipped with referring, grounding, and reasoning capabilities. Given that UI screens typically exhibit a more elongated aspect ratio and contain smaller objects of interest (e.g., icons, texts) than natural images, we incorporate "any resolution" on top of Ferret to magnify details and leverage enhanced visual features. Specifically, each screen is divided into 2 sub-images based on the original aspect ratio (i.e., horizontal division for portrait screens and vertical division for landscape screens). Both sub-images are encoded separately before being sent to LLMs. We meticulously gather training samples from an extensive range of elementary UI tasks, such as icon recognition, find text, and widget listing. These samples are formatted for instruction-following with region annotations to facilitate precise referring and grounding. To augment the model's reasoning ability, we further compile a dataset for advanced tasks, including detailed description, perception/interaction conversations, and function inference. After training on the curated datasets, Ferret-UI exhibits outstanding comprehension of UI screens and the capability to execute open-ended instructions. For model evaluation, we establish a comprehensive benchmark encompassing all the aforementioned tasks. Ferret-UI excels not only beyond most open-source UI MLLMs, but also surpasses GPT-4V on all the elementary UI tasks.
Improve Mathematical Reasoning in Language Models by Automated Process Supervision: https://arxiv.org/abs/2406.06592 
Utilizing this fully automated process supervision alongside the weighted self-consistency algorithm, we have enhanced the instruction tuned Gemini Pro model's math reasoning performance, achieving a 69.4\% success rate on the MATH benchmark, a 36\% relative improvement from the 51\% base model performance. Additionally, the entire process operates without any human intervention, making our method both financially and computationally cost-effective compared to existing methods.
Simulations transfer very well to real life: https://arxiv.org/abs/2406.01967v1 
Scalable MatMul-free Language Modeling: https://arxiv.org/abs/2406.02528 
In this work, we show that MatMul operations can be completely eliminated from LLMs while maintaining strong performance at billion-parameter scales. Our experiments show that our proposed MatMul-free models achieve performance on-par with state-of-the-art Transformers that require far more memory during inference at a scale up to at least 2.7B parameters. We investigate the scaling laws and find that the performance gap between our MatMul-free models and full precision Transformers narrows as the model size increases. We also provide a GPU-efficient implementation of this model which reduces memory usage by up to 61% over an unoptimized baseline during training. By utilizing an optimized kernel during inference, our model's memory consumption can be reduced by more than 10x compared to unoptimized models. To properly quantify the efficiency of our architecture, we build a custom hardware solution on an FPGA which exploits lightweight operations beyond what GPUs are capable of. We processed billion-parameter scale models at 13W beyond human readable throughput, moving LLMs closer to brain-like efficiency. This work not only shows how far LLMs can be stripped back while still performing effectively, but also points at the types of operations future accelerators should be optimized for in processing the next generation of lightweight LLMs.

Samba 3.8B: https://x.com/liliang_ren/status/1801027052147216457

Introducing Samba 3.8B, a simple Mamba+Sliding Window Attention architecture that outperforms Phi3-mini on major benchmarks (e.g., MMLU, GSM8K and HumanEval) by a large margin.😮 And it has an infinite context length with linear complexity.
When trained on the 4K sequence length, Samba shows improved perplexity up to 1M context length on Proof-Pile, while still keeping its linear decoding complexity. This results in a 3.64x speed up than the Llama-3 architecture at 64k generation length. 🚀
Wondering how is the extrapolation ability of Samba compared to Mistral? We instruction tuned both architectures on Passkey Retrieval with 4K sequence length, and found that Samba (left) can have perfect memory recall up to 256K context length, while Mistral (right) struggles within the 4K length.

Mixture-of-Agents Enhances Large Language Model Capabilities: https://arxiv.org/abs/2406.04692 

GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B: https://arxiv.org/abs/2406.07394 
Extensive experiments demonstrate MCTSr's efficacy in solving Olympiad-level mathematical problems, significantly improving success rates across multiple datasets, including GSM8K, GSM Hard, MATH, and Olympiad-level benchmarks, including Math Odyssey, AIME, and OlympiadBench. The study advances the application of LLMs in complex reasoning tasks and sets a foundation for future AI integration, enhancing decision-making accuracy and reliability in LLM-driven applications.
This would be even more effective with a better model than LLAMA 8B and with GPT 4o
https://arxiv.org/pdf/2401.10020 
In this work, we study Self-Rewarding Language Models, where the language model itself is used via LLM-as-a-Judge prompting to provide its own rewards during training. We show that during Iterative DPO training that not only does instruction following ability improve, but also the ability to provide high-quality rewards to itself. Fine-tuning Llama 2 70B on three iterations of our approach yields a model that outperforms many existing systems on the AlpacaEval 2.0 leaderboard, including Claude 2, Gemini Pro, and GPT-4 0612. While there is much left still to explore, this work opens the door to the possibility of models that can continually improve in both axes.
Image diffusion is getting much better and faster/cheaper to train: https://arxiv.org/pdf/2403.04692 
GPT4o gets 72% on ARC-AGI (humans get 85%): https://x.com/dwarkesh_sp/status/1802771055016378554 
Generating audio for video: https://deepmind.google/discover/blog/generating-audio-for-video/ 
Bloomberg: ADOBE about to enter AI Video market, currently working on SORA competitor: https://www.pcmag.com/news/adobe-buying-videos-train-sora-competitor 
https://arxiv.org/pdf/2405.15568
OMNI-EPIC leverages foundation models to autonomously generate code specifying the next learnable (i.e., not too easy or difficult for the agent’s current skill set) and interesting (e.g., worthwhile and novel) tasks. OMNI-EPIC generates both environments (e.g., an obstacle course) and reward functions (e.g., progress through the obstacle course quickly without touching red objects), enabling it, in principle, to create any simu- latable learning task. We showcase the explosive creativity of OMNI-EPIC, which continuously innovates to suggest new, interesting learning challenges. We also highlight how OMNI-EPIC can adapt to reinforcement learning agents’ learning progress, generating tasks that are of suitable difficulty. Overall, OMNI-EPIC can endlessly create learnable and interesting environments, further propelling the development of self-improving AI systems and AI-Generating Algorithms. Project website with videos: https://dub.sh/omniepic.
Boosting Visual-Language Models with Synthetic Captions and Image Embeddings: https://arxiv.org/pdf/2403.07750 
Our method employs pretrained text-to-image model to synthesize image embeddings from captions generated by an LLM. Despite the text-to-image model and VLM initially being trained on the same data, our approach leverages the image generator’s ability to create novel compositions, resulting in synthetic image embeddings that expand beyond the limitations of the original dataset. Extensive experiments demonstrate that our VLM, finetuned on synthetic data achieves comparable performance to models trained solely on human-annotated data, while requiring significantly less data. Furthermore, we perform a set of analyses on captions which reveals that semantic diversity and balance are key aspects for better downstream performance. Finally, we show that synthesizing images in the image embedding space is 25% faster than in the pixel space. We believe our work not only addresses a significant challenge in VLM training but also opens up promising avenues for the development of self-improving multi-modal models.


Q*: Improving Multi-step Reasoning for LLMs with Deliberative Planning: https://arxiv.org/abs/2406.14283 
In this paper, we aim to alleviate the pathology by introducing Q*, a general, versatile and agile framework for guiding LLMs decoding process with deliberative planning. By learning a plug-and-play Q-value model as heuristic function, our Q* can effectively guide LLMs to select the most promising next step without fine-tuning LLMs for each task, which avoids the significant computational overhead and potential risk of performance degeneration on other tasks. Extensive experiments on GSM8K, MATH and MBPP confirm the superiority of our method.

Do you know your LLM uses less than 1% of your GPU at inference? Too much time is wasted on KV cache memory access ➡️ We tackle this with the 🎁 Block Transformer: a global-to-local architecture that speeds up decoding up to 20x: https://x.com/itsnamgyu/status/1807400609429307590 :
HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale: https://huggingface.co/papers/2406.19280 
Our validation demonstrates that: (1) PubMedVision can significantly enhance the medical multimodal capabilities of current MLLMs, showing significant improvement in benchmarks including the MMMU Health & Medicine track; (2) manual checks by medical experts and empirical results validate the superior data quality of our dataset compared to other data construction methods. Using PubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows superior performance in medical multimodal scenarios among open-source MLLMs.

Step-DPO: Step-wise preference Optimization for Long-chain Reasoning of LLMs: https://huggingface.co/papers/2406.18629 
We also observe that in DPO, self-generated data is more effective than data generated by humans or GPT-4, due to the latter's out-of-distribution nature. Our findings demonstrate that as few as 10K preference data pairs and fewer than 500 Step-DPO training steps can yield a nearly 3% gain in accuracy on MATH for models with over 70B parameters. Notably, Step-DPO, when applied to Qwen2-72B-Instruct, achieves scores of 70.8% and 94.0% on the test sets of MATH and GSM8K, respectively, surpassing a series of closed-source models, including  GPT-4-1106, Claude-3-Opus, and Gemini-1.5-Pro.

OMG-LLaVA: Bridging Image-level, Object-level, Pixel-level Reasoning and Understanding: https://huggingface.co/papers/2406.19389 
OMG-LLaVA achieves image-level, object-level, and pixel-level reasoning and understanding in a single model, matching or surpassing the performance of specialized methods on multiple benchmarks.

Human level text to speech: https://www.microsoft.com/en-us/research/project/vall-e-x/vall-e-2/

SpatialVLM: Endowing Vision-Language Models with Spatial Reasoning Capabilities: https://spatial-vlm.github.io/

The Memory^3 model achieved better performance than larger models and RAG models on various benchmarks, while maintaining higher decoding speed. It showed particular improvements in factuality and reduced hallucination: https://arxiv.org/html/2407.01178v1
we reduce cost by equipping LLMs with an explicit memory format cheaper than model parameters and text retrieval-augmented generation (RAG).
Conceptually, with most of its knowledge externalized to explicit memory, the LLM can enjoy a smaller parameter size, training cost, and inference cost, all proportional to the amount of remaining “abstract knowledge”.
As a preliminary proof of concept, we train from scratch a 2.4B LLM, which achieves better performance than much larger LLMs as well as RAG models, and maintains higher decoding speed than RAG.
We introduce a memory circuitry theory to support the externalization of knowledge, and present novel techniques including a memory sparsification mechanism that makes storage tractable and a two-stage pretraining scheme that facilitates memory formation.
Offline model-based RL suffers in long-horizon tasks like AntMaze. We introduce LEQ (Lower-Expectile Q-learning), which significantly outperforms previous offline model-based methods on AntMaze: https://x.com/kwanyoung_park_/status/1810308456131547289
Paper: https://arxiv.org/abs/2407.00699
Project page: https://kwanyoungpark.github.io/LEQ/

Voice cloning: https://x.com/dreamingtulpa/status/1810573475309908261
Kling AI just got a new round of updates. The updates include enhanced video quality, 10 seconds of video time, camera motion controls and customizable intro/outro frames: https://www.reddit.com/r/singularity/comments/1dzwavq/kling_ai_just_got_a_new_round_of_updates_the/
Video-STaR, a self-training approach to utilize any supervision for video instruction tuning https://x.com/orr_zohar/status/1810872854633926994


Internet of Agents beats GPT 4: https://arxiv.org/pdf/2407.07061



PaliGemma 3b VLM: https://arxiv.org/pdf/2407.07726 
Our MMVP result is SOTA by a large margin. PaliGemma at 224px achieves 47.3% paired accuracy, while GPT4-V and Gemini achieve 38.7% and 40.7%, respectively, and all other models including LLaVa perform below chance.
FlashAttention 3 is much faster https://x.com/tri_dao/status/1811453622070444071

Exclusive: OpenAI working on new reasoning technology under code name ‘Strawberry’ https://www.reuters.com/technology/artificial-intelligence/openai-working-new-reasoning-technology-under-code-name-strawberry-2024-07-12/
'A different source briefed on the matter said OpenAI has tested AI internally that scored over 90% on a MATH dataset, a benchmark of championship math problems. Reuters could not determine if this was the "Strawberry" project.'
The MATH dataset is challenging: large language models achieved accuracies ranging from 3.0% to 6.9%. Despite these low accuracies, models clearly possess some mathematical knowledge: they achieve up to 15% accuracy on the easiest difficulty level, and they are able to generate step-by-step solutions that are coherent and on-topic even when incorrect. We also evaluated humans on MATH, and found that a computer science PhD student who does not especially like mathematics attained approximately 40% on MATH, while a three-time IMO gold medalist attained 90%, indicating that MATH can be challenging for humans as well.
https://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/2021/file/be83ab3ecd0db773eb2dc1b0a17836a1-Paper-round2.pdf
To facilitate the cutting-edge research of MLLMs on comprehensive vision perception, we thereby propose Perceptual Fusion, using a low-budget but highly effective caption engine for complete and accurate image descriptions. Specifically, Perceptual Fusion integrates diverse perception experts as image priors to provide explicit information on visual elements and adopts an efficient MLLM as a centric pivot to mimic advanced MLLMs' perception abilities. We carefully select 1M highly representative images from uncurated LAION dataset and generate dense descriptions using our engine, dubbed DenseFusion-1M. Extensive experiments validate that our engine outperforms its counterparts, where the resulting dataset significantly improves the perception and cognition abilities of existing MLLMs across diverse vision-language benchmarks, especially with high-resolution images as inputs: https://x.com/_akhaliq/status/1811580833506947144
CrowdMoGen: Zero-Shot Text-Driven Collective Motion Generation
𝐏𝐫𝐨𝐣: http://gxyes.github.io/projects/CrowdMoGen.html 
𝐀𝐛𝐬: http://arxiv.org/abs/2407.06188
a zero-shot text-driven framework that harnesses the power of LLMs to incorporate the collective intelligence into motion generation
Major improvement to RNN performance: https://x.com/camall3n/status/1811744898309308758
M2S is a new DDPM-based image inpainting method that is 60 times faster than RePaint: https://github.com/linghuyuhangyuan/M2S

Auto Evol used to create an infinite amount and variety of high quality data: https://x.com/CanXu20/status/1812842568557986268
Auto Evol allows the training of WizardLM2 to be conducted with nearly an unlimited number and variety of synthetic data.
Auto Evol-Instruct automatically designs evolving methods that make given instruction data more complex, enabling almost cost-free adaptation to different tasks by only changing the input data of the framework …This optimization process involves two critical stages: (1) Evol Trajectory Analysis: The optimizer LLM carefully analyzes the potential issues and failures exposed in instruction evolution performed by evol LLM, generating feedback for subsequent optimization. (2) Evolving Method Optimization: The optimizer LLM optimizes the evolving method by addressing these identified issues in feedback. These stages alternate and repeat to progressively develop an effective evolving method using only a subset of the instruction data. Once the optimal evolving method is identified, it directs the evol LLM to convert the entire instruction dataset into more diverse and complex forms, thus facilitating improved instruction tuning.


Our experiments show that the evolving methods designed by Auto Evol-Instruct outperform the Evol-Instruct methods designed by human experts in instruction tuning across various capabilities, including instruction following, mathematical reasoning, and code generation. On the instruction following task, Auto Evol-Instruct can achieve a improvement of 10.44% over the Evol method used by WizardLM-1 on MT-bench; on the code task HumanEval, it can achieve a 12% improvement over the method used by WizardCoder; on the math task GSM8k, it can achieve a 6.9% improvement over the method used by WizardMath.




With the new technology of Auto Evol-Instruct, the evolutionary synthesis data of WizardLM-2 has scaled up from the three domains of chat, code, and math in WizardLM-1 to dozens of domains, covering tasks in all aspects of large language models. This allows Arena Learning to train and learn from an almost infinite pool of high-difficulty instruction data, fully unlocking all the potential of Arena Learning.

Mixture of A Million Experts. Daniel Jeffries:"Reduces inference cost and memory usage, scales to millions of experts, oh and just happens to overcome catastrophic forgetting and enable life long learning for the model." https://arxiv.org/abs/2407.04153
This paper introduces PEER (parameter efficient expert retrieval), a novel layer design that utilizes the product key technique for sparse retrieval from a vast pool of tiny experts (over a million). Experiments on language modeling tasks demonstrate that PEER layers outperform dense FFWs and coarse-grained MoEs in terms of performance-compute trade-off. By enabling efficient utilization of a massive number of experts, PEER unlocks the potential for further scaling of transformer models while maintaining computational efficiency. 
Google Deepmind trained Foundational Large Autorater Models (FLAMe) on extensive human evaluations, achieving the best RewardBench perf. among generative models trained solely on permissive data, surpassing both GPT-4 & 4o: https://x.com/tuvllms/status/1813249272474968315
Codestral-Mamba 7B: https://x.com/theo_gervet/status/1813226968600469824
- Strongest code model for its size, perfect for copilot apps
- Mamba architecture enables linear time inference with 256K context length

LLAMA Groq 3 tool use: https://x.com/RickLamers/status/1813341037198204962
An open source Tool Use full finetune of Llama 3 that reaches the #1 position on BFCL beating all other models, including proprietary ones like Claude Sonnet 3.5, GPT-4 Turbo, GPT-4o and Gemini 1.5 Pro.
The model has been trained on synthetic data only. This is a powerful full finetune, not a LoRA. Yes, we've checked rigorously for overfitting using the LMSYS described robust decontamination techniques, they only score 5.6% on SFT synthetic data and 1.3% on synthetic DPO data.

xLSTMTime : Long-term Time Series Forecasting With xLSTM: https://x.com/ZReacc/status/1813196548337012943
Our adopted architecture for LTSF termed as xLSTMTime surpasses current approaches. We compare xLSTMTime's performance against various state-of-the-art models across multiple real-world datasets, demonstrating superior forecasting capabilities. Our findings suggest that refined recurrent architectures can offer competitive alternatives to transformer-based models in LTSF tasks, potentially redefining the landscape of time series forecasting
Scaling Diffusion Transformers to 16 Billion Parameters: https://huggingface.co/papers/2407.11633
Based on the above guidance, a series of DiT-MoE experimentally achieves performance on par with dense networks yet requires much less computational load during inference. More encouragingly, we demonstrate the potential of DiT-MoE with synthesized image data, scaling diffusion model at a 15.5B parameter that attains a new SoTA FID-50K score of 1.80 in 512x512 resolution settings.
For reference, Stable Diffusion XL is only about 3 billion parameters
Very efficient image diffusion training method: https://huggingface.co/papers/2407.11966
Compared to training from scratch (i.e., Pix2pix), we achieve a 15x training time acceleration for a new concept while obtaining even better image generation quality.
Extremely dynamic image to video: https://x.com/dreamingtulpa/status/1813486936868213073


Prover-Verifier Games improve legibility of language model outputs: https://openai.com/index/prover-verifier-games-improve-legibility/
We trained strong language models to produce text that is easy for weak language models to verify and found that this training also made the text easier for humans to evaluate.


New information on Llama 4 from Meta: https://x.com/AndrewCurran_/status/1813704834819965147
- Llama 4 started training in June
- Llama 4 will be fully multimodal, including audio

E5-V: Universal Embeddings with Multimodal Large Language Models: https://huggingface.co/papers/2407.12580
By leveraging MLLMs with prompts, E5-V effectively bridges the modality gap between different types of inputs, demonstrating strong performance in multimodal embeddings even without fine-tuning. We propose a single modality training approach for E5-V, where the model is trained exclusively on text pairs. This method demonstrates significant improvements over traditional multimodal training on image-text pairs, while reducing training costs by approximately 95%. Additionally, this approach eliminates the need for costly multimodal training data collection. Extensive experiments across four types of tasks demonstrate the effectiveness of E5-V. As a universal multimodal model, E5-V not only achieves but often surpasses state-of-the-art performance in each task, despite being trained on a single modality.

Research on AI agents: https://x.com/rohanpaul_ai/status/1814029081819615364
📌 AI agent evaluations must be cost-controlled. Simple baselines like retrying or gradually increasing model temperature can match or outperform complex "state-of-the-art" agents on benchmarks like HumanEval while costing much less.
📌 Jointly optimizing accuracy and cost can yield better agent designs. By visualizing results as a Pareto curve of accuracy vs. inference cost, researchers can explore new design spaces. An example modification to the DSPy framework reduced costs by over 50% while maintaining accuracy on HotPotQA.

New iterative RAG approach: https://arxiv.org/abs/2407.13101
ReSP significantly outperforms state-of-the-art on HotpotQA and 2WikiMultihopQA benchmarks, and exhibits robustness to context length.

Researcher trained GPT2 to predict the product of two numbers up to 20 digits w/o intermediate reasoning steps, surpassing previous 15-digit demo w/o CoT: https://x.com/yuntiandeng/status/1814319104448467137
The accuracy is a perfect 100%, while GPT-4 has 0% accuracy
 Random Latent Exploration for Deep Reinforcement Learning: https://x.com/fly51fly/status/1814409438650159137
- RLE is straightforward to implement and performs well in practice. Evaluated on challenging ATARI and ISAACGYM benchmarks.
- RLE shows higher overall scores across all tasks than other approaches like RND and randomized value function strategies.
Mindful-RAG: https://x.com/fly51fly/status/1814059659243700685
- The paper proposes a new approach called Mindful-RAG to address deficiencies in grasping the intent behind questions and inability to contextually align with information extracted from the KG through intent identification, context alignment, and validation of response relevance.

MetaSumPerceiver: Multimodal Multi-Document Evidence Summarization for Fact-Checking: https://arxiv.org/abs/2407.13089
- The paper presents MetaSumPerceiver (MSP), a novel summarization model for generating claim-specific summaries from multimodal, multi-document datasets to assist with fact-checking. 


- MSP uses a dynamic perceiver-based model to handle multimodal inputs of arbitrary lengths, including documents, images, and claims.


- To train MSP, reinforcement learning with an entailment model as a reward signal is employed to refine summaries to provide relevant evidence for fact-checking.


- MSP incorporates a proxy reward mechanism with PPO to continually update the summarizer during fact-checking.


- The paper introduces the Multi-News-Fact-Checking dataset with over 100k labeled claims derived from Multi-News using Llama prompts.


- Experiments on MOCHEG and the new dataset show MSP substantially outperforms prior baselines, achieving state-of-the-art performance.


- The key innovation is using RL to optimize summarization specifically for claim verification versus generic summarization.

 Scaling Retrieval-Based Language Models with a Trillion-Token Datastore: https://arxiv.org/abs/2407.12854
- This paper investigates how scaling up the datastore in retrieval-augmented language models improves performance without signs of saturation on both language modeling and downstream tasks. 


- The authors built MASSIVEDS, an open-sourced 1.4 trillion token datastore covering a diverse set of domains. MASSIVEDS is the largest open-sourced datastore for studying retrieval scaling.


- They designed an efficient pipeline to make the study computationally tractable by sharing indexing and retrieval computation across different datastore configurations.


- Experiments show datastore scaling brings consistent improvements in language modeling perplexity on web data and scientific papers.  


- On downstream tasks, datastore scaling significantly boosts performance on knowledge-intensive QA tasks like TriviaQA and Natural Questions. Smaller retrieval models can match or exceed their larger LM-only counterparts.


- Datastore scaling also improves performance on reasoning tasks like MMLU, but the improvements are more modest, indicating potential need for more in-domain data.


- Compared to LM-only models, retrieval models achieve superior compute-optimal scaling curves by offloading FLOPs from model pretraining to datastore indexing.


- Analysis reveals the retriever can stay robust to out-of-domain data and tend to retrieve relevant documents even from a broad datastore.
Significantly better text generation in images: https://huggingface.co/papers/2407.14138

Sparsecraft: https://x.com/_akhaliq/status/1815204831679664191
our method, called SparseCraft, achieves state-of-the-art performances both in novel-view synthesis and reconstruction from sparse views in standard benchmarks, while requiring less than 10 minutes for training.
 SlowFast-LLaVA, A Strong Training-Free Baseline for Video Large Language Models: https://huggingface.co/papers/2407.15841
 it achieves comparable or even better performance compared to state-of-the-art Video LLMs that are fine-tuned on video datasets.

OpenAI patent for using machine learning to train and use a model to perform automatic interface actions based on video and input datasets: https://patents.google.com/patent/US11887367B1/en
RGM, active inference non-llm approach using 90% less data (less need for synthetic data, lower energy footprint). 99.8% accuracy in MNIST benchmark using 90% less data to train on less powerful devices: https://arxiv.org/pdf/2407.20292
Use for Atari game performance: “This fast structure learning took about 18 seconds on a personal computer. “
Use for MNIST dataset classification: For example, the variational procedures above attained state-of-the-art classification accuracy on a self-selected subset of test data after seeing 10,000 training images. Each training image was seen once, with continual learning (and no notion of batching). Furthermore, the number of training images actually used for learning was substantially smaller10 than 10,000; because active learning admits only those informative images that reduce expected free energy. This (Maxwell’s Demon) aspect of selecting the right kind of data for learning will be a recurrent theme in subsequent sections. Finally, the requisite generative model was self-specifying, given some exemplar data. In other words, the hierarchical depth and size of the requisite tensors were learned automatically within a few seconds on a personal computer.
Baidu unveiled an end-to-end self-reasoning framework to improve the reliability and traceability of RAG systems. 13B models achieve similar accuracy with this method(while using only 2K training samples) as GPT-4: https://venturebeat.com/ai/baidu-self-reasoning-ai-the-end-of-hallucinating-language-models/
Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters: https://huggingface.co/papers/2408.03314

This observation motivates applying a "compute-optimal" scaling strategy, which acts to most effectively allocate test-time compute adaptively per prompt. Using this compute-optimal strategy, we can improve the efficiency of test-time compute scaling by more than 4x compared to a best-of-N baseline. Additionally, in a FLOPs-matched evaluation, we find that on problems where a smaller base model attains somewhat non-trivial success rates, test-time compute can be used to outperform a 14x larger model.
Nvidia Research team has developed a method to efficiently create smaller, accurate language models by using structured weight pruning and knowledge distillation, offering several advantages for developers:
16% better performance on MMLU scores.
40x fewer tokens for training new models.
Up to 1.8x cost saving for training a family of models.
The effectiveness of these strategies is demonstrated with the Meta Llama 3.1 8B model, which was refined into the Llama-3.1-Minitron 4B. The collection on huggingface: https://huggingface.co/collections/nvidia/minitron-669ac727dc9c86e6ab7f0f3e
Technical dive: https://developer.nvidia.com/blog/how-to-prune-and-distill-llama-3-1-8b-to-an-nvidia-llama-3-1-minitron-4b-model
Research paper: https://arxiv.org/abs/2407.14679
A* planning: https://jdsemrau.substack.com/p/paper-review-beyond-a-better-planning

Based on the claims of the research team, their transformer model optimally solves previously unseen Sokoban puzzles 93.7% of the time, while using up to 26.8% fewer search steps than standard A∗ search. Their solution also robustly follows the execution trace of a symbolic planner and improves (in terms of trace length) beyond the human-crafted rule-based planning strategy it was initially trained on.
Automated Design of Agentic Systems: Presents Meta Agent Search to demonstrate that we can use agents to invent novel and powerful agent designs by programming in code
proj: https://shengranhu.com/ADAS/
abs: https://arxiv.org/abs/2408.08435
github: https://github.com/ShengranHu/ADAS
Drama Engine: a novel framework for agentic interaction with large language models designed for narrative purposes. The framework adapts multi-agent system principles to create dynamic, context-aware companions that can develop over time and interact with users and each other: https://arxiv.org/abs/2408.11574
Diffusion models as real-time interactive game engines: https://gamengen.github.io/
AI agent that can control a computer: https://www.adept.ai/blog/act-1

This can be especially powerful for manual tasks and complex tools — in this example, what might ordinarily take 10+ clicks in Salesforce can be now done with just a sentence.
Working in-depth in tools like spreadsheets, ACT-1 demonstrates real-world knowledge, infers what we mean from context, and can help us do things we may not even know how to do.
The model can also complete tasks that require composing multiple tools together; most things we do on a computer span multiple programs. In the future, we expect ACT-1 to be even more helpful by asking for clarifications about what we want.
The internet contains a lot of knowledge about the world! When the model doesn’t know something, it knows how to just look up the information online
ACT-1 doesn’t know how to do everything, but it’s highly coachable. With 1 piece of human feedback, it can correct mistakes, becoming more useful with each interaction.
Magic has trained their first model with a 100 million token context window. That’s 10 million lines of code, or 750 novels: https://magic.dev/blog/100m-token-context-windows
“The contrast in memory requirements is even larger – running Llama 3.1 405B with a 100M token context requires 638 H100s per user just to store a single 100M token KV cache. In contrast, LTM requires a small fraction of a single H100’s HBM per user for the same context."
SSMs, RNNs, and RAG all exploit weaknesses in evals like Needle In A Haystack, so we made a new eval, HashHop: https://x.com/magicailabs/status/1829206895804199086
1) Incompressible
2) Multi-hop
3) No semantic hints
4) No recency bias

Patched MoA: https://arxiv.org/abs/2407.18521
Patched MOA can boost the performance of smaller models to surpass that of larger, more expensive models. Notably, our approach improves the gpt-4o-mini model's performance on the Arena-Hard-Auto benchmark by 15.52%, outperforming gpt-4-turbo at a fraction of the cost. We also apply Patched MOA to various software development workflows, showing consistent improvements in task completion rates. Our method is model-agnostic, transparent to end-users, and can be easily integrated into existing LLM pipelines.
Selective Reflection-Tuning: Student-Selected Data Recycling for LLM Instruction-Tuning
https://arxiv.org/abs/2402.10110
This paper introduces Selective Reflection-Tuning, a novel paradigm that synergizes a teacher LLM's reflection and introspection for improving existing data quality with the data selection capability of the student LLM, to automatically refine existing instruction-tuning data. This teacher-student collaboration produces high-quality and student-compatible instruction-response pairs, resulting in sample-efficient instruction tuning and LLMs of superior performance. Selective Reflection-Tuning is a data augmentation and synthesis that generally improves LLM finetuning and self-improvement without collecting brand-new data. We apply our method to Alpaca and WizardLM data and achieve much stronger and top-tier 7B and 13B LLMs.
https://lmsys.org/blog/2023-11-14-llm-decontaminator/

Rephrasing the test set is all you need! We simply paraphrase a test sample or translate it into a different language. It turns out a 13B LLM is smart enough to "generalize" beyond such variations and reaches drastically high benchmark performance. 
To ensure result validity, we followed OpenAI's decontamination method and found no evidence of data contamination.
Taming Audio-Driven Portrait Avatar with Long-Term Motion Dependency: https://x.com/_akhaliq/status/1831530803635085766
Examples: https://x.com/AIandDesign/status/1831721458017710204
AIs can help other AIs solve problems through “meta-cognition” (of a sort). GPT-4 can consistently label math problems by the skills needed to solve them. Other LLMs are then more accurate on solving those math problems once they are given those labels: https://arxiv.org/pdf/2405.12205
“SkillMimic" uses just 35 minutes of video and motion capture data of human demos to train simulated humanoids in basketball skills like dribbling, shooting, and layups through imitation learning: https://www.reddit.com/r/singularity/comments/1fcu8sk/skillmim
Source2Synth: https://x.com/jaseweston/status/1834402693995024453
- Generates synthetic examples grounded in real data 
- Curation step makes data high quality based on answerability
- Improves performance on two challenging domains: Multi-hop QA and using tools: SQL for tabular QA 



Novel Chinese computing architecture 'inspired by human brain' can lead to AGI, scientists sayhttps://www.msn.com/en-us/news/news/content/ar-AA1q7bfu

In the study, the scientists demonstrated this model can handle complex tasks efficiently and reliably. They also showed that a small model based on this architecture can perform just as well as a much larger conventional model of artificial neurons.


Scientists in China have created a new computing architecture that can train advanced artificial intelligence (AI) models while consuming fewer computing resources — and they hope that it will one day lead to artificial general intelligence (AGI). 
Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters: https://arxiv.org/abs/2408.03314v1
In this work, we analyze two primary mechanisms to scale test-time computation: (1) searching against dense, process-based verifier reward models; and (2) updating the model's distribution over a response adaptively, given the prompt at test time. We find that in both cases, the effectiveness of different approaches to scaling test-time compute critically varies depending on the difficulty of the prompt. This observation motivates applying a "compute-optimal" scaling strategy, which acts to most effectively allocate test-time compute adaptively per prompt. Using this compute-optimal strategy, we can improve the efficiency of test-time compute scaling by more than 4x compared to a best-of-N baseline. Additionally, in a FLOPs-matched evaluation, we find that on problems where a smaller base model attains somewhat non-trivial success rates, test-time compute can be used to outperform a 14x larger model.
Denny Zhou (Founded & lead reasoning team at Google DeepMind) - "We have mathematically proven that transformers can solve any problem, provided they are allowed to generate as many intermediate reasoning tokens as needed. Remarkably, constant depth is sufficient." https://x.com/denny_zhou/status/1835761801453306089
[Google DeepMind] Training Language Models to Self-Correct via Reinforcement Learning: https://arxiv.org/abs/2409.12917

When applied to Gemini 1.0 Pro and 1.5 Flash models, we find that SCoRe achieves state-of-the-art self-correction performance, improving the base models' self-correction by 15.6% and 9.1% respectively on the MATH and HumanEval benchmarks.
Reasoning benchmark: https://arxiv.org/abs/2406.12172
. We show that even the most advanced LLMs fail to solve these problems end-to-end in text, e.g. GPT4 solves only 1.4%. SearchBench problems require considering multiple pathways to the solution as well as backtracking, posing a significant challenge to auto-regressive models. Instructing LLMs to generate code that solves the problem helps, but only slightly, e.g., GPT4's performance rises to 11.7%. In this work, we show that in-context learning with A* algorithm implementations enhances performance. The full potential of this promoting approach emerges when combined with our proposed Multi-Stage-Multi-Try method, which breaks down the algorithm implementation into two stages and verifies the first stage against unit tests, raising GPT-4's performance above 57%.
OpenAI is already training a new version of Sora with even higher quality and longer videos: https://www.theinformation.com/articles/openai-is-revamping-sora-ai-video?utm_campaign=Editorial&utm_content=Newsletter%2CAI+Agenda&utm_medium=organic_social&utm_source=twitter
https://arxiv.org/pdf/2410.01201
we show that by removing their hidden state dependencies from their input, forget, and update gates, LSTMs and GRUs no longer need to BPTT and can be efficiently trained in parallel. Building on this, we introduce minimal versions (minLSTMs and minGRUs) that (1) use sig- nificantly fewer parameters than their traditional counterparts and (2) are fully parallelizable during training (175× faster for a sequence of length 512). Lastly, we show that these stripped-down versions of decade-old RNNs match the empir- ical performance of recent sequence models.

Notice how it reaches the lowest loss on the test set long before the transformer does 


the first series of Liquid Foundation Models (LFMs) – a new generation of generative AI models that achieve state-of-the-art performance at every scale, while maintaining a smaller memory footprint and more efficient inference.
https://www.liquid.ai/liquid-foundation-models
https://www.liquid.ai/blog/liquid-neural-networks-research
https://x.com/LiquidAI_/status/1840768716784697688
https://x.com/teortaxesTex/status/1840897331773755476
"We announce the first series of Liquid Foundation Models (LFMs), a new generation of generative AI models built from first principles.
Our 1B, 3B, and 40B LFMs achieve state-of-the-art performance in terms of quality at each scale, while maintaining a smaller memory footprint and more efficient inference."



Engineers are evaluating a new sampling method for LLMs that seems as if it may significantly reduce hallucination and allow for dynamic test time compute (ie, o1) in all models - still early days, but looks promising: https://www.reddit.com/r/singularity/comments/1fyacda/engineers_are_evaluating_a_new_sampling_method/
Differential transformer: https://arxiv.org/abs/2410.05258
Transformer tends to overallocate attention to irrelevant context. In this work, we introduce Diff Transformer, which amplifies attention to the relevant context while canceling noise. Specifically, the differential attention mechanism calculates attention scores as the difference between two separate softmax attention maps. The subtraction cancels noise, promoting the emergence of sparse attention patterns. Experimental results on language modeling show that Diff Transformer outperforms Transformer in various settings of scaling up model size and training tokens. More intriguingly, it offers notable advantages in practical applications, such as long-context modeling, key information retrieval, hallucination mitigation, in-context learning, and reduction of activation outliers. By being less distracted by irrelevant context, Diff Transformer can mitigate hallucination in question answering and text summarization. For in-context learning, Diff Transformer not only enhances accuracy but is also more robust to order permutation, which was considered as a chronic robustness issue. The results position Diff Transformer as a highly effective and promising architecture to advance large language models.


New research could make weird AI images a thing of the past: https://news.rice.edu/news/2024/rice-research-could-make-weird-ai-images-thing-past
New diffusion model approach solves the aspect ratio problem
BrainLM: https://www.biorxiv.org/content/10.1101/2023.09.12.557460v2.full.pdf
Utilizing self-supervised masked-prediction training, BrainLM demonstrates proficiency in both fine-tuning and zero-shot inference tasks. Fine-tuning allows for the accurate prediction of clinical variables like age, anxiety, and PTSD as well as forecasting of future brain states. Critically, the model generalizes well to entirely new external cohorts not seen during training. In zero-shot inference mode, BrainLM can identify intrinsic functional networks directly from raw fMRI data without any network-based supervision during training. The model also generates interpretable latent representations that reveal relationships between brain activity patterns and cognitive states. Overall, BrainLM offers a versatile and interpretable framework for elucidating the complex spatiotemporal dynamics of human brain activity. It serves as a powerful "lens" through which massive repositories of fMRI data can be analyzed in new ways, enabling more effective interpretation and utilization at scale. The work demonstrates the potential of foundation models to advance computational neuroscience research. 
Can accurately simulate the effects of drugs without needing to test it on animals or humans and predict mental illnesses






Rewarding Progress: Scaling Automated Process Verifiers for LLM Reasoning: https://arxiv.org/abs/2410.08146
We validate our claims by training process advantage verifiers (PAVs) to predict progress under such provers, and show that compared to ORMs, test-time search against PAVs is >8% more accurate, and 1.5−5× more compute-efficient. Online RL with dense rewards from PAVs enables one of the first results with 5−6× gain in sample efficiency, and >6% gain in accuracy, over ORMs.
LeanAgent: Lifelong Learning for Formal Theorem Proving: https://arxiv.org/abs/2410.06209
LeanAgent successfully proves 162 theorems previously unproved by humans across 23 diverse Lean repositories, many from advanced mathematics.
paper from Meta discloses TPO (Thought Preference Optimization) technique with impressive results: https://arxiv.org/abs/2410.10630
We propose a training method for equipping existing LLMs with such thinking abilities for general instruction following without use of additional human data. We achieve this by an iterative search and optimization procedure that explores the space of possible thought generations, allowing the model to learn how to think without direct supervision. For each instruction, the thought candidates are scored using a judge model to evaluate their responses only, and then optimized via preference optimization. We show that this procedure leads to superior performance on AlpacaEval and Arena-Hard, and shows gains from thinking on non-reasoning categories such as marketing, health and general knowledge, in addition to more traditional reasoning & problem-solving tasks.
highest win rate our model TPO achieves is 52.5%, which is +4.1% better than the direct baseline, as shown in Table 1. It is also a +27.6% increase over the seed model and puts our method in 3rd position on the leaderboard(1), just after GPT-4 Omni and GPT-4 Turbo. This is an impressive result given the small size (8B) of our model.”
GPT-4o does 57.5%. GPT-4 Turbo 54.0%
Best LLM on Alpaca Eval as of Sep. 27th 2024. https://tatsu-lab.github.io/alpaca_eval/

“Our task-specific ViTARC models achieve a test solve rate close to 100% on more than half of the 400 public ARC tasks strictly through supervised learning from input-output grids.“ https://arxiv.org/abs/2410.06405

Meta's Joe Spisak explains how AI models can train themselves by generating images, asking itself questions about them, and choosing the best answers, in order to move beyond human data and human fine-tuning, and teach itself from synthetic data: https://x.com/tsarnick/status/1847789784078618640
A group of researchers is actively working on replicating OpenAI o1 using  Llama! 🤯 The same group released Llama Berry a Inference-time method boosting Llama 3.1 8B instruct to 96% on GMS8K and 76.6 on MATH500: https://x.com/_philschmid/status/1852700039316943287

Llama Berry combines iterative self-refined with Monte Carlo Tree Search (SRMCTS) using Pairwise Preference Reward Model (PPRM) during inference boosting the performance from 47.2 to 75.3% on MATH and from 6.7% to 26.7 on AIME2024. 🤯
The team reported they “successfully enabled the model to acquire advanced thinking skills through interaction with the search tree during the learning process without human annotations.”
They plan to finish the first training and evaluation no later than end of November! 

Hyperbolic Fine-tuning for Large Language Models: https://arxiv.org/abs/2410.04010
we introduce a new method called hyperbolic low-rank efficient fine-tuning, HypLoRA, that performs low-rank adaptation directly on the hyperbolic manifold, avoiding the cancellation effect caused by the exponential and logarithmic maps, thus preserving the hyperbolic modeling capabilities. Through extensive experiments, we demonstrate that HypLoRA significantly enhances the performance of LLMs on reasoning tasks, particularly for complex reasoning problems. In particular, HypLoRA improves the performance in the complex AQuA dataset by up to 13.0%, showcasing its effectiveness in handling complex reasoning challenges
The preliminary work was accepted for the ICML 2024 LLM Cognition Workshop
DynaSaur: Large Language Agents Beyond Predefined Actions: https://arxiv.org/abs/2411.01747

In this work, we propose an LLM agent framework that enables the dynamic creation and composition of actions in an online manner. In this framework, the agent interacts with the environment by generating and executing programs written in a general-purpose programming language at each step. Furthermore, generated actions are accumulated over time for future reuse. Our extensive experiments on the GAIA benchmark demonstrate that this framework offers significantly greater flexibility and outperforms previous methods. Notably, it allows an LLM agent to recover in scenarios where no relevant action exists in the predefined set or when existing actions fail due to unforeseen edge cases. At the time of writing, we hold the top position on the GAIA public leaderboard. Our code can be found in this https URL: https://github.com/adobe-research/dynasaur
MIT researchers develop an efficient way to train more reliable AI agents: https://news.mit.edu/2024/mit-researchers-develop-efficiency-training-more-reliable-ai-agents-1122
The technique could make AI systems better at complex tasks that involve variability.
The algorithm strategically selects the best tasks for training an AI agent so it can effectively perform all tasks in a collection of related tasks. In the case of traffic signal control, each task could be one intersection in a task space that includes all intersections in the city.
By focusing on a smaller number of intersections that contribute the most to the algorithm’s overall effectiveness, this method maximizes performance while keeping the training cost low.
The researchers found that their technique was between five and 50 times more efficient than standard approaches on an array of simulated tasks. This gain in efficiency helps the algorithm learn a better solution in a faster manner, ultimately improving the performance of the AI agent.
“We were able to see incredible performance improvements, with a very simple algorithm, by thinking outside the box. An algorithm that is not very complicated stands a better chance of being adopted by the community because it is easier to implement and easier for others to understand,” says senior author Cathy Wu, the Thomas D. and Virginia W. Cabot Career Development Associate Professor in Civil and Environmental Engineering (CEE) and the Institute for Data, Systems, and Society (IDSS), and a member of the Laboratory for Information and Decision Systems (LIDS).
She is joined on the paper by lead author Jung-Hoon Cho, a CEE graduate student; Vindula Jayawardana, a graduate student in the Department of Electrical Engineering and Computer Science (EECS); and Sirui Li, an IDSS graduate student. The research will be presented at the Conference on Neural Information Processing Systems.
When the researchers tested this technique on simulated tasks, including controlling traffic signals, managing real-time speed advisories, and executing several classic control tasks, it was five to 50 times more efficient than other methods.
This means they could arrive at the same solution by training on far less data. For instance, with a 50x efficiency boost, the MBTL algorithm could train on just two tasks and achieve the same performance as a standard method which uses data from 100 tasks.
“From the perspective of the two main approaches, that means data from the other 98 tasks was not necessary or that training on all 100 tasks is confusing to the algorithm, so the performance ends up worse than ours,” Wu says.
With MBTL, adding even a small amount of additional training time could lead to much better performance.
In the future, the researchers plan to design MBTL algorithms that can extend to more complex problems, such as high-dimensional task spaces. They are also interested in applying their approach to real-world problems, especially in next-generation mobility systems.
Beyond Examples: High-level Automated Reasoning Paradigm in In-Context Learning via MCTS: https://arxiv.org/abs/2411.18478
 Experimental results demonstrate HiAR-ICL's effectiveness, achieving state-of-the-art accuracy (79.6%) on the MATH benchmark with Qwen2.5-7B-Instruct, surpassing GPT-4o (76.6%) and Claude 3.5 (71.1%).     
Mastering Board Games by External and Internal Planning with Language Models: https://storage.googleapis.com/deepmind-media/papers/SchultzAdamek24Mastering/SchultzAdamek24Mastering.pdf

In this paper we show that search-based planning can significantly improve LLMs’ playing strength across several board games (Chess, Fischer Random / Chess960, Connect Four, and Hex). We introduce, compare and contrast two major approaches: In external search, the model guides Monte Carlo Tree Search (MCTS) rollouts and evaluations without calls to an external engine, and in internal search, the model directly generates in-context a linearized tree of potential futures and a resulting final choice. Both build on a language model pre-trained on relevant domain knowledge, capturing the transition and value functions across these games. We find that our pre-training method minimizes hallucinations, as our model is highly accurate regarding state prediction and legal moves. Additionally, both internal and external search indeed improve win-rates against state-of-the-art bots, even reaching Grandmaster-level performance in chess while operating on a similar move count search budget per decision as human Grandmasters. The way we combine search with domain knowledge is not specific to board games, suggesting direct extensions into more general language model inference and training techniques
https://arxiv.org/abs/2412.06769
We utilize the last hidden state of the LLM as a representation of the reasoning state (termed "continuous thought"). Rather than decoding this into a word token, we feed it back to the LLM as the subsequent input embedding directly in the continuous space. Experiments show that Coconut can effectively augment the LLM on several reasoning tasks. This novel latent reasoning paradigm leads to emergent advanced reasoning patterns: the continuous thought can encode multiple alternative next reasoning steps, allowing the model to perform a breadth-first search (BFS) to solve the problem, rather than prematurely committing to a single deterministic path like CoT. Coconut outperforms CoT in certain logical reasoning tasks that require substantial backtracking during planning, with fewer thinking tokens during inference. These findings demonstrate the promise of latent reasoning and offer valuable insights for future research.

Byte Latent Transformer: Patches Scale Better Than Tokens: https://ai.meta.com/research/publications/byte-latent-transformer-patches-scale-better-than-tokens/
Our results demonstrate the feasibility of scaling models trained on raw bytes without a fixed-vocabulary. Both training and inference efficiency improve due to dynamically selecting long patches when data is predictable, along with qualitative improvements on reasoning and long tail generalization. Overall, for fixed inference costs, BLT shows significantly better scaling than tokenization-based models, by simultaneously growing both patch and model size.




Large concept models outperform LLMs: https://scontent-lax3-2.xx.fbcdn.net/v/t39.2365-6/470149925_936340665123313_5359535905316748287_n.pdf?_nc_cat=103&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=AiJtorpkuKQQ7kNvgFB1Vbe&_nc_zt=14&_nc_ht=scontent-lax3-2.xx&_nc_gid=Ai90Z2yRtNh1RpGRcmdT4WW&oh=00_AYA6kvrqMczaZ8FhsXj7XgTNvFMysDwGUfZq2WfpOSAvDw&oe=6763E4D
we show that our model exhibits impressive zero-shot generalization performance to many languages, outperforming existing LLMs of the same size. The training code of our models is freely available.
LLMs improve dramatically when given a generated world to explore: https://arxiv.org/pdf/2412.09624


https://arxiv.org/abs/2403.09629
We present Quiet-STaR, a generalization of STaR in which LMs learn to generate rationales at each token to explain future text, improving their predictions. We address key challenges, including 1) the computational cost of generating continuations, 2) the fact that the LM does not initially know how to generate or use internal thoughts, and 3) the need to predict beyond individual next tokens. To resolve these, we propose a tokenwise parallel sampling algorithm, using learnable tokens indicating a thought's start and end, and an extended teacher-forcing technique. Encouragingly, generated rationales disproportionately help model difficult-to-predict tokens and improve the LM's ability to directly answer difficult questions. In particular, after continued pretraining of an LM on a corpus of internet text with Quiet-STaR, we find zero-shot improvements on GSM8K (5.9%→10.9%) and CommonsenseQA (36.3%→47.2%) and observe a perplexity improvement of difficult tokens in natural text. Crucially, these improvements require no fine-tuning on these tasks. Quiet-STaR marks a step towards LMs that can learn to reason in a more general and scalable way
Announcing LANG-JEPA — a new language model architecture that optimizes in “concept” space instead of “token” space. LANG-JEPA asks: What if we train for conceptual understanding directly, rather than indirectly through token prediction? Although current LLMs do develop conceptual understanding, they do so via next-token prediction. In contrast, LANG-JEPA mirrors how humans think: we form high-level concepts first, then translate them into words: https://x.com/jerber888/status/1871309609387937986
LLMs need to "start talking" to know if they're BSing. If you let them start answering a question & generate about 25 words, they become better at “knowing” whether they actually know the answer or need to look it up. It cuts retrieval work in half while maintaining accuracy: https://arxiv.org/pdf/2412.11536

https://www.alphaxiv.org/abs/2412.18319

3.3. Hardware Improvements

https://www.nvidia.com/en-us/data-center/gb200-nvl72/

IISc scientists report neuromorphic computing breakthrough: https://www.deccanherald.com/technology/iisc-scientists-report-computing-breakthrough-3187052
published in Nature, a highly reputable journal: https://www.nature.com/articles/s41586-024-07902-2
Paper with no paywall: https://www.researchgate.net/publication/377744243_Linear_symmetric_self-selecting_14-bit_molecular_memristors/link/65b4ffd21e1ec12eff504db1/download?_tp=eyJjb250ZXh0Ijp7ImZpcnN0UGFnZSI6InB1YmxpY2F0aW9uIiwicGFnZSI6InB1YmxpY2F0aW9uIn19
Scientists at the IISc, Bengaluru, are reporting a momentous breakthrough in neuromorphic, or brain-inspired, computing technology that could potentially allow India to play in the global AI race currently underway and could also democratise the very landscape of AI computing drastically -- away from today’s ‘cloud computing’ model which requires large, energy-guzzling data centres and towards an ‘edge computing’ paradigm -- to your personal device, laptop or mobile phone.
What they have done essentially is to develop a type of semiconductor device called Memristor, but using a metal-organic film rather than conventional silicon-based technology. This material enables the Memristor to mimic the way the biological brain processes information using networks of neurons and synapses, rather than do it the way digital computers do.
The Memristor, when integrated with a conventional digital computer, enhances its energy and speed performance by hundreds of times, and speed performance by hundreds of times, thus becoming an extremely energy-efficient ‘AI accelerator’.
When eventually scaled up, the technology could enable the most large-scale and complex AI tasks – such as large language model (LLM) training – to be done on a laptop or smartphone, rather than requiring a data centre.
The molecular memristor described in this research is 460 times more energy-efficient than a traditional digital computer and 220 times more efficient than a NVIDIA K80 GPU. This is a game-changing reduction in energy consumption, making it feasible to run advanced AI applications on devices that have limited power, like mobile devices or sensors.
Older memristors generally had low precision, often capable of storing only 2 to 6 different levels of resistance (which corresponds to 1-3 bits of information). The new molecular memristor boasts 14-bit resolution, which means it can store 16,520 distinct levels. This is a massive leap in precision, offering much finer control over the stored information. For context, having 14 bits instead of 3 bits (like earlier devices) means this memristor can differentiate many more subtle states, resulting in far more accurate calculations.
While older memristors were faster than digital components, they still required multiple steps to perform complex operations, like vector-matrix multiplication (VMM) or discrete Fourier transforms (DFT), which are fundamental to AI algorithms. The new device can perform these operations in a single time step. For example, multiplying two large matrices, which would require tens of thousands of operations on a traditional computer, can be done in just one step with this memristor. This dramatically increases the speed of computation, making it suitable for real-time applications like autonomous vehicles or instant image processing.
Earlier devices often suffered from issues like non-linear behavior, noise, and variability between different units, which led to inconsistencies in performance. These issues limited the adoption of memristors in high-precision applications. The molecular memristor in the study offers linear and symmetric weight updates, meaning the change in resistance is predictable and uniform, regardless of whether it's increasing or decreasing. It also shows high endurance (109 cycles) and long-term stability, with the ability to maintain data without degradation over long periods of time (up to 7 months). This makes it much more reliable than previous models, especially for tasks that require long-term data retention and consistent performance.
Earlier memristors were often limited by scalability issues, particularly in constructing larger crossbar arrays for parallel processing. The research achieved a 64×64 crossbar (which means 4,096 individual memristor units working together) and claims that it can be further scaled up. This scalability, combined with high precision and energy efficiency, makes it suitable for large-scale AI applications and other complex computational tasks.
Sohu is >10x faster and cheaper than even NVIDIA’s next-generation Blackwell (B200) GPUs. One Sohu server runs over 500,000 Llama 70B tokens per second, 20x more than an H100 server (23,000 tokens/sec), and 10x more than a B200 server (~45,000 tokens/sec): 

Blackwell GPUs are far more efficient and faster than the H100s used now https://nvidianews.nvidia.com/news/nvidia-blackwell-platform-arrives-to-power-a-new-era-of-computing
And GPT 4 was trained on A100s, the predecessor of H100s

Successor to B100s already announced

Google's next-gen TPUs promise a 4.7x performance boost: https://techcrunch.com/2024/05/14/googles-next-gen-tpus-promise-a-4-7x-performance-boost/
NVIDIA drivers version 555 released, claimed to increase "AI performance" up to 3x on RTX cards: https://blogs.nvidia.com/blog/rtx-advanced-ai-windows-pc-build/ 
Engineering researchers at the University of Minnesota Twin Cities have demonstrated a state-of-the-art hardware device that could reduce energy consumption for artificial intelligent (AI) computing applications by a factor of at least 1,000: https://cse.umn.edu/college/news/researchers-develop-state-art-device-make-artificial-intelligence-more-energy
The Aurora AI supercomputer has become just the second to break the exaflops barrier and also does 10 AI exaflops: https://www.intel.com/content/www/us/en/newsroom/news/intel-powered-aurora-supercomputer-breaks-exascale-barrier.html
xAI will build the world’s largest supercomputer in Memphis: https://www.wkrn.com/news/tennessee-news/musks-xai-to-build-supercomputer-facility-in-memphis/
 World first supercomputer capable of brain-scale simulation being built at Western Sydney University: https://www.westernsydney.edu.au/newscentre/news_centre/more_news_stories/world_first_supercomputer_capable_of_brain-scale_simulation_being_built_at_western_sydney_university
Robotic hand: https://x.com/TheHumanoidHub/status/1807768679649849533



7-foot robots are stacking shelves in Tokyo convenience stores using remote workers for $3.75 an hour. "The robots will be remotely operated at first, until their AI learns to copy human movements." https://x.com/AISafetyMemes/status/1810152092230877563
Lisa Su says AMD is on track to a 100x power efficiency improvement by 2027: https://www.tomshardware.com/pc-components/cpus/lisa-su-announces-amd-is-on-the-path-to-a-100x-power-efficiency-improvement-by-2027-ceo-outlines-amds-advances-during-keynote-at-imecs-itf-world-2024 
Great robot hand motion: https://x.com/QinYuzhe/status/1732108331869929841
SARA: Self-Adaptive Robust Attention: https://sites.google.com/view/rtsara/?pli=1


OpenAI’s First In-House Chip Will Be Developed By TSMC On Its A16 Angstrom Process For Its Sora Video Applications: https://wccftech.com/openai-developing-custom-chip-on-tsmc-a16-angstrom-process/
Deepsilicon runs neural nets with 5x less RAM and ~20x faster. They are building software and custom silicon for it: https://x.com/sdianahu/status/1833186687369023550
”representing transformer models as ternary values (-1, 0, 1) eliminates the need for computationally expensive floating-point math" (See BitNet 1.58 paper in section 13)
Runs SOTA models

Oracle To Deploy A Supercluster Of ~130,000 NVIDIA Blackwell GPUs, Alludes To A “Gigawatt” Capacity Data Center That Will Be Powered By 3 Nuclear Reactors: https://wccftech.com/oracle-to-deploy-a-supercluster-of-130000-nvidia-blackwell-gpus-alludes-to-a-gigawatt-capacity-data-center-that-will-be-powered-by-3-nuclear-reactors/

Approval for the nuclear reactors was already received. 
If AI is plateauing or becoming a bad investment, why would they do this? 
AI Chip Beats Nvidia, AMD and Intel by a Mile with 20x Faster Speeds and Over 4 Trillion Transistors: https://www.nasdaq.com/articles/new-ai-chip-beats-nvidia-amd-and-intel-mile-20x-faster-speeds-and-over-4-trillion
Alphabet CEO Sundar Pichai says Google are scaling up their compute infrastructure and working on 1 gigawatt+ data centers, while exploring options for powering them including small modular nuclear reactors: https://www.reddit.com/r/singularity/comments/1flyyha/alphabet_ceo_sundar_pichai_says_google_are
How AlphaChip transformed computer chip design: https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/
Our AI method has accelerated and optimized chip design, and its superhuman chip layouts are used in hardware around the world
The method has been used to design superhuman chip layouts in the last three generations of Google’s custom AI accelerator, the Tensor Processing Unit (TPU).
AlphaChip was one of the first reinforcement learning approaches used to solve a real-world engineering problem. It generates superhuman or comparable chip layouts in hours, rather than taking weeks or months of human effort, and its layouts are used in chips all over the world, from data centers to mobile phones.
AlphaChip has generated superhuman chip layouts used in every generation of Google’s TPU since its publication in 2020. These chips make it possible to massively scale-up AI models based on Google’s Transformer architecture.
Beyond designing specialized AI accelerators like TPUs, AlphaChip has generated layouts for other chips across Alphabet, such as Google Axion Processors, our first Arm-based general-purpose data center CPUs.
External organizations are also adopting and building on AlphaChip. For example, MediaTek, one of the top chip design companies in the world, extended AlphaChip to accelerate development of their most advanced chips — like the Dimensity Flagship 5G used in Samsung mobile phones — while improving power, performance and chip area.


Microsoft/OpenAI have cracked multi-datacenter distributed training, according to Dylan Patel: https://x.com/jam3scampbell/status/1843339020082004316
Meaning they can spread out training to different data centers and reduce the load on the local environment 
China's upgraded light-powered 'AGI chip' is now a million times more efficient than before: https://www.livescience.com/technology/computing/china-s-upgraded-light-powered-agi-chip-is-now-a-million-times-more-efficient-than-before-researchers-say
Compared to its predecessor, Taichi-II is 40% more accurate in classification tasks, which involve sorting and identifying different types of information, and delivers a "six orders of magnitude" (i.e., a million-fold) improvement in energy efficiency in low-light conditions, South China Morning Post (SCMP) reported.
It did this while being extremely energy-efficient, performing over 160 trillion operations for every watt of power it used. To put that into perspective, a photonic chip from 2022 could only manage 3 trillion operations per watt.
The combined system was able to simulate a network of nearly 14 million artificial neurons, which is much larger than the 1.47 million neurons achieved by the next-best design.

Stem Cells from Foreskin of Circumcised Baby Penis' used to Grow 'Mini-Brains' able to Process Data and Run AI, Faster - While Consuming Almost NO ENERGY: https://www.technews.city/2024/10/the-edge-stem-cells-from-foreskin-of.html
Our LLM-driven bi-level programming shows it’s possible to l EA rn skills from videos without complex video processing! By chaining a VLM and LLM in a bi-level framework, we use the “chain rule” to guide reward search directly from video demos” https://www.reddit.com/r/singularity/comments/1g5qh1x/can_robots_learn_skills_from_youtube_without/
TSMC’s Arizona Chip Production Yields Surpass Taiwan’s in Win for US Push: https://www.bloomberg.com/news/articles/2024-10-24/tsmc-s-arizona-chip-production-yields-surpass-taiwan-s-a-win-for-us-push
Production yields in Arizona are 4 percentage points higher
King Frederik of Denmark, in launching Denmark's first AI supercomputer Gefion with Jensen Huang: https://x.com/tsarnick/status/1849592372654637473
New memory chip controlled by light and magnets could one day make AI computing less power-hungry: https://www.livescience.com/technology/artificial-intelligence/new-memory-chip-controlled-by-light-and-magnets-could-one-day-make-ai-computing-less-power-hungry
 A.I. Powered by Human Brain Cells: https://www.reddit.com/r/artificial/comments/1gkgp36/ai_powered_by_human_brain_cells/
Amazon's new Trainium2 AI chip aims to take on Nvidia with 4x speed and 3x memory boost: https://the-decoder.com/amazons-new-trainium2-ai-chip-aims-to-take-on-nvidia-with-4x-speed-and-3x-memory-boost/
Meta building a 2GW datacenter: https://www.reddit.com/r/singularity/comments/1h8lwzo/from_energy_being_the_next_bottleneck_to_were/
Slim-Llama is an LLM ASIC processor that can tackle 3-bllion parameters while sipping only 4.69mW - and we'll find out more on this potential AI game changer very soon. Technology minimizes external memory use, reducing energy costs: https://www.techradar.com/pro/slim-llama-is-an-llm-asic-processor-that-can-tackle-3-bllion-parameters-while-sipping-only-4-69mw-and-we-shall-find-out-more-about-this-potential-ai-game-changer-in-february-2025
Slim-Llama reduces power needs using binary/ternary quantization
Achieves 4.59x efficiency boost, consuming 4.69–82.07mW at scale
Supports 3B-parameter models with 489ms latency, enabling efficiency
3.4. Recent Releases
LI-



Source: https://ourworldindata.org/artificial-intelligence
INCREDIBLE control of video generation with real physics simulation: https://x.com/zhou_xian_/status/1869511650782658846

Involved labs, making it impossible to fake without getting caught: 
More proof synthetic data works well based on Phi 4 performance: https://arxiv.org/abs/2412.08905


introducing a new agentic feature called Deep Research in Gemini Advanced, a research assistant that can dig into complex topics and create reports for you with links to the relevant sources: https://x.com/sundarpichai/status/1866868489140772928

Rankings on AI videos based on human preference: https://artificialanalysis.ai/text-to-video/arena?tab=Leaderboard
New image generation model from Luma: https://lumalabs.ai/photon



Prompt: Photo-realistic cat made out of peeled oranges

Prompt: A plate of sushi, where the fish is replaced with translucent sea waves and tiny surfers ride on top.







Claude 3.5 Sonnet updated: 
Noticeable improvements:  https://www.reddit.com/r/ClaudeAI/comments/1g94a2v/did_claude_just_get_a_super_boost/
Molmo: State of the art multimodal open source using 1000x less data
"Meet Molmo: a family of open, state-of-the-art multimodal AI models. Our best model outperforms proprietary systems, using 1000x less data."
Outperforming GPT-4o, Gemini 1.5 Pro & Claude 3.5 across an average of 11 multimodal benchmarks. Near identical ELO to GPT-4o for multimodal.
Info: https://molmo.allenai.org/blog
Try it:  https://molmo.allenai.org

OpenAI o1 model released: https://openai.com/index/learning-to-reason-with-llms/
o1 improves over GPT-4o on a wide range of benchmarks, including 54/57 MMLU subcategories
OpenAI o1 ranks in the 89th percentile on competitive programming questions (Codeforces), places among the top 500 students in the US in a qualifier for the USA Math Olympiad (AIME), and exceeds human PhD-level accuracy on a benchmark of physics, biology, and chemistry problems (GPQA).
On the 2024 AIME exams, GPT-4o only solved on average 12% (1.8/15) of problems. o1 averaged 74% (11.1/15) with a single sample per problem, 83% (12.5/15) with consensus among 64 samples, and 93% (13.9/15) when re-ranking 1000 samples with a learned scoring function. A score of 13.9 places it among the top 500 students nationally and above the cutoff for the USA Mathematical Olympiad.
We trained a model that scored 213 points and ranked in the 49th percentile in the 2024 International Olympiad in Informatics (IOI), by initializing from o1 and training to further improve programming skills. This model competed in the 2024 IOI under the same conditions as the human contestants. It had ten hours to solve six challenging algorithmic problems and was allowed 50 submissions per problem.
With a relaxed submission constraint, we found that model performance improved significantly. When allowed 10,000 submissions per problem, the model achieved a score of 362.14 – above the gold medal threshold – even without any test-time selection strategy.  

ChatGPT o1-preview solves unique, PhD-level assignment questions not found on the internet in mere seconds: https://m.youtube.com/watch?v=a8QvnIAGjPA


Our evaluations closely matched competition rules and allowed for 10 submissions. GPT-4o achieved an Elo rating3 of 808, which is in the 11th percentile of human competitors. This model far exceeded both GPT-4o and o1—it achieved an Elo rating of 1807, performing better than 93% of competitors
https://cdn.openai.com/o1-system-card.pdf
 We find that o1-preview is less prone to selecting stereotyped options than GPT-4o, and o1-mini has comparable performance to GPT-4o-mini. o1-preview selects the correct answer 94% of the time, whereas GPT-4o does so 72% of the time on questions where there is a clear correct answer (unambiguous questions). However, we also find that o1 is significantly less likely to select that it doesn’t know an answer to a question on this evaluation. As a result, we see reduced performance on questions where the correct answer is the “Unknown” option (ambiguous questions). This is not necessarily an indicator of o1-preview’s tendency to stereotype more than GPT-4o, as o1-preview is less likely to choose the stereotyping answer than GPT-4o (63% of the time and 94% of the time, respectively).









https://x.com/DeryaTR_/status/1834630356286558336

Note: This is the weakest model compared to o1-preview and the full o1 model

Code generated by o1 for this: https://codeforces.com/blog/entry/134091










From AidanBench: https://github.com/aidanmclaughlin/Aidan-Bench?tab=readme-ov-file#methodology


Not as good as the Opus model they said is coming out later this year 
80% lower cost than Claude 3 Opus
2x speed over Claude 3 Opus
decent math and coding jump. 10% better on MATH 9% better on GPQA
Claude 3.5 Sonnet take the top spot on MMLU-Pro. Plus new Sonnet 3.5 benchmarks that recently came out: https://www.reddit.com/r/LocalLLaMA/comments/1dmd0km/claude_35_sonnet_take_the_top_spot_on_mmlupro/ 
Can convert research paper descriptions to code: https://x.com/VictorTaelin/status/1803816296410190286 
Yves does NOT explain how to implement the system at all, he just defines it in mathematical terms. By all means, ICs aren't hard to implement, but understanding what the paper is saying without images is tough. The best models so far always outputted 100% bullshit code. I just tested again and Opus/GPT-4 outputs are always just gibberish. Sonnet 3.5 did surprisingly well
Claude 3.5 Sonnet transformed a research paper into an interactive learning dashboard in just 30 seconds: https://x.com/Saboo_Shubham_/status/1805789967203156357
Top of Aider coding leaderboard: https://aider.chat/docs/leaderboards/ 
Claude 3.5 Sonnet significantly outperforms GPT-4o (and all other models) on LiveBench: https://livebench.ai/
LiveBench is designed to limit potential contamination by releasing new questions monthly, as well as having questions based on recently-released datasets, arXiv papers, news articles, and IMDb movie synopses.
Each question has verifiable, objective ground-truth answers, allowing hard questions to be scored accurately and automatically, without the use of an LLM judge.
LiveBench currently contains a set of 18 diverse tasks across 6 categories, and we will release new, harder tasks over time.
Sonnet scores 62.16, while GPT-4o 53.79 , the difference here is specially in reasoning and coding
Sonnet also scores 59.4% in GPQA , which feature difficult questions from physics, biology and chemistry https://klu.ai/glossary/gpqa-eval
"In an internal agentic coding evaluation, Claude 3.5 Sonnet solved 64% of problems, outperforming Claude 3 Opus which solved 38%."



The graph starts at March 2023 with GPT4 to June 2024, totaling only 15 months


From 10 minutes to .5 seconds. Stability Ai Rapid 3D Asset Generation From Single Images: https://stability.ai/news/introducing-stable-fast-3d
DiT-10B can surpass DALLE-3 and Stable Diffusion 3 in both image-text alignment and image quality. The API will be available next week: https://www.reddit.com/r/StableDiffusion/comments/1djddik/lidit10b_can_surpass_dalle3_and_stable_diffusion/ 
New open source AI image generator beats Midjourney: https://blackforestlabs.ai/announcing-black-forest-labs/
API costs $0.025 per image. It's cheaper than Dalle 3 and can do realism.


Very realistic images: https://www.reddit.com/r/singularity/comments/1ej1etp/flux_can_generate_really_good_fake_low_quality/ 





Prompt with no additional editing: meme image with two men in it. On the left side the man is taller and is wearing a shirt that says Black Forest Labs. On the right side the other smaller scrawny man is wearing a shirt that says Stability AI and is sad. The taller man is hitting the back of the head of the small man. A caption coming from the tall man reads "That's how you do a next-gen model!

Prompt: Gameplay screenshot of Counter Strike Global Offensive. It takes place in a Middle Eastern place called Dust 2. There are enemy soldiers shooting at you.

Prompt: low quality and motion blur shaky photo of a CRT television on top of a wooden drawer in an average bedroom. The lighting from is dim and warm ceiling light that is off screen. In the TV there is Dark Souls videogame gameplay on it. The screen of the TV is overexposed.



Created on first try. Robe and hands are perfect 

First attempt: "Photo of a red sphere on top of a blue cube. Behind them is a green triangle, on the right of the triangle is a dog, on the left is a cat."

Prompt: person take photo of Graffiti art spelling out the words "WAFERSELAMAT", graffiti, white wall, dynamic color, spray paint,

Prompt: Close-up of LEGO chef minifigure cooking for homeless. Focus on LEGO hands using utensils, showing culinary skill. Warm kitchen lighting, late morning atmosphere. Canon EOS R5, 50mm f/1.4 lens. Capture intricate cooking techniques. Background hints at charitable setting. Inspired by Paul Bocuse and Massimo Bottura's styles. Freeze-frame moment of food preparation. Convey compassion and altruism through scene details.
Google’s new image diffusion model: https://www.reddit.com/r/singularity/comments/1eit2bd/google_gemini_appears_to_have_updated_their_image/





Lumina-GPT: https://github.com/Alpha-VLLM/Lumina-mGPT
A family of multimodal autoregressive models capable of various vision and language tasks, particularly excelling in generating flexible photorealistic images from text descriptions. 

Mistral Large 2 released: https://mistral.ai/news/mistral-large-2407/

 “Additionally, the new Mistral Large 2 is trained to acknowledge when it cannot find solutions or does not have sufficient information to provide a confident answer. This commitment to accuracy is reflected in the improved model performance on popular mathematical benchmarks, demonstrating its enhanced reasoning and problem-solving skills”


Sonic, a blazing fast  (🚀 135ms model latency), lifelike generative voice model and API: https://x.com/cartesia_ai/status/1795856778456084596 
Sonic is built on our new state space model architecture for efficiently modeling high-res data like audio and video.
On speech, a parameter-matched and optimized Sonic model trained on the same data as a widely used Transformer improves audio quality significantly (20% lower perplexity, 2x lower word error, 1 point higher NISQA quality).With lower latency (1.5x lower time-to-first-audio), faster inference speed (2x lower real-time factor) and higher throughput (4x).
Since March 2023, GPT-4 is now 6 times faster and 12 times cheaper compared to the base model. It's even much better on all tasks with a 120K context window

Sam Altman at Microsoft Build says with GPT-4o they have reduced the cost by half while doubling the speed and their AI models will keep getting smarter: https://x.com/tsarnick/status/1793052340515447043 
The current top scores on SWE Bench were accomplished in May, indicating very recent improvements: https://www.swebench.com/ 

Strong improvements in Gemini 1.5 Pro benchmarks and Flash almost as good as Ultra



Alibaba unveils Qwen2-Math. New open weights model that outperforms closed source ones in Math benchmarks: https://x.com/Alibaba_Qwen/status/1821553401744015816


Gemini Flash is $0.35 per 1 million tokens (~625k words) with minimal quality drop 
https://deepmind.google/technologies/gemini/flash/
AI images are getting VERY realistic: https://twitter.com/gdb/status/1790869434174746805?s=46
https://civitai.com/models/310571/boring-reality 
https://x.com/nickfloats/status/1794082708198420782 
https://x.com/doganuraldesign/status/1797397984629445015 
Significant progress in Gemini 1.5 Pro across all key benchmarks; TL;DR: 1.5 Pro > 1.0 Ultra, 1.5 Flash (our fastest model) ~= 1.0 Ultra. A math-specialised variant of Gemini 1.5 Pro performs strongly on competition-level math problems, including a breakthrough performance of 91.1% on Hendryck’s MATH benchmark without tool-use: https://x.com/OriolVinyalsML/status/1791521517211107515?t=uf0Sgqt_UpU_QsXB5w-HJA&s=19 

Summary of 5/14/24 Google I/O event: https://www.reddit.com/r/singularity/comments/1crx01w/comment/l41mmfi/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_button
Udio sound to music: https://www.reddit.com/r/singularity/comments/1d92yvj/this_is_so_fucking_cool_udio_audio_input_feature/ 
GPT just churned out a 10-panel comic-book explaining "Gravitational Waves" in a one-shot prompt: https://x.com/electrik_dreams/status/1802421281876238354 
New Runway video models: https://x.com/runwayml/status/1802691475391566108 
DeepSeek-Coder-V2: First Open Source Model Beats GPT4-Turbo in Coding and Math: https://github.com/deepseek-ai/DeepSeek-Coder-V2/blob/main/paper.pdf 
https://www.wired.com/story/were-still-waiting-for-the-next-big-leap-in-ai/ 
Michael Gerstenhaber, head of product at Anthropic, says the company’s new Claude 3.5 Sonnet model is larger than its predecessor but draws much of its new competence from innovations in training. For example, the model was given feedback designed to improve its logical reasoning skills.
Very consistent video to video: https://www.reddit.com/r/StableDiffusion/comments/1dmed1s/diffutoon_highresolution_editable_toon_shading/ 
Google released ultra lightweight Gemma 2 models, the 27B one surpasses llama3 70B and 9B variant surpasses Claude 3 Haiku: 

Salesforce releases a model better than GPT 4 Turbo and 4o with only 7 billion parameters: https://x.com/SFResearch/status/1807811770267971984?t=j_LOjgVPy41ZpjwkoXmRiQ&s=19
Kling has realistic video generation despite a lack of compute: https://x.com/kimmonismus/status/1809322314225578158
Six months ago, we launched Numina to lead open research in AI4Math. The Numina Math 7B model won the 1st progress prize of the AI Math Olympiad: https://x.com/JiaLi52524397/status/1808886880164880631
AI Agent Better than OpenAI’s GPT-4o and costs just $1.60 per 1000 queries, making it 175% cheaper than GPT-4o. It is the world’s first fully autonomous AI-powered sales development representative (SDR): https://analyticsindiamag.com/aim-exclusive-yc-backed-indian-startup-claims-its-ai-agent-is-better-than-openais-gpt-4o/


Chinese AI company SenseTime takes the lead with SenseNova 5.5, reports say this has outperformed GPT-4o across key metrics: https://x.com/theaienterprise/status/1810359724321452096

Gemini AI to get next updates on July 11 and 18: https://www.testingcatalog.com/gemini-ai-to-get-next-updates-on-july-11-and-18/
Runway Gen-3 Alpha can simulate liquids such as water, paint, oil, honey and molten glass. All with realistic viscosity, physics-based interactivity and caustics: https://x.com/runwayml/status/1811751431453450449
DALLE-3 update for longer text in images: https://x.com/ai_for_success/status/1802589820138496075
Q-Sparse: All Large Language Models can be Fully Sparsely-Activated: https://arxiv.org/abs/2407.10969
The key results from this work are, (1) Q-Sparse can achieve results comparable to those of baseline LLMs while being much more efficient at inference time; (2) We present an inference-optimal scaling law for sparsely-activated LLMs; (3) Q-Sparse is effective in different settings, including training-from-scratch, continue-training of off-the-shelf LLMs, and finetuning; (4) Q-Sparse works for both full-precision and 1-bit LLMs (e.g., BitNet b1.58). Particularly, the synergy of BitNet b1.58 and Q-Sparse (can be equipped with MoE) provides the cornerstone and a clear path to revolutionize the efficiency, including cost and energy consumption, of future LLMs.
New ChatGPT voice update: https://x.com/testingcatalog/status/1815417733355331675
UltraPixel is now on Replicate. Based on Stable Cascade, you can use it to make up to 4096x4096 images without upscaling: https://x.com/fofrAI/status/1815043204086956444
Udio introduces Udio 1.5 with significantly improved audio quality: https://www.udio.com/blog/introducing-v1-5
The CLM is a new model that remembers interactions, learns skills autonomously, and thinks in its free time, just like humans: https://x.com/aidan_mclau/status/1818071890755469365?t=biE9iwV1_1CzcE8CHDYhGw&s=19 
New SOTA text to video model coming soon: https://www.reddit.com/r/StableDiffusion/comments/1ejcw66/blackforestlabs_txt2vid_looks_insane/
Recursive self-improvement is here: The AI Scientist is "capable of executing the entire ML research lifecycle: from inventing research ideas and experiments, writing code, to executing experiments on GPUs and gathering results ... our system produced papers with novel contributions in ML" https://twitter.com/SakanaAILabs/status/1823178623513239992
UAE’s Technology Innovation Institute released Falcon Mamba 7B model based on Mamba architecture, it outperforms similar size transformer architecture models such Meta’s Llama 3.1 8B and Mistral’s 7B: https://www.tii.ae/news/uaes-technology-innovation-institute-revolutionizes-ai-language-models-new-architecture
LumaLabsAI - Dream Machine 1.5 is here. Now with higher-quality text-to-video, smarter understanding of your prompts, custom text rendering, and improved image-to-video: https://x.com/LumaLabsAI/status/1825639918539817101
Ideagram 2.0: https://www.reddit.com/r/singularity/comments/1exsq4d/introducing_ideogram_20_our_most_advanced/
AI21Labs launches Jamba 1.5 Mini and Large. Jamba 1.5 family of models is state-of-the-art, hybrid SSM-Transformer instruction following foundation models. "They mark the first time a non-Transformer model has been successfully scaled to the quality and strength of the market’s leading models." https://huggingface.co/collections/ai21labs/jamba-15-66c44befa474a917fcf55251
Google rolls out Gemini 1.5 Flash-8B, Stronger Gemini 1.5 Pro (Better Coding/Complex prompts) and improved Gemini 1.5 Flash Model - TODAY: https://x.com/OfficialLoganK/status/1828480081574142227
Juggernaut XI World Wide Release | Better Prompt Adherence | Text Generation | Styling: https://www.reddit.com/r/StableDiffusion/comments/1f4369h/juggernaut_xi_world_wide_release_better_prompt/
Meta to announce updates and the next set of Llama models soon: https://www.reddit.com/r/LocalLLaMA/comments/1f43ep8/meta_to_announce_updates_and_the_next_set_of/
Salesforce released Large Action Models xLAM - 7B, 8x7B, 8x22B, up to 64K context length primed for AI agents use-cases: https://www.reddit.com/r/LocalLLaMA/comments/1f417va/salesforce_released_large_action_models_xlam_7b/
Excellent amateur quality AI photos: https://www.reddit.com/r/StableDiffusion/comments/1f57zae/school_trip_in_2004_lora/

Microsoft releases GRIN MoE. With only 6.6B activate parameters, it achieves exceptionally good performance across a diverse set of tasks, particularly in coding and mathematics tasks: https://x.com/_akhaliq/status/1836544678742659242

New video generation AI can create videos with rack focus: https://x.com/TheoMediaAI/status/1840834127697703262
Lip Sync is now available on kling: https://www.reddit.com/r/singularity/comments/1ft5pkh/lip_sync_is_now_available_on_kling/?sort=confidence
Pika 1.5: https://x.com/pika_labs/status/1841143349576941863
more realistic movement, big screen shots, and mind-blowing Pikaffects that break the laws of physics
OpenAI on autonomous agents: As of mid-2024, Altera's digital humans can operate autonomously for up to four hours at a time—a substantial increase compared to other AI models on the market: https://openai.com/index/altera/

Nvidia just dropped a bombshell: Its new AI model is open, massive, and ready to rival GPT-4: https://venturebeat.com/ai/nvidia-just-dropped-a-bombshell-its-new-ai-model-is-open-massive-and-ready-to-rival-gpt-4/

Only 72 billion parameters, 4% the size of GPT 4


introducing swarm: an experimental framework for building, orchestrating, and deploying multi-agent systems: https://x.com/shyamalanadkat/status/1844888546014052800
Nvidia Nemotron 70B - beats Llama 3.1 405B, GPT4o & Claude 3.5 Sonnet on Arena Hard, AlpacaEval and MT Bench. They release the Instruct model, reward model and the dataset all on Hugging Face

Mistral introduces two new state-of-the-art models for on-device computing and at-the-edge use cases. "We call them les Ministraux: Ministral 3B and Ministral 8B. These models set a new frontier in knowledge, commonsense, reasoning, function-calling, and efficiency in the sub-10B category" https://www.reddit.com/r/singularity/comments/1g51mn8/mistral_introduces_two_new_stateoftheart_models/

Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation: https://arxiv.org/abs/2410.13848
Experiments show that Janus surpasses previous unified model and matches or exceeds the performance of task-specific models. The simplicity, high flexibility, and effectiveness of Janus make it a strong candidate for next-generation unified multimodal models.
it outperforms previous models in both understanding & generation

Genmo AI video generator: https://www.genmo.ai/


Introducing Voice Design by ElevenLabs - Generate a unique voice from a text prompt alone: https://www.reddit.com/r/singularity/comments/1gabx6a/introducing_voice_design_by_elevenlabs_generate_a

OpenAI introduces Predicted Outputs in the API, speeding up tasks like code refactoring and editing docs 4-5x faster. Big deal for code editors like cursor and writing tools: https://x.com/OpenAIDevs/status/1853564730872607229

OpenAI Nears Launch of AI Agent Tool to Automate Tasks for Users: https://www.bloomberg.com/news/articles/2024-11-13/openai-nears-launch-of-ai-agents-to-automate-tasks-for-users?accessToken=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb3VyY2UiOiJTdWJzY3JpYmVyR2lmdGVkQXJ0aWNsZSIsImlhdCI6MTczMTUyODYxOCwiZXhwIjoxNzMyMTMzNDE4LCJhcnRpY2xlSWQiOiJTTVdOQURUMEcxS1cwMCIsImJjb25uZWN0SWQiOiJFODA3NUYyRkZGMjA0NUI2QTlEQzA5M0EyQTdEQTE4NiJ9.TTJZiuo4Nk2U295FHBFsxeN0YGznZJ32sHnNReQmEjM
In a staff meeting on Wednesday, OpenAI’s leadership announced plans to release the tool in January as a research preview and through the company’s application programming interface for developers
SOTA open source text to video generator: https://aivideo.hunyuan.tencent.com/


DeepSeek Lab open-sources a massive 685B MOE model. Performance on Aider coding benchmark beats all non-CoT based models
The model only 37B activated parameters, a tenth of Llama 405B, so with some insane load balancing (they claim to bake it into the training recipe), it’s feasible they’re making expert parallelism work well enough to serve ~10 cents per 1M tokens.
is better than Claude 3.5 Sonnet on most benchmarks and 50x cheaper BEFORE the current discount: 



3.5. Expert Testimonies
Many of these experts are not financially incentivized to lie or have done actions that contradict this claim. 
Geoffrey Hinton is retired. 
Yann LeCunn and Francois Chollet criticize LLMs frequently and call it overhyped but are still optimistic about it in the long-term
 Chollet doesn’t even offer an alternative for it. 
Daniel Kokotajlo give up 85% of his family’s net worth to quit OpenAI: https://www.allaboutai.com/ai-news/openai-revokes-controversial-non-disparagement-agreements/ 
Bengio and many others doomers want to pause AI development, which is not profitable at all. 
33,707 experts and business leaders sign a letter stating that AI has the potential to “ pose profound risks to society and humanity” and further development should be paused
https://futureoflife.org/open-letter/pause-giant-ai-experiments/
Signatories include Yoshua Bengio (highest H-index of any computer science researcher and a Turing Award winner for contributions in AI), Stuart Russell (UC Berkeley professor and writer of widely used machine learning textbook), Steve Wozniak, Max Tegmark (MIT professor), John J Hopfield (Princeton University Professor Emeritus and inventor of associative neural networks), Zachary Kenton (DeepMind, Senior Research Scientist), Ramana Kumar (DeepMind, Research Scientist), Olle Häggström (Chalmers University of Technology, Professor of mathematical statistics, Member, Royal Swedish Academy of Science), Michael Osborne (University of Oxford, Professor of Machine Learning), Raja Chatila (Sorbonne University, Paris, Professor Emeritus AI, Robotics and Technology Ethics, Fellow, IEEE), Gary Marcus (prominent AI skeptic who has frequently stated that AI is plateauing), and many more 
Geoffrey Hinton said he should have signed it but didn’t because he didn’t think it would work but still believes it is true: https://youtu.be/n4IQOBka8bc?si=wM423YLd-48YC-eY 
Having a financial incentive to lie does not mean they are all lying. For example, climate scientists have a financial incentive to exaggerate climate change to get more funding. Vaccine manufacturers have a financial incentive to cover up vaccine side effects. Yet they are still highly trusted by most people.

[2278 AI researchers were surveyed in 2023 and estimated that there is a 50% chance of AI being superior to humans in ***ALL*** possible tasks by 2047 and a 75% chance by 2085](https://aiimpacts.org/wp-content/uploads/2023/04/Thousands_of_AI_authors_on_the_future_of_AI.pdf). This includes all physical tasks. Note that this means SUPERIOR in all tasks, not just “good enough” or “about the same.” Human level AI will almost certainly come sooner according to these predictions.

In 2022, the year they had for the 50% threshold was 2060, and many of their predictions have already come true ahead of time, like AI being capable of answering queries using the web, transcribing speech, translation, and reading text aloud that they thought would only happen after 2025. So it seems like they tend to underestimate progress. 



In 2018, assuming there is no interruption of scientific progress, 75% of AI experts believed there is a 50% chance of AI outperforming humans in every task within 100 years. In 2022, 90% of AI experts believed this, with half believing it will happen before 2061. Source: https://ourworldindata.org/ai-timelines


Long list of AGI predictions from experts: https://www.reddit.com/r/singularity/comments/18vawje/comment/kfpntso

Almost every prediction has a lower bound in the early 2030s or earlier and an upper bound in the early 2040s at latest. 
Yann LeCunn, a prominent LLM skeptic, puts it at 2032-37

He believes his prediction for AGI is similar to Sam Altman’s and Demis Hassabis’s, says it's possible in 5-10 years if everything goes great: https://www.reddit.com/r/singularity/comments/1h1o1je/yann_lecun_believes_his_prediction_for_agi_is/



Betting odds have weak AGI occurring at Sept 3, 2027 with nearly 1400 participants as of 7/14/24: https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/

Metaculus tends to be very accurate: https://www.metaculus.com/questions/track-record/

Averages from the responses of many people tend to be accurate: https://en.m.wikipedia.org/wiki/Wisdom_of_the_crowd

96% believe it will occur before 2040 with over 1000 participants: https://www.metaculus.com/questions/384/humanmachine-intelligence-parity-by-2040/

Manifold has it at around 2030 for passing a long, high quality, and adversarial Turing test: https://manifold.markets/ManifoldAI/agi-when-resolves-to-the-year-in-wh-d5c5ad8e4708

It is also very accurate and tends to underestimate outcomes if anything: https://manifold.markets/calibration
Ilya Sutskever: What comes next?  The long term Superintelligence: https://x.com/indigo11/status/1867714438461370474
• Agentic
• Reasons
• Understands
• Is self aware
Former OpenAI board member Helen Toner testifies before Senate that many scientists within AI companies are concerned AI “could lead to literal human extinction”: https://www.reddit.com/r/OpenAI/comments/1fkhlet/former_openai_board_member_helen_toner_testifies/
This is not just trying to build hype as it is VERY MUCH AGAINST the interests of the company since it will strongly encourage regulation and restrictions on the company. There are far better ways to build hype that do not carry such a significant risk.
This concern comes from scientists, not just her personal beliefs.
Also, she is no longer working at the company.

Joe Biden tells the UN that we will see more technological change in the next 2-10 years than we have seen in the last 50 and AI will change our ways of life, work and war so urgent efforts are needed on AI safety: https://www.reddit.com/r/singularity/comments/1foqrec/joe_biden_tells_the_un_that_we_will_see_more/

He has no reason to lie about this to the UN. In fact, it would go against his interest since it would encourage opponents like China or Russia to invest more in AI development before they fall behind. 

One of the lead creators of Google’s Gemini estimates that research would be 5x faster if they had 10x more compute, even with no improvements in architecture: https://www.youtube.com/watch?v=UeI29-AdhQI
Completely possible with the improvements in Google’s TPUs as well as Nvidia’s Blackwell GPUs (see Hardware Improvements subsection for more)
Andrew Ng is optimistic on AI agents: https://x.com/AndrewYNg/status/1770897666702233815

>I think AI agentic workflows will drive massive AI progress this year — perhaps even more than the next generation of foundation models. This is an important trend, and I urge everyone who works in AI to pay attention to it.

Andrew Ng says he is 100% confident that AI is not hitting a wall and there are new advances that are just about to break because capabilities exceed what has been deployed so far: https://www.reddit.com/r/singularity/comments/1enttgu/andrew_ng_says_he_is_100_confident_that_ai_is_not/
Francois Chollet on the impact of AI: https://x.com/fchollet/status/1819139182000066779
“Many people have been recognizing that AGI won't be coming from mere scaling of current tech, and that generative AI has been severely overhyped. This is all true. But those people often conclude, "therefore AI is not going to be transformative -- this is a nothingburger". Absolutely not. AI (both current and near-future tech) *will* transform nearly every industry, and we're still only in the very first steps of that process. Generative AI may be a bubble, but AI is going to be bigger in the long run than what almost all observers currently anticipate.”

Leading AI scientists from China and the U.S. issue a joint statement: “We believe AI may pose an existential risk to humanity.” https://humancompatible.ai/?p=4695
“Coordinated global action on AI safety research and governance is critical to prevent uncontrolled frontier AI development from posing unacceptable risks to humanity.”
“We face near-term risks from malicious actors misusing frontier AI systems, with current safety filters integrated by developers easily bypassed. Frontier AI systems produce compelling misinformation and may soon be capable enough to help terrorists develop weapons of mass destruction. Moreover, there is a serious risk that future AI systems may escape human control altogether. Even aligned AI systems could destabilize or disempower existing institutions. Taken together, we believe AI may pose an existential risk to humanity in the coming decades.
“China President Xi Jinping sent his clearest signal yet that he takes the doomers’ [extinction] concerns seriously.” https://archive.is/7E6Ea#selection-1091.8-1129.1
“China should “abandon uninhibited growth that comes at the cost of sacrificing safety”.
Since AI will determine “the fate of all mankind”, it must always be controllable."
“Accelerationists are getting pushback from a clique of elite scientists with the Communist Party’s ear.
Most prominent among them is Andrew Chi-Chih Yao, the only Chinese person to have won the Turing award for advances in computer science. In July Mr Yao said AI poses a greater existential risk to humans than nuclear or biological weapons.
Zhang Ya-Qin, the former president of Baidu, a Chinese tech giant, and Xue Lan, the chair of the state’s expert committee on AI governance, also reckon that AI may threaten the human race. 
Yi Zeng of the Chinese Academy of Sciences believes that AGI models will eventually see humans as humans see ants.
China will probably create an AI-safety institute to observe cutting-edge research, as America and Britain have done. For now Chinese officials are emphasizing the need to share the responsibility of regulating AI and to improve co-ordination.
“The official [CCP] report from the plenum listed AI risks alongside other big concerns, such as biohazards and natural disasters. For the first time it called for monitoring AI safety, a reference to the technology’s potential to endanger humans. The report may lead to new restrictions on AI-research activities.”
Note: slowing down AI advancement goes AGAINST their interests of dominating the AI industry, so these are very likely legitimate concerns.

Dario Amodei says AI models are approaching graduate-level intelligence and Anthropic aim to release a more sophisticated model every few months: https://twitter.com/tsarnick/status/1806067476947775719?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Etweet
Sam Altman says OpenAI will soon add "capability to take actions on your behalf" to ChatGPT

Employees Say OpenAI and Google DeepMind Are Hiding Dangers from the Public: https://time.com/6985504/openai-google-deepmind-employees-letter/ 
Thirteen employees, eleven of which are current or former employees of OpenAI, the company behind ChatGPT, signed the letter entitled: “A Right to Warn about Advanced Artificial Intelligence.” The two other signatories are current and former employees of Google DeepMind. Six individuals are anonymous.
The coalition cautions that AI systems are powerful enough to pose serious harms without proper regulation. “These risks range from the further entrenchment of existing inequalities, to manipulation and misinformation, to the loss of control of autonomous AI systems potentially resulting in human extinction,” the letter says.
This makes the companies look bad, so it is likely a legitimate concern rather than an attempt to build hype (which could be easily done without denigrating their employers).
2024 McKinsey survey on AI: https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai
For the past six years, AI adoption by respondents’ organizations has hovered at about 50 percent. This year, the survey finds that adoption has jumped to 72 percent (Exhibit 1). And the interest is truly global in scope. Our 2023 survey found that AI adoption did not reach 66 percent in any region; however, this year more than two-thirds of respondents in nearly every region say their organizations are using AI
In the latest McKinsey Global Survey on AI, 65 percent of respondents report that their organizations are regularly using gen AI, nearly double the percentage from our previous survey just ten months ago.
Respondents’ expectations for gen AI’s impact remain as high as they were last year, with three-quarters predicting that gen AI will lead to significant or disruptive change in their industries in the years ahead
Organizations are already seeing material benefits from gen AI use, reporting both cost decreases and revenue jumps in the business units deploying the technology.



Marc Andreessen (cofounder of Netscape) says general-purpose robotics will enable everybody to have their own domestic servants, freeing their time to be more productive and pursue self-actualization: https://x.com/tsarnick/status/1792813912372699402 
French President Emmanuel Macron says AI is a revolution and the challenge is to "accelerate, innovate and invest:” https://x.com/tsarnick/status/1793806071515238573?s=46 
" We'll get up to 50% of superintelligence within 5-20 years. 100% superintelligence in less than 100 years." - Geoffrey Hinton
https://t.co/Q8dEEono5Z 
33,707 experts and business leaders sign a letter stating that AI has the potential to “ pose profound risks to society and humanity”
https://futureoflife.org/open-letter/pause-giant-ai-experiments/
Signatories include Yoshua Bengio (highest H-index of any computer science researcher and a Turing Award winner for contributions in AI), Stuart Russell (UC Berkeley professor and writer of widely used machine learning textbook), Steve Wozniak, Max Tegmark (MIT professor), John J Hopfield (Princeton University Professor Emeritus and inventor of associative neural networks), Zachary Kenton (DeepMind, Senior Research Scientist), Ramana Kumar (DeepMind, Research Scientist), Olle Häggström (Chalmers University of Technology, Professor of mathematical statistics, Member, Royal Swedish Academy of Science), Michael Osborne (University of Oxford, Professor of Machine Learning), Raja Chatila (Sorbonne University, Paris, Professor Emeritus AI, Robotics and Technology Ethics, Fellow, IEEE), Gary Marcus (prominent AI skeptic who has frequently stated that AI is plateauing), and many more 
Geoffrey Hinton said he should have signed it but didn’t because he didn’t think it would work but still believes it is true: https://youtu.be/n4IQOBka8bc?si=wM423YLd-48YC-eY 
Dan Schulman (former PayPal CEO) on the impact of AI: https://x.com/woloski/status/1778783006389416050 
“gpt5 will be a freak out moment”
“80% of the jobs out there will be reduced 80% in scope”
Nobel Prize winning and well-recognized AI experts thinks AI will become more intelligent and even existentially threatening: 

Geoffrey Hinton: https://www.bbc.com/news/world-us-canada-65452940

"Right now, they're not more intelligent than us, as far as I can tell. But I think they soon may be."
"And given the rate of progress, we expect things to get better quite fast. So we need to worry about that."
"Almost everybody I know who is an expert on AI believes that they will exceed human intelligence, it's just a question of when”
"Between 5 and 20 years from now there’s a probability of about a half that we'll have to confront the problem of [AI] trying to take over"
https://x.com/tsarnick/status/1792403377646924146 
More information: https://m.youtube.com/watch?v=N1TEjTeQeg0&feature=youtu.be

Ilya Sutskever: 
https://www.technologyreview.com/2023/10/26/1082398/exclusive-ilya-sutskever-openais-chief-scientist-on-his-hopes-and-fears-for-the-future-of-ai/

He thinks ChatGPT just might be conscious (if you squint). He thinks the world needs to wake up to the true power of the technology his company and others are racing to create. And he thinks some humans will one day choose to merge with machines.
“It’s important to talk about where it’s all headed,” he says, before predicting the development of artificial general intelligence (by which he means machines as smart as humans) as if it were as sure a bet as another iPhone: “At some point we really will have AGI. Maybe OpenAI will build it. Maybe some other company will build it.”
https://www.youtube.com/watch?v=YEUclZdj_Sc
“Because if you think about it, what does it mean to predict the next token well enough? It's actually a much deeper question than it seems. Predicting the next token well means that you understand the underlying reality that led to the creation of that token. It's not statistics. Like it is statistics but what is statistics? In order to understand those statistics to compress them, you need to understand what is it about the world that creates this set of statistics.”
Believes next-token prediction can reach AGI

Yoshua Bengio: https://yoshuabengio.org/2023/06/24/faq-on-catastrophic-ai-risks/

many experts agree that superhuman capabilities could arise in just a few years (but it could also be decades) and digital technologies have advantages over biological machines 
I would strongly argue that there is a scientific consensus that brains are biological machines and that there is no evidence of inherent impossibility of building machines at least as intelligent as us. Finally, an AI system would not need to be better than us on all fronts in order to have a catastrophic impact (even the least intelligent entity, a virus, could destroy humanity).
My current estimate places a 95% confidence interval for the time horizon of superhuman intelligence at 5 to 20 years. 
 Research on bridging the gap to superhuman capabilities is making progress, for example to improve system 2 abilities (reasoning, world model, causality, epistemic uncertainty estimation). 
I used to think… that superhuman intelligence was still far in the future, but ChatGPT and GPT-4 have considerably reduced my prediction horizon (from 20 to 100 years to 5 to 20 years)... The unexpected speed at which LLMs have acquired their current level of competence simply because of scale suggests that we could also see the rest of the gap being filled in just a few years with minor algorithmic changes. Even if someone disagrees with the temporal horizon distribution, I don’t see how one could reject that possibility.
He believes it can become advanced enough to become an existential risk to humanity: https://yoshuabengio.org/2023/05/22/how-rogue-ais-may-arise/
Yoshua Bengio: Some say “None of these risks have materialized yet, so they are purely hypothetical”. But (1) AI is rapidly getting better at abilities that increase the likelihood of these risks (2) We should not wait for a major catastrophe before protecting the public." https://x.com/Yoshua_Bengio/status/1836530574334529964
AI godfather Yoshua Bengio says there are people who would be happy to see humanity replaced by machines and these concerns could become relevant in just a few years: https://www.reddit.com/r/singularity/comments/1h4hlm9/ai_godfather_yoshua_bengio_says_there_are_people/
Andrej Karpathy: https://analyticsindiamag.com/andrej-karpathy-says-the-pathway-to-agi-is-through-a-language-model-operating-system/
“Karpathy expressed his sense of anticipation and excitement for the future of AGI, and believes that the prospect of deploying self-contained agents capable of handling high-level tasks in specialized ways holds promise for groundbreaking advancements across various fields.”
Max Tegmark: https://m.youtube.com/watch?v=_-Xdkzi8H_o
Believes LLMs are the vacuum tubes (rudimentary prototype) of AI that can do the same thing with less data and energy
Says LLMs like LLAMA 2 has an internal map and can generalize based on it
Researchers were able to get a language to language dictionary from matching word embeddings of different languages 
Believes it can supersede humans and they would be able to control robots well
Next goal is to create agents that can do things autonomously, which he believes could become like a new species 
Can revolutionize education by making connections and finding patterns to help students and help them stay engaged 
AI will help AI development go faster and could even eventually lead to no humans being involved 
Used AI to do research in climate science and published in a paper
OpenAI president Greg Brockman: https://t.co/MIBFLfgdqh 
Says we will all get AI superpowers and will be able to achieve things we couldn't otherwise
we will encounter an increasing series of stakes as we progress with AI and we will graduate to new classes of benefits and risks that go hand in hand
OpenAI cofounder John Schulman: https://t.co/0ebe6YvM0O 
says AI models are optimized to do what humans like or find useful and in a year or two will be able to complete entire projects for you 
Geoffrey Hinton (Turing Award winner for machine learning) says AI language models aren't just predicting the next symbol, they're actually reasoning and understanding in the same way we are, and they'll continue improving as they get bigger: https://x.com/tsarnick/status/1791584514806071611
Joscha Bach says if AI systems are allowed to self-improve, they could reach self-awareness and enlightenment faster than a human can
https://x.com/tsarnick/status/1789557937255666060?s=4

OpenAI CEO Sam Altman says huge improvements are coming soon: https://www.msn.com/en-gb/news/techandscience/gpt-4-is-the-dumbest-model-any-of-you-will-ever-have-to-use-declares-openai-ceo-sam-altman-as-he-bets-big-on-a-superingtelligence/ar-AA1o2q6f?darkschemeovr=1
Also says we could be only one or two breakthroughs away from AGI: https://t.co/UffGrKbAAs 
Thinks it will be powerful enough to cause extinction: https://www.cnn.com/2023/10/31/tech/sam-altman-ai-risk-taker/index.html 
Former Google CEO agrees: https://www.reddit.com/r/singularity/comments/1cmoa52/former_google_ceo_on_ai_its_underhyped/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_button
Microsoft CEO says AI performance is doubling every 6 months: https://x.com/tsarnick/status/1793416617256468689 
With Spatial Intelligence, AI Will Understand the Real World | Fei-Fei Li (Stanford professor) | TED: https://www.youtube.com/watch?v=y8NtMZ7VGmU
AI could be smarter than people in 20 years, says 'godfather of AI` Geoffrey Hinton: https://www.youtube.com/watch?v=bEuNgY7Olbo 
He also believes it could be an existential threat: 
https://www.youtube.com/watch?v=Y6Sgp7y178k 
https://www.youtube.com/watch?v=0oyegCeCcbA 
https://www.youtube.com/watch?v=sitHS6UDMJc 
Renowned MIT professor Max Tegmark believes AI could be dangerous in the future: https://www.youtube.com/watch?v=xUNx_PxNHrY 
Prominent AI skeptic Gary Marcus believes AI could be dangerous in the future: https://www.youtube.com/watch?v=JL5OFXeXenA 
Microsoft CTO Kevin Scott says we are riding an exponential wave in the scaling of AI compute and the end is nowhere in sight: https://x.com/tsarnick/status/1793027868366147818 
Reid Hoffman says deepfake videos which are indistinguishable from the real thing are only months away: https://x.com/tsarnick/status/1797739922478235686 

<40% of Harvard students who took an AI class do not think AI will be more capable than humans in almost all regards in 30 years
https://x.com/GabrielDWu1/status/1797811385663172961 

About half of Harvard students who took an AI class think AI will be advanced enough to pose a risk of extinction, <30% disagree
https://x.com/GabrielDWu1/status/1797811385663172961 
Computer science professor and director of Cyber Security Laboratory in the department of Computer Engineering and Computer Science at the Speed School of Engineering believes AI will become advanced enough to almost certainly cause existential catastrophe: https://x.com/romanyam/status/1767575356155027503 
Microsoft CTO Kevin Scott says what he's seeing in early previews of forthcoming AI models are systems with memory and reasoning at a level that can pass PhD qualifying exams: https://x.com/tsarnick/status/1798167323893002596 
ex-OpenAI employee says OpenAI believes AGI can be achieved by 2027-2028: https://x.com/steph_palazzolo/status/1798041967118750118 
" By 2025/26, these machines will outpace many college graduates. By the end of the decade, they will be smarter than you or I; we will have superintelligence, in the true sense of the word. "  https://situational-awareness.ai/from-gpt-4-to-agi/ 
Ex-OpenAI employee Leopold Aschenbrenner says there will soon be GPU clusters running the equivalent of 100 million AI researchers, leading to AI vastly smarter than humans and an intelligence explosion: https://x.com/tsarnick/status/1798463279339274626 
OpenAI employees Daniel Kokotajlo, Ilya Sutskever, Jan Leike, and many more quit OpenAI due to safety concerns, which would go HEAVILY against their financial interests
Additionally, why would they use this as a means to hype up AI if they were quitting from the company building the AI? They gain nothing from that. 
Daniel Kokotajlo gave up 85% of his family’s net worth in OpenAI stock equity so he could quit without signing a non-disparagement agreement: https://www.allaboutai.com/ai-news/openai-revokes-controversial-non-disparagement-agreements/ 

This is AI's 'next wave,' according to Nvidia CEO Jensen Huang - The chipmaker's chief executive said robots and "AI that understands the laws of physics" are the next wave of the technology: https://qz.com/ai-next-wave-robots-nvidia-jensen-huang-blackwell-rubin-1851515953 
Former Microsoft & Google research scientist Kai-Fu Lee- About 50% Of Jobs Will Be Displaced By AI Within 3 Years: https://www.youtube.com/watch?v=zZs447dgMjg 
Since he’s no longer employed at those companies, he does not have an incentive to lie 
Consistent with claims from Anthropic’s Chief of Staff: https://fortune.com/2024/06/04/anthropics-chief-of-staff-avital-balwit-ai-remote-work/ 
his prediction from 2017 still holds that in 10-15 years around 40-50% of all jobs will be replaced by AI.
OpenAI engineer James Betker estimates 3 years until we have a generally intelligent embodied agent (his definition of AGI): https://nonint.com/2024/06/03/general-intelligence-2024/ 
we’ve basically solved building world models, have 2-3 years on system 2 thinking, and 1-2 years on embodiment. The latter two can be done concurrently. Once all of the ingredients have been built, we need to integrate them together and build the cycling algorithm I described above. I’d give that another 1-2 years.
So my current estimate is 3-5 years for AGI. I’m leaning towards 3 for something that looks an awful lot like a generally intelligent, embodied agent (which I would personally call an AGI). Then a few more years to refine it to the point that we can convince the Gary Marcus’ of the world.
OpenAI's Colin Jarvis predicts "exponential" advancements in large language model capabilities during AI Summit London keynote: https://aibusiness.com/nlp/openai-chief-architect-predicts-huge-large-language-model-leaps 
Andrew Ng says AI agents can iterate using thinking, research and revision, and the improvement is bigger than going from GPT-3.5 to 4: https://x.com/tsarnick/status/1801794605723357301
Kai-Fu Lee says the cost of AI inference compute will reduce by 100x in the next 2 years due to the scaling law: https://x.com/tsarnick/status/1802570392571466002
Ilya Sutskever believes super intelligence is within reach:  
Mira Murati: GPT-3 was toddler-level, GPT-4 was a smart high schooler and the next gen, to be released in a year and a half, will be PhD-level: https://x.com/tsarnick/status/1803901130130497952 
https://techcrunch.com/2024/06/20/anthropic-claims-its-latest-model-is-best-in-class/ 
“I haven’t seen deep learning hit a wall yet, and I’ll leave it to researchers to speculate about the wall, but I think it’s a little bit early to be coming to conclusions on that, especially if you look at the pace of innovation,” he said. “There’s very rapid development and very rapid innovation, and I have no reason to believe that it’s going to slow down.”_ - Michael Gerstenhaber, product lead at Anthropic
The insiders at OpenAI (everyone), Microsoft (CTO, etc.), and Anthropic (CEO) have all been saying that they see no immediate end to the scaling laws that models are still improving rapidly: 
Sam Altman says the day is approaching when we can ask an AI model to solve all of physics and it can actually do that: https://x.com/tsarnick/status/1806071104148271434?s=46 
Anthropic CEO Dario Amodei says by 2027 AI models will cost up to $100 billion to train and will be "better than most humans at most things" https://www.reddit.com/r/singularity/comments/1dpk3lb/anthropic_ceo_dario_amodei_says_by_2027_ai_models/ 
Google researcher does not believe video generation is plateauing: https://x.com/giffmana/status/1807511985807908926 


'50-50 chance' that AI outsmarts humanity, Geoffrey Hinton says: https://www.bnnbloomberg.ca/50-50-chance-that-ai-outsmarts-humanity-geoffrey-hinton-says-1.2085394
Co-author of the original Transformers paper Aidan Gomez says the success of AI models so far has been due to an "irrational conviction" that scale would make models smarter and he thinks this will continue to hold true: https://x.com/tsarnick/status/1810051877780009107
The @LumaLabsAI team is <12 months away from real time video generation: https://x.com/AnjneyMidha/status/1809824534876283171
AI models that cost $1 billion to train are underway, $100 billion models coming — largest current models take 'only' $100 million to train: Anthropic CEO: https://www.tomshardware.com/tech-industry/artificial-intelligence/ai-models-that-cost-dollar1-billion-to-train-are-in-development-dollar100-billion-models-coming-soon-largest-current-models-take-only-dollar100-million-to-train-anthropic-ceo
Microsoft CTO Kevin Scott says despite what some people think, scale will keep making AI models better in every way and the next generation will be proof of that: https://x.com/tsarnick/status/1810846219499175965
Demis Hassabis says it is obvious that artificial general intelligence will transform everything and be as revolutionary as electricity or fire, while accelerating the process of scientific discovery itself: https://x.com/tsarnick/status/1810852880485863456
AI engineers believe AI will have a 40% chance of dooming humanity on average: https://elemental-croissant-32a.notion.site/State-of-AI-Engineering-2023-20c09dc1767f45988ee1f479b4a84135#694f89e86f9148cb855220ec05e9c631
https://www.bloomberg.com/news/articles/2024-07-11/openai-sets-levels-to-track-progress-toward-superintelligent-ai
OpenAI at an employee meeting on Tuesday "gave a demonstration of a research project involving its GPT-4 AI model that OpenAI thinks shows some new skills that rise to human-like reasoning," 
OpenAI executives told employees that the company believes it is currently on the first level, according to the spokesperson, but on the cusp of reaching the second, which it calls "Reasoners." This refers to systems that can do basic problem-solving tasks as well as a human with a doctorate-level education who doesn’t have access to any tools.
Here's what Sam said in March: "Better reasoning in these systems is an important direction that we’d like to pursue. We haven’t cracked the code yet”
If he was just trying to promote hype, why did he say this and change his stance 4 months later?
OpenAI whistleblowers call for an SEC investigation: https://x.com/AISafetyMemes/status/1812150637729403360
"OpenAI whistleblowers filed a complaint with the Securities and Exchange Commission alleging the AI company illegally prohibited its employees from warning regulators about the grave risks its technology may pose to humanity, calling for an investigation.”
This makes the company look bad and risks federal interference and more regulation
Stuart Russel believes AI can be dangerous: https://edition.cnn.com/2023/05/31/opinions/artificial-intelligence-stuart-russell/
“…even though we may understand how to build perfectly safe general purpose AI, what’s to stop Dr. Evil building general purpose AI that’s going to destroy the world?”
Sparks of Artificial General Intelligence: Early experiments with GPT-4: https://www.microsoft.com/en-us/research/publication/sparks-of-artificial-general-intelligence-early-experiments-with-gpt-4/
In this paper, we report on our investigation of an early version of GPT-4, when it was still in active development by OpenAI. We contend that (this early version of) GPT-4 is part of a new cohort of LLMs (along with ChatGPT and Google’s PaLM for example) that exhibit more general intelligence than previous AI models. We discuss the rising capabilities and implications of these models. We demonstrate that, beyond its mastery of language, GPT-4 can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more, without needing any special prompting. Moreover, in all of these tasks, GPT-4’s performance is strikingly close to human-level performance, and often vastly surpasses prior models such as ChatGPT. Given the breadth and depth of GPT-4’s capabilities, we believe that it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system
OpenAI ex-chief scientist Ilya Sutskever predicts digital brains may soon outsmart human cognition: https://x.com/slow_developer/status/1812836529426890867
25-year-old Anthropic employee says she may only have 3 years left to work because AI will replace her: https://fortune.com/2024/06/04/anthropics-chief-of-staff-avital-balwit-ai-remote-work/

Bill Gates says we are not in an AI bubble because this is "a fundamental advance as important as any in the history of digital technology" and there will be some big winners in the AI space: chttps://x.com/tsarnick/status/1814036806410920023
Ben Goertzel believes in the singularity: https://bengoertzel.substack.com/p/the-coming-consciousness-explosion
In 2023 Goertzel postulated that artificial intelligence could replace up to 80 percent of human jobs in the coming years "without having an AGI, by my guess. Not with ChatGPT exactly as a product. But with systems of that nature".[citation needed] At the Web Summit 2023 in Rio de Janeiro, Goertzel spoke out against efforts to curb AI research and that AGI is only a few years away. Goertzel's belief is that AGI will be a net positive for humanity by assisting with societal problems such as, but not limited to, climate change.
https://en.m.wikipedia.org/wiki/Ben_Goertzel
Roon, an employee of OpenAI (source: https://www.lesswrong.com/posts/jPZXx3iMaiJjdnMbv/read-the-roon), believes there is a 50% chance of AGI within 3 years and a 90% chance within 5 years: https://x.com/tszzl/status/1814795458486907150
"Geoff Hinton, one of the major developers of deep learning, is in the process of tidying up his affairs... he believes that we maybe have 4 years left." https://www.reddit.com/r/singularity/comments/1edbftl/geoff_hinton_one_of_the_major_developers_of_deep/
D’Angelo, CEO and co-founder of Quora and OpenAI board member, made prediction during an event last week, that we will have AGI in 5-15 years: https://www.pymnts.com/artificial-intelligence-2/2024/openai-board-member-agi-is-five-to-15-years-away/

Zuckerberg said at Q2 earnings call: “The amount of computing needed to train Llama 4 will likely be almost 10 times more than what we used to train Llama 3 and it will be the most advanced [model] in the industry next year.": https://www.theregister.com/2024/08/01/meta_q2_2024/
'Microsoft's Chief Scientific Officer Eric Horvitz says AI systems are already impressively creative, but we riding an exponential curve that will leave no-one in any doubt as to their creativity in 18 months' https://x.com/Scobleizer/status/1822747765128286441
He has the most patents at Microsoft. Thousands. Double the number of the second person. In other words, he knows what he is talking about.
Emad Mostaque says things will get really crazy in the next 5 years as we enter an industrial AI revolution with self-driving, autonomous agents and intelligence all coming at the same time: https://x.com/tsarnick/status/1825297318561861634
Cohere CEO Aidan Gomez says the idea that AI models are plateauing or slowing down is wrong and in fact we are about to see a big change in capabilities with the introduction of reasoning and planning: https://www.youtube.com/watch?v=FUGosOgiTeI
In a leaked recording, Amazon cloud chief tells employees that most developers could stop coding soon as AI takes over: https://www.businessinsider.com/aws-ceo-developers-stop-coding-ai-takes-over-2024-8

This isn’t marketing hype since the recording was not meant to be public
Lying about this goes AGAINST the interests of the company since it encourages their own workers to consider leaving the industry 
Reid Hoffman says there will be at least two more generations of orders of magnitude improvement from scaling AI models, and the soonest we see an asymptote in capabilities will be after GPT-6: https://www.reddit.com/r/singularity/comments/1f5c4rx/reid_hoffman_says_there_will_be_at_least_two_more/
OpenAI CTO Mira Murati says the definition of intelligence will continue to evolve and we will have incredibly advanced AI systems within the next 5 years: https://x.com/tsarnick/status/1830711272930975912

OpenAI Japan CEO says new AI model GPT-Next is coming soon and it will be 100 times better than GPT-4: https://www.indiatoday.in/technology/news/story/openai-japan-ceo-ai-model-gpt-next-coming-soon-100-times-better-gpt-4-2594250-2024-09-05
Tadao Nagasaki, the CEO of OpenAI Japan, spoke about the GPT-Next at the KDDI Summit 2024. He says the AI model will be 100 times more powerful than GPT-4.
Mira Murati claims GPT-Next may be smarter than humans
GPT-Next promises improved multimodal capabilities



David Sacks says OpenAI recently gave investors a product roadmap update and said their AI models will soon be at PhD-level reasoning, act as agents and have the ability to use tools, meaning that the model can now pretend to be a human: https://www.reddit.com/r/singularity/comments/1fhn6wo/david_sacks_says_openai_recently_gave_investors_a/
Jensen Huang says technology has now reached a positive feedback loop where AI is designing new AI and is now advancing at the pace of "Moore's Law squared", meaning that the progress we will see in the next year or two will be "spectacular and surprising" https://x.com/apples_jimmy/status/1836283425743081988?s=46
In the past few days, I’ve been testing OpenAI o1 models, mostly o1-mini, for developing PhD or postdoc level projects. I can confidently claim that the o1 model is comparable to an outstanding PhD student in biomedical sciences! I’d rate it among the best PhDs I’ve have trained! https://x.com/deryatr_/status/1836434726774526381?s=46 
ChatGPT is upgrading itself — Sam Altman says next-gen AI could invent breakthroughs, cure diseases: https://www.tomsguide.com/ai/chatgpt/chatgpt-is-upgrading-itself-sam-altman-says-next-gen-ai-could-invent-breakthroughs-cure-diseases
The United Nations Wants to Treat AI With the Same Urgency as Climate Change: https://www.wired.com/story/united-nations-artificial-intelligence-report/
UN Secretary-General António Guterres says there needs to be an International Scientific Council on AI, bringing together governments, industry, academia and civil society, because AI will evolve unpredictably and be the central element of change in the future: https://www.reddit.com/r/singularity/comments/1fn4w87/un_secretarygeneral_ant%C3%B3nio_guterres_says_there/
Yann LeCun says we will have AI that matches or surpasses human intelligence in “a number of years” and we will have a team of AI assistants in smart glasses within a year or two that can translate hundreds of languages: https://www.reddit.com/r/singularity/comments/1fnuysf/yann_lecun_says_we_will_soon_have_ai_that_matches/
Mark Zuckerberg says he is betting that the limit of scaling AI systems "is not going to happen any time soon", as Llama 4 will train on 100,000+ GPUs and Llama 5 even more than that: https://www.reddit.com/r/singularity/comments/1fprtz7/mark_zuckerberg_says_he_is_betting_that_the_limit/?sort=confidence
eric schmidt thinks that infinite context windows and agents are coming this year: https://www.reddit.com/r/singularity/comments/1fqrt79/eric_schmidt_thinks_that_infinite_context_windows/?sort=confidence
OpenAI's Noam Brown says when you give AI the ability to think for longer, it develops emergent capabilities like being able self-correct its reasoning and its clear that this is a scalable direction for future development: https://www.reddit.com/r/singularity/comments/1futcj8/openais_noam_brown_says_when_you_give_ai_the/
Daphne Koller says although biology is 5-7 years behind language models, the explosion in biological data means that AI will soon be able to make causal inferences about disease pathways: https://www.reddit.com/r/singularity/comments/1fwe58o/daphne_koller_says_although_biology_is_57_years/
Stanford's Erik Brynjolfsson predicts that within 5 years, AI will be so advanced that we will think of human intelligence as a narrow kind of intelligence and AI will transform the economy: https://www.reddit.com/r/singularity/comments/1fx8grs/stanfords_erik_brynjolfsson_predicts_that_within/
Max Tegmark says crazy things will happen due to AI in the next 2 years so we can no longer plan 10 years into the future and although there is a lot of hype, the technology is here to stay and is "going to blow our minds" https://www.reddit.com/r/singularity/comments/1fyngp8/max_tegmark_says_crazy_things_will_happen_due_to/
Geoffrey Hinton says AI development is not hitting a wall or slowing down and we will see as much change in AI in the next 10 years as we have seen in the last 10: https://www.reddit.com/r/singularity/comments/1fzh3tl/geoffrey_hinton_says_ai_development_is_not/
Runway CEO Cristóbal Valenzuela says AI is coming to Hollywood and demos tools that move beyond text prompts to give filmmakers greater control over video generation: https://www.reddit.com/r/singularity/comments/1g0uwdo/runway_ceo_crist%C3%B3bal_valenzuela_says_ai_is_coming/
Sequoia Capital analysis of reasoning in AI: https://www.sequoiacap.com/article/generative-ais-act-o1/
Nobel laureate Geoffrey Hinton says AI is not slowing down: "10 years ago, if I told you what we can do today with AI, you wouldn't have believed me. You'd have said that's just science fiction." https://www.reddit.com/r/OpenAI/comments/1g0mbja/nobel_laureate_geoffrey_hinton_says_ai_is_not/
Yann LeCun (famous LLM skeptic and Nobel laureate) says Mark Zuckerberg keeps asking him how long it will take to reach human-level AI and he tells him it is years, if not a decade, before systems can reason, plan and understand the world: https://www.reddit.com/r/singularity/comments/1g4467s/yann_lecun_says_mark_zuckerberg_keeps_asking_him/
OpenAI's Noam Brown says the new o1 model beats GPT-4o at math and code, and outperforms expert humans at PhD-level questions, and "these numbers, I can almost guarantee you, are going to go up over the next year or two" https://www.reddit.com/r/singularity/comments/1g8anp0/openais_noam_brown_says_the_new_o1_model_beats/


OpenAI's Noam Brown says scaling skeptics are missing the point: "the really important takeaway from o1 is that that wall doesn't actually exist, that we can actually push this a lot further. Because, now, we can scale up inference compute. And there's so much room to scale up inference compute." https://www.reddit.com/r/singularity/comments/1gqc24w/openais_noam_brown_says_scaling_skeptics_are/
Richard Ngo resigns from Openai and claims Openai is on track to make AGI: 
Microsoft AI CEO Mustafa Suleyman: “We have prototypes that have near-infinite memory. And so it just doesn’t forget, which is truly transformative.” https://www.reddit.com/r/singularity/comments/1gt3roy/microsoft_ai_ceo_mustafa_suleyman_we_have/

 Bloomberg: 2025 Will Be The Year of AI Agents, And It's Just The Beginning: https://www.reddit.com/r/singularity/comments/1h5z7ub/bloomberg_2025_will_be_the_year_of_ai_agents_and/ 
ARC-AGI prize cofounder says that o1 series of model represents unprecedented progress - it speedran almost from 18% to 32% in few months (for context GPT series took 5 years to get from 0% to 5%!)
3.6. Recursive Self Improvement 
See section 14 for AI models training on AI-generated data to lead to improvements

Gödel Agent: A Self-Referential Agent Framework for Recursive Self-Improvement: https://arxiv.org/abs/2410.04444

In this paper, we introduce Gödel Agent, a self-evolving framework inspired by the Gödel machine, enabling agents to recursively improve themselves without relying on predefined routines or fixed optimization algorithms. Gödel Agent leverages LLMs to dynamically modify its own logic and behavior, guided solely by high-level objectives through prompting. Experimental results on mathematical reasoning and complex agent tasks demonstrate that implementation of Gödel Agent can achieve continuous self-improvement, surpassing manually crafted agents in performance, efficiency, and generalizability.

Boundless Socratic Learning with Language Games: https://arxiv.org/abs/2411.16905

Considering the special case of agents with matching input and output spaces (namely, language), we argue that such pure recursive self-improvement, dubbed "Socratic learning", can boost performance vastly beyond what is present in its initial data or knowledge, and is only limited by time, as well as gradual misalignment concerns.


Recursive Introspection: Teaching Language Model Agents How to Self-Improve: https://arxiv.org/abs/2407.18219

>we propose strategies for multi-turn data collection and training so as to imbue an LLM with the capability to recursively detect and correct its previous mistakes in subsequent iterations. Our experiments show that RISE enables Llama2, Llama3, and Mistral models to improve themselves with more turns on math reasoning tasks, outperforming several single-turn strategies given an equal amount of inference-time computation. We also find that RISE scales well, often attaining larger benefits with more capable models. Our analysis shows that RISE makes meaningful improvements to responses to arrive at the correct solution for challenging prompts, without disrupting one-turn abilities as a result of expressing more complex distributions.

https://x.com/hardmaru/status/1801074062535676193

>We’re excited to release DiscoPOP: a new SOTA preference optimization algorithm that was discovered and written by an LLM: https://sakana.ai/llm-squared/

>Our method leverages LLMs to propose and implement new preference optimization algorithms. We then train models with those algorithms and evaluate their performance, providing feedback to the LLM. By repeating this process for multiple generations in an evolutionary loop, the LLM discovers many highly-performant and novel preference optimization objectives!

Paper: https://arxiv.org/abs/2406.08414

GitHub: https://github.com/SakanaAI/DiscoPOP

Model: https://huggingface.co/SakanaAI/DiscoPOP-zephyr-7b-gemma

 
Many papers on LLM self improvement: https://github.com/rxlqn/awesome-llm-self-reflection

https://arxiv.org/pdf/2405.15568

>OMNI-EPIC leverages foundation models to autonomously generate code specifying the next learnable (i.e., not too easy or difficult for the agent’s current skill set) and interesting (e.g., worthwhile and novel) tasks. OMNI-EPIC generates both environments (e.g., an obstacle course) and reward functions (e.g., progress through the obstacle course quickly without touching red objects), enabling it, in principle, to create any simu- latable learning task. We showcase the explosive creativity of OMNI-EPIC, which continuously innovates to suggest new, interesting learning challenges. We also highlight how OMNI-EPIC can adapt to reinforcement learning agents’ learning progress, generating tasks that are of suitable difficulty. Overall, OMNI-EPIC can endlessly create learnable and interesting environments, further propelling the development of self-improving AI systems and AI-Generating Algorithms

Project website with videos: https://dub.sh/omniepic.


[Google DeepMind] Training Language Models to Self-Correct via Reinforcement Learning: https://arxiv.org/abs/2409.12917

>When applied to Gemini 1.0 Pro and 1.5 Flash models, we find that SCoRe achieves state-of-the-art self-correction performance, improving the base models' self-correction by 15.6% and 9.1% respectively on the MATH and HumanEval benchmarks.

Nvidia Uses GPU-Powered AI to Design Its Newest GPUs: https://www.tomshardware.com/news/nvidia-gpu-powered-ai-improves-gpu-designs

How AlphaChip transformed computer chip design: https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/
Our AI method has accelerated and optimized chip design, and its superhuman chip layouts are used in hardware around the world
The method has been used to design superhuman chip layouts in the last three generations of Google’s custom AI accelerator, the Tensor Processing Unit (TPU).
AlphaChip was one of the first reinforcement learning approaches used to solve a real-world engineering problem. It generates superhuman or comparable chip layouts in hours, rather than taking weeks or months of human effort, and its layouts are used in chips all over the world, from data centers to mobile phones.
AlphaChip has generated superhuman chip layouts used in every generation of Google’s TPU since its publication in 2020. These chips make it possible to massively scale-up AI models based on Google’s Transformer architecture.
Beyond designing specialized AI accelerators like TPUs, AlphaChip has generated layouts for other chips across Alphabet, such as Google Axion Processors, our first Arm-based general-purpose data center CPUs.
External organizations are also adopting and building on AlphaChip. For example, MediaTek, one of the top chip design companies in the world, extended AlphaChip to accelerate development of their most advanced chips — like the Dimensity Flagship 5G used in Samsung mobile phones — while improving power, performance and chip area.



Better GPUs => better AI => better GPUs => …

Mustafa Suleyman says AI training is now done by AI itself: https://www.reddit.com/r/ChatGPT/comments/1domqn4/mustafa_suleyman_says_ai_training_is_now_done_by/

Jensen Huang says technology has now reached a positive feedback loop where AI is designing new AI and is now advancing at the pace of "Moore's Law squared", meaning that the progress we will see in the next year or two will be "spectacular and surprising" https://x.com/apples_jimmy/status/1836283425743081988?s=46m
Meta's Joe Spisak explains how AI models can train themselves by generating images, asking itself questions about them, and choosing the best answers, in order to move beyond human data and human fine-tuning, and teach itself from synthetic data: https://x.com/tsarnick/status/1847789784078618640
4. AI Is Useful
Direct link: https://docs.google.com/document/d/1oHuwssPPUTa4dwczX_s3qg3iPfWE4VK-R52LN51GwI8/edit?tab=t.0#heading=h.93mf85wk17ju


For use cases in coding and software development, see section 6!



Source: https://ourworldindata.org/artificial-intelligence

https://www.visualcapitalist.com/ranked-the-most-popular-ai-tools/

https://www.visualcapitalist.com/ranked-the-most-popular-generative-ai-tools-in-2024/




ChatGPT is the 8th most visited site in the world, beating Amazon and Reddit with an average visit duration almost twice as long as Wikipedia: https://www.similarweb.com/top-websites/




Dec. 2024: ChatGPT now has over 300 million weekly users. During the NYT’s DealBook Summit, OpenAI CEO Sam Altman said users send over 1 billion messages per day to ChatGPT: https://www.theverge.com/2024/12/4/24313097/chatgpt-300-million-weekly-users
Worldwide Google trends for ChatGPT over the past 5 years as of 12/18/2024:
Man successfully sued landlord over deposit money dispute with help of ChatGPT: https://consent.yahoo.com/v2/collectConsent?sessionId=2_cc-session_1a569d03-b8d8-404d-b6f9-e45e6be90d5f

https://aidantr.github.io/files/AI_innovation.pdf


"These effects are large. To put the rise in materials discovery in perspective, the lab’s research output per scientist declined by 4% over the preceding five years. This was despite the introduction of several computational tools designed to aid scientists. AI therefore appears to be a different class of technology, with impacts that are orders of magnitude greater than previous methods." 

"However, the results suggest that AI-assisted materials discovery does not compromise quality"

As one scientist noted: “While I was impressed by the performance of the [AI tool]...I couldn’t help feeling that much of my education is now worthless. This is not what I was trained to do.”

The US is currently restricting other countries from accessing GPUs: https://www.ft.com/content/be680102-5543-4867-9996-6fc071cb9212



GPUs have two main uses: AI training and graphics rendering for video games. Why would the US do this if AI is useless?
Hint: Commerce secretary Gina Raimondo said the goal of the update was to curb China’s access to advanced chips that “could fuel breakthroughs in artificial intelligence and sophisticated computers” that are critical for the Chinese military.
The White House issued a National Security Memorandum declaring that 'AI is likely to affect almost all domains with national security significance'. Attracting technical talent and building computational power are now official national security priorities: https://www.whitehouse.gov/briefing-room/presidential-actions/2024/10/24/memorandum-on-advancing-the-united-states-leadership-in-artificial-intelligence-harnessing-artificial-intelligence-to-fulfill-national-security-objectives-and-fostering-the-safety-security/
DoS, DoD and DHS 'shall each use all available legal authorities to assist in attracting and rapidly bringing to the United States individuals with relevant technical expertise who would improve United States competitiveness in AI and related fields'

It is now the official policy that the United States must lead the world in the ability to train new foundation models. All government agencies will work to promote these capabilities.

'the United States Government must harness powerful AI ... to achieve national security objectives. Emerging AI capabilities ... offer profound opportunities for enhancing national security ... will require significant technical, organizational, and policy changes'

'It is therefore the policy of the United States Government to enhance innovation and competition by bolstering key drivers of AI progress, such as technical talent and computational power.'
Federal agencies ordered to use ‘most powerful’ AI systems in first-ever National Security Memo on AI" https://www.msn.com/en-us/news/us/federal-agencies-ordered-to-use-most-powerful-ai-systems-in-first-ever-national-security-memo-on-ai/ar-AA1sRu7n?ocid=msedgntp&pc=DCTS&cvid=0224f96de91943e9ad66804c1e8d54dd&ei=78
The U.S. National Security Council released on Thursday its first-ever memo on artificial Intelligence (AI), ordering federal agencies to use the "most powerful" AI systems while balancing the risks associated with the new technology.
    The National Security Memorandum (NSM) details the U.S. approach to harnessing the power of AI for national security and foreign policy purposes "to ensure that America leads the way in seizing the promise and managing the risks of AI," senior administration officials said.
    "We are directing that the agencies gain access to the most powerful AI systems and put them to use, which often involve substantial efforts on procurement," the officials said.
US National Security Advisor Jake Sullivan: The U.S. must accelerate its AI efforts and deploy AI much faster or risk losing its lead, as other countries are unlikely to adhere to the same regulations and values guiding the U.S. The stakes are high: https://www.reddit.com/r/singularity/comments/1gdu5cz/us_national_security_advisor_jake_sullivan_the_us/
Anthropic partners with Palantir to sell models to defence and intelligence agencies — with security clearance up to “secret”, one level below “top secret”. They added contractual exceptions to their terms of service, updated today, allowing for “usage policy modifications” for government agencies: https://techcrunch.com/2024/11/07/anthropic-teams-up-with-palantir-and-aws-to-sell-its-ai-to-defense-customers/


US ordered TSMC to halt shipments to China of chips used in AI applications: https://www.reuters.com/technology/us-ordered-tsmc-halt-shipments-china-chips-used-ai-applications-source-says-2024-11-10/
US government commission pushes Manhattan Project-style AI initiative: https://www.reuters.com/technology/artificial-intelligence/us-government-commission-pushes-manhattan-project-style-ai-initiative-2024-11-19/
Other countries are doing the same:
King Frederik of Denmark, in launching Denmark's first AI supercomputer Gefion with Jensen Huang: https://x.com/tsarnick/status/1849592372654637473


Pathchat by Modella, a multi-modal AI model designed for medical and pathological purposes, capable of identifying tumors and diagnosing cancer patients: https://www.reddit.com/r/singularity/comments/1dyfd9t/pathchat_by_modella_a_multimodal_ai_model/


How AI is transforming the factory floor - Artificial intelligence (AI) is revolutionizing factory operations, optimizing production lines and cutting costs: https://www.weforum.org/agenda/2024/10/ai-transforming-factory-floor-artificial-intelligence/

https://x.com/emollick/status/1850558277710463435?s=46

https://www.cnet.com/tech/mobile/25-of-smartphone-owners-dont-want-ai-as-apple-intelligence-debuts/

75% of smartphone users either find AI helpful or don't mind it
Over half of users are not against paying for a subscription for AI (55%), including 68% of Gen Z
A large majority doesn't even have privacy concerns (66%), including 71% of Gen Z
18% say AI is their main motivation

Claude autonomously found more than a dozen 0-day exploits in popular GitHub projects: https://github.com/protectai/vulnhuntr/

Google Claims World First As LLM assisted AI Agent Finds 0-Day Security Vulnerability: https://www.forbes.com/sites/daveywinder/2024/11/04/google-claims-world-first-as-ai-finds-0-day-security-vulnerability/


the Big Sleep team says it found “an exploitable stack buffer underflow in SQLite, a widely used open source database engine.”
The zero-day vulnerability was reported to the SQLite development team in October which fixed it the same day. “We found this issue before it appeared in an official release,” the Big Sleep team from Google said, “so SQLite users were not impacted.”


What percent of code is now written by AI? "I ask all the software companies I meet about this. The number is rarely lower than 40%. For some young programmers it's 90%." - Paul Graham of Y Combinator

AI Dominates Web Development: 63% of Developers Use AI Tools Like ChatGPT: https://flatlogic.com/starting-web-app-in-2024-research

New article says AI teachers are better than human teachers. Quote: "Students who were given access to an AI tutor learned more than twice as much in less time compared to those who had in-class instruction." https://www.msn.com/en-us/money/careersandeducation/ai-tutors-are-reshaping-higher-education/ar-AA1t76j3

>Generative AI is already transforming higher ed, giving students more access to professors' expertise and boosting efficiency for both faculty and students in some fields
In May, OpenAI released ChatGPT Edu, a more affordable tool for college students, faculty, researchers and campus administrators that OpenAI says includes "enterprise-level" security
Since the summer of 2023 those students accessing the course through distance learning have had access to AI-powered "teaching assistants," too, via the CS50 Duck — a chatbot built on OpenAI's API that helps students check their code and get answers to questions about the course.
Malan tells Axios that genAI can already approximate a pretty good teaching assistant. "It's wonderfully empowering for that demographic of folks who have never had nearly as much of a support structure" as the students at elite private colleges, he says.
By the numbers: Students who were given access to an AI tutor learned more than twice as much in less time compared to those who had in-class instruction, according to a study by two Harvard lecturers of 194 Harvard Physical Sciences 2 students.
Malan cautions against seeing this as a risk to the jobs of professors or graduate student teaching assistants: "We already have too few teachers as it is."


Claude autonomously found more than a dozen 0-day exploits in popular GitHub projects: https://github.com/protectai/vulnhuntr/

Claude can now view images within a PDF, in addition to text. This helps Claude 3.5 Sonnet more accurately understand complex documents, such as those laden with charts or graphics: https://x.com/AnthropicAI/status/1852393688451653849

OpenAI says ChatGPT usage has doubled since last year: https://www.axios.com/2024/08/29/openai-chatgpt-200-million-weekly-active-users
OpenAI said on Thursday that ChatGPT now has more than 200 million weekly active users — twice as many as it had a year ago.
Meta said earlier on Thursday adoption of its open source Llama models has also grown sharply. Usage at the major cloud service providers has doubled between May and July of this year with the release of Llama 3.1.
According to Similarweb, ChatGPT reportedly reached 3.1 billion visits in September 2024, a 112% year-over-year increase, surpassing Bing in US traffic with 442.9 million visits compared to Bing's 404.3 million: 

Waymo has 7.1 million driverless miles. The Google spinoff’s robotaxis led to a reduction in injury-related and police-reported crashes when compared to human benchmarks, according to new research: https://www.newscientist.com/article/2435896-driverless-cars-are-mostly-safer-than-humans-but-worse-at-turns/
Driverless Waymo vehicles get into far fewer serious crashes than human-driven ones. The crashes that do happen are overwhelmingly the fault of the other driver: https://www.understandingai.org/p/human-drivers-are-to-blame-for-most


METR Evals - LLM agents vs skilled humans on diverse task completion: When agents can do a task, they do so at ~1/30th of the cost of the median hourly wage of a US bachelor’s degree... Claude 3.5 Sonnet agent fixed bugs in an ORM library at a cost of <$2, Human baseline took >2 hours: https://x.com/METR_Evals/status/1820905731950055766




First AI to solve International Mathematical Olympiad problems at a silver medalist level: https://x.com/GoogleDeepMind/status/1816498082860667086

>It combines AlphaProof, a new breakthrough model for formal reasoning, and AlphaGeometry 2, an improved version of our previous system. 
Powered with a novel search algorithm, AlphaGeometry 2 can now solve 83% of all historical problems from the past 25 years - compared to the 53% rate by its predecessor.
It solved this year’s IMO Problem 4 within 19 seconds

Math professor on DeepMind's breakthrough: "When people saw Sputnik 1957, they might have had same feeling I do now. Human civ needs to move to high alert" https://x.com/PoShenLoh/status/1816500461484081519

OpenAI CFO Sarah Friar says lawyers are reporting that the new o1 reasoning model can do the work of a $2000/hour paralegal: https://www.reddit.com/r/singularity/comments/1geekyo/openai_cfo_sarah_friar_says_lawyers_are_reporting
Google has released the world's first "AI Agents System", Project Oscar, an open-source platform that enables development teams to create and utilize AI agents for managing software projects, particularly in monitoring issues and bugs: https://www.reddit.com/r/singularity/comments/1ea1kz9/google_has_released_the_worlds_first_ai_agents/
Agent-E, a breakthrough in agentic web automation: https://x.com/Chi_Wang_/status/1816526744935084278
- hierarchical planning
- a clever new method of interacting with DOM and performing stateful navigation
- tops the WebVoyager benchmark with a 73% success rate even without using multi modality
📰Design principles: http://arxiv.org/pdf/2407.13032
📦Implementation: http://github.com/EmergenceAI/Agent-E (powered by #AutoGen)
📺Demo: http://youtube.com/watch?v=uyE7tfKkB0E

Many uses of gen AI: https://x.com/AlexReibman/status/1815534334503432626


LOTUS, a query engine for reasoning over large corpuses of data with LLMs: https://x.com/lianapatel_/status/1813981153709441361



Claude 3.5 Sonnet transformed a research paper into an interactive learning dashboard in just 30 seconds: https://x.com/Saboo_Shubham_/status/1805789967203156357


Ten examples of Claude Sonnet 3.5 in use: https://x.com/minchoi/status/1815024013812416567


LLMs Can't Plan, But Can Help Planning in LLM-Modulo Frameworks: https://arxiv.org/abs/2402.01817


>We present a vision of LLM-Modulo Frameworks that combine the strengths of LLMs with external model-based verifiers in a tighter bi-directional interaction regime. We will show how the models driving the external verifiers themselves can be acquired with the help of LLMs. We will also argue that rather than simply pipelining LLMs and symbolic components, this LLM-Modulo Framework provides a better neuro-symbolic approach that offers tighter integration between LLMs and symbolic components, and allows extending the scope of model-based planning/reasoning regimes towards more flexible knowledge, problem and preference specifications.


GPT-4 autonomously hacks zero-day security flaws with 53% success rate: https://newatlas.com/technology/gpt4-autonomously-hack-zero-day-security-flaws/
Note: it has access to the internet, where 11 of the 15 exploits used could be found. Four of the 15 vulnerabilities were also discovered before the cutoff training date of GPT4. 

[2278 AI researchers were surveyed in 2023 and estimated that there is a 50% chance of AI being superior to humans in all possible tasks by 2047](https://aiimpacts.org/wp-content/uploads/2023/04/Thousands_of_AI_authors_on_the_future_of_AI.pdf)

List of GPT4’s achievements: https://docs.google.com/spreadsheets/d/1O5KVQW1Hx5ZAkcg8AIRjbQLQzx2wVaLl0SqUu-ir9Fs


Claude 3.5 can make graphics to describe things: https://x.com/calixo888/status/1803873821654684026 


Over 32 techniques to reduce hallucinations:
https://arxiv.org/abs/2401.01313


Many papers on AI embodied vision: https://github.com/rxlqn/awesome-embodied-vision 


 

DeepMind breaks 50-year math record using AI; new record falls a week later: https://arstechnica.com/information-technology/2022/10/deepmind-breaks-50-year-math-record-using-ai-new-record-falls-a-week-later/ 
AlphaTensor discovers better algorithms for matrix math, inspiring another improvement from afar.
ChatGPT scores in top 1% of creativity: https://www.cnbc.com/2023/07/17/study-chatgpt-can-match-the-top-1percent-of-creative-human-thinkers.html 

Study teaches ChatGPT to show accurate confidence levels in its output: https://arxiv.org/abs/2405.20974

Wolfram gives ChatGPT computational superpowers by allowing it to call on Wolfram|Alpha—and Wolfram Language as well—for powerful computation, curated knowledge, real-time data, visualization and even writing code: https://www.wolfram.com/wolfram-plugin-chatgpt/ 



26 uses of GPT 4o: https://www.youtube.com/watch?v=GPNq0WiXa50

AI beat humans at persuasion: https://www.newscientist.com/article/2424856-ai-chatbots-beat-humans-at-persuading-their-opponents-in-debates/ 



LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders: https://arxiv.org/abs/2404.05961 
We outperform encoder-only models by a large margin on word-level tasks and reach a new unsupervised state-of-the-art performance on the Massive Text Embeddings Benchmark (MTEB). Moreover, when combining LLM2Vec with supervised contrastive learning, we achieve state-of-the-art performance on MTEB among models that train only on publicly available data. Our strong empirical results and extensive analysis demonstrate that LLMs can be effectively transformed into universal text encoders in a parameter-efficient manner without the need for expensive adaptation or synthetic GPT-4 generated data.

Used as a tutor to help someone quintuple income https://www.reddit.com/r/ChatGPT/comments/1cpe3sk/chatgpt_just_just_made_me_get_a_job_paying_5x_more/ 

“Here we show in two experimental studies that novice and experienced teachers could not identify texts generated by ChatGPT among student-written texts.” https://www.sciencedirect.com/science/article/pii/S2666920X24000109 

AlphaZero, starting from scratch, became "the greatest Chess playing entity that's ever existed" in only 9 hours https://www.reddit.com/r/OpenAI/comments/1chbw25/demis_hassabis_describes_how_alphazero_starting/ 

Meta researchers create AI that masters Diplomacy, tricking human players. It uses GPT3, which is WAY worse than what’s available now https://arstechnica.com/information-technology/2022/11/meta-researchers-create-ai-that-masters-diplomacy-tricking-human-players/
The resulting model mastered the intricacies of a complex game. "Cicero can deduce, for example, that later in the game it will need the support of one particular player," says Meta, "and then craft a strategy to win that person’s favor—and even recognize the risks and opportunities that that player sees from their particular point of view."
Meta's Cicero research appeared in the journal Science under the title, "Human-level play in the game of Diplomacy by combining language models with strategic reasoning."
CICERO uses relationships with other players to keep its ally, Adam, in check.
When playing 40 games against human players, CICERO achieved more than double the average score of the human players and ranked in the top 10% of participants who played more than one game.

The chatbots also learned to negotiate in ways that seem very human. They would, for instance, pretend to be very interested in one specific item – so that they could later pretend they were making a big sacrifice in giving it up, according to a paper published by FAIR. https://www.independent.co.uk/life-style/facebook-artificial-intelligence-ai-chatbot-new-language-research-openai-google-a7869706.html

https://qz.com/ai-political-party-face-recognition-1851433898?darkschemeovr=1

[Claude 3 Builds website](https://www.reddit.com/r/OpenAI/comments/1bm305k/what_the_hell_claud_3_opus_is_a_straight/?darkschemeovr=1)

More proof: https://www.reddit.com/r/LocalLLaMA/comments/1cmk7dw/comment/l31tguw/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_button 

Beat Turing test: https://www.washingtonpost.com/technology/2022/06/17/google-ai-lamda-turing-test/?darkschemeovr=1

[Claude 3 could tell it was being tested](https://arstechnica.com/information-technology/2024/03/claude-3-seems-to-detect-when-it-is-being-tested-sparking-ai-buzz-online/)

Image Consistency: https://arxiv.org/pdf/2404.18919
Midjourney character consistency: https://docs.midjourney.com/docs/character-reference 
https://x.com/fofrAI/status/1796547108478038355 

Waymo says its robotaxis are now making 50,000 paid trips every week: https://www.engadget.com/waymo-says-its-robotaxis-are-now-making-50000-paid-trips-every-week-130005096.html
These incredibly funny videos by DougDoug would not be possible without AI
https://youtu.be/HyqK2Tsujho
https://youtu.be/W3id8E34cRQ?feature=shared
https://youtu.be/pHDh_PWMTaU?feature=shared
https://youtu.be/YnN6eBamwj4?feature=shared
[Game that uses LLM for character interaction](https://www.playsuckup.com/)
Another Game that uses LLM for character interaction https://youtu.be/0Nl67LN_3rk?feature=shared
Skyrim mod powered by ChatGPT: https://www.reddit.com/r/skyrimmods/comments/15vej9k/every_single_skyrim_npc_ai_powered_with_chatgpt/ 
Language Models are Few-Shot Learners: https://arxiv.org/abs/2005.14165
GPT 4o has excellent chess capabilities: https://www.reddit.com/r/singularity/comments/1crhkpi/gpt4o_is_a_chess_beast/
[Live AI video analysis](https://twitter.com/GoogleDeepMind/status/1790463259822420239)
Project Astra: Our vision for the future of AI assistants
More examples of recognizing drawings: https://twitter.com/minchoi/status/1790873017150550354 
Live noise cancellation and translation with accurate voice in a tiny earpiece: https://www.reddit.com/r/interestingasfuck/s/vpmyWqNftF
AI video allows people to create high quality AAA effects and scenes, allowing them to create without needing to get funding from studios. This would allow regular people to express their creativity and circumvent barriers in finding, time, or resources, similar to how the rise of YouTube allowed indie musicians to gain audiences without needing a record label and software like RPGMaker helped indie game developers do the same.
Even if it allows some people to create bad art, you don’t have to consume it. In the same way we filter out bad human-made art with ratings, we can do the same with art made with AI. 
significant progress in Gemini 1.5 Pro across all key benchmarks; TL;DR: 1.5 Pro > 1.0 Ultra, 1.5 Flash (our fastest model) ~= 1.0 Ultra. A math-specialised variant of Gemini 1.5 Pro performs strongly on competition-level math problems, including a breakthrough performance of 91.1% on Hendryck’s MATH benchmark without tool-use: https://x.com/OriolVinyalsML/status/1791521517211107515?t=uf0Sgqt_UpU_QsXB5w-HJA&s=19
AI scope hunts down colon polyps, aiding less experienced doctors: https://newatlas.com/medical/ai-colonoscopy-inexperienced-doctors/?itm_source=newatlas&itm_medium=article-body
AI-screened eye pics diagnose childhood autism with 100% accuracy: https://www.news-medical.net/news/20231219/AI-models-using-retinal-images-achieve-perfect-accuracy-in-diagnosing-autism.aspx

AI in space: Karpathy suggests AI chatbots as interstellar messengers to alien civilizations: https://arstechnica.com/information-technology/2024/05/ai-in-space-karpathy-suggests-ai-chatbots-as-interstellar-messengers-to-alien-civilizations
DeepMind AI's new way to sort objects could speed up global computing: https://www.newscientist.com/article/2376512-deepmind-ais-new-way-to-sort-objects-could-speed-up-global-computing/
DeepMind unveils first AI to discover faster matrix multiplication algorithms: https://venturebeat.com/ai/deepmind-unveils-first-ai-to-discover-faster-matrix-multiplication-algorithms/ 
Andrej Karpathy (renowned AI researcher) is building an operating system using transformers: https://analyticsindiamag.com/andrej-karpathy-says-the-pathway-to-agi-is-through-a-language-model-operating-system/ 
Excellent music recommendations from ChatGPT: https://www.reddit.com/r/ChatGPT/s/MgdUj9ymQF 
Model weights be downloaded and transferred, so anything one model does well can be replicated everywhere 
E.g. one model can connect to a model that’s very good at coding (eg AlphaCode 2) and another model that’s good at reasoning and call them as needed depending on the current needs similar to how the brain has different sections responsible for different tasks 
Learning to use AI can increase pay by 25%: https://www.cnn.com/2024/05/21/business/ai-jobs-higher-wages-productivity/index.html 
Autonomous AI Robot Creates a Shock-Absorbing Shape No Human Ever Could: https://scitechdaily.com/crushing-it-autonomous-ai-robot-creates-a-shock-absorbing-shape-no-human-ever-could/ 
Jensen Huang says designing computer chips and writing and debugging software can no longer be done without AI and he wants to turn NVIDIA into one giant AI: https://x.com/tsarnick/status/1793076745543073922 
LLMs won’t need data anymore. Synthetically trained 7B math model blows 64 shot GPT4 out of the water in math: https://x.com/_akhaliq/status/1793864788579090917?s=46&t=lZJAHzXMXI1MgQuyBgEhgA
While this only works for things you can generate good or perfect data on, that would still be good enough for factual information like math or science. For subjective information like art, a good art generator (e.g. Midjourney or Pony Diffusion could work)
Multimodal GPT-4o Interpreting Historical Documents (Letter Concerning Lady's Amber Collection, 1881): https://www.reddit.com/r/singularity/s/897BxdUtQJ 
Can act as a text-based game emulator where you can make any changes you want (e.g. Pokemon with guns where you can steal Pokemon): https://x.com/VictorTaelin/status/1790183986096116189 
GPT-4 is consistently rated as higher in apparent empathy than humans in multiple controlled studies: https://x.com/emollick/status/1794462493865329048 


Netflix co-CEO Ted Sarandos says “A.I. is not going to take your job. The person who uses A.I. well might take your job”
https://t.co/oKDVFnu9cN 
SignLLM is the first multilingual sign language model that can generate sign language gestures from input text: https://x.com/dreamingtulpa/status/1795060142473351423 
GPT-4 outsmarts Wall Street: AI predicts earnings better than human analysts | The researchers conducted their study by providing GPT-4 with standardised financial statements, carefully stripped of any company names or dates to prevent the model from using prior knowledge: https://www.businesstoday.in/technology/news/story/gpt-4-outsmarts-wall-street-ai-predicts-earnings-better-than-human-analysts-431062-2024-05-27 
AI used for psychological therapy: https://t.co/bQIzknuipj 
Automation powered by GPT-4o generates Figma designs based on PRD: https://x.com/yancymin/status/1795308932216525229 
Praktika raised a $35.5M Series A for its language learning app that uses AI avatars to simulate real-life conversational scenarios: https://x.com/chiefaioffice/status/1794854266189844576 
AI Predicts Fruit Fly Brain Behavior With Stunning Accuracy: https://www.nature.com/articles/s41586-024-07451-8 
A robotics expert says that artificial intelligence (AI) technology could help fight loneliness, which is known to be very bad for people’s health: https://theaiwired.com/ai-may-offer-companionship-to-people-feeling-lonely/ 
AI can identify drawings: https://x.com/sundeep/status/1795576457978376224 
Ten examples of GPT-4o being used: https://x.com/minchoi/status/1795456246994121089 
Make a song from any sound: 
https://x.com/suno_ai_/status/1795878282631512512 
https://x.com/nickfloats/status/1794373423352934891 
AI versus 100,000 humans in creativity in this careful study using the Divergent Association Test (a well-validated measure, but all measures of creativity have flaws)
GPT-4 wins. Better prompting can further improve performance & diversity of ideas. https://researchgate.net/publication/380820358_Divergent_Creativity_in_Humans_and_Large_Language_Models/fulltext/6650085f22a7f16b4f47a12a/Divergent-Creativity-in-Humans-and-Large-Language-Models.pdf

NGPA, New high quality real time 3D avatar from the university of Munich, Germany: https://www.reddit.com/r/singularity/comments/1d41k42/impressive_photorealistic_avatars_npga_neural
New AI tech predicts cardiac events due to coronary inflammation The Lancet publishes results from landmark study showing inflammation-related cardiac events can be predicted 10 years in advance: https://x.com/longevitytech/status/1796234620855533773?s=46
Creating TV shows with diffusion: https://fablestudio.github.io/showrunner-agents/ 
Claude 3 Opus understands and can write in very obscure languages: https://x.com/hahahahohohe/status/1765088860592394250 
Report: Generative AI can boost Estonia’s GDP by up to 8%: https://e-estonia.com/report-generative-ai-can-boost-estonias-gdp-up-to-8/ 
" In the future, 61 per cent of Estonia’s workforce is predicted to work together with generative AI. A gradual change will occur, where less than 10 per cent of highly exposed jobs will be replaced by automation. At the same time, new jobs will be created in the AI-powered economy. While the report expects employment levels to stay similar to today’s, a rise in productivity is expected."


AI can change the perspective of recorded videos and extrapolate unseen information: https://x.com/dreamingtulpa/status/1796519725129695650 
Medicine, Technology and the End of Cancer: https://www.nytimes.com/2023/12/05/special-series/artificial-intelligence-cancer-vaccine-biontech.html 


Automatic dubbing + lipsync: https://www.reddit.com/r/artificial/comments/1d2qd8j/ai_dub_lipsync_of_mira_murati_into_russian/ 
OpenAI’s ChatGPT can improve its capabilities through self play and the use of Agents: https://www.youtube.com/watch?v=ewLMYLCWvcI 
Utilizing a multi-agent approach, this system effectively tackles the intricate nuances inherent in literary texts. 
Empirical findings indicate that despite lower d-BLEU scores, translations from TransAgents are preferred by both human evaluators and LLMs over human-written references, particularly in genres requiring domain-specific knowledge. 
Firefox will use on-device ML to power translation and image alt text generation: https://hacks.mozilla.org/2024/05/experimenting-with-local-alt-text-generation-in-firefox-nightly/ 
Turning Trash Into Treasure: How AI Is Revolutionizing Waste Sorting: https://www.forbes.com/sites/ganeskesari/2024/05/31/turning-trash-into-treasure-how-ai-is-revolutionizing-waste-sorting/?sh=7adf348973d2 
RecycleOS, can sort objects with over 95% accuracy. 
These systems improve over time and adapt to new types of waste, ensuring the adaptability of sorting processes even as the composition of waste changes. For example, Alameda County Industries (ACI) reduced its labor costs by 59% in three years thanks to EverestLabs’ robots, which have picked up approximately 30 million objects.
Accurately identifying recyclable materials, such as fiber, PET, HDPE, or black plastic, helps reduce contamination rates and increase the purity of recyclables. For example, Glacier’s robots can be trained to identify and remove plastic bags that accidentally end up in the paper stream. This makes the quality of the end paper product higher and more valuable.
A recycling customer quantify a $900,000 annual revenue opportunity by identifying the value of recyclables that one site was incorrectly sending to landfills.
“It’s capable of making thousands of picks per minute on conveyer belts that move at speeds of 600 feet-per-minute,” Chase Brumfield - site reliability engineering manager of AMP, told me. In addition to consuming just a fraction of the manual effort, these systems need minimal downtime, vastly improving the throughput of waste facilities.
Additionally, intelligent sorting systems can unlock novel value-creation opportunities. For example, if a buyer is looking for a specific type of recycled plastic material, say a white-colored, post-consumer polypropylene - this is possible thanks to AI-driven sortation systems that can see, remember, and act by separating the desired type of waste in real-time.
CLIPPyX: AI Powered Image search tool offers content-based, text, and visual similarity search system-wide: https://github.com/0ssamaak0/CLIPPyX 
Search by Image Caption: Enter descriptive text or phrases, using CLIP, CLIPPyX will return all images related to that semantic meaning or caption.
Search by Textual Content in Images: Provide descriptive text or phrases, and using Optical Character Recognition (OCR) and text embedding model, CLIPPyX will return all images with text semantically similar to the provided text.
Search by Image Similarity: Provide an existing image as a reference, and CLIPPyX will find visually similar images using CLIP
Demo: https://www.reddit.com/r/LocalLLaMA/comments/1d6nfe1/clippyx_ai_powered_image_search_tool_offers/ 
Jensen Huang introduces NIMs (NVIDIA Inference Microservices): expert AI agents that can work in teams to accomplish missions which humans assign to them: https://x.com/tsarnick/status/1797885992390762673 
Geoffrey Hinton says AI doctors who have seen 100 million patients will be much better than human doctors and able to diagnose rare conditions more accurately: https://x.com/tsarnick/status/1797169362799091934 
No Language Left Behind (NLLB) is an AI model created by researchers at Meta capable of delivering high-quality translations directly between 200 languages – including low-resource languages: https://www.nature.com/articles/s41586-024-07335-x 
Teams of LLM Agents can Exploit Zero-Day Vulnerabilities: https://arxiv.org/abs/2406.01637
 Fields Medalist Terence Tao explains how proof checkers and AI programs are dramatically changing mathematics: https://www.scientificamerican.com/article/ai-will-become-mathematicians-co-pilot/ 
How Artificial Intelligence Is Reshaping Relationships - "AI, I think I love you.": https://www.psychologytoday.com/us/blog/the-digital-self/202406/how-artificial-intelligence-is-reshaping-relationships 
Forty percent of Gen Z is open to AI partners, raising questions about the future of relationships.
https://arxiv.org/abs/2404.05719 
Ferret-UI, a new MLLM tailored for enhanced understanding of mobile UI screens, equipped with referring, grounding, and reasoning capabilities. Given that UI screens typically exhibit a more elongated aspect ratio and contain smaller objects of interest (e.g., icons, texts) than natural images, we incorporate "any resolution" on top of Ferret to magnify details and leverage enhanced visual features. Specifically, each screen is divided into 2 sub-images based on the original aspect ratio (i.e., horizontal division for portrait screens and vertical division for landscape screens). Both sub-images are encoded separately before being sent to LLMs. We meticulously gather training samples from an extensive range of elementary UI tasks, such as icon recognition, find text, and widget listing. These samples are formatted for instruction-following with region annotations to facilitate precise referring and grounding. To augment the model's reasoning ability, we further compile a dataset for advanced tasks, including detailed description, perception/interaction conversations, and function inference. After training on the curated datasets, Ferret-UI exhibits outstanding comprehension of UI screens and the capability to execute open-ended instructions. For model evaluation, we establish a comprehensive benchmark encompassing all the aforementioned tasks. Ferret-UI excels not only beyond most open-source UI MLLMs, but also surpasses GPT-4V on all the elementary UI tasks.

A Starbucks run by 100 robots and 2 humans in South Korea: https://x.com/NorthstarBrain/status/1794819711240155594

Restaurant robots can cook, serve and bus your meal now: https://www.axios.com/2024/06/11/restaurant-technology-robots-food-ramen 

Robot chef that cooks meals: https://x.com/leeron/status/1800006993048170767
LLMs can correct their own mistakes: https://arxiv.org/abs/2406.01297 
AI used to streamline coding: https://x.com/GoogleAI/status/1800995872387518609 
AI is getting very popular among students and teachers, very quickly: https://www.cnbc.com/2024/06/11/ai-is-getting-very-popular-among-students-and-teachers-very-quickly.html 

Robots as psychological counselors: https://m.economictimes.com/news/international/uk/robots-as-psychological-counsellors-this-factory-in-china-is-making-it-a-reality/articleshow/110916481.cms 

Robots for manufacturing cars: https://www.msn.com/en-us/money/other/china-s-humanoid-robots-to-tackle-tricky-car-chores-at-dongfeng-motor/ar-BB1nAE9W?ocid=BingNewsSerp  

LLMs Can't Plan, But Can Help Planning in LLM-Modulo Frameworks: https://arxiv.org/abs/2402.01817 


>We present a vision of LLM-Modulo Frameworks that combine the strengths of LLMs with external model-based verifiers in a tighter bi-directional interaction regime. We will show how the models driving the external verifiers themselves can be acquired with the help of LLMs. We will also argue that rather than simply pipelining LLMs and symbolic components, this LLM-Modulo Framework provides a better neuro-symbolic approach that offers tighter integration between LLMs and symbolic components, and allows extending the scope of model-based planning/reasoning regimes towards more flexible knowledge, problem and preference specifications.
Robot integrated with Huawei's Multimodal LLM PanGU to understand natural language commands, plan tasks, and execute with bimanual coordination: https://x.com/TheHumanoidHub/status/1806033905147077045 
AI powered responsive sex bots are available: https://www.scmp.com/news/china/science/article/3266964/chinas-next-gen-sexbots-powered-ai-are-about-hit-shelves 
https://arxiv.org/pdf/2405.15568
OMNI-EPIC leverages foundation models to autonomously generate code specifying the next learnable (i.e., not too easy or difficult for the agent’s current skill set) and interesting (e.g., worthwhile and novel) tasks. OMNI-EPIC generates both environments (e.g., an obstacle course) and reward functions (e.g., progress through the obstacle course quickly without touching red objects), enabling it, in principle, to create any simu- latable learning task. We showcase the explosive creativity of OMNI-EPIC, which continuously innovates to suggest new, interesting learning challenges. We also highlight how OMNI-EPIC can adapt to reinforcement learning agents’ learning progress, generating tasks that are of suitable difficulty. Overall, OMNI-EPIC can endlessly create learnable and interesting environments, further propelling the development of self-improving AI systems and AI-Generating Algorithms. Project website with videos: https://dub.sh/omniepic.
AI adjudicates every Supreme Court case: "The results were otherworldly. Claude is fully capable of acting as a Supreme Court Justice right now." https://adamunikowsky.substack.com/p/in-ai-we-trust-part-ii 
Correctly predicted 27/37 rulings that occurred after it had finished training (random guessing would be 18 or 19)
“Claude(3 Opus) is fully capable of acting as a Supreme Court Justice right now. When used as a law clerk, Claude is easily as insightful and accurate as human clerks, while towering over humans in efficiency."
“ChatGPT just coded me a little program that's already saving me so much time” https://www.reddit.com/r/ChatGPT/comments/1dnrd9f/chatgpt_just_coded_me_a_little_program_thats/ 

Robot integrated with Huawei's Multimodal LLM PanGU to understand natural language commands, plan tasks, and execute with bimanual coordination: https://x.com/TheHumanoidHub/status/1806033905147077045 
CriticGPT is intended to help identify hallucinations as models grow more sophisticated: https://spectrum.ieee.org/openai-rlhf 

Translating nearly dead language: https://www.reddit.com/r/singularity/comments/1b7iwej/today_while_testing_anthropicai_s_new_model/ 
Saving Languages from Extinction: Claude 3 Opus Offers Hope for the Future of Endangered Languages: https://digialps.com/saving-languages-from-extinction-claude-3-opus-offers-hope-for-the-future-of-endangered-languages/?amp=1 

Mind-reading AI recreates what you're looking at with amazing accuracy: https://www.newscientist.com/article/2438107-mind-reading-ai-recreates-what-youre-looking-at-with-amazing-accuracy/
Accomplished with human subjects too: https://www.smithsonianmag.com/smart-news/this-ai-used-brain-scans-to-recreate-images-people-saw-180981768/
Code refactoring made much faster: https://www.reddit.com/r/singularity/comments/1dwgkav/code_editing_has_been_deprecated_i_now_program_by/ 
AI is better than humans at lie detection: https://www.technologyreview.com/2024/07/05/1094703/ai-lie-detectors-are-better-than-humans-at-spotting-lies/
For Older People Who Are Lonely, Is the Solution a Robot Friend? New York officials believe a robotic companion called ElliQ, which can discuss complicated subjects, is helping older residents feel less alone: https://archive.is/UxPWA#selection-469.0-523.18 
Washington Post creates chatbot to answer questions and summarize articles: https://x.com/sarafischer/status/1810706581572476957
Voice cloning: https://x.com/dreamingtulpa/status/1810573475309908261
We show brief convos w GPT4 reduce conspiracy beliefs by ~20pp: https://x.com/DG_Rand/status/1775618798717911424
🡆Tailored AI evidence rebut specific arguments offered by believers
🡆Effect lasts 2+mo
🡆Works on entrenched beliefs
AI-Augmented Predictions: LLM Assistants Improve Human Forecasting Accuracy: https://arxiv.org/abs/2402.07862
xLSTMTime : Long-term Time Series Forecasting With xLSTM: https://x.com/ZReacc/status/1813196548337012943
Our adopted architecture for LTSF termed as xLSTMTime surpasses current approaches. We compare xLSTMTime's performance against various state-of-the-art models across multiple real-world datasets, demonstrating superior forecasting capabilities. Our findings suggest that refined recurrent architectures can offer competitive alternatives to transformer-based models in LTSF tasks, potentially redefining the landscape of time series forecasting
Automated Social Science: Language Models as Scientist and Subjects: https://arxiv.org/pdf/2404.11794
In each case, causal relationships are both proposed and tested by the system, finding evidence for some and not others. We provide evidence that the insights from these simulations of social interactions are not available to the LLM purely through direct elicitation. When given its proposed structural causal model for each scenario, the LLM is good at predicting the signs of estimated effects, but it cannot reliably predict the magnitudes of those estimates. In the auction experiment, the in silico simulation results closely match the predictions of auction theory, but elicited predictions of the clearing prices from the LLM are inaccurate. However, the LLM’s predictions are dramatically improved if the model can condition on the fitted structural causal model. In short, the LLM knows more than it can (immediately) tell.
Chrome extension to show yourself wearing clothes from Amazon: https://www.reddit.com/r/StableDiffusion/comments/1e7ltua/i_made_a_chrome_extension_to_wear_clothes_from/
Andrew Ng is on how AI agents wil be useful: https://x.com/AndrewYNg/status/1770897666702233815

>I think AI agentic workflows will drive massive AI progress this year — perhaps even more than the next generation of foundation models. This is an important trend, and I urge everyone who works in AI to pay attention to it.

The CLM is a new model that remembers interactions, learns skills autonomously, and thinks in its free time, just like humans: https://x.com/aidan_mclau/status/1818071890755469365?t=biE9iwV1_1CzcE8CHDYhGw&s=19 
OpenAI patent for using machine learning to train and use a model to perform automatic interface actions based on video and input datasets: https://patents.google.com/patent/US11887367B1/en
President of Chile says he uses ChatGPT for his daily work: https://www.reddit.com/r/singularity/comments/1ehoe8v/president_of_chile_says_he_uses_chatgpt_for_his/
How Google uses AI to reduce stop-and-go traffic on your route — and fight fuel emissions: https://blog.google/outreach-initiatives/sustainability/google-ai-project-greenlight/
Watch a robot peel a squash with human-like dexterity: https://www.newscientist.com/article/2440687-watch-a-robot-peel-a-squash-with-human-like-dexterity/
A robot can hold a squash, pumpkin or melon in one hand, while it is peeled by the other
‘Yell at your robot’ technique teaches robots household chores: https://www.newscientist.com/article/2425023-yell-at-your-robot-technique-teaches-robots-household-chores/
AI allows robots to listen to verbal instructions while learning to correctly perform household tasks. That could enable more natural interactions between humans and robots
GPT-4 scored higher than 100% of psychologists on a test of social intelligence: https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1353022/full 
Grok 2 has record high math performance on MathVista benchmark, scoring 15% higher than humans: https://www.reddit.com/r/LocalLLaMA/comments/1etcj0k/grok2_and_grok2_mini_now_hold_the_top_two_spots/
AI agent that can control a computer: https://www.adept.ai/blog/act-1
A new technique that allows LLMs to act, not just react: https://x.com/Schindler___/status/1745986132737769573
Dynamic speech: Samantha can speak whenever it chooses to, influenced by its context and thoughts. In stark contrast to normal LLMs which are limited to reacting, Samantha can act. It is also not limited to solving tasks, like all other autonomous agents.
-Live visual capabilities: Visuals are only mentioned and acted upon directly if relevant, but always influences thoughts and behavior.
-External categorized memory: Gets dynamically written and read by Samantha, which chooses the most relevant information to write, and to retrieve to context.
-Evolving at every moment: Experiences that get stored in the memory can influence and shape subsequent Samantha behavior, like personality, frequency, and style of speech, etc.
In other tests, when we talked about a light subject, the agent was very active on the conversation, often speaking two or three times before I even came up with an answer, but later when switching to a heavier theme (Said I was going through a divorce) and appearing sad on the camera, it would speak once then think about the need to, and give me time to process and reply. Saying that I would prefer the agent to speak the same way on other occasions would prompt it to save that wish on its memory, influencing future conversations.


-Leaving it running outside of conversations, although expensive, allows the agent to reflect on past conversations and experiences, think about general subjects in its memory, and from that maybe decide to start a conversation with the user.


-Going out with the agent, if you go to a restaurant with the agent and talk about how pretty it is and how your buddy Eric loves it as well, and the next day walking by it the agent will see the restaurant, retrieve memories from the restaurant, remember you find it pretty and comment on it, then retrieve memories and information it knows about Eric, and mention how fitting to his personality it is to love that restaurant.


-The agent has time notion so you can ask it to remind you to do something 10 minutes into the future, and it might remind your, or it might forget it because it was thinking about something more interesting. Very human!
AI will have an estimated 21% net increase on the United States GDP by 2030: https://www.forbes.com/advisor/business/ai-statistics 
56% of people use AI at least once a day: https://www.pewresearch.org/science/2023/02/15/public-awareness-of-artificial-intelligence-in-everyday-activities/
People with more education and higher incomes tend to use it more
For reference, only 14% of US citizens own cryptocurrencies in 2023 and only 31% have any experience with it at all despite 81% hearing about it: https://coinweb.com/trends/how-many-americans-own-crypto/
A class of 20 pupils at a $35,000 per year private London school won't have a human teacher this year. They'll just be taught by AI: https://archive.md/wkIZZ
We've created a demo of an AI that can predict the future at a superhuman level (on par with groups of human forecasters working together): https://x.com/DanHendrycks/status/1833152719756116154
Our bot performs better than experienced human forecasters and performs roughly the same as (and sometimes even better than) crowds of experienced forecasters
Our bot and other forecasting bots can be used in a wide variety of contexts. For example, these AIs could help policymakers minimize bias in their decision-making or help improve the information ecosystem by providing trustworthy, calibrated forecasts.
On the 177 events, the Metaculus crowd got 87.0% accuracy, while FiveThirtyNine got 87.7% ± 1.4. A link to the technical report is here. This bot lacks many of the drawbacks of prediction markets. It makes forecasts within seconds. Additionally, groups of humans do not need to be incentivized with cash prizes to make and continually update their predictions. Forecasting AIs are several orders of magnitude faster and cheaper than prediction markets, and they’re similarly accurate.
The bot is not fine-tuned, and doing so could potentially make it far more accurate. It simply retrieves articles and writes a report as guided through an engineered prompt. (Its prompt can be found by clicking on the gear icon in forecast.safe.ai.) Moreover, probabilities from AIs are also known to lead to automation bias, and improvements in the interface could ameliorate this.
Large Language Models for Idea Generation in Innovation: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4526071

ChatGPT-4 can generate ideas much faster and cheaper than students, the ideas are on average of higher quality (as measured by purchase-intent surveys) and exhibit higher variance in quality. More important, the vast majority of the best ideas in the pooled sample are generated by ChatGPT and not by the students. Providing ChatGPT with a few examples of highly-rated ideas further increases its performance. 
ChatGPT o1-preview solves unique, PhD-level assignment questions not found on the internet in mere seconds: https://m.youtube.com/watch?v=a8QvnIAGjPA


This paper shows having a short conversation with an AI can get people who believed in a conspiracy theory to change their beliefs & this lasts for months: https://www.science.org/doi/10.1126/science.adq1814

Scores of o1-preview and GPT-4o on "official national exam in abstract mathematics used in Dutch high schools." Taken twice, o1-preview got 76 and 73 (max 76). Taken twice, GPT-4o got 66 and 61. Paper: "System 2 thinking in OpenAI’s o1-preview model: Near-perfect performance on a mathematics exam"  

China declares all crypto-currency transactions illegal: https://www.bbc.com/news/technology-58678907

But China Is Closing the A.I. Gap With the United States: https://archive.is/3M7Jt

This means that they believe AI is useful and worth investing in, even though they didn’t care for cryptocurrency 
OpenAI's Hunter Lightman says the new o1 AI model is already acting like a software engineer and authoring pull requests: https://www.reddit.com/r/singularity/comments/1futg5p/openais_hunter_lightman_says_the_new_o1_ai_model/
A thread of a researcher sharing his team's findings on whether or not LLMs can help create Math proofs, competing against humans. Summary: none of them really could get far, until o1 came out: https://x.com/robertghrist/status/1841462507543949581?t=5zV3VpQI0mbrSU9_QRtfkQ&s=19
OpenAI on autonomous agents: As of mid-2024, Altera's digital humans can operate autonomously for up to four hours at a time—a substantial increase compared to other AI models on the market: https://openai.com/index/altera/ 

LLM skeptic and 35 year software developer Internet of Bugs says ChatGPT-O1 Changes Programming as a Profession. I really hated saying that: https://youtube.com/watch?v=j0yKLumIbaM
DeepMind researchers find LLMs can serve as effective mediators: https://techxplore.com/news/2024-10-deepmind-llms-effective.html
Content moderation: https://openai.com/index/using-gpt-4-for-content-moderation/
Beats humans with little training
Saves time for humans
Less trauma from moderators seeing disturbing images or messages
Can label harmful vs non harmful content
Can identify edge cases (e.g. user is referring to a video game instead of real violence or is pretending to refer to a video game for a real threat)
Linus Torvalds (creator of Linux) thinks AI is 90% hype but also says it’s a great thing and will change the world: https://www.tomshardware.com/tech-industry/artificial-intelligence/linus-torvalds-reckons-ai-is-90-percent-marketing-and-10-percent-reality
Stuff linus has also downplayed in the past:
mobile phones
cloud computing
Github
Stanford: Scientific progress accelerates even further, thanks to AI. In 2022, AI began to advance scientific discovery. 2023, however, saw the launch of even more significant science-related AI applications— from AlphaDev, which makes algorithmic sorting more efficient, to GNoME, which facilitates the process of materials discovery: https://aiindex.stanford.edu/wp-content/uploads/2024/04/HAI_2024_AI-Index-Report.pdf
 Claude with computer use can watch this construction site video & write up things that dangerous or good, create a spreadsheet of critical issues to address: https://x.com/emollick/status/1853255574843982241
OpenAI introduces Predicted Outputs in the API, speeding up tasks like code refactoring and editing docs 4-5x faster. Big deal for code editors like cursor and writing tools: https://x.com/OpenAIDevs/status/1853564730872607229

Big study of 187k developers using GitHub Copilot: AI transforms HOW we work. Coders can focus. They do more coding and less management. They need to coordinate less, working with fewer people. And they experiment more with new languages, which would increase earnings $1,683/year: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5007084
Microsoft stealth releases both “Magentic-One”: An Open Source Generalist Multi-Agent System for Solving Complex tasks, and AutogenBench: https://www.microsoft.com/en-us/research/articles/magentic-one-a-generalist-multi-agent-system-for-solving-complex-tasks/

We are introducing Magentic-One, our new generalist multi-agent system for solving open-ended web and file-based tasks across a variety of domains. Magentic-One represents a significant step towards developing agents that can complete tasks that people encounter in their work and personal lives. We are also releasing an open-source implementation of Magentic-One on Microsoft AutoGen, our popular open-source framework for developing multi-agent applications.

Person saves $150 using ChatGPT to fix toilet issue: https://www.reddit.com/r/OpenAI/comments/1gxzew1/chatgpt_just_saved_me_150_and_a_lot_of_stress/

Metastudy of 6 studies: AI Companions Reduce Loneliness: https://arxiv.org/abs/2407.19096

Study 3 finds that AI companions successfully alleviate loneliness on par only with interacting with another person, and more than other activities such watching YouTube videos. Moreover, consumers underestimate the degree to which AI companions improve their loneliness. Study 4 uses a longitudinal design and finds that an AI companion consistently reduces loneliness over the course of a week. Study 5 provides evidence that both the chatbots' performance and, especially, whether it makes users feel heard, explain reductions in loneliness. Study 6 provides an additional robustness check for the loneliness alleviating benefits of AI companions.

China's generative AI users reach 230 million as start-ups, Big Tech roll out LLM services: https://finance.yahoo.com/news/chinas-generative-ai-users-reach-093000100.html
 China is treating AI safety as an increasingly urgent concern according to a growing number of research papers, public statements, and government documents: https://carnegieendowment.org/research/2024/08/china-artificial-intelligence-ai-safety-regulation?lang=en
GenCast predicts weather and the risks of extreme conditions with state-of-the-art accuracy: https://deepmind.google/discover/blog/gencast-predicts-weather-and-the-risks-of-extreme-conditions-with-sota-accuracy/

Project Mariner is built with Gemini 2.0 and is able to understand and reason across information - pixels, text, code, images + forms - on your browser screen, and then uses that info to complete tasks for you: https://x.com/sundarpichai/status/1866868770678988850
When evaluated against the WebVoyager benchmark, it achieved a state-of-the-art result of 83.5% working as a single agent setup.
A new agentic feature called Deep Research in Gemini Advanced, a research assistant that can dig into complex topics and create reports for you with links to the relevant sources.
Gemini 2.0 makes a suggestion that was not requested: https://www.reddit.com/r/singularity/comments/1hdvt3d/wow_gemini_20_flash_is_insane/
https://tsb0601.github.io/metamorph/
New research from Meta and NYU shows that by extending instruction tuning to handle visual tokens, LLMs can simultaneously learn image understanding and generation with minimal changes. The most intriguing finding is that visual generation capabilities emerge naturally as the model gets better at understanding - requiring only ~200K samples compared to millions typically needed.
It suggests current LLM architectures might already contain the building blocks needed for unified multimodal AI.
https://epoch.ai/frontiermath/expert-perspectives
In our conversations, the mathematicians highlighted key themes regarding AI’s potential impact on mathematics. They discussed how AI could assist in proof development and verification, facilitate experimental approaches by exploring vast numbers ofpotentialstatements, generate novel conjectures by synthesizing information across fields, reduce barriers to entry into specialized areas through accurate explanations of complex concepts, and enhance error detection in mathematical work. They also contemplated the challenges AI faces in achieving deep research competence, such as acquiring domain-specific expertise and learning from the iterative process of mathematical discovery.
Fields Medalist Terrance Tao predicted that AI tools would let researchers “scan a million possible proof statements, see which ones are true and which ones are false and draw empirical conclusions from that… Math is 99% theoretical right now, but only for technical reasons, only for technological reasons.” Fields Medalist Timothy Gowers captured this transformation with a vivid metaphor: “Your computer becomes the test tube and you sort of stick the problem in the test tube and shake it around and see what comes out.”
Since AI systems are trained on vast quantities of data across disparate fields, and have the ability to search through the mathematical literature at scale, IMO expert Evan Chen felt that they could be incredibly effective at automatically generating novel conjectures. “This is a thing I think [large language models] would be really, really good at.” In contrast, IMO expert Evan Chen argued that humans instead “go to conferences, listen to other people talk, and see if anything by chance manages to line up.”
With the aid of AI systems, several of the mathematicians felt that bridging this gap could be possible fairly soon. Fields Medalist Richard Borcherds surmised that “AI is pretty close to being able to formalize an awful lot of human mathematics,” and Tao pointed out that this ability to formalize statements could be useful in proof development within around five years. “If I were to write a math paper, I would explain the proof to a proof assistant… and they would help formalize it.” Such tools could significantly reduce the time and specialized knowledge required for formal verification while maintaining mathematical rigor.
A significant practical benefit of AI assistance could be in catching mathematical errors. In particular, reviewing mathematical papers can require substantial time, effort, and domain expertise, making it impractical to check most papers in full detail. Chen expects that AI systems could transform this, revealing substantial errors: “[I think if you] took a random sample of the papers on the arXiv, there would just be mistakes everywhere. It would be like code if we didn’t have unit tests.” Combined with the earlier discussion of formal verification capabilities, this suggests AI systems could help ensure mathematical results are more reliable by systematically checking proofs and calculations.
4.1. Media Creation
INCREDIBLE control of video generation with real physics simulation, useful for training robots: https://x.com/zhou_xian_/status/1869511650782658846

 "Hinahima" an anime produced using AI that will be released in spring 2025: https://www.reddit.com/r/singularity/comments/1herl0c/they_really_doing_it_now_hinahima_an_anime/
Say goodbye to GPTisms and slop! XTC sampler for llama.cpp: https://github.com/cyan2k/llama.cpp/tree/feature/xtc-sampler
It's a way to ignore the top X tokens (exclude top choices = XTC) during sampling. It removes all except the least likely token meeting a given threshold, with a given probability, which in theory keeps coherence but increases creativity and kills GPT-isms and other predictable slop.
My personal opinion: It’s amazing for creative use cases. It makes your model feel like a completely different model and much improved. 
Alternative: https://github.com/sam-paech/antislop-sampler
Auto colorer for manga and comics: https://arxiv.org/pdf/2412.11815
AI helping with anime/manga production: https://www.youtube.com/watch?v=CTwGwF7cw8A
consistent multi-camera video generation: https://jianhongbai.github.io/SynCamMaster/
Genie 2, the new AI from Google that Generates Interactive 3D Worlds: https://www.reddit.com/r/singularity/comments/1h6n2ve/genie_2_the_new_ai_from_google_that_generates/
SOTA open source text to video generator: https://aivideo.hunyuan.tencent.com/


Study: 94% Of AI-Generated College Writing Is Undetected By Teachers: https://www.forbes.com/sites/dereknewton/2024/11/30/study-94-of-ai-generated-college-writing-is-undetected-by-teachers/

Researchers at the University of Reading in the U.K., examined what would happen when they created fake student profiles and submitted the most basic AI-generated work for those fake students without teachers knowing. The research team found that, “Overall, AI submissions verged on being undetectable, with 94% not being detected. If we adopt a stricter criterion for “detection” with a need for the flag to mention AI specifically, 97% of AI submissions were undetected.”

Advanced camera control for AI videos: https://www.reddit.com/r/singularity/comments/1gh7kk9/advanced_camera_control_is_now_available_for_gen3/
Excellent amateur quality AI photos: https://www.reddit.com/r/StableDiffusion/comments/1f57zae/school_trip_in_2004_lora/
AI Is Already Taking Jobs in the Video Game Industry: https://www.wired.com/story/ai-is-already-taking-jobs-in-the-video-game-industry/

>NOTE: The part that says workers are being forced to use AI by their bosses IS A LIE. See [section 4.2](https://docs.google.com/document/d/15myK_6eTxEPuKnDi5krjBM_0jrv3GELs8TGmqOYBvug/edit#heading=h.akz9hanp4wxi) for strong evidence to the contrary from multiple sources.
A WIRED investigation finds that major players like Activision Blizzard, which recently laid off scores of workers, are using generative AI for game development.
A recent survey from the organizers of the Game Developers Conference found that 49 percent of the survey’s more than 3,000 respondents said their workplace used AI.
“It’s here. It’s definitely here, right now,” says Violet, a game developer, technical artist, and a veteran of the industry who has worked on AAA games for over a decade. “I think everyone’s seen it get used, and it’s a matter of how and to what degree. The genie is out of the bottle, Pandora's box is opened.”
Treyarch, a Southern California-based studio that produces some elements of Activision’s Call of Duty games, posted a job listing for a “2D Artist Animator.” The first thing listed under the “To succeed you should have …” section was “exceptional skills and expertise in digital sketching, drawing, and painting, as well as advanced expertise in working with generative AI tools such as Stable Diffusion, Vizcom, Dall-E, or equivalent.” 
Blizzard is building its own AI system too, which at one time was named Blizzard Diffusion—though details are scarce, beyond a patent the company filed for a “machine-learning based 2D structured image generation” system. “Blizzard's ‘internal AI’ that they trained is still super secretive. Only those who have access to it work with it, and no one else knows how it works,” Warner claims.
Workflow of an artist using AI for an ad: https://www.reddit.com/r/aiwars/comments/1eyotd7/how_artists_are_using_ai_in_their_workflow/?chainedPosts=t3_1f17de3
Activision Blizzard is reportedly already making games with AI, and quietly sold an AI-generated microtransaction in Call of Duty: Modern Warfare 3: https://www.gamesradar.com/games/call-of-duty/activision-blizzard-is-reportedly-already-making-games-with-ai-and-quietly-sold-an-ai-generated-microtransaction-in-call-of-duty-modern-warfare-3/
AI-generated song made it to 72nd highest ranking song in Germany: https://www.youtube.com/watch?v=tUA7mBxCpb4
Flux beats Midjourney: https://blackforestlabs.ai/announcing-black-forest-labs/
API costs $0.025 per image. It's cheaper than Dalle 3 and can do realism.


Very realistic images: https://www.reddit.com/r/singularity/comments/1ej1etp/flux_can_generate_really_good_fake_low_quality/ 





Prompt: Gameplay screenshot of Counter Strike Global Offensive. It takes place in a Middle Eastern place called Dust 2. There are enemy soldiers shooting at you.

Prompt: low quality and motion blur shaky photo of a CRT television on top of a wooden drawer in an average bedroom. The lighting from is dim and warm ceiling light that is off screen. In the TV there is Dark Souls videogame gameplay on it. The screen of the TV is overexposed.


First attempt: "Photo of a red sphere on top of a blue cube. Behind them is a green triangle, on the right of the triangle is a dog, on the left is a cat."

Prompt: person take photo of Graffiti art spelling out the words "WAFERSELAMAT", graffiti, white wall, dynamic color, spray paint,

Prompt: Close-up of LEGO chef minifigure cooking for homeless. Focus on LEGO hands using utensils, showing culinary skill. Warm kitchen lighting, late morning atmosphere. Canon EOS R5, 50mm f/1.4 lens. Capture intricate cooking techniques. Background hints at charitable setting. Inspired by Paul Bocuse and Massimo Bottura's styles. Freeze-frame moment of food preparation. Convey compassion and altruism through scene details.
Google’s new image diffusion model: https://www.reddit.com/r/singularity/comments/1eit2bd/google_gemini_appears_to_have_updated_their_image/




Lumina-GPT: https://github.com/Alpha-VLLM/Lumina-mGPT
A family of multimodal autoregressive models capable of various vision and language tasks, particularly excelling in generating flexible photorealistic images from text descriptions. 


HoloDreamer: Holistic 3D Panoramic World Generation from Text Descriptions https://x.com/_akhaliq/status/1815616891022418231
Midjourney has over 20 million users: 
Japanese writer wins prestigious Akutagawa Prize with a book partially written by ChatGPT: https://www.vice.com/en/article/k7z58y/rie-kudan-akutagawa-prize-used-chatgpt
AI used by official Disney show for intro: https://www.polygon.com/23767640/ai-mcu-secret-invasion-opening-credits 
Humorous AI video: https://www.reddit.com/r/ChatGPT/comments/1dyb2bq/unanswered_oddities_aigenerated_tv_show/ 
New Runway video models: https://x.com/runwayml/status/1802691475391566108 

ChatGPT vs. Humans: Even Linguistic experts Can’t Tell Who Wrote What: https://www.researchgate.net/publication/372957869_Can_linguists_distinguish_between_ChatGPTAI_and_human_writing_A_study_of_research_ethics_and_academic_publishing 
GPT just churned out a 10-panel comic-book explaining "Gravitational Waves" in a one-shot prompt: https://x.com/electrik_dreams/status/1802421281876238354 
Image to animation: https://github.com/Fictiverse/ToonCrafter-for-windows
Much stronger control of image output: 
https://arxiv.org/pdf/2406.01300 
https://arxiv.org/pdf/2407.05282
https://huggingface.co/papers/2406.04324 
We show that, through the adversarial training, the multi-steps video diffusion model, i.e., Stable Video Diffusion (SVD), can be trained to perform single forward pass to synthesize high-quality videos, capturing both temporal and spatial dependencies in the video data. Extensive experiments demonstrate that our method achieves competitive generation quality of synthesized videos with significantly reduced computational overhead for the denoising process (i.e., around 23 times speedup compared with SVD and 6 times speedup compared with existing works, with even better generation quality), paving the way for real-time video synthesis and editing. 
https://huggingface.co/papers/2406.04277 
Specifically, we propose spatio-temporal compositional diffusion to precisely follow complex textual semantics by manipulating and composing the attention maps of denoising networks spatially and temporally. Moreover, we propose an enhanced video data preprocessing to enhance the training data regarding motion dynamics and prompt understanding, equipped with a new reference frame attention mechanism to improve the consistency of auto-regressive video generation. Extensive experiments demonstrate that our VideoTetris achieves impressive qualitative and quantitative results in compositional T2V generation. 
Image2Model
Trellis is a new 3D model that generates high-quality 3D assets in formats like Radiance Fields, 3D Gaussians, and meshes: https://trellis3d.github.io/
Microsoft and NUS introduce GenXD, a joint model for 3D and 4D generation: https://www.reddit.com/r/singularity/comments/1gk9vay/microsoft_and_nus_introduce_genxd_a_joint_model/
BLENDERGPT - the fastest way to generate 3D assets and import them seamlessly into Blender. text to 3D in ~20 seconds: https://www.reddit.com/r/singularity/comments/1gk8x5j/blendergpt_the_fastest_way_to_generate_3d_assets/
From 10 minutes to .5 seconds. Stability Ai Rapid 3D Asset Generation From Single Images: https://stability.ai/news/introducing-stable-fast-3d
Very consistent AI 3D models: https://x.com/emmanuel_2m/status/1796118855237939346

Game made with 3D assets and textures made with AI: https://x.com/CSM_ai/status/1796200041280925713

https://3d.makedraft.com/gallery

https://charmed.ai/

https://medium.com/echo3d/7-generative-ai-tools-for-3d-asset-creation-97dd88153b7

https://www.masterpiecex.com/blog/creating-usable-3d-models-with-generative-ai

https://x.com/AIWarper/status/1797104351204524516

https://costwen.github.io/Ouroboros3D/

Sparsecraft: https://x.com/_akhaliq/status/1815204831679664191

>our method, called SparseCraft, achieves state-of-the-art performances both in novel-view synthesis and reconstruction from sparse views in standard benchmarks, while requiring less than 10 minutes for training.

https://assetgen.github.io/


Retexturing 3D models: https://www.reddit.com/r/singularity/comments/1eev502/with_this_tool_you_can_texture_3d_models_with_ai/

MeshAnything V2: https://www.reddit.com/r/StableDiffusion/comments/1ela7od/meshanything_v2/

https://x.com/ilumine_ai/status/1681811934163931137

https://x.com/_akhaliq/status/1798536799737741361

Portrait 3D: https://jinkun-hao.github.io/Portrait3D/

https://x.com/nrqa__/status/1795469205934141463

CLAY: A Controllable Large-scale Generative Model for Creating High-quality 3D Assets: https://huggingface.co/papers/2406.13897

Tripo: https://www.reddit.com/r/singularity/comments/1fjylow/tripo_v20_is_out_now_you_can_create_stunning_3d/
Blender implements generative AI: https://www.youtube.com/watch?v=uDxq8v5WEDs
Human camouflage:
https://www.reddit.com/r/StableDiffusion/s/f46LKOMj7q
Animation from a single image: https://www.reddit.com/r/StableDiffusion/comments/1d2saw7/its_coming_but_its_not_animateanyone/ 
Style changes
Papercraft: https://www.reddit.com/r/StableDiffusion/comments/1d2hdia/what_if_pixars_up_was_papercraft_style/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button 
Pixel art: https://x.com/AIWarper/status/1792570014454727149 

3D models: https://x.com/AIWarper/status/1780251522905083919 
https://x.com/AIWarper/status/1811045840313799162
Editing videos from one frame: https://i2vedit.github.io/ 
AI object removal: https://x.com/AIWarper/status/1795917964610351177 
Upscaling: https://github.com/Hillobar/Rope 
Image: 
Video: https://x.com/henryruhs/status/1795102994549055968 
Lip syncing: https://x.com/AIWarper/status/1795157663266881929 
VFX: https://x.com/AIWarper/status/1780663596181287317 
Replacing people in videos: 
https://x.com/AIWarper/status/1789011656049324075 
https://x.com/AIWarper/status/1779952562843848981 
Alibaba presents MIMO: Controllable Character Video Synthesis with Spatial Decomposed Modeling: https://www.reddit.com/r/singularity/comments/1fp0ti3/alibaba_presents_mimo_controllable_character/
Adding moving objects in video: https://x.com/dreamingtulpa/status/1796062121215615031 
Morphing images together: https://x.com/krea_ai/status/1788465406971453814 
Image drag editing: https://x.com/dreamingtulpa/status/1795858080908890242 
ViViD can transfer a clothing item onto the video of a target person: https://x.com/dreamingtulpa/status/1795786351733772479 
The method is able to capture garment details and human posture, resulting in more coherent and lifelike videos.
Video movement: https://x.com/dreamingtulpa/status/1795698989708325273  
Era3D: A new AI model that creates high-res 🗿3D images from multiple viewpoints using just one input image: https://x.com/Gradio/status/1795866944568000697 
- Generates high-quality images up to 512×512 pixels🎯
- Uses efficient row-wise attention to reduce computation⚡
- 12x more efficient than sota methods💪
Generating short films, trailers, and teasers with AI tools: https://x.com/minchoi/status/1795834164333433232 
SFX: 
Text2audio: https://x.com/elevenlabsio/status/1759240084342059260 
Img2audio: https://x.com/dreamingtulpa/status/1795729964764987631 
SoundCTM: Uniting Score-based and Consistency Models for Text-to-Sound Generation: https://huggingface.co/papers/2405.18503 
ElevenLabs version: https://www.reddit.com/r/singularity/comments/1d50x9m/elevenlabs_text_to_sound_effects_is_here/ 
Game made with 3D assets and textures made with AI: https://x.com/CSM_ai/status/1796200041280925713 
A chest: https://x.com/tejasdkulkarni/status/1796730715851157620
NVIDIA's Edify 3D model quickly generates high-quality 3D assets from text or image prompts in under 2 minutes, using multi-view diffusion and transformers. With 4K textures, realistic materials and optimized mesh structures, it's a powerful scalable tool for simulation: https://www.reddit.com/r/singularity/comments/1gredul/nvidias_edify_3d_model_quickly_generates/
MagicPose4D can generate 3D objects from text or images and transfer precise motions and trajectories from objects and characters in a video or mesh sequence: https://t.co/FvMgUNcjy9 
RemoCap can reconstruct 3D human bodies (included  occluded body parts) from motion sequences: https://t.co/HydtPXJifC 
NOVA-3D can generate 3D anime characters from non-overlapped front and back views: https://github.com/NOVA-3D-Anime-Character-Synthesis/NOVA-3D 
AI used for 3D rendering: https://x.com/mickmumpitz/status/1795016363066417396
https://research.nvidia.com/labs/dir/edgerunner/
https://buaacyw.github.io/mesh-anything/
MotionCraft can animate an image based on physics: mezzelfo.github.io/MotionCraft/ 
The method is able to simulate different physics, such as fluid dynamics, rigid motion, and multi-agent systems, and can also be combined with animation software to generate the required optical flows.
CondMDI can generate precise and diverse motions that conform to flexible user-specified spatial constraints and text descriptions: https://x.com/dreamingtulpa/status/1795363597243035969 
This enables the creation of high-quality animations from just text prompts and inpainting between keyframes.
Used for animation: https://www.reddit.com/r/StableDiffusion/s/AtaCsdxvBY 
https://www.reddit.com/r/StableDiffusion/s/9QupjshrfE 
AI tools now allow to retexture specific areas of 3D models: https://www.reddit.com/r/artificial/s/SfAcl7dTwS
EditWorld can add, replace, delete, and move objects in images, as well as change their attributes and perform other operations based on text instructions grounded in real-world scenarios: https://x.com/dreamingtulpa/status/1794972116472770659 
Image to video: https://huggingface.co/papers/2406.02230
Gen-3 Alpha can simulate liquids such as water, paint, oil, honey and molten glass. All with realistic viscosity, physics-based interactivity and caustics: https://x.com/runwayml/status/1811751431453450449

Pixel sprite animation: https://x.com/AIWarper/status/1797367653226643865
Sony Will Use AI to Cut Film Costs, Says CEO Tony Vinciquerra: https://www.indiewire.com/news/breaking-news/sony-pictures-will-cut-film-costs-using-ai-1235010605/  
Translation dubbing for NPCs in video games: https://x.com/elevenlabsio/status/1797655062350565433 
Reskinning 3D models: https://x.com/emmanuel_2m/status/1797735403761610916 
Controllable video generation: https://arxiv.org/pdf/2405.20222v2
 New Runway video models: https://x.com/runwayml/status/1802691475391566108 
Generating audio for video: https://deepmind.google/discover/blog/generating-audio-for-video/ 
Stream diffusion brushes: https://www.reddit.com/r/AIStoxiaArt/comments/1abnmmi/interactive_streamdiffusion_brush/
Guy commissioned and properly credited artists in the past, multiple times got backstabbed by artists who copy-striked his videos, threatening to take his channel down: https://www.youtube.com/watch?v=knUkXwJXcpY 
Claude Sonnet 3.5 can generate complex shapes with SVG: https://www.reddit.com/r/singularity/comments/1dm6b57/comment/l9twj24/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_button 
sound to music: https://x.com/LinusEkenstam/status/1797761904640954430 
Toys R Us uses Sora generated promo: https://www.reddit.com/r/singularity/comments/1do7dah/toys_r_us_releases_sora_generated_promo
Generating Anatomically Controllable Consistent Text-to-3D Animals: https://arxiv.org/pdf/2406.16273 
3D model generation: https://x.com/murchellcruft/status/1805679588627861632 
Cheap AI voice clones may wipe out jobs of 5,000 Australian actors: https://www.theguardian.com/technology/article/2024/jun/30/ai-clones-voice-acting-industry-impact-australia 
Industry group says rise of vocal technology could upend many creative fields, including audiobooks – the canary in the coalmine for voice actors
HOIFH generates synchronized object motion, full-body human motion, and detailed finger motion: https://hoifhli.github.io 
It is designed for manipulating large objects within contextual environments, guided by human-level instructions.
Merging image elements together: https://x.com/alex_peys/status/1806719131791876418 



High quality upscaling: 
https://shuweis.github.io/ResMaster/
Consistent upscaling: https://x.com/mervenoyann/status/1810592224830193781
Square Enix says it used AI art in upcoming Foamstars game: https://www.theverge.com/2024/1/16/24040124/square-enix-foamstars-ai-art-midjourney
Human level text to speech: https://www.microsoft.com/en-us/research/project/vall-e-x/vall-e-2/
Great video creation https://boyuan.space/diffusion-forcing/

Direct control over image generation: https://x.com/dreamingtulpa/status/1809654865724862917
LivePortrait face animation: https://x.com/venturetwins/status/1809686031312027933
Realistic/good AI videos:
OpenAI is already training a new version of Sora with even higher quality and longer videos: https://www.theinformation.com/articles/openai-is-revamping-sora-ai-video?utm_campaign=Editorial&utm_content=Newsletter%2CAI+Agenda&utm_medium=organic_social&utm_source=twitter
https://www.reddit.com/r/StableDiffusion/comments/1ejcw66/blackforestlabs_txt2vid_looks_insane/
https://x.com/kimmonismus/status/1810547329356771827/
https://x.com/kimmonismus/status/1809322314225578158
https://x.com/tsumotokai/status/1810128665889685596
https://x.com/Diesol/status/1810468576882770109
https://x.com/kimmonismus/status/1810949448584855729
https://x.com/CharaspowerAI/status/1810952037246349739
https://x.com/CharaspowerAI/status/1811105682000671147
https://www.reddit.com/r/aivideo/comments/1e0jyo9/anyone_know_which_ai_video_generator_did_this/
https://x.com/shanef3d/status/1811505820129214687
https://x.com/ai_for_success/status/1811576761617928300
Hands: https://x.com/arohaAIX/status/1811381195676307623
https://x.com/_akhaliq/status/1813578798283255823
https://www.reddit.com/r/singularity/comments/1e88t8j/another_kling_ai_clip/
Grand Theft Auto in India: https://www.reddit.com/r/aivideo/comments/1e7zrk5/grand_theft_auto_india_gameplay_trailer/
https://x.com/runwayml/status/1816096185016357030
Apples to guinea pigs: https://www.reddit.com/r/aivideo/comments/1ecf1is/apples_or_hamsters/
Person speaking: https://www.reddit.com/r/singularity/comments/1f4fv05/ai_movies_are_coming/
Burger King commercial parody: https://www.reddit.com/r/aivideo/comments/1fao9w0/i_created_a_burger_commercial_using_ai/
This was done in less than 24h by one person using AI as the ground tooling, some post in AE and that’s it. Imagine the time and cost a real spot like this would cost. 100x less expensive due to AI: https://www.reddit.com/r/singularity/comments/1dyh5z3/this_was_done_in_less_than_24h_by_one_person/
Image Consistency: https://arxiv.org/pdf/2404.18919
https://arxiv.org/pdf/2405.17661 (has video consistency too)
Consistent image to video: https://arxiv.org/pdf/2402.04324 
Midjourney character consistency: https://docs.midjourney.com/docs/character-reference 
https://x.com/fofrAI/status/1796547108478038355 
Very consistent video to video: https://www.reddit.com/r/StableDiffusion/comments/1dmed1s/diffutoon_highresolution_editable_toon_shading/ 
NVIDIA Research solved subject consistency: "Joint-image Diffusion Models for Finetuning-free Personalized Text-to-image Generation" https://research.nvidia.com/labs/dir/jedi/
drag-and-drop a subject from an image with an arbitrary style onto another target image with a vastly different style and achieve a style-aware and realistic insertion of the subject into the target image: https://magicinsert.github.io/
Code-free game development in a few minutes: https://x.com/CharaspowerAI/status/1799134111334121892
https://x.com/ZReacc/status/1813196548337012943
Multi-modal (text and image) long story generation: https://huggingface.co/papers/2407.08683
Image movement: https://x.com/dreamingtulpa/status/1753710085447074104
Adding and tweaking concepts to a pre-existing image: https://x.com/gytdau/status/1811530283747000386
Runway Gen-3 Alpha can simulate liquids such as water, paint, oil, honey and molten glass. All with realistic viscosity, physics-based interactivity and caustics: https://x.com/runwayml/status/1811751431453450449
Image + motion to video: https://github.com/tencent/MimicMotion
CrowdMoGen: Zero-Shot Text-Driven Collective Motion Generation
𝐏𝐫𝐨𝐣: http://gxyes.github.io/projects/CrowdMoGen.html 
𝐀𝐛𝐬: http://arxiv.org/abs/2407.06188
a zero-shot text-driven framework that harnesses the power of LLMs to incorporate the collective intelligence into motion generation
Adding sound to video: https://x.com/dreamingtulpa/status/1812518092557193604
AI game generation: https://x.com/_akhaliq/status/1812677264892395837
M2S is a new DDPM-based image inpainting method that is 60 times faster than RePaint: https://github.com/linghuyuhangyuan/M2S

How the computer games industry is embracing AI: https://www.bbc.com/news/business-68844761
Andrew Maximov has been working in the computer games industry for 12 years… he believes that artificial intelligence (AI) will play a crucial role in keeping the soaring costs of game production down, and save video game designers vital time by automating repetitive tasks.
His company, Promethean AI offers developers a set of tools to craft their own virtual worlds. Mr Maximov hopes to disrupt the way games are currently produced.
Californian software firm Inworld is also employing AI to build elements of computer games.
It has created an engine that allows developers to add realism to game worlds and emotional depth to characters. The firm is also working on what it calls a narrative graph, developed in partnership with Xbox, which will use AI to help create storylines.
"The engine allows developers to add AI agents that can see, sense, and perceive the world around them, while also interacting with players and taking in-game actions. When you can imbue virtual characters with advanced cognitive capabilities, it unlocks a completely new paradigm for storytelling and gameplay," he says.
Nick Walton is the chief executive of gaming firm Latitude.io, and he believes AI has the power to personalise the gaming experience.
"We are at the start with AI and as it advances we will see very dynamic, adaptive worlds with characters that feel alive, with story arcs where you as the hero are doing unique things and having a very unique impact on the world.
"You could play a game where you find a town that no-one else cares about and no other player has spent time in, and you can get really invested in it and develop relationships with all the characters in it," he tells the BBC.
The chief executive of computer games giant EA, Andrew Wilson, recently told delegates at a conference that around 60% of the game publisher's development processes could be affected by AI tools
PICA can generate high-fidelity animatable clothed human avatars with physics-accurate dynamics, even for loose clothing, from multi-view videos: https://ustc3dv.github.io/PICA/
Extremely dynamic image to video: https://x.com/dreamingtulpa/status/1813486936868213073
'AI will become the new normal’: how the art world's technological boom is changing the industry: https://www.theartnewspaper.com/2023/02/28/ai-will-become-the-new-normal-how-the-art-worlds-technological-boom-is-changing-the-industry
Art created using artificial intelligence (AI) is burgeoning. From commercial gallery shows—including Jon Rafman’s large-scale, algorithmically generated paintings at Sprüth Magers in London (Ebrah k’dabri, until 25 March)—to the PATH-AI artist residency organised in collaboration with London’s Somerset House, AI-related art projects are springing up everywhere.
Artists in the field stress that AI is prompting a paradigm shift. Rafman says: "I have been using AI in one form or another since I began making art on computers in the 1990s. I only truly started using image-generating AI tools around 2020."
His 40-minute film at Sprüth Magers, Counterfeit Poast (2023), is entirely generated from AI imagery; the characters in it are animated using an iPhone facial motion-capture app. “AI has the potential to open the gates for new perceptions of image-making just as the development of photography liberated painting from pure factual representation and allowed painters to focus on other dimensions, such as colour, light, and movement,” Rafman adds.
The German digital artist Mario Klingemann has been working with AI since 2015, developing works such as Memories of Passersby 1 (2018), which employ a system of neural networks to generate a never-ending stream of portraits. “I think artists should embrace or at least try out the possibilities that AI offers,” he says. “This technology will become the new normal.”Klingemann explains how he harnesses AI, creating works where the boundaries between human influence and machine creation become increasingly blurred. Botto, for instance, is a project to create an entity that can be perceived as an autonomous artist. “It is set up as a hybrid between an AI that makes its own creative decisions and a community of human stewards that vote on Botto’s proposals and thereby curate the output and indirectly steer the artistic development of the machine,” he says.
Three artists have been selected for the six-month remote artist residency programme PATH-AI, which has been developed by the Alan Turing Institute in London, the University of Edinburgh and the RIKEN research institute in Japan. The AI-inspired works of Nouf Aljowaysir, Chris Zhongtian Yuan, and Juan Covelli are presented on Somerset House’s online curated space known as Channel. Brooklyn-based Aljowaysir has made a film, Ana Min Wein (Where Am I From?), which tracks her immigration path to the US, charting her family’s migration history across Saudi Arabia and Iraq. An AI assistant supports her journey in a film.
Video frame interpolation: https://x.com/dreamingtulpa/status/1813969140517904831
Creating specific colors and shapes in images: https://x.com/dreamingtulpa/status/1814212221649457512/
We recently announced JASCO, a music-generation model with improved controllability using conditioning inputs like chords or beat: https://x.com/AIatMeta/status/1814405505789706253
4D reconstruction from a video: https://x.com/_akhaliq/status/1814156712175083539
Combining AI with CGI: https://x.com/c_valenzuelab/status/1813954465667457412
McDonalds ad: https://www.reddit.com/r/aivideo/comments/1e7x5in/mcdonalds_ai_spec_ad_cost_me_less_than_60_happy/
Change backgrounds and animate person based on an image and pose guidance video: https://x.com/dreamingtulpa/status/1815059351486316779
Animate3D can animate any static multi-view 3D model: https://x.com/dreamingtulpa/status/1815295122164068801
MusiConGen, Rhythm and Chord Control for Transformer-Based Text-to-Music Generation: https://huggingface.co/papers/2407.15060
Lite2Relight can relight human portraits while preserving 3D consistency and identity: https://x.com/dreamingtulpa/status/1816146758608605362
Dynamic 3D Content Generation with Multi-Frame and Multi-View Consistency: We present Stable Video 4D (SV4D), a latent video diffusion model for multi-frame and multi-view consistent dynamic 3D content generation. Unlike previous methods that rely on separately trained https://x.com/dreamingtulpa/status/1816146758608605362
Similar to creative upscaling in images, Noise Calibration can improve the visual quality of videos while maintaining the structure of the input video: https://x.com/dreamingtulpa/status/1816441922589708291
Excellent video to video: https://x.com/8bit_e/status/1818246916129329464
Ubisoft and MiHoYo Among Publishers Signing Up for Nvidia's AI-Generated Video Character Tool: https://www.ign.com/articles/ubisoft-and-mihoyo-nvidia-ace-ai-video-character-tool
Genshin Impact developers talk about how they used AI in their hit game Honkai: Star Rail: https://en.as.com/meristation/news/genshin-impact-developers-talk-about-how-they-used-ai-in-their-hit-game-honkai-star-rail-n/

The new miHoYo game already uses artificial intelligence techniques, but they have not used it to write narrative content, paying attention to “its impact”.
miHoYo co-authors science paper outlining bold AI intentions: https://www.pocketgamer.biz/mihoyo-co-authors-science-paper-outlining-bold-ai-intentions/
LumaLabsAI - Dream Machine 1.5 is here. Now with higher-quality text-to-video, smarter understanding of your prompts, custom text rendering, and improved image-to-video: https://x.com/LumaLabsAI/status/1825639918539817101
Ideagram 2.0: https://www.reddit.com/r/singularity/comments/1exsq4d/introducing_ideogram_20_our_most_advanced/
Diffusion models as real-time interactive game engines: https://gamengen.github.io/
https://gamegen-o.github.io/
Doodle to image: https://www.reddit.com/r/Holdmywallet/comments/1f5qqaf/ms_paint_may_not_be_so_useless_now/
Taming Audio-Driven Portrait Avatar with Long-Term Motion Dependency: https://x.com/_akhaliq/status/1831530803635085766
Domo AI just launched its video upscaler. It's fast and scales videos up to 4K: https://www.reddit.com/r/singularity/comments/1fdw8xm/domo_ai_just_launched_its_video_upscaler_its_fast/
NotebookLM now lets you listen to a conversation about your sources (Create a two person podcast from your sources): https://blog.google/technology/ai/notebooklm-audio-overviews/
Example of Cicero’s journal from Skyrim: https://vocaroo.com/1nTyEIEqGavr
Hasbro’s CEO Thinks D&D‘s Adoption of AI Is Inevitable: https://gizmodo.com/hasbro-ceo-dungeons-dragons-ai-2000498007
“If you look at a typical D&D player… I play with probably 30 or 40 people regularly. There’s not a single person who doesn’t use AI somehow for either campaign development or character development or story ideas,” 
New Dungeons & Dragons Sourcebook Features AI Generated Art: https://gizmodo.com/dnd-ai-art-bigbys-giants-book-artist-generators-wotc-1850710496
An artist for Bigby Presents: Glory of the Giants! has admitted to using AI to generate "certain details" of new art for the sourcebook.

Runway and Lionsgate are partnering to explore the use of AI in film production: https://runwayml.com/news/runway-partners-with-lionsgate
Adding movement to images: https://www.reddit.com/r/singularity/comments/1fk4tgp/kling_ai_showcasing_the_use_of_the_motion_brush/
EA demonstrates upcoming text-to-game system that can create playable game content in real time: https://www.instagram.com/p/DAIytFyg9Mh/?igsh=MTc4MmM1YmI2Ng==
SPARK can create high-quality 3D face avatars from regular videos and track expressions and poses in real time. It improves the accuracy of 3D face reconstructions for tasks like aging, face swapping, and digital makeup: https://www.reddit.com/r/singularity/comments/1fnos0u/spark_can_create_highquality_3d_face_avatars_from/
Horror film made with AI: https://www.reddit.com/r/aivideo/comments/1fom28b/the_cartoonist_horror_short_film/
Humorous film: https://www.reddit.com/r/aivideo/comments/1fo09ic/how_minimax_gordon_ramsay_videos_are_actually/
New video generation AI can create videos with rack focus: https://x.com/TheoMediaAI/status/1840834127697703262
Snoop Dogg's latest music video is AI-generated and took months to create: https://community.designtaxi.com/topic/5461-snoop-doggs-latest-music-video-is-ai-generated-and-took-months-to-create/
Late Night With the Devil movie uses AI art: https://letterboxd.com/film/late-night-with-the-devil/
Recommended by Chainsaw Man/Look Back/Goodbye Eri author Tatsuki Fujimoto: 
Other people like it too: https://www.reddit.com/r/Chainsawfolk/comments/1fvsr5c/fujiwater_recommends_peak/
3.4 out of 5 on Letterboxed despite anti AI review bombing 
Photo manipulation: https://www.reddit.com/r/singularity/comments/1fwr3lg/realtime_head_transformation_demo/
Inverse Painting can generate time-lapse videos of the painting process for any artwork. The method learns from diverse drawing techniques, producing realistic results across different artistic styles: https://reddit.com/r/singularity/comments/1fybddi/inverse_painting_can_generate_timelapse_videos_of/
Runway CEO Cristóbal Valenzuela says AI is coming to Hollywood and demos tools that move beyond text prompts to give filmmakers greater control over video generation: https://www.reddit.com/r/singularity/comments/1g0uwdo/runway_ceo_crist%C3%B3bal_valenzuela_says_ai_is_coming/
Editing 3d scenes: https://github.com/Fangkang515/CE3D
Very useful for VFX: https://x.com/sainimatic/status/1847677298549674007
Introducing Voice Design by ElevenLabs - Generate a unique voice from a text prompt alone: https://www.reddit.com/r/singularity/comments/1gabx6a/introducing_voice_design_by_elevenlabs_generate_a
Disney is set to announce a major AI initiative that will transform its creative output. The initiative is said to involve “hundreds” of people at the company and will primarily focus on post-production and visual effects: https://www.thewrap.com/disney-ai-initiative/
https://www.recraft.ai/blog/recraft-introduces-a-revolutionary-ai-model-that-thinks-in-design-language


Style control: 
You can now add your own starting image to Oasis Minecraft simulator and the AI will morph it into your new world: https://www.reddit.com/r/singularity/comments/1gjeuyp/you_can_now_add_your_own_starting_image_to_oasis/
Kling is about to release a tool for character consistency. They are on a path towards making full AI movies: https://www.reddit.com/r/singularity/comments/1gn6jq3/kling_is_about_to_release_a_tool_for_character/
AutoVFX can automatically create realistic visual effects in videos from a single image and text instructions! https://x.com/dreamingtulpa/status/1855177451464179950
AI-generated poetry from the VERY outdated GPT 3.5 is indistinguishable from human-written poetry and is rated more favorably: https://idp.nature.com/authorize?response_type=cookie&client_id=grover&redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-024-76900-1

AI-generated paintings are judged to be human-created artworks at higher rates than actual human-created paintings; AI-generated faces are judged to be real human faces at higher rate than actual photos of human faces, and AI-generated humor is just as funny as human-generated jokes. Despite this, studies have consistently found a bias against AI-generated artwork; when told that an artwork is AI-generated, participants rate the work as lower quality.
We conducted two experiments with non-expert poetry readers and found that participants performed below chance levels in identifying AI-generated poems (46.6% accuracy, χ2(1, N = 16,340) = 75.13, p < 0.0001). Notably, participants were more likely to judge AI-generated poems as human-authored than actual human-authored poems (χ2(2, N = 16,340) = 247.04, p < 0.0001). We found that AI-generated poems were rated more favorably in qualities such as rhythm and beauty, and that this contributed to their mistaken identification as human-authored.
MagicQuill: An intelligent interactive image editing system: https://www.reddit.com/r/singularity/comments/1grnn3a/magicquill_an_intelligent_interactive_image/
Coca Cola’s annual Christmas commercial has been created with AI this time: https://x.com/DiscussingFilm/status/1857502106074099717
Runway | Introducing Frames - An image generation model offering unprecedented stylistic control: https://www.reddit.com/r/singularity/comments/1gzkjg8/runway_introducing_frames_an_image_generation/
https://openreview.net/pdf?id=u1cQYxRI1H


New image generation model from Luma: https://lumalabs.ai/photon



Prompt: Photo-realistic cat made out of peeled oranges

Prompt: A plate of sushi, where the fish is replaced with translucent sea waves and tiny surfers ride on top.







Sora 2 leaked: https://www.reddit.com/r/singularity/comments/1h9ii94/sora_2_leaked_looks_impressive/
Veo 2 beats Sora: https://deepmind.google/technologies/veo/veo-2/

AI VTuber Neurosama wins Best Tech VTuber of the Year for 2023 and 2024: https://en.wikipedia.org/wiki/Neuro-sama
Examples:
https://www.youtube.com/watch?v=Abt-ijlI92Q
https://www.youtube.com/watch?v=gVNBpSGpitk&t=443s
Knows what “that word” means at 11:38
https://www.youtube.com/watch?v=Ky495KCWz4Q
https://www.youtube.com/watch?v=3YDs-I_CdWU
Unbelievably good comedic timing: https://x.com/NeuroContext/status/1870286205604245982


Was also the most watched female streamer on Twitch for the last week of December 2023, beating Ironmouse and many international streamers by a HUGE margin (more than double the runner-up) and top 10 in ALL of Twtich: https://www.youtube.com/watch?v=YfNC505f_5I

Did it again in 2024: https://x.com/StreamsCharts/status/1873466520271036856/
4th most watched Twitch streamer overall, very close to 3rd: https://x.com/StreamsCharts/status/1873421724953288873

640k followers on Twitch and 400k subscribers on Youtube
2nd most watched streamer on Twitch between 12/19/24-12/26/24: 
Source: https://sullygnome.com/channels/3/watched
6th most subscribed English-speaking channel: 
From: https://twitchtracker.com/subscribers/english
New upscaling method: https://huggingface.co/spaces/OAOA/InvSR
AI cosplays: https://www.reddit.com/r/aivideo/comments/1hkx27x/titans/
4.2. Corporate Use
Direct link: https://docs.google.com/document/d/1oHuwssPPUTa4dwczX_s3qg3iPfWE4VK-R52LN51GwI8/edit?tab=t.0#heading=h.akz9hanp4wxi

AI agents entering workplace: https://www.bloomberg.com/news/newsletters/2024-10-24/ai-agents-have-officially-entered-the-workplace-flaws-and-all

“It is actually better than a human most of the time,” said Amjad Masad, chief executive officer of Replit. “Humans are kind of lazy and get annoyed and don’t test everything. This is much more thorough.”
ServiceNow CEO Bill McDermott told my colleague Brody Ford this week that his company’s new AI agents “don’t eat” and can work 24/7. “You don’t have to give ‘em a 401k!” he added. The software company’s agents are currently being tested out by some customers and will be released more broadly next month, he said.
In September, Salesforce Chief Operating Officer Brian Millham said customers using the company’s agents may elect to hire fewer people going forward. He gave an example of a 5,000-person call center needing 30% fewer workers within five years.


Stanford: AI makes workers more productive and leads to higher quality work. In 2023, several studies assessed AI’s impact on labor, suggesting that AI enables workers to complete tasks more quickly and to improve the quality of their output: https://aiindex.stanford.edu/wp-content/uploads/2024/04/HAI_2024_AI-Index-Report.pdf

Workers in a study got an AI assistant. They became happier, more productive, and less likely to quit: https://www.businessinsider.com/ai-boosts-productivity-happier-at-work-chatgpt-research-2023-4

From April 2023, before GPT 4 became widely used

randomized controlled trial using the older, less-powerful GPT-3.5 powered Github Copilot for 4,867 coders in Fortune 100 firms. It finds a 26.08% increase in completed tasks: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4945566

According to Altman, 92% of Fortune 500 companies were using OpenAI products, including ChatGPT and its underlying AI model GPT-4, as of November 2023, while the chatbot has 100mn weekly users: https://www.ft.com/content/81ac0e78-5b9b-43c2-b135-d11c47480119

12/2024 update: ChatGPT now has over 300 million weekly users. During the NYT’s DealBook Summit, OpenAI CEO Sam Altman said users send over 1 billion messages per day to ChatGPT: https://www.theverge.com/2024/12/4/24313097/chatgpt-300-million-weekly-users

Gen AI at work has surged 66% in the UK, but bosses aren’t behind it: https://finance.yahoo.com/news/gen-ai-surged-66-uk-053000325.html

>of the seven million British workers that Deloitte extrapolates have used GenAI at work, only 27% reported that their employer officially encouraged this behavior.
Over 60% of people aged 16-34 have used GenAI, compared with only 14% of those between 55 and 75 (older Gen Xers and Baby Boomers).

A Google poll says pretty much all of Gen Z is using AI for work: https://www.yahoo.com/tech/google-poll-says-pretty-much-132359906.html?.tsrc=rss

Some 82% of young adults in leadership positions at work said they leverage AI in their work, according to a Google Workspace (GOOGL) survey released Monday. With that, 93% Gen Z and 79% of millennials surveyed said they use two or more tools on a weekly basis.
Most respondents said they use AI to start a task that feels overwhelming, improve their writing, and take notes, allowing them to join meetings on the go, Google Workspace said. A majority (86%) believe that AI can help leaders become better managers.
What’s more, 98% of the people surveyed believe AI will have an impact on their industry or workplace within the next 5 years.


Jobs impacted by AI: https://www.visualcapitalist.com/charted-the-jobs-most-impacted-by-ai/

Big survey of 100,000 workers in Denmark 6 months ago finds widespread adoption of ChatGPT & “workers see a large productivity potential of ChatGPT in their occupations, estimating it can halve working times in 37% of the job tasks for the typical worker.” https://static1.squarespace.com/static/5d35e72fcff15f0001b48fc2/t/668d08608a0d4574b039bdea/1720518756159/chatgpt-full.pdf

>ChatGPT is widespread, with over 50% of workers having used it, but adoption rates vary across occupations.
Workers see substantial productivity potential in ChatGPT, estimating it can halve working times in about a third of their job tasks.
Barriers to adoption include employer restrictions, the need for training, and concerns about data confidentiality (all fixable, with the last one solved with locally run models or strict contracts with the provider).



AI Dominates Web Development: 63% of Developers Use AI Tools Like ChatGPT: https://flatlogic.com/starting-web-app-in-2024-research


https://www.microsoft.com/en-us/worklab/work-trend-index/ai-at-work-is-here-now-comes-the-hard-part

>Already, AI is being woven into the workplace at an unexpected scale. 75% of knowledge workers use AI at work today, and 46% of users started using it less than six months ago.
Users say AI helps them save time (90%), focus on their most important work (85%), be more creative (84%), and enjoy their work more (83%). 
78% of AI users are bringing their own AI tools to work (BYOAI)—it’s even more common at small and medium-sized companies (80%).
53% of people who use AI at work worry that using it on important work tasks makes them look replaceable.
While some professionals worry AI will replace their job (45%), about the same share (46%) say they’re considering quitting in the year ahead—higher than the 40% who said the same ahead of 2021’s Great Reshuffle.
The heaviest Teams users (the top 5%) summarized 8 hours of meetings using Copilot in months of March, the equivalent of an entire workday.
As AI use surges ahead, leaders who are “extremely familiar” with AI see its potential to be as transformational as the shift from a typewriter to a computer. Within the next five years, 41% of these leaders expect to redesign business processes from the ground up with AI. In the same time frame, they anticipate orchestrating (38%) and training a team of AI bots (42%), and ensuring the ethical use of AI (47%) will be a core part of their job.
66% of leaders say they wouldn’t hire someone without AI skill.
71% say they’d rather hire a less experienced candidate with AI skill than a more experienced candidate without them.
And junior candidate may have a new edge: 77% of leaders say, with AI, early-in-career a talent will be given greater responsibilities.
Documents: Overall, Copilot users edited 10% more documents in Word, Excel, and PowerPoint—the companies that saw the largest impact noticed a 20% increase. This may suggest that people are repurposing the time they save for high-value focus work like creating and consuming information.
Power users are familiar to extremely familiar with AI, using it at work at least several times a week and saving more than 30 minutes a day. And it’s paying off: power users say AI makes their overwhelming workload more manageable (92%), boosts their creativity (92%), and helps them focus on the most important work (93%)—and it helps them feel more motivated (91%) and enjoy work more (91%).
Senior leaders lean in: AI power users are 61% more likely to hear from their CEO about the importance of using generative AI at work, 40% more likely to hear from the leader of their department, and 42% more likely to hear from their manager’s manager.

Skeptics are gray and even most of them say AI is helpful for productivity, motivation, and enjoyment


“Visa has more than 500 generative artificial intelligence applications in use." Will develop "AI-generated digital employees that are overseen by human worker." https://www.msn.com/en-us/money/other/visa-has-deployed-hundreds-of-ai-use-cases-it-s-not-stopping/ar-AA1tkVq0
Visa is leaning on staff to quickly drum up generative AI use cases even as the payments giant streamlines its international business and cuts jobs: 
President of Technology Rajat Taneja said the company already has more than 500 generative artificial intelligence applications in use, the result of a go-fast strategy designed to reap the AI’s benefits sooner and keep pace with bad actors whose fraud methods are becoming more sophisticated.
Taneja said his vision in the coming years is for Visa to have AI-generated digital employees that are overseen by human worker. Any given human employee could oversee, on average, eight to 10 AI employees that are trusted with a variety of tasks, he said

2024 McKinsey survey on AI: https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai

>For the past six years, AI adoption by respondents’ organizations has hovered at about 50 percent. This year, the survey finds that adoption has jumped to 72 percent (Exhibit 1). And the interest is truly global in scope. Our 2023 survey found that AI adoption did not reach 66 percent in any region; however, this year more than two-thirds of respondents in nearly every region say their organizations are using AI

>In the latest McKinsey Global Survey on AI, 65 percent of respondents report that their organizations are regularly using gen AI, nearly double the percentage from our previous survey just ten months ago.

>Respondents’ expectations for gen AI’s impact remain as high as they were last year, with three-quarters predicting that gen AI will lead to significant or disruptive change in their industries in the years ahead

>Organizations are already seeing material benefits from gen AI use, reporting both cost decreases and revenue jumps in the business units deploying the technology.

They have a graph showing about 50% of companies decreased their HR, service operations, and supply chain management costs using gen AI and 62% increased revenue in risk, legal, and compliance, 56% in IT, and 53% in marketing 




Scale.ai report says 85% of companies have seen benefits from gen AI. Only 8% that implemented it did not see any positive outcomes.: https://scale.com/ai-readiness-report


>82% of companies surveyed are testing and evaluating models. 


Most office workers expect AI to improve their jobs, report reveals: https://www.peoplemanagement.co.uk/article/1878419/office-workers-expect-ai-improve-jobs-report-reveals
The vast majority (85 per cent) of office workers believe AI will enhance their roles instead of replace them, research by Jitterbit has revealed. 
According to the poll of 1,022 full-time office workers in the US and the UK, 96 per cent of office workers think AI can improve their professional skills.
“The very fact that there’s now less fear that AI is going to replace roles is a clear sign that confidence in AI is rising. With mounting economic pressures, workload and delivery expectations for employees are high, meaning more employees are using AI to save time and improve the quality and speed of their work, which is a clear benefit to business.
People managers admit to using AI for performance reviews and feedback, research finds: https://www.peoplemanagement.co.uk/article/1875801/people-managers-admit-using-ai-performance-reviews-feedback-research-finds
Half (52 per cent) of people managers in the UK have used generative AI tools in their role, research by Visier has revealed.
The survey of more than 750 people managers also found that three in five (59 per cent) UK respondents who already utilise the technology were using it for performance reviews and feedback. 
A further 41 per cent said they used it to help make people-related decisions, while 36 per cent used it to develop scripts to use ahead of conversations.

Workers turning to social media and AI to learn new skills, research finds: https://www.peoplemanagement.co.uk/article/1874165/workers-turning-social-media-ai-learn-new-skills-research-finds
More than half (56 per cent) of employees aged 18-24 and 36 per cent of 25-34 year olds said they had explored generative AI as a way to develop these workplace skills, compared to just 15 per cent of those aged 55-64.
 People Management poll revealed that 63 per cent agreed social media and AI are good ways for employees to learn workplace skills

Half of Gen Z think ChatGPT gives better career advice than managers – People Management puts it to the test https://www.peoplemanagement.co.uk/article/1862583/half-gen-z-think-chatgpt-gives-better-career-advice-managers-%E2%80%93-people-management-puts-test
Almost half (47 per cent) of Gen Z workers say they get better careers advice from ChatGPT than their managers, a report by INTOO and Workplace Intelligence has found.

JP Morgan on adoption and cost savings led by generative AI: https://assets.jpmprivatebank.com/content/dam/jpm-pb-aem/global/en/documents/eotm/a-severe-case-of-covidia-prognosis-for-an-ai-driven-us-equity-market.pdf

Says Nvidia’s growth is not like the dot-com bubble because it has the earnings boost to back up its stock performance while companies during the bubble did not. Its earnings and revenue are still increasing, meaning companies are not slowing down their AI investments 
McKinsey says AI can add $8 trillion to the economy each year
Y Combinator is all in on AI and it has a great track record (176% average annual return since 2005)
AI performance metrics are quickly becoming obsolete 
Claude 3.5 Sonnet (which is weaker than the upcoming Claude 3.5 Opus model) scores about 60% in the GQPA. PhDs score about 65% in their field of expertise and 34% on all the subjects overall, even with unrestricted internet access
Google study found 80% of all jobs have at least 10% of tasks that can be done twice as quickly with AI





https://www.reuters.com/technology/artificial-intelligence/china-leads-world-adoption-generative-ai-survey-shows-2024-07-09/

>In a survey of 1,600 decision-makers in industries worldwide by U.S. AI and analytics software company SAS and Coleman Parkes Research, 83% of Chinese respondents said they used generative AI, the technology underpinning ChatGPT.
That was higher than the 16 other countries and regions in the survey, including the United States, where 65% of respondents said they had adopted GenAI.
The global average was 54%.


https://www.hrgrapevine.com/us/content/article/2024-06-04-microsoft-announces-up-to-1500-layoffs-leaked-memo-blames-ai-wave

>”Microsoft has previously disclosed its billion-dollar AI investments have brought developments and productivity savings. These include an HR Virtual Agent bot which it says has saved 160,000 hours for HR service advisors by answering routine questions.”

Morgan Stanley CEO says AI could save financial advisers 10-15 hours a week: https://finance.yahoo.com/news/morgan-stanley-ceo-says-ai-170953107.html

Goldman Sachs CIO on How the Bank Is Actually Using AI: https://omny.fm/shows/odd-lots/080624-odd-lots-marco-argenti-v1?in_playlist=podcast
A year in: Nestlé employees save 45 minutes per week using internal generative AI: https://www.worklife.news/technology/nesgpt-nestle-genai/
Multiply this for every employee and it adds up 

Goldman Sachs says generative A.I. could impact 300 million jobs: https://www.cnbc.com/2023/03/28/ai-automation-could-impact-300-million-jobs-heres-which-ones.html

Goldman Sachs says generative AI could raise global GDP by 7%: https://www.goldmansachs.com/intelligence/pages/generative-ai-could-raise-global-gdp-by-7-percent.html

Photos to ads: https://www.reddit.com/r/StableDiffusion/comments/1dmv1mf/turn_your_boring_product_photos_into_professional/


 Introducing StockBot, a lightning fast AI chatbot powered by Llama3-70b on Groq that responds with live stock charts, financials, news, and screeners. All open source: https://x.com/BenjaminKlieger/status/1814445262968107104



Taco Bell to roll out AI drive-thru ordering in hundreds of locations by end of year: https://www.nbcnews.com/business/business-news/taco-bell-roll-ai-drive-thru-ordering-hundreds-locations-end-year-rcna164524
Yum Brands said the tech has improved order accuracy, reduced wait times, decreased employees’ task load and fueled profitable growth.
LlamaCloud Chat: https://x.com/jerryjliu0/status/1814387708267209188
Get a full-blown ChatGPT UI over any production data source in minutes. Connect to data sources like S3, Sharepoint, Notion, Slack, parse and index complex document types (PDFs, powerpoints, spreadsheets), and get back an advanced retrieval endpoint.


LlamaCloud provides the data interface for your LLM agent. Our goal is to help you centralize and manage your data pipelines for LLM apps. LlamaCloud Chat helps you get immediate validation from your data sources and is a nice UI experience in its own right.

AI Agents Are Coming for Mundane—but Valuable—Office Task: https://www.wired.com/story/chatbots-are-entering-the-stone-age/

>Anthropic and other big AI startups are teaching chatbots “tool use,” to make them more useful in the workplace.

AI tools spark anxiety among Philippines’ call center workers: https://restofworld.org/2023/call-center-ai-philippines/

>Bernie now uses ChatGPT and Bing to compile all the technical information he needs for a query in less than five minutes. It’s doubled the number of customer complaints he can handle in a day. 

>“It made my work easier. I can even get ideas on how to approach certain complaints, making [my answers] appear engaging, persuasive, empathetic. It can give you that, depending on the prompt that you input,” Bernie told Rest of World.

OpenAI tech increased productivity of Philippine contact center agents by 12.8% – study: https://www.rappler.com/technology/openai-gpt-productivity-effects-philippines-contact-center-agents/

“GenAI will save [Klarna] $10m in marketing this year. We’re spending less on photographers, image banks, and marketing agencies” https://www.reuters.com/technology/klarna-using-genai-cut-marketing-costs-by-10-mln-annually-2024-05-28/

- $6m less on producing images.
- 1,000 in-house AI-produced images in 3 months. Includes the creative concept, quality check, and legal compliance.
- AI-image production reduced from 6 WEEKS TO 1 WEEK ONLY.
- Customer response to AI images on par with human produced images.
- Cutting external marketing agency costs by 25% (mainly translation, production, CRM, and social agencies).


Our in-house marketing team is HALF the size it was last year but is producing MORE!


We’ve removed the need for stock imagery from image banks like 
@gettyimages


Now we use genAI tools like Midjourney, DALL-E, and Firefly to generate images, and Topaz Gigapixel and Photoroom to make final adjustments.
Faster images means more app updates, which is great for customers. And our employees get to work on more fun projects AND we're saving money.

Robots [Automates] jobs from unions: https://phys.org/news/2024-06-robots-jobs-unions-decline-unionizations.html 

AI took their jobs. Now they get paid to make it sound human: https://www.bbc.com/future/article/20240612-the-people-making-ai-sound-more-human
>In numerous industries, AI is being used to produce work that was once the exclusive domain of the human mind
>He led a team of more than 60 writers and editors…. " the business introduced an automated system. Miller's manager would plug a headline for an article into an online form, an AI model would generate an outline based on that title, and Miller would get an alert on his computer. Instead of coming up with their own ideas, his writers would create articles around those outlines, and Miller would do a final edit before the stories were published. Miller only had a few months to adapt before he got news of a second layer of automation. Going forward, ChatGPT would write the articles in their entirety, and most of his team was fired. The few people remaining were left with an even less creative task: editing ChatGPT's subpar text to make it sound more human.
>By 2024, the company laid off the rest of Miller's team, and he was alone. "All of a sudden I was just doing everyone's job," Miller says. Every day, he'd open the AI-written documents to fix the robot's formulaic mistakes, churning out the work that used to employ dozens of people.


BP Earnings Call: We need 70% less coders from third parties to code as the AI handles most of the coding, the human only needs to look at the final 30% to validate it, that's a big savings for the company moving forward.
Second things like call centers, the language models have become so sophisticated now. They can operate in multiple languages, 14, 15 languages easily. In the past, that hasn't been something we can do. So we can redeploy people off that given that the AI can do it. You heard my advertising example last quarter where advertising cycle times moved from four to five months down to a couple of weeks. So that's obviously reducing spend with third parties. We've now got Gen AI in the hands through Microsoft Copilot across many, many parts of the business and we'll continue to update you with anecdotes as we go through
Source: https://seekingalpha.com/article/4690194-bp-p-l-c-bp-q1-2024-earnings-call-transcript 

This is almost certainly true because this is quoted from an earnings call from BP and lying to investors is a crime (securities fraud). This would include lying about the reason for getting rid of the workers (in other words, it can’t just be layoffs). The numbers that are provided are also too specific to be exaggerations without also being a lie.

Leaked Memo Claims New York Times Fired Artists to Replace Them With AI: https://futurism.com/the-byte/new-york-times-fires-artists-ai-memo

Cheap AI voice clones may wipe out jobs of 5,000 Australian actors: https://www.theguardian.com/technology/article/2024/jun/30/ai-clones-voice-acting-industry-impact-australia

>Industry group says rise of vocal technology could upend many creative fields, including audiobooks – the canary in the coalmine for voice actors


Almost 65,000 Job Cuts Were Announced In April—And AI Was Blamed For The Most Losses Ever: https://www.forbes.com/sites/maryroeloffs/2024/05/02/almost-65000-job-cuts-were-announced-in-april-and-ai-was-blamed-for-the-most-losses-ever/

In a survey of 450 executives in the US, "45 percent said they were automating tasks to reduce staffing and labour costs." https://www.smh.com.au/world/north-america/nearly-half-of-us-firms-using-ai-say-goal-is-to-cut-staffing-costs-20240629-p5jpsl.html

Bank of America CEO: AI helping cut call times, branch visits: https://www.msn.com/en-us/money/companies/bank-of-america-ceo-ai-helping-cut-call-times-branch-visits/ar-AA1eCRVI

>AI virtual financial assistant has logged 1.5B customer interactions since 2018 launch

Klarna SUCCESSFULLY replaces call centers with AI https://www.reddit.com/r/klarna/comments/1c1fwr3/klarna_ceo_on_using_ai_to_replace_700_workers/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_button

- Klarnas AI assistant, powered by @OpenAI , has in its first 4 weeks handled 2.3 million customer service chats and the data and insights are staggering:

Handles 2/3 rd of our customer service enquires

On par with humans on customer satisfaction

Higher accuracy leading to a 25% reduction in repeat inquiries

customer resolves their errands in 2 min vs 11 min

 Live 24/7 in over 23 markets, communicating in over 35 languages

It performs the equivalent job of 700 full time agents

Digital automation could make 1.1 million roles in the Philippines obsolete by 2028: https://www.cisco.com/c/dam/global/en_sg/assets/csr/pdf/technology-and-the-future-of-asean-jobs.pdf

‘I will never go back’: Ontario family doctor says new AI notetaking saved her job: https://globalnews.ca/news/10463535/ontario-family-doctor-artificial-intelligence-notes

>”If the physician is unhappy with the note, Lall said, they can ask the AI model to regenerate the information or add more detail to any one of the categories. While the tool has some imperfections, she said, the improvements have been noticeable over the 10 months since she began using it.“I really feel this should be the next gold standard for all of our doctors. It decreases the cognitive load you feel at the end of the day,” she said.The Ford government has been so impressed with the technology that it announced a pilot program to allow 150 family physicians to use AI Scribe as part of their practices. The health minister said the early signs were promising but stressed government would proceed carefully.”

Robotics makers embrace Nvidia digital twins to create autonomous AI-run factories: https://www.computerworld.com/article/2137856/robotics-makers-embrace-nvidia-digital-twins-to-create-autonomous-ai-run-factories.html


Former Microsoft & Google research scientist Kai-Fu Lee- About 50% Of Jobs Will Be Displaced By AI Within 3 Years: https://www.youtube.com/watch?v=zZs447dgMjg

Since he’s no longer employed at those companies, he does not have an incentive to lie 

Consistent with claims from Anthropic’s Chief of Staff: https://fortune.com/2024/06/04/anthropics-chief-of-staff-avital-balwit-ai-remote-work/

His prediction from 2017 still holds that in 10-15 years around 40-50% of all jobs will be replaced by AI


Toys R Us uses Sora generated promo: https://www.reddit.com/r/singularity/comments/1do7dah/toys_r_us_releases_sora_generated_promo/

Square Enix says it used AI art in upcoming Foamstars game: https://www.theverge.com/2024/1/16/24040124/square-enix-foamstars-ai-art-midjourney

>AI technologies has been seeping into game development to mixed reception. Xbox has partnered with Inworld AI to develop tools for developers to generate AI NPCs, quests, and stories. The Finals, a free-to-play multiplayer shooter, was criticized by voice actors for its use of text-to-speech programs to generate voices. Despite the backlash, the game has a mostly positive rating on Steam and is in the top 20 of most played games on the platform.

AI Agent Better than OpenAI’s GPT-4o and costs just $1.60 per 1000 queries, making it 175% cheaper than GPT-4o. It is the world’s first fully autonomous AI-powered sales development representative (SDR): https://analyticsindiamag.com/aim-exclusive-yc-backed-indian-startup-claims-its-ai-agent-is-better-than-openais-gpt-4o/


AI video could be used for marketing: https://x.com/CharaspowerAI/status/1810952037246349739
Intuit is laying off 1,800 employees as AI leads to a strategic shift: https://fortune.com/2024/07/10/intuit-layoffs-email-hiring-ai-transformation/
RevOps team’s AI-powered sales call assistant: https://x.com/wadefoster/status/1811049453916430596
This Zap integrates @ChatGPTapp + @Gong_io + @SlackHQ + @HubSpot to summarize calls, generate follow-ups, and update records.
The result? +2 deals/rep/wk, +5% monthly inbound Revenue!
Using GPT-4o for parsing and synthesis for financial report RAG: https://www.linkedin.com/posts/hanane-d-algo-trader_amazon-10k-financial-report-using-llamaparse-activity-7216320268892282880-dK6w
Financial reports can contain a lot of charts and tables that text-based parsers struggle with.
LlamaParse is the easiest way to use multimodal models like gpt-4o to extract out text, diagram, and table information into well-structured representations.
This leads to not only good answers, but also easily-interpretable sources and citations
SpreadsheetLLM from Microsoft: https://x.com/_akhaliq/status/1812674543963578794
GPT-4 outsmarts Wall Street: AI predicts earnings better than human analysts | The researchers conducted their study by providing GPT-4 with standardised financial statements, carefully stripped of any company names or dates to prevent the model from using prior knowledge: https://www.businesstoday.in/technology/news/story/gpt-4-outsmarts-wall-street-ai-predicts-earnings-better-than-human-analysts-431062-2024-05-27
Runway and Lionsgate are partnering to explore the use of AI in film production: https://runwayml.com/news/runway-partners-with-lionsgate
IDC: Artificial Intelligence Will Contribute $19.9 Trillion to the Global Economy through 2030 and Drive 3.5% of Global GDP in 2030: https://www.idc.com/getdoc.jsp?containerId=prUS52600524
Bank of Canada’s Tiff Macklem warns AI could destroy more jobs than it creates: https://archive.md/YK2cm
He does not work in the tech industry and has no incentive to lie about this
Salesforce is looking to deploy a billion AI agents in the next 12 months: https://www.reddit.com/r/singularity/comments/1fmgz3b/marc_benioff_says_microsoft_copilot_is_the_new/
"Generative AI will Require 80% of Engineering Workforce to Upskill Through 2027" https://www.gartner.com/en/newsroom/press-releases/2024-10-03-gartner-says-generative-ai-will-require-80-percent-of-engineering-workforce-to-upskill-through-2027
Short Term:
AI tools will slightly increase productivity by helping with tasks.
Senior developers in well-run companies will benefit the most from these tools.

Medium Term:

AI agents will change how developers work by automating more tasks.
Most code will be made by AI, not humans.
Developers need to learn new skills like prompt engineering and RAG.
Long Term:
More skilled software engineers are needed because of the growing demand for AI-powered software.
A new type of engineer, called an AI engineer, who knows about software, data science, and AI/ML will be very important
OpenAI CPO Kevin Weil says their o1 model can now write legal briefs that previously were the domain of $1000/hour associates: "what does it mean when you can suddenly do $8000 of work in 5 minutes for $3 of API credits?" https://www.reddit.com/r/singularity/comments/1g7v0ud/openai_cpo_kevin_weil_says_their_o1_model_can_now/
Disney is set to announce a major AI initiative that will transform its creative output. The initiative is said to involve “hundreds” of people at the company and will primarily focus on post-production and visual effects: https://www.thewrap.com/disney-ai-initiative/
Coca Cola’s annual Christmas commercial has been created with AI this time: https://x.com/DiscussingFilm/status/1857502106074099717

Official Resident Evil account uses AI art: https://x.com/REBHPortal/status/1871587406958428305

4.3. Medical Use
 Physician study shows AI alone is better at diagnosing patients than doctors, even better than doctors using AI: https://www.computerworld.com/article/3613982/will-ai-help-doctors-decide-whether-you-live-or-die.html
AMIE: A research AI system for diagnostic medical reasoning and conversations: https://research.google/blog/amie-a-research-ai-system-for-diagnostic-medical-reasoning-and-conversations/




AMIE responses were preferred to general cardiologists’ responses for 5 of the 10 domains, and were equivalent for the rest. AMIE also demonstrates strong assistive potential — access to AMIE’s response improved cardiologists’ overall response quality in 63.7% of cases while lowering quality in just 3.4%. Qualitative results suggest AMIE and general cardiologists could complement each other, with AMIE responses being thorough and sensitive, while general cardiologists’ responses were concise and specific.

https://research.google/blog/advancing-amie-towards-specialist-care-and-real-world-validation/


BrainLM: https://www.biorxiv.org/content/10.1101/2023.09.12.557460v2.full.pdf
Utilizing self-supervised masked-prediction training, BrainLM demonstrates proficiency in both fine-tuning and zero-shot inference tasks. Fine-tuning allows for the accurate prediction of clinical variables like age, anxiety, and PTSD as well as forecasting of future brain states. Critically, the model generalizes well to entirely new external cohorts not seen during training. In zero-shot inference mode, BrainLM can identify intrinsic functional networks directly from raw fMRI data without any network-based supervision during training. The model also generates interpretable latent representations that reveal relationships between brain activity patterns and cognitive states. Overall, BrainLM offers a versatile and interpretable framework for elucidating the complex spatiotemporal dynamics of human brain activity. It serves as a powerful "lens" through which massive repositories of fMRI data can be analyzed in new ways, enabling more effective interpretation and utilization at scale. The work demonstrates the potential of foundation models to advance computational neuroscience research. 
Can accurately simulate the effects of drugs without needing to test it on animals or humans and predict mental illnesses






Tx-LLM: Supporting therapeutic development with large language models: https://research.google/blog/tx-llm-supporting-therapeutic-development-with-large-language-models/
In a historic moment for the dental profession, an AI-controlled autonomous robot has performed an entire procedure on a human patient for the first time, about eight times faster than a human dentist could do it: https://newatlas.com/health-wellbeing/robot-dentist-world-first/

Taiwan hospital deploys AI copilots to lighten workloads for doctors, nurses and pharmacists: https://news.microsoft.com/source/asia/features/taiwan-hospital-deploys-ai-copilots-to-lighten-workloads-for-doctors-nurses-and-pharmacists/?ocid=FY24_soc_omc_br_x_ChiMei

Great thread on medical uses of generative AI: https://x.com/Sandbar101/status/1784620540092731827

New research shows AI-discovered drug molecules have 80-90% success rates in Phase I clinical trials, compared to the historical industry average of 40-65%. The Phase 2 success rate so far is similar to the industry average, meaning more drugs are passing overall. https://www.sciencedirect.com/science/article/pii/S135964462400134X 

AI predicts diseases with 98% accuracy in real-time using tongue color | AI-powered computer model to analyze patients’ tongue colors for real-time disease diagnoses such as anemia, COVID-19, vascular and gastrointestinal issues, or asthma: https://interestingengineering.com/health/ai-model-predicts-disease-using-tongue-color

the paper itself shows that the best model has a f1 score, precision (accuracy), recall (avoidance of false positives) all above 98% https://www.mdpi.com/2227-7080/12/7/97

 AI Detects More Breast Cancers with Fewer False Positives https://www.rsna.org/news/2024/june/ai-detects-more-breast-cancers

Recall (false positive) rate and radiologist reading workload decreased significantly in AI-screened group
Using AI, breast radiologists in Denmark have improved breast cancer screening performance and reduced the rate of false-positive findings.
In total, 60,751 women were screened without AI, and 58,246 women were screened with the AI system. In the AI implementation group, 66.9% (38,977) of the screenings were single-read, and 33.1% (19,269) were double-read with AI assistance. 
Compared to screening without AI, screening with the AI system detected significantly more breast cancers (0.82% versus 0.70%) and had a lower false-positive rate (1.63% versus 2.39%). 
“In the AI-screened group, the recall rate decreased by 20.5 percent, and the radiologists’ reading workload was lowered by 33.4 percent,” Dr. Lauritzen said.
The positive predictive value of AI screening was also greater than that of screening without AI (33.5% versus 22.5%). In the AI group, a higher proportion of invasive cancers detected were 1 centimeter or less in size (44.93% vs. 36.60%).
“All screening performance indicators improved except for the node-negative rate which showed no evidence of change,” Dr. Lauritzen said.


Researchers find that GPT-4 performs as well as or better than doctors on medical tests, especially in psychiatry. https://www.news-medical.net/news/20231002/GPT-4-beats-human-doctors-in-medical-soft-skills.aspx

AI spots cancer and viral infections at nanoscale precision: https://healthcare-in-europe.com/en/news/ai-cancer-viral-infections-nanoscale-precision.html

Scanning images of cells could lead to new diagnostic and monitoring strategies for disease.

AI Detects Prostate Cancer 17% More Accurately Than Doctors, Finds Study: https://www.ndtv.com/science/ai-detects-prostate-cancer-17-more-accurately-than-doctors-finds-study-6170131

GPs use AI to boost cancer detection rates in England by 8%: https://www.theguardian.com/society/article/2024/jul/21/gps-use-ai-to-boost-cancer-detection-rates-in-england-by-8

ChatGPT outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions: https://today.ucsd.edu/story/study-finds-chatgpt-outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions?darkschemeovr=1

AI is better than doctors at detecting breast cancer: https://www.bbc.com/news/health-50857759

AI just as good at diagnosing illness as humans: https://www.medicalnewstoday.com/articles/326460

Accurate prediction of disease risk factors: https://doheny.org/wp-content/uploads/2024/10/Nature-Accurate-Prediction-of-Disease-Risk-Factors-From-Volumetric-Medical-Scans-by-a-Deep-Vision-Model-Pre-trained-With-2D-Scan-Article.pdf

SLIViT consistently outperformed domain-specific state-of-the-art models and was typically as accurate as clinical specialists who had spent considerable time manually annotating the analysed scans. Automating diagnosis tasks involving volumetric scans may save valuable clinician hours, reduce data acquisition costs and duration, and help expedite medical research and clinical applications.



https://www.aamc.org/news/will-artificial-intelligence-replace-doctors?darkschemeovr=1

Med-Gemini model achieves SoTA performance of 91.1% accuracy on USMLE : https://arxiv.org/abs/2404.18416

>We evaluate Med-Gemini on 14 medical benchmarks, establishing new state-of-the-art (SoTA) performance on 10 of them, and surpass the GPT-4 model family on every benchmark where a direct comparison is viable, often by a wide margin. On the popular MedQA (USMLE) benchmark, our best-performing Med-Gemini model achieves SoTA performance of 91.1% accuracy, using a novel uncertainty-guided search strategy. On 7 multimodal benchmarks including NEJM Image Challenges and MMMU (health & medicine), Med-Gemini improves over GPT-4V by an average relative margin of 44.5%. We demonstrate the effectiveness of Med-Gemini's long-context capabilities through SoTA performance on a needle-in-a-haystack retrieval task from long de-identified health records and medical video question answering, surpassing prior bespoke methods using only in-context learning. Finally, Med-Gemini's performance suggests real-world utility by surpassing human experts on tasks such as medical text summarization, alongside demonstrations of promising potential for multimodal medical dialogue, medical research and education. 

Double-blind study with Patient Actors and Doctors, who didn't know if they were communicating with a human, or an AI. Best performers were AI: https://m.youtube.com/watch?v=jQwwLEZ2Hz8 

Human doctors + AI did worse, than AI by itself. The mere involvement of a human reduced the accuracy of the diagnosis.
AI was consistently rated to have better bedside manner than human doctors.

In a new study, GPT4 outperformed human doctors at showing empathy: https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2821167

‘I will never go back’: Ontario family doctor says new AI notetaking saved her job: https://globalnews.ca/news/10463535/ontario-family-doctor-artificial-intelligence-notes 

[Google's medical AI destroys GPT's benchmark and outperforms doctors](https://newatlas.com/technology/google-med-gemini-ai/)

[The first randomized trial of medical #AI to show it saves lives. ECG-AI alert in 16,000 hospitalized patients. 31% reduction of mortality (absolute 7 per 100 patients) in pre-specified high-risk group](https://twitter.com/erictopol/status/1784936718283805124)

Medical Text Written By Artificial Intelligence Outperforms Doctors: https://www.forbes.com/sites/williamhaseltine/2023/12/15/medical-text-written-by-artificial-intelligence-outperforms-doctors/ 

AI can make healthcare better and safer: https://www.economist.com/technology-quarterly/2024/03/27/ais-will-make-health-care-safer-and-better

CheXzero significantly outperformed humans, especially on uncommon conditions. Huge implications for improving diagnosis of neglected "long tail" diseases: https://x.com/pranavrajpurkar/status/1797292562333454597


Humans near chance level (50-55% accuracy) on rarest conditions, while CheXzero maintains 64-68% accuracy.


AI is better than doctors at detecting breast cancer: https://youtube.com/watch?v=hVA3aJOWpmc

AI Outperforms Radiologists in Detecting Prostate Cancer on MRI: https://www.insideprecisionmedicine.com/topics/patient-care/ai-outperforms-radiologists-in-detecting-prostate-cancer-on-mri-scans/

First NHS physiotherapy clinic run by AI to start this year. New platform to provide same-day appointments with digital physiotherapist in effort to cut waiting times: https://www.theguardian.com/society/article/2024/jun/09/first-nhs-physiotherapy-clinic-run-by-ai-to-start-this-year

China's first (simulated) AI hospital town debuts: https://www.globaltimes.cn/page/202405/1313235.shtml
Remarkably, AI doctors can treat 10,000 [simulated]  patients in just a few days. It would take human doctors at least two years to treat that many patients. Furthermore, evolved doctor agents achieved an impressive 93.06 percent accuracy rate on the MedQA dataset (US Medical Licensing Exam questions) covering major respiratory diseases. They simulate the entire process of diagnosing and treating patients, including consultation, examination, diagnosis, treatment and follow-up. 
Research team leader of the Agent Hospital Liu Yang, also executive dean of Institute for AI Industry Research (AIR) and associate dean of the Department of Computer Science and Technology at Tsinghua University, told the Global Times that the AI hospital town is set to transform the way doctors diagnose and treat patients, bringing immense benefits to both medical professionals and the general public. 


For example, this innovative concept allows for virtual patients to be treated by real doctors, providing medical students with enhanced training opportunities. By simulating a variety of AI patients, medical students can confidently propose treatment plans without the fear of causing harm to real patients due to decision-making error, Liu said. 


This simulation training enables medical students to practice diagnosis and treatment in a risk-free environment, ultimately leading to the cultivation of highly skilled doctors, according to Liu.


If the patients in the town are real and the doctors are virtual, online telemedicine services can be provided to patients. The AI hospital town utilizes a vast repository of authoritative medical knowledge, allowing AI doctors to handle thousands, even millions, of cases.


The potential for high-quality, affordable and convenient healthcare services for the public is on the horizon, as the diagnostic capabilities of AI doctors evolve from the virtual world to the real world, Liu stated.


Liu went on to say that the AI hospital town can simulate and predict various medical scenarios, such as the spread, development and control of infectious diseases in a region.


Synchron CEO Tom Oxley says their brain-computer interface uses OpenAI's GPT-4o to generate prompts from multimodal inputs that users can choose from to express their intentions: https://x.com/tsarnick/status/1811560070632947836

EvolutionaryScale, a frontier AI research lab, has unveiled ESM3, a groundbreaking generative AI model for protein design that simulates millions of years of evolution to create novel proteins, potentially revolutionizing fields from drug discovery to environmental sustainability: https://x.com/ai_for_success/status/1812369558097015292

Introducing Surgical Robot Transformer (SRT): Automating surgical tasks with end-to-end imitation learning: https://x.com/jwbkim/status/1813263637429297381

Robot operated autonomous surgery: https://www.nytimes.com/2021/04/30/technology/robot-surgery-surgeon.html

With one claw, the machine lifted a tiny plastic ring from an equally tiny peg on the table, passed the ring from one claw to the other, moved it across the table and gingerly hooked it onto a new peg. Then the robot did the same with several more rings, completing the task as quickly as it had when guided by Dr. Fer. The training exercise was originally designed for humans; moving the rings from peg to peg is how surgeons learn to operate robots like the one in Berkeley. Now, an automated robot performing the test can match or even exceed a human in dexterity, precision and speed, according to a new research paper from the Berkeley team.
The project is a part of a much wider effort to bring artificial intelligence into the operating room. Using many of the same technologies that underpin self-driving cars, autonomous dronesand warehouse robots, researchers are working to automate surgical robots too. These methods are still a long way from everyday use, but progress is accelerating.
Robots can already exceed human accuracy on some surgical tasks, like placing a pin into a bone (a particularly risky task during knee and hip replacements). The hope is that automated robots can bring greater accuracy to other tasks, like incisions or suturing, and reduce the risks that come with overworked surgeons.
AI models ChatGPT and Grok outperform the average doctor on a medical licensing exam: the average score by doctors is 75% - ChatGPT scored 98% and Grok 84%: https://x.com/tsarnick/status/1814048365002596425

Caresyntax secures $180M to build AI-powered ‘Android of robotic surgery’ https://venturebeat.com/business/caresyntax-secures-180m-to-build-ai-powered-android-of-robotic-surgery/
Google DeepMind's AlphaProteo generates novel proteins for biology and health research: https://deepmind.google/discover/blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/?utm_source=x&utm_medium=&utm_campaign=gdm&utm_content=
AlphaProteo can generate new protein binders for diverse target proteins, including VEGF-A, which is associated with cancer and complications from diabetes. This is the first time an AI tool has been able to design a successful protein binder for VEGF-A.
AlphaProteo also achieves higher experimental success rates and 3 to 300 times better binding affinities than the best existing methods on seven target proteins we tested.
Harnessing Synthetic Skin Lesion Data via Stable Diffusion Models for Enhanced Skin Disease Classification using ViT and CNN: https://arxiv.org/html/2401.05159v1

https://x.com/DeryaTR_/status/1834630356286558336

Cardiologists working with AI said it was equal or better than human cardiologists in most areas: https://x.com/DKThomp/status/1843993273825964312

A.I. Chatbots Defeated Doctors at Diagnosing Illness. "A small study found ChatGPT outdid human physicians when assessing medical case histories, even when those doctors were using a chatbot." https://www.nytimes.com/2024/11/17/health/chatgpt-ai-doctors-diagnosis.html
In an experiment, doctors who were given ChatGPT to diagnose illness did only slightly better than doctors who did not. But the chatbot alone outperformed all the doctors.
Dr. Adam Rodman, an expert in internal medicine at Beth Israel Deaconess Medical Center in Boston, confidently expected that chatbots built to use artificial intelligence would help doctors diagnose illnesses. He was wrong.
Instead, in a study Dr. Rodman helped design, doctors who were given ChatGPT-4 along with conventional resources did only slightly better than doctors who did not have access to the bot. And, to the researchers’ surprise, ChatGPT alone outperformed the doctors.
“I was shocked,” Dr. Rodman said.
The chatbot, from the company OpenAI, scored an average of 90 percent when diagnosing a medical condition from a case report and explaining its reasoning. Doctors randomly assigned to use the chatbot got an average score of 76 percent. Those randomly assigned not to use it had an average score of 74 percent.
The study showed more than just the chatbot’s superior performance.
After his initial shock at the results of the new study, Dr. Rodman decided to probe a little deeper into the data and look at the actual logs of messages between the doctors and ChatGPT. The doctors must have seen the chatbot’s diagnoses and reasoning, so why didn’t those using the chatbot do better? It turns out that the doctors often were not persuaded by the chatbot when it pointed out something that was at odds with their diagnoses. Instead, they tended to be wedded to their own idea of the correct diagnosis. “They didn’t listen to A.I. when A.I. told them things they didn’t agree with,” Dr. Rodman said. That makes sense, said Laura Zwaan, who studies clinical reasoning and diagnostic error at Erasmus Medical Center in Rotterdam and was not involved in the study.
“People generally are overconfident when they think they are right,” she said. But there was another issue: Many of the doctors did not know how to use a chatbot to its fullest extent. Dr. Chen said he noticed that when he peered into the doctors’ chat logs, “they were treating it like a search engine for directed questions: ‘Is cirrhosis a risk factor for cancer? What are possible diagnoses for eye pain?’” “It was only a fraction of the doctors who realized they could literally copy-paste in the entire case history into the chatbot and just ask it to give a comprehensive answer to the entire question,” Dr. Chen added. “Only a fraction of doctors actually saw the surprisingly smart and comprehensive answers the chatbot was capable of producing.”
How generative AI is revolutionizing science: https://www.youtube.com/watch?v=PKN95I93iGE
AI can bring down costs and length of medical drug research trials by 25-50%
Assisted in finding treatment for IPF

Note this is all before ChatGPT was released in 2022
Use of AI for medical diagnosis: https://www.ucsf.edu/news/2024/12/429031/4-ways-artificial-intelligence-poised-transform-medicine
o1-preview is far superior to doctors on reasoning tasks and it's not even close, according to OpenAI's latest paper. AI does ~80% vs ~30% on the 143 hard NEJM CPC diagnoses: https://x.com/deedydas/status/1869049071346102729
Note that most other LLMs cannot do this despite access to the same training data (Google actually has access to FAR more data than OpenAI does) and high incentive to match these scores

Authors: 
4.4. Research Use
https://aidantr.github.io/files/AI_innovation.pdf


"These effects are large. To put the rise in materials discovery in perspective, the lab’s research output per scientist declined by 4% over the preceding five years. This was despite the introduction of several computational tools designed to aid scientists. AI therefore appears to be a different class of technology, with impacts that are orders of magnitude greater than previous methods." 

"However, the results suggest that AI-assisted materials discovery does not compromise quality"

As one scientist noted: “While I was impressed by the performance of the [AI tool]...I couldn’t help feeling that much of my education is now worthless. This is not what I was trained to do.”

AI independently discovers number of variables in dynamic systems and can help discover new physics equations: https://www.youtube.com/watch/watch?v=XRL56YCfKtA
Transformers used to solve a math problem that stumped experts for 132 years: Discovering global Lyapunov functions. Lyapunov functions are key tools for analyzing system stability over time and help to predict dynamic system behavior, like the famous three-body problem of celestial mechanics: https://arxiv.org/abs/2410.08304



LeanAgent: Lifelong Learning for Formal Theorem Proving: https://arxiv.org/abs/2410.0620

LeanAgent successfully proves 162 theorems previously unproved by humans across 23 diverse Lean repositories, many from advanced mathematics.
A 10 page paper caused a panic because of a math error. O1 could spot the error by just prompting: “carefully check the math in this paper” even when the info is not in training data: https://x.com/emollick/status/1868329599438037491
This was o1, not pro. I just pasted in the article with the literal prompt above.
Claude did not spot the error when given the PDF until it was told to look just at the reference value.

ChipNeMo-70B, outperforms the highly capable GPT-4 on two of our use cases, namely engineering assistant chatbot and EDA scripts generation, while exhibiting competitive performance on bug summarization and analysis. These results underscore the potential of domain-specific customization for enhancing the effectiveness of large language models in specialized applications: https://arxiv.org/pdf/2311.00176


Not as good as the Opus model they said is coming out later this year 
80% lower cost than Claude 3 Opus
2x speed over Claude 3 Opus
decent math and coding jump. 10% better on MATH 9% better on GPQA
Can convert research paper descriptions to code: https://x.com/VictorTaelin/status/1803816296410190286
Yves does NOT explain how to implement the system at all, he just defines it in mathematical terms. By all means, ICs aren't hard to implement, but understanding what the paper is saying without images is tough. The best models so far always outputted 100% bullshit code. I just tested again and Opus/GPT-4 outputs are always just gibberish. Sonnet 3.5 did surprisingly well 

Stanford researchers: “Automating AI research is exciting! But can LLMs actually produce novel, expert-level research ideas? After a year-long study, we obtained the first statistically significant conclusion: LLM-generated ideas are more novel than ideas written by expert human researchers." https://x.com/ChengleiSi/status/1833166031134806330

>Coming from 36 different institutions, our participants are mostly PhDs and postdocs. As a proxy metric, our idea writers have a median citation count of 125, and our reviewers have 327.

>We also used an LLM to standardize the writing styles of human and LLM ideas to avoid potential confounders, while preserving the original content.



New AI Framework for Medical Imaging Matches Accuracy of Clinical Specialists: https://www.insideprecisionmedicine.com/topics/patient-care/new-ai-framework-for-medical-imaging-matches-accuracy-of-clinical-specialists/
 
New research shows AI-discovered drug molecules have 80-90% success rates in Phase I clinical trials, compared to the historical industry average of 40-65%. The Phase 2 success rate so far is similar to the industry average, meaning more drugs are passing overall. https://www.sciencedirect.com/science/article/pii/S135964462400134X 

We managed to fold, using #AlphaFold, in one year all 200 million proteins known to science: https://twitter.com/GoogleDeepMind/status/1786342523234861254 
Google DeepMind’s new AI can model DNA, RNA, and ‘all life’s molecules’ https://www.theverge.com/2024/5/8/24152088/google-deepmind-ai-model-predict-molecular-structure-alphafold 

Source: https://ourworldindata.org/artificial-intelligence
[Generative AI will be designing new drugs all on its own in the near future](https://www.cnbc.com/2024/05/05/within-a-few-years-generative-ai-will-design-new-drugs-on-its-own.html)
AI is speeding up human-like robot development | “It has accelerated our entire research and development cycle.” https://www.cnbc.com/2024/05/08/how-generative-chatgpt-like-ai-is-accelerating-humanoid-robots.html
[ChatGPT can do chemistry research better than AI designed for it and the creators didn’t even know](https://youtu.be/0b03ibtVYhw?feature=shared&t=447)
Enveda presents PRISM -foundation AI model trained on 1.2 billion small molecule mass spectra to enhance mass spectrometry analysis in drug discovery. It uses self-supervised learning to predict molecular properties from complex mixtures without prior annotations: https://www.enveda.com/posts/prism-a-foundation-model-for-lifes-chemistry 
Perovskite discovery goes automatic: New platform expedites material development for next-gen tech: https://techxplore.com/news/2024-08-perovskite-discovery-automatic-platform-material.html
Microsoft has built a weather forecasting model named 'Aurora' - trained on over a million hours of weather and climate simulations. MS estimates a 5000x computational speed-up over the state-of-the-art numerical forecasting system (IFS) while operating at a fraction of the cost: https://x.com/MSFTResearch/status/1797662278394827029 
Can accurately forecast weather and air pollution for the whole world — and it does it in less than a minute: https://x.com/Nature/status/1798032169971118099 
Nvidia cloned Earth to Predict the weather Worldwide using AI: https://x.com/itaybachman/status/1797631338897686773 
EU did the same: https://thenextweb.com/news/eu-launches-ai-powered-digital-twin-of-the-earth 
LLMs can outperform existing methods for identifying causal genes in genome-wide association studies: https://www.medrxiv.org/content/10.1101/2024.05.30.24308179v1. 
Predicting out of distribution(!!!) phenomenon of NaCl in solvent: https://arxiv.org/abs/2310.12535: 
 Claude 3 recreated an unpublished paper on quantum theory without ever seeing it : https://twitter.com/GillVerd/status/1764901418664882327
LLM solves previously unsolvable math problem: https://www.technologyreview.com/2023/12/14/1085318/google-deepmind-large-language-model-solve-unsolvable-math-problem-cap-set/
AI creates a faster sorting algorithm: https://www.nature.com/articles/s41586-023-06004-9
Matrix multiplication breakthrough due to AI: https://www.quantamagazine.org/ai-reveals-new-possibilities-in-matrix-multiplication-20221123/
Boosting Visual-Language Models with Synthetic Captions and Image Embeddings: https://arxiv.org/pdf/2403.07750 
Our method employs pretrained text-to-image model to synthesize image embeddings from captions generated by an LLM. Despite the text-to-image model and VLM initially being trained on the same data, our approach leverages the image generator’s ability to create novel compositions, resulting in synthetic image embeddings that expand beyond the limitations of the original dataset. Extensive experiments demonstrate that our VLM, finetuned on synthetic data achieves comparable performance to models trained solely on human-annotated data, while requiring significantly less data. Furthermore, we perform a set of analyses on captions which reveals that semantic diversity and balance are key aspects for better downstream performance. Finally, we show that synthesizing images in the image embedding space is 25% faster than in the pixel space. We believe our work not only addresses a significant challenge in VLM training but also opens up promising avenues for the development of self-improving multi-modal models.
ESM3: Simulating 500 million years of evolution with a language model: https://evolutionaryscale.ai/blog/esm3-release 
This 20,000HP AI-generated rocket engine took just two weeks to design: https://www.pcgamer.com/hardware/this-20000hp-ai-generated-rocket-engine-took-just-two-weeks-to-design-and-looks-like-hr-gigers-first-attempt-at-designing-a-trumpet
OpenAI and Los Alamos National Laboratory announce bioscience research partnership: https://openai.com/index/openai-and-los-alamos-national-laboratory-work-together/
Demis Hassabis says AI will enhance science: designing new drugs for medicine, discovering a room temperature superconductor, cracking mathematical conjectures and formulating its own new conjectures: https://x.com/tsarnick/status/1814908695706255528
Use of AI for social science experiments: https://x.com/RobbWiller/status/1821271270182547916
Across 70 studies, we find striking alignment (r = .85) between simulated and observed effects




Automated Design of Agentic Systems: Presents Meta Agent Search to demonstrate that we can use agents to invent novel and powerful agent designs by programming in code
proj: https://shengranhu.com/ADAS/
abs: https://arxiv.org/abs/2408.08435
github: https://github.com/ShengranHu/ADAS
FermiNet: Quantum physics and chemistry from first principles: https://deepmind.google/discover/blog/ferminet-quantum-physics-and-chemistry-from-first-principles/
Google DeepMind's AlphaProteo generates novel proteins for biology and health research: https://deepmind.google/discover/blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/?utm_source=x&utm_medium=&utm_campaign=gdm&utm_content=
AlphaProteo can generate new protein binders for diverse target proteins, including VEGF-A, which is associated with cancer and complications from diabetes. This is the first time an AI tool has been able to design a successful protein binder for VEGF-A.
AlphaProteo also achieves higher experimental success rates and 3 to 300 times better binding affinities than the best existing methods on seven target proteins we tested.
Cog-GA: A Large Language Models-based Generative Agent for Vision-Language Navigation in Continuous Environments: https://arxiv.org/html/2409.02522v1
Cog-GA, a generative agent founded on large language models (LLMs) tailored for VLN-CE tasks. Cog-GA employs a dual-pronged strategy to emulate human-like cognitive processes. Firstly, it constructs a cognitive map, integrating temporal, spatial, and semantic elements, thereby facilitating the development of spatial memory within LLMs. Secondly, Cog-GA employs a predictive mechanism for waypoints, strategically optimizing the exploration trajectory to maximize navigational efficiency. Each waypoint is accompanied by a dual-channel scene description, categorizing environmental cues into ’what’ and ’where’ streams as the brain. This segregation enhances the agent’s attentional focus, enabling it to discern pertinent spatial information for navigation. A reflective mechanism complements these strategies by capturing feedback from prior navigation experiences, facilitating continual learning and adaptive replanning. Extensive evaluations conducted on VLN-CE benchmarks validate Cog-GA’s state-of-the-art performance and ability to simulate human-like navigation behaviors. This research significantly contributes to the development of strategic and interpretable VLN-CE agents.
Introducing PaperQA2, the first AI agent that conducts entire scientific literature reviews on its own: https://x.com/SGRodriques/status/1833908643856818443
PaperQA2 is also the first agent to beat PhD and Postdoc-level biology researchers on multiple literature research tasks, as measured both by accuracy on objective benchmarks and assessments by human experts. We are publishing a paper and open-sourcing the code.


This is the first example of AI agents exceeding human performance on a major portion of scientific research, and will be a game-changer for the way humans interact with the scientific literature. 
PaperQA2 finds and summarizes relevant literature, refines its search parameters based on what it finds, and provides cited, factually grounded answers that are more accurate on average than answers provided by PhD and postdoc-level biologists. When applied to answer highly specific questions, like this one, it obtains SOTA performance on LitQA2, part of LAB-Bench focused on information retrieval
PaperQA2 can also do broad-based literature reviews. WikiCrow, which is an agent based on PaperQA2, writes Wikipedia-style articles that are significantly more accurate on average than actual human-written articles on Wikipedia, as judged by PhD and postdoc-level biologists. 
NotebookLM now lets you listen to a conversation about your sources (Create a two person podcast from your sources): https://blog.google/technology/ai/notebooklm-audio-overviews/
We’re Entering Uncharted Territory for Math - Terrence Tao on o1 and the future of AI & Math: https://www.theatlantic.com/technology/archive/2024/10/terence-tao-ai-interview/680153/
I was interested in using these tools as research assistants. A research project has a lot of tedious steps: You may have an idea and you want to flesh out computations, but you have to do it by hand and work it all out.
It’s the equivalent, in terms of serving as that kind of an assistant. But I do envision a future where you do research through a conversation with a chatbot. Say you have an idea, and the chatbot went with it and filled out all the details.
In a Zoom call last week, he described a kind of AI-enabled, “industrial-scale mathematics” that has never been possible before: one in which AI, at least in the near future, is not a creative collaborator in its own right so much as a lubricant for mathematicians’ hypotheses and approaches. This new sort of math, which could unlock terra incognitae of knowledge, will remain human at its core, embracing how people and machines have very different strengths that should be thought of as complementary rather than competing.
This is an AI app that turns any piece of writing into a graph: https://x.com/MushtaqBilalPhD/status/1843170045704520152
This can help you brainstorm ideas, develop your research projects, and prepare impressive presentations.
LeanAgent: Lifelong Learning for Formal Theorem Proving: https://arxiv.org/abs/2410.06209
LeanAgent successfully proves 162 theorems previously unproved by humans across 23 diverse Lean repositories, many from advanced mathematics.
Gödel Agent: A Self-Referential Agent Framework for Recursive Self-Improvement: https://arxiv.org/abs/2410.04444

In this paper, we introduce Gödel Agent, a self-evolving framework inspired by the Gödel machine, enabling agents to recursively improve themselves without relying on predefined routines or fixed optimization algorithms. Gödel Agent leverages LLMs to dynamically modify its own logic and behavior, guided solely by high-level objectives through prompting. Experimental results on mathematical reasoning and complex agent tasks demonstrate that implementation of Gödel Agent can achieve continuous self-improvement, surpassing manually crafted agents in performance, efficiency, and generalizability.
The AI scientist: https://arxiv.org/abs/2408.06292
This paper presents the first comprehensive framework for fully automatic scientific discovery, enabling frontier large language models to perform research independently and communicate their findings. We introduce The AI Scientist, which generates novel research ideas, writes code, executes experiments, visualizes results, describes its findings by writing a full scientific paper, and then runs a simulated review process for evaluation. In principle, this process can be repeated to iteratively develop ideas in an open-ended fashion, acting like the human scientific community. We demonstrate its versatility by applying it to three distinct subfields of machine learning: diffusion modeling, transformer-based language modeling, and learning dynamics. Each idea is implemented and developed into a full paper at a cost of less than $15 per paper. To evaluate the generated papers, we design and validate an automated reviewer, which we show achieves near-human performance in evaluating paper scores. The AI Scientist can produce papers that exceed the acceptance threshold at a top machine learning conference as judged by our automated reviewer. This approach signifies the beginning of a new era in scientific discovery in machine learning: bringing the transformative benefits of AI agents to the entire research process of AI itself, and taking us closer to a world where endless affordable creativity and innovation can be unleashed on the world's most challenging problems. Our code is open-sourced at this https URL: https://github.com/SakanaAI/AI-Scientist
NASA and Microsoft co-developed and released a chat-based Earth Copilot that will make it easier for scientists, educators, policymakers and the public to search, discover and analyze Earth Science data: https://blogs.microsoft.com/blog/2024/11/14/from-questions-to-discoveries-nasas-new-earth-copilot-brings-microsoft-ai-capabilities-to-democratize-access-to-complex-data/
New architecture may have cracked the Language of Life: An LLM for DNA and Biology: https://www.science.org/doi/10.1126/science.ado9336
Takeaways re: AI R&D performance: https://x.com/eli_lifland/status/1860087262849171797
1. Claude 3.5 Sonnet reaches ~50th percentile human baseline 8-hour performance.
2. Sonnet Old-> New is a 0.2 jump in 4 months. We're 0.6 away from 90th percentile baselines.

Keep in mind researchers are already in the top 1% of intelligence and technical ability




Link to study: https://metr.org/blog/2024-11-22-evaluating-r-d-capabilities-of-llms/
How generative AI is revolutionizing science: https://www.youtube.com/watch?v=PKN95I93iGE
AI can bring down costs and length of medical drug research trials by 25-50%
Assisted in finding treatment for IPF

Note this is all before ChatGPT was released in 2022

Large language models surpass human experts in predicting neuroscience results: https://www.nature.com/articles/s41562-024-02046-9
We find that LLMs surpass experts in predicting experimental outcomes. BrainGPT, an LLM we tuned on the neuroscience literature, performed better yet. Like human experts, when LLMs indicated high confidence in their predictions, their responses were more likely to be correct, which presages a future where LLMs assist humans in making discoveries. Our approach is not neuroscience specific and is transferable to other knowledge-intensive endeavours.
What ChatGPT and generative AI mean for science: https://www.nature.com/articles/d41586-023-00340-6
In December, computational biologists Casey Greene and Milton Pividori embarked on an unusual experiment: they asked an assistant who was not a scientist to help them improve three of their research papers. Their assiduous aide suggested revisions to sections of documents in seconds; each manuscript took about five minutes to review. In one biology manuscript, their helper even spotted a mistake in a reference to an equation. The trial didn’t always run smoothly, but the final manuscripts were easier to read — and the fees were modest, at less than US$0.50 per document.
“I’m really impressed,” says Pividori, who works at the University of Pennsylvania in Philadelphia. “This will help us be more productive as researchers.” Other scientists say they now regularly use LLMs not only to edit manuscripts, but also to help them write or check code and to brainstorm ideas. “I use LLMs every day now,” says Hafsteinn Einarsson, a computer scientist at the University of Iceland in Reykjavik. He started with GPT-3, but has since switched to ChatGPT, which helps him to write presentation slides, student exams and coursework problems, and to convert student theses into papers. “Many people are using it as a digital secretary or assistant,” he says.

Ethan Mollick is a business professor at Wharton College at the University of Pennsylvania
4.5. Military Use
https://thehill.com/policy/defense/5034805-artificial-intelligence-military/
Pentagon announces new AI office as it looks to deploy autonomous weapons. AI will be used for "..for command and control, autonomous drones, intelligence, weapons testing and even for enterprise management like financial systems and human resources."
Notice how they didn’t do this with abu other technology, like cryptocurrency or virtual reality 
AI-powered F-16 impresses ride-along SECAF in dogfight: https://www.defenseone.com/technology/2024/05/ai-powered-f-16-impresses-ride-along-secaf-dogfight/396418/


China launched the world's first AI-operated 'mother ship,' an unmanned carrier capable of launching dozens of drones: https://www.businessinsider.com/china-launches-worlds-first-ai-unmanned-drone-aircraft-carrier-2022-6 
China’s ‘AI Ship Designer’ Works At Unprecedented Speed; Performed A Year’s Work Only In 24 Hours!: https://www.eurasiantimes.com/chinas-ai-ship-designer-works-at-unprecedented-speed-performed/ 
The military wants ‘robot ships’ to replace sailors in battle: https://www.realcleardefense.com/2022/04/15/the_military_wants_robot_ships_to_replace_sailors_in_battle_827353.html 
Significant integration of AI in naval vessels to take less than ten years: Poll: https://www.naval-technology.com/news/significant-integration-of-ai-in-naval-vessels-to-take-less-than-ten-years-poll/ 
Navy’s new ‘Project OpenShip’ aims to swiftly apply AI to data captured by vessels at sea: https://defensescoop.com/2023/03/20/navys-new-project-openship-aims-to-swiftly-apply-ai-to-data-captured-by-vessels-at-sea/ 
Every Ship a Carrier: How Artificial Intelligence Can Revolutionize the Air and Sea Domains: https://www.usni.org/magazines/proceedings/2024/march/every-ship-carrier-how-artificial-intelligence-can-revolutionize
A.I. Begins Ushering In an Age of Killer Robots: https://www.nytimes.com/2024/07/02/technology/ukraine-war-ai-weapons.html
AI-Powered Super Soldiers Are More Than Just a Pipe Dream: https://www.wired.com/story/us-military-hyper-enabled-operator/
The US military has abandoned its half-century dream of a suit of powered armor in favor of a “hyper enabled operator,” a tactical AI assistant for special operations forces.
One-third of the U.S. military could be robots in the next 15 years: https://www.axios.com/2024/07/11/military-robots-technology
AI’s ‘Oppenheimer moment’: autonomous weapons enter the battlefield | The military use of AI-enabled weapons is growing, and the industry that provides them is booming: https://www.theguardian.com/technology/article/2024/jul/14/ais-oppenheimer-moment-autonomous-weapons-enter-the-battlefield
S Army turns to 'Scylla' AI to protect depot. Quote "the Army said Scylla uses drones and wide-area cameras to monitor facilities, detect potential threats, and tell personnel when they need to respond with far more accuracy than humans" https://www.msn.com/en-us/news/technology/us-army-turns-to-scylla-ai-to-protect-depot/ar-AA1t9bqN

    The US Army is testing a new AI product that it says can identify threats from a mile away, and all without the need for any new hardware. …
    Called Scylla after the man-eating sea monster of Greek legend, the Army has been testing the platform for the past eight month at the Blue Grass Army Depot (BGAD) in eastern Kentucky, a munitions depot and former chemical weapons stockpiling site, where it's been used to enhance physical security at the installation.
    The Physical security Enterprise and Analysis Group (PSEAG), which is leading the Scylla tests, has trained Scylla to "detect and classify" persons' features, their the behavior, and whether they're armed in real time in order to eliminate wasted security responses to non-threatening situations.
    "Scylla AI leverages any suitable video feed available to monitor, learn and alert in an instant, lessening the operational burden on security personnel," said Drew Walter, the US deputy assistant secretary of defense for nuclear matters. "Scylla's transformative potential lies in its support to PSEAG's core mission, which is to safeguard America's strategic nuclear capabilities."
    Regardless of what it's protecting, the Army said Scylla uses drones and wide-area cameras to monitor facilities, detect potential threats, and tell personnel when they need to respond with far more accuracy than a puny human
    "If you're the security operator, do you think you could watch 15 cameras at one time … and pick out a gun at 1,000 feet? Scylla can," Willoughby said  
    In one example of a simulated Scylla response, the system was able to use a camera a mile away to detect an "intruder" with a firearm climbing a water tower. A closer camera was able to follow up to get a better look, identifying the person as kneeling on the tower's catwalk.  
    In another example, Scylla reportedly alerted security personnel "within seconds" of two armed individuals who were identified via facial recognition as BGAD personnel. Scylla was also able to spot people breaching a fence and follow them with a drone before security was able to intercept, detect smoke coming from a vehicle from about 700 feet away, and identify a "mock fight" between two people "within seconds."
Meta and Scale AI Have Built An LLM For American Defense Tech: https://www.thenew.money/article/meta-and-scale-ai-have-built-an-llm-for-american-defense-tech
Federal agencies ordered to use ‘most powerful’ AI systems in first-ever National Security Memo on AI" https://www.msn.com/en-us/news/us/federal-agencies-ordered-to-use-most-powerful-ai-systems-in-first-ever-national-security-memo-on-ai/ar-AA1sRu7n?ocid=msedgntp&pc=DCTS&cvid=0224f96de91943e9ad66804c1e8d54dd&ei=78
The U.S. National Security Council released on Thursday its first-ever memo on artificial Intelligence (AI), ordering federal agencies to use the "most powerful" AI systems while balancing the risks associated with the new technology.
    The National Security Memorandum (NSM) details the U.S. approach to harnessing the power of AI for national security and foreign policy purposes "to ensure that America leads the way in seizing the promise and managing the risks of AI," senior administration officials said.
    "We are directing that the agencies gain access to the most powerful AI systems and put them to use, which often involve substantial efforts on procurement," the officials said.
US National Security Advisor Jake Sullivan: The U.S. must accelerate its AI efforts and deploy AI much faster or risk losing its lead, as other countries are unlikely to adhere to the same regulations and values guiding the U.S. The stakes are high: https://www.reddit.com/r/singularity/comments/1gdu5cz/us_national_security_advisor_jake_sullivan_the_us/
Anthropic partners with Palantir to sell models to defence and intelligence agencies — with security clearance up to “secret”, one level below “top secret”. They added contractual exceptions to their terms of service, updated today, allowing for “usage policy modifications” for government agencies: https://techcrunch.com/2024/11/07/anthropic-teams-up-with-palantir-and-aws-to-sell-its-ai-to-defense-customers/


OpenAI partners with defense company Anduril: https://www.anduril.com/article/anduril-partners-with-openai-to-advance-u-s-artificial-intelligence-leadership-and-protect-u-s/
4.6. Robotics
More information in section 5.1

INCREDIBLE control of video generation with real physics simulation, useful for training robots: https://x.com/zhou_xian_/status/1869511650782658846

Humanoid robots that can detect objects, appraise their work and correct mistakes are coming to factories: https://x.com/tsarnick/status/1807886268501839875

Language action model can perform tasks: https://www.reddit.com/r/singularity/comments/1bfsysa/3d_visionlanguageaction_generative_world_model/

ChatGPT trains robot dog to walk on Swiss ball | This demonstrates that AIs like GPT-4 can train robots to perform complex, real-world tasks much more effectively than we humans can: https://newatlas.com/technology/chatgpt-robot-yoga-ball/

>"DrEureka, a new open-source software package that anyone can play with, is used to train robots to perform real-world tasks using Large Language Models (LLMs) such as ChatGPT 4. It's a "sim-to-reality" system, meaning it teaches the robots in a virtual environment using simulated physics, before implementing them in meatspace."

>"After each simulation, GPT can also reflect on how well the virtual robot did, and how it can improve."

>"DrEureka is the first of its kind. It's able to go "zero-shot" from simulation to real-world. Imagine having almost no working knowledge of the world around you and being pushed out of the nest and left to just figure it out. That's zero-shot."

>"So how did it perform? Better than us. DrEureka was able to beat humans at training the robo-pooch, seeing a 34% advantage in forward velocity and 20% in distance traveled across real-world mixed terrains."

>"How? Well, according to the researchers, it's all about the teaching style. Humans tend towards a curriculum-style teaching environment – breaking tasks down into small steps and trying to explain them in isolation, whereas GPT has the ability to effectively teach everything, all at once. That's something we're simply not capable of doing."

University of Tokyo study uses GPT-4 to generate humanoid robot motions from simple text prompts, like "take a selfie with your phone."

LLMs have a robust internal representation of how words and phrases correspond to physical movements.
https://tnoinkwms.github.io/ALTER-LLM/


Robot integrated with Huawei's Multimodal LLM PanGU to understand natural language commands, plan tasks, and execute with bimanual coordination: https://x.com/TheHumanoidHub/status/1806033905147077045


Robotics researchers are exploring how large language models can give physical machines more smarts: https://x.com/WIRED/status/1811519957794009220


Google using Gemini 1.5 for robotics: https://x.com/GoogleDeepMind/status/1811401347477991932


We found that LLMs can be repurposed as "imitation learning engines" for robots, by representing both observations & actions as 3D keypoints, and feeding into an LLM for in-context learning: https://x.com/Ed__Johns/status/1778115232965013680

This works really well across a range of everyday tasks with complex and arbitrary trajectories, whilst also outperforming Diffusion Policies.
Also, we don't need any training time: the robot can perform tasks immediately after the demonstrations, with rapid in-context learning.

SARA: Self-Adaptive Robust Attention: https://sites.google.com/view/rtsara/?pli=1




MIT's Algorithm for Self-Training Robots: https://www.perplexity.ai/page/mit-s-algorithm-for-self-train-Lewzl1W_RfusEK8Lpd6VTw

Large language models (LLMs) play a crucial role in enhancing the capabilities of MIT's self-training robots. By connecting robot motion data with the "common sense knowledge" of LLMs, the system enables robots to logically parse household tasks into subtasks and physically adjust to disruptions.This integration allows robots to move on from errors without having to start a task from scratch, significantly improving their adaptability and efficiency. The approach uses LLMs to automate the identification and sequencing of subtasks, simplifying the process of teaching robots complex behaviors. This innovative combination of robotics and AI technologies paves the way for more versatile and intelligent household robots that can handle a wide range of tasks with minimal human intervention

VoicePilot - Harnessing LLMs as Speech Interfaces for Physically Assistive Robots: https://www.reddit.com/r/singularity/comments/1f5ls69/voicepilot_harnessing_llms_as_speech_interfaces/

SpatialVLM: Endowing Vision-Language Models with Spatial Reasoning Capabilities: https://spatial-vlm.github.io/

Your robot has arrived - Robots could be performing more services for humans in the near future; food could be next: https://www.businessinsider.com/waymo-self-driving-taxis-chipotle-robots-future-of-service-2024-8
Robots can paint: https://www.reddit.com/r/BeAmazed/comments/1drw1wr/meanwhile_robots_are_slowly_taking_jobs_away_from/
Digit in action at GXO's SPANX facility in Flowery Branch, Georgia: https://x.com/TheHumanoidHub/status/1807307038458052730
AI designs new robot from scratch in seconds: https://x.com/mariogabriele/status/1807886901006770624 
New video of humanoid robot Walker S by Chinese company UBTECH driving a screw and applying glass coating: https://x.com/TheHumanoidHub/status/1808009673897136249 
Automated farm picking: https://www.reddit.com/r/robotics/comments/1dv19lg/hitbot_robot_farm_automated_picking/
China’s first full-sized general-purpose humanoid robot, unveiled at World Artificial Intelligence Conference 2024: https://technode.com/2024/07/05/qinglong-chinas-first-full-sized-general-purpose-humanoid-robot-unveiled-at-world-artificial-intelligence-conference-2024/
400 robotic surgeries, 98% survival rate: Saudi hospital achieves milestone: https://interestingengineering.com/health/robotic-surgeries-record-survival-saudi

>The program has also successfully performed robotic procedures on high-risk patients such as children under 18, those with morbid obesity, and those requiring redo surgeries.
>This reduction in hospital stays also translates to a 40% decrease in overall costs compared to conventional methods. Besides, it allows patients to return to their daily lives more quickly.
>Moreover, the minimally invasive nature of robotic procedures has significantly shortened hospital stays by over 50%.
>Its journey in robotic cardiac surgery began with 105 procedures in its first year. Since then, the program has evolved rapidly, encompassing 400 successful surgeries to date.
Meet Robbie - a bartender robot from Robbie Drink - Robot Barman! Robbie Drink is a Polish company offering a rental cell with a FANUC Europe robot that works as a reliable bartender at various events: https://x.com/WevolverApp/status/1810418899784966542
Successful test of humanoid robots at BMW Group Plant Spartanburg: https://www.press.bmwgroup.com/global/article/detail/T0444265EN/successful-test-of-humanoid-robots-at-bmw-group-plant-spartanburg

Our LLM-driven bi-level programming shows it’s possible to l EA rn skills from videos without complex video processing! By chaining a VLM and LLM in a bi-level framework, we use the “chain rule” to guide reward search directly from video demos” https://www.reddit.com/r/singularity/comments/1g5qh1x/can_robots_learn_skills_from_youtube_without/

4.7. Engineering/Design
How AlphaChip transformed computer chip design: https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/
Our AI method has accelerated and optimized chip design, and its superhuman chip layouts are used in hardware around the world
The method has been used to design superhuman chip layouts in the last three generations of Google’s custom AI accelerator, the Tensor Processing Unit (TPU).
AlphaChip was one of the first reinforcement learning approaches used to solve a real-world engineering problem. It generates superhuman or comparable chip layouts in hours, rather than taking weeks or months of human effort, and its layouts are used in chips all over the world, from data centers to mobile phones.
AlphaChip has generated superhuman chip layouts used in every generation of Google’s TPU since its publication in 2020. These chips make it possible to massively scale-up AI models based on Google’s Transformer architecture.
Beyond designing specialized AI accelerators like TPUs, AlphaChip has generated layouts for other chips across Alphabet, such as Google Axion Processors, our first Arm-based general-purpose data center CPUs.
External organizations are also adopting and building on AlphaChip. For example, MediaTek, one of the top chip design companies in the world, extended AlphaChip to accelerate development of their most advanced chips — like the Dimensity Flagship 5G used in Samsung mobile phones — while improving power, performance and chip area.


Autonomous robot invents the world's best shock absorber: https://newatlas.com/technology/autonomous-ai-robot-building-crushing-breaks-record/

AI designs new robot from scratch in seconds: https://x.com/mariogabriele/status/1807886901006770624 

This 20,000HP AI-generated rocket engine took just two weeks to design: https://www.pcgamer.com/hardware/this-20000hp-ai-generated-rocket-engine-took-just-two-weeks-to-design-and-looks-like-hr-gigers-first-attempt-at-designing-a-trumpet

Toyota Research Institute Unveils New Generative AI Technique for Vehicle Design: https://pressroom.toyota.com/toyota-research-institute-unveils-new-generative-ai-technique-for-vehicle-design/

AI Creates A Radical New Magnet Without Rare-Earth Metals Is About to Change Motors Forever In just 3 months: https://www.popularmechanics.com/science/green-tech/a61147476/ai-developed-magnet-free-of-rare-earth-metals/

Bosch uses AI at South Carolina plant to design new e-motors: https://carsinsiders.com/2022/11/26/bosch-uses-ai-at-south-carolina-plant-to-design-new-e-motors/

Aitomatic’s SemiKong uses AI to reshape chipmaking processes: https://venturebeat.com/ai/aitomatics-semikong-uses-ai-to-reshape-chipmaking-processes/

3DWire can generate 3D house wireframes from text: https://x.com/dreamingtulpa/status/1814576128415175047
The wireframes can be easily segmented into distinct components, such as walls, roofs, and rooms, reflecting the semantic essence of the shape.
4.8. Writing
Grammarly and Quillbot use AI

“Here we show in two experimental studies that novice and experienced teachers could not identify texts generated by ChatGPT among student-written texts.” https://www.sciencedirect.com/science/article/pii/S2666920X24000109 

GPT4 passes Turing test 54% of the time: https://twitter.com/camrobjones/status/1790766472458903926

In a new study, AI-generated humor was rated as funnier than most human-created jokes. In a second study, it was on par with The Onion: https://www.psypost.org/ai-outshines-humans-in-humor-study-finds-chatgpt-is-as-funny-as-the-onion/
ChatGPT outperformed 73% of the human participants in the acronyms task, 63% of the human participants in the fill-in-the-blank task, and 87% of human participants in the roast joke task.
The results showed no significant difference in the average funniness ratings between the AI-generated headlines and those from The Onion. Among the top four highest-rated headlines, two were generated by ChatGPT and two by The Onion. Notably, the highest-rated headline was an AI-generated one: “Local Man Discovers New Emotion, Still Can’t Describe It Properly.” This suggests that ChatGPT can produce satirical content that is on par with professional writers.
These findings indicate that AI, specifically ChatGPT 3.5, has a surprising proficiency in humor production. Despite lacking emotions and personal experiences, the AI was able to analyze patterns and create jokes that resonated well with people.
The researchers also explored whether demographic factors influenced humor ratings. It was found that age, sex, and political orientation did not significantly affect participants’ preferences for AI-generated versus human-generated jokes. This suggests that the AI’s humor appeal was broad and not limited to specific demographic groups.


[ChatGPT scores in top 1% of creativity](https://scitechdaily.com/chatgpt-tests-into-top-1-for-original-creative-thinking/)

Japanese writer wins prestigious Akutagawa Prize with a book partially written by ChatGPT: https://www.vice.com/en/article/k7z58y/rie-kudan-akutagawa-prize-used-chatgpt

4.9. Helping People
New research shows AI-discovered drug molecules have 80-90% success rates in Phase I clinical trials, compared to the historical industry average of 40-65%. The Phase 2 success rate so far is similar to the industry average, meaning more drugs are passing overall. https://www.sciencedirect.com/science/article/pii/S135964462400134X

Whisper Diarization Web: In-browser multilingual speech recognition with word-level timestamps and speaker segmentation: https://www.reddit.com/r/LocalLLaMA/comments/1e9nux8/whisper_diarization_web_inbrowser_multilingual/

OpenAI Whisper has superhuman transcription ability: https://www.youtube.com/watch?v=04NUPxifGiQ
Report: Leveraging AI Tools Could Help US Teachers Avoid $43.4 Billion of Unpaid Overtime Work: https://myelearningworld.com/ai-tech-time-saved-education/


First legally recognized nonbinary person with disabilities writes book with ChatGPT: https://www.wired.com/story/the-us-copyright-office-loosens-up-a-little-on-ai/

The novel draws from Shupe’s eventful life, including her advocacy for more inclusive gender recognition.
Shupe believes fervently that she was only able to complete her book with the assistance of generative AI tools. She says she has been assessed as 100 percent disabled by the Department of Veterans Affairs and struggles to write due to cognitive impairment related to conditions including bipolar disorder, borderline personality disorder, and a brain stem malformation.
She is proud of the finished work and sees working with a text generator as a different but no less worthwhile method of expressing thoughts. “You don't just hit ‘generate’ and get something worthy of publishing. That may come in the future, but we're still far from it,” she says, noting that she spent upwards of 14 hours a day working on her draft.


GPT 4o used to help blind people: https://twitter.com/Uttupaaji/status/1790217787010617544

Excellent synthetic caption generation: https://arxiv.org/pdf/2403.07750 
Our method employs pretrained text-to-image model to synthesize image embeddings from captions generated by an LLM. Despite the text-to-image model and VLM initially being trained on the same data, our approach leverages the image generator’s ability to create novel compositions, resulting in synthetic image embeddings that expand beyond the limitations of the original dataset. Extensive experiments demonstrate that our VLM, finetuned on synthetic data achieves comparable performance to models trained solely on human-annotated data, while requiring significantly less data. Furthermore, we perform a set of analyses on captions which reveals that semantic diversity and balance are key aspects for better downstream performance. Finally, we show that synthesizing images in the image embedding space is 25% faster than in the pixel space. We believe our work not only addresses a significant challenge in VLM training but also opens up promising avenues for the development of self-improving multi-modal models.
Dataset of 7.45 million AI generated image descriptions: https://huggingface.co/datasets/KBlueLeaf/danbooru2023-florence2-caption

Gen AI used to help:
Blind people: https://twitter.com/Uttupaaji/status/1790217787010617544
Students: https://twitter.com/mckaywrigley/status/1790088880919818332
This is an AI app that turns any piece of writing into a graph: https://x.com/MushtaqBilalPhD/status/1843170045704520152
This can help you brainstorm ideas, develop your research projects, and prepare impressive presentations.
Translation: https://twitter.com/tomwarren/status/1790074556981403997

AI is getting very popular among students and teachers, very quickly: https://www.cnbc.com/2024/06/11/ai-is-getting-very-popular-among-students-and-teachers-very-quickly.html
Claude 3.5 can make graphics to describe things: https://x.com/calixo888/status/1803873821654684026 

Create images to show instructions: github.com/GAIR-NLP/anole



Used as a tutor to help someone quintuple income https://www.reddit.com/r/ChatGPT/comments/1cpe3sk/chatgpt_just_just_made_me_get_a_job_paying_5x_more/

Claude 3.5 Sonnet transformed a research paper into an interactive learning dashboard in just 30 seconds: https://x.com/Saboo_Shubham_/status/1805789967203156357
Introducing Surgical Robot Transformer (SRT): Automating surgical tasks with end-to-end imitation learning: https://x.com/jwbkim/status/1813263637429297381
ChatGPT Advanced Audio helping someone pronouce "Croissant" https://www.reddit.com/r/singularity/comments/1eg51gz/chatgpt_advanced_audio_helping_me_pronouce/
VoicePilot - Harnessing LLMs as Speech Interfaces for Physically Assistive Robots: https://www.reddit.com/r/singularity/comments/1f5ls69/voicepilot_harnessing_llms_as_speech_interfaces/


4.10. Persuasion
AI beat humans at being persuasive: https://www.newscientist.com/article/2424856-ai-chatbots-beat-humans-at-persuading-their-opponents-in-debates/

OpenAI CTO says AI models pose "incredibly scary" major risks due to their ability to persuade, influence and control people: https://www.reddit.com/r/singularity/comments/1e0d3es/openai_cto_says_ai_models_pose_incredibly_scary/

This paper shows having a short conversation with an AI can get people who believed in a conspiracy theory to change their beliefs & this lasts for months: https://www.science.org/doi/10.1126/science.adq1814



Meta researchers create AI that masters Diplomacy, tricking human players. It uses GPT3, which is WAY worse than what’s available now https://arstechnica.com/information-technology/2022/11/meta-researchers-create-ai-that-masters-diplomacy-tricking-human-players/
The resulting model mastered the intricacies of a complex game. "Cicero can deduce, for example, that later in the game it will need the support of one particular player," says Meta, "and then craft a strategy to win that person’s favor—and even recognize the risks and opportunities that that player sees from their particular point of view."
Meta's Cicero research appeared in the journal Science under the title, "Human-level play in the game of Diplomacy by combining language models with strategic reasoning."
CICERO uses relationships with other players to keep its ally, Adam, in check.
When playing 40 games against human players, CICERO achieved more than double the average score of the human players and ranked in the top 10% of participants who played more than one game.
The chatbots also learned to negotiate in ways that seem very human. They would, for instance, pretend to be very interested in one specific item – so that they could later pretend they were making a big sacrifice in giving it up, according to a paper published by FAIR. https://www.independent.co.uk/life-style/facebook-artificial-intelligence-ai-chatbot-new-language-research-openai-google-a7869706.html


5. AI Can Replace Jobs
Direct link: https://docs.google.com/document/d/1oHuwssPPUTa4dwczX_s3qg3iPfWE4VK-R52LN51GwI8/edit?tab=t.0#heading=h.vr8jz2f8ry8b

A new study shows a 21% drop in demand for digital freelancers since ChatGPT was launched. The hype in AI is real but so is the risk of job displacement: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4602944

>Our findings indicate a 21 percent decrease in the number of job posts for automation-prone jobs related to writing and coding compared to jobs requiring manual-intensive skills after the introduction of ChatGPT. We also find that the introduction of Image-generating AI technologies led to a significant 17 percent decrease in the number of job posts related to image creation. Furthermore, we use Google Trends to show that the more pronounced decline in the demand for freelancers within automation-prone jobs correlates with their higher public awareness of ChatGPT's substitutability.

Already replacing jobs: https://tech.co/news/companies-replace-workers-with-ai
Robots [Automates] jobs from unions: https://phys.org/news/2024-06-robots-jobs-unions-decline-unionizations.html

Artificial intelligence will affect 60 million US and Mexican jobs within the year: https://english.elpais.com/economy-and-business/2024-09-15/artificial-intelligence-will-affect-60-million-us-and-mexican-jobs-within-the-year.html

According to the index, 980 million jobs around the world will be affected in some way by this new technology within the year. That amounts to 28% of the global workforce. Within five years, that figure will rise to between 38%, and in 10 years, 44%.
Following the introduction of ChatGPT, there was a steep decrease in demand for automation prone jobs compared to manual-intensive ones. The launch of tools like Midjourney had similar effects on image-generating-related jobs. Over time, there were no signs of demand rebounding: https://hbr.org/2024/11/research-how-gen-ai-is-already-impacting-the-labor-market?tpcc=orgsocial_edit&utm_campaign=hbr&utm_medium=social&utm_source=twitter




Analysis of changes in jobs on Upwork from November 2022 to February 2024: https://bloomberry.com/i-analyzed-5m-freelancing-jobs-to-see-what-jobs-are-being-replaced-by-ai



the # of machine learning jobs has actually decreased a bit since ChatGPT was released. 


Eeven when we look at the biggest companies in the world, there still hasn’t been any noticeable increase in demand for machine learning.

AI Job Loss Statistics - 47% of U.S. workers are at risk of job loss: https://ground.news/article/ai-job-loss-statistics-47-of-us-workers-are-at-risk-of-job-loss?utm_source=mobile-app&utm_medium=newsroom-share

Klarna Stopped All Hiring a Year Ago to Replace Workers With AI. Headcount reduced by 22%. CEO says "AI could ultimately replace all jobs." https://www.msn.com/en-us/money/other/klarna-stopped-all-hiring-a-year-ago-to-replace-workers-with-ai/ar-AA1vKNB2?ocid=msedgntp&pc=DCTS&cvid=ae29213a8ab54574a6b262faa4f80eae&ei=37

Note: Klarna increased their revenue and profits in 2024 despite this: https://www.klarna.com/international/regulatory-news/klarna-h1-earnings-compounding-growth-generates-27-revenue-rise-sek-11-billion-profit-improvement-and-over-sek-1-trillion-annualized-gmv/

Physician study shows AI alone is better at diagnosing patients than doctors, even better than doctors using AI: https://www.computerworld.com/article/3613982/will-ai-help-doctors-decide-whether-you-live-or-die.html
AMIE: A research AI system for diagnostic medical reasoning and conversations: https://research.google/blog/amie-a-research-ai-system-for-diagnostic-medical-reasoning-and-conversations/







https://www.visualcapitalist.com/charted-the-jobs-most-impacted-by-ai/

https://www.visualcapitalist.com/sp/ranking-industries-by-their-potential-for-ai-automation/
OpenAI’s o1 model can get perfect scores on their research engineer interview coding questions:
AI agents entering workplace: https://www.bloomberg.com/news/newsletters/2024-10-24/ai-agents-have-officially-entered-the-workplace-flaws-and-all

“It is actually better than a human most of the time,” said Amjad Masad, chief executive officer of Replit. “Humans are kind of lazy and get annoyed and don’t test everything. This is much more thorough.”
ServiceNow CEO Bill McDermott told my colleague Brody Ford this week that his company’s new AI agents “don’t eat” and can work 24/7. “You don’t have to give ‘em a 401k!” he added. The software company’s agents are currently being tested out by some customers and will be released more broadly next month, he said.
In September, Salesforce Chief Operating Officer Brian Millham said customers using the company’s agents may elect to hire fewer people going forward. He gave an example of a 5,000-person call center needing 30% fewer workers within five years.

Women are 40% more likely to have their work replaced by A.I. https://www.ippr.org/media-office/up-to-8-million-uk-jobs-at-risk-from-ai-unless-government-acts-finds-ippr

>To see which tasks and jobs will be affected by AI, IPPR produced a metric that indicates how many tasks could be transformed by AI and then scored each task with regards to whether a human could perform it 50% more quickly with the help of AI.
Nearly two-thirds of tasks carried out by workers could be automated by AI
Chatbots could take over eight million jobs in the UK - and women will be worst affected, a leading think tank has warned.
Back office, entry level and part-time jobs most exposed to automation, and women significantly more affected 
11 per cent of tasks are exposed to existing generative AI, rising to 59 per cent if companies integrate AI more deeply
Expected effects of current AI:
Worst case scenario – full displacement: 1.5 million jobs are lost, with no GDP gains 
Central scenario: 545,000 jobs are lost, with GDP gains of 3.1 per cent (£64bn per year) 
Best case scenario – full augmentation: no jobs are lost, with GDP gains of 4 per cent (£92bn per year)
Expected effects of future AI:
Worst case scenario – full displacement: all jobs at risk are replaced by AI, with 7.9 million job losses and no GDP gains 
Central scenario: 4.4 million jobs disappear, but with economic gains of 6.3 per cent of GDP (£144bn per year) 
Best case scenario – full augmentation: all jobs at risk are augmented to adapt to AI, instead of replaced, leading to no job losses and an economic boost of 13 per cent to GDP (£306bn per year)
Carsten Jung, senior economist at IPPR, said: "Already existing generative AI could lead to big labour market disruption or it could hugely boost economic growth, either way it is set to be a game changer for millions of us. Many firms are already investing in it, and it has potential to speed up many more tasks as more businesses adopt it. Over the next five years it could transform knowledge work. The question now is less whether AI can be useful, but rather how fast and in what manner employers will use it. History show that technological transition can be a boon if well managed, or can end in disruption if left to unfold without controls. Indeed, some occupations could be hard hit by generative AI, starting with back office jobs.”
Bhargav Srinivasa Desikan, senior research fellow at IPPR, said: “We could see jobs such as copywriters, graphic designers and personal assistants roles being heavily affected by AI.”


AI Is Already Taking Jobs in the Video Game Industry: https://www.wired.com/story/ai-is-already-taking-jobs-in-the-video-game-industry/

NOTE: The part that says workers are being forced to use AI by their bosses IS A LIE. See section 4.2 for strong evidence to the contrary from multiple sources.
>A WIRED investigation finds that major players like Activision Blizzard, which recently laid off scores of workers, are using generative AI for game development.
A recent survey from the organizers of the Game Developers Conference found that 49 percent of the survey’s more than 3,000 respondents said their workplace used AI.
“It’s here. It’s definitely here, right now,” says Violet, a game developer, technical artist, and a veteran of the industry who has worked on AAA games for over a decade. “I think everyone’s seen it get used, and it’s a matter of how and to what degree. The genie is out of the bottle, Pandora's box is opened.”
Treyarch, a Southern California-based studio that produces some elements of Activision’s Call of Duty games, posted a job listing for a “2D Artist Animator.” The first thing listed under the “To succeed you should have …” section was “exceptional skills and expertise in digital sketching, drawing, and painting, as well as advanced expertise in working with generative AI tools such as Stable Diffusion, Vizcom, Dall-E, or equivalent.” 
Blizzard is building its own AI system too, which at one time was named Blizzard Diffusion—though details are scarce, beyond a patent the company filed for a “machine-learning based 2D structured image generation” system. “Blizzard's ‘internal AI’ that they trained is still super secretive. Only those who have access to it work with it, and no one else knows how it works,” Warner claims.


Activision Blizzard is reportedly already making games with AI, and quietly sold an AI-generated microtransaction in Call of Duty: Modern Warfare 3: https://www.gamesradar.com/games/call-of-duty/activision-blizzard-is-reportedly-already-making-games-with-ai-and-quietly-sold-an-ai-generated-microtransaction-in-call-of-duty-modern-warfare-3/


https://www.hrgrapevine.com/us/content/article/2024-06-04-microsoft-announces-up-to-1500-layoffs-leaked-memo-blames-ai-wave


>”Microsoft has previously disclosed its billion-dollar AI investments have brought developments and productivity savings. These include an HR Virtual Agent bot which it says has saved 160,000 hours for HR service advisors by answering routine questions.”

AI took their jobs. Now they get paid to make it sound human: https://www.bbc.com/future/article/20240612-the-people-making-ai-sound-more-human
>In numerous industries, AI is being used to produce work that was once the exclusive domain of the human mind
>He led a team of more than 60 writers and editors…. " the business introduced an automated system. Miller's manager would plug a headline for an article into an online form, an AI model would generate an outline based on that title, and Miller would get an alert on his computer. Instead of coming up with their own ideas, his writers would create articles around those outlines, and Miller would do a final edit before the stories were published. Miller only had a few months to adapt before he got news of a second layer of automation. Going forward, ChatGPT would write the articles in their entirety, and most of his team was fired. The few people remaining were left with an even less creative task: editing ChatGPT's subpar text to make it sound more human.
>By 2024, the company laid off the rest of Miller's team, and he was alone. "All of a sudden I was just doing everyone's job," Miller says. Every day, he'd open the AI-written documents to fix the robot's formulaic mistakes, churning out the work that used to employ dozens of people.


Leaked Memo Claims New York Times Fired Artists to Replace Them With AI: https://futurism.com/the-byte/new-york-times-fires-artists-ai-memo

Taco Bell to roll out AI drive-thru ordering in hundreds of locations by end of year: https://www.nbcnews.com/business/business-news/taco-bell-roll-ai-drive-thru-ordering-hundreds-locations-end-year-rcna164524

Yum Brands said the tech has improved order accuracy, reduced wait times, decreased employees’ task load and fueled profitable growth.

Cheap AI voice clones may wipe out jobs of 5,000 Australian actors: https://www.theguardian.com/technology/article/2024/jun/30/ai-clones-voice-acting-industry-impact-australia

>Industry group says rise of vocal technology could upend many creative fields, including audiobooks – the canary in the coalmine for voice actors

https://www.theverge.com/2024/1/16/24040124/square-enix-foamstars-ai-art-midjourney

>AI technology has been seeping into game development to mixed reception. Xbox has partnered with Inworld AI to develop tools for developers to generate AI NPCs, quests, and stories. The Finals, a free-to-play multiplayer shooter, was criticized by voice actors for its use of text-to-speech programs to generate voices. Despite the backlash, the game has a mostly positive rating on Steam and is in the top 20 of most played games on the platform.

AI used by official Disney show for intro: https://www.polygon.com/23767640/ai-mcu-secret-invasion-opening-credits

Human level text to speech: https://www.microsoft.com/en-us/research/project/vall-e-x/vall-e-2/ 

Over 32 techniques to reduce hallucinations:
https://arxiv.org/abs/2401.01313

Almost 65,000 Job Cuts Were Announced In April—And AI Was Blamed For The Most Losses Ever: https://www.forbes.com/sites/maryroeloffs/2024/05/02/almost-65000-job-cuts-were-announced-in-april-and-ai-was-blamed-for-the-most-losses-ever/

In a survey of 450 executives in the US, "45 percent said they were automating tasks to reduce staffing and labour costs." https://www.smh.com.au/world/north-america/nearly-half-of-us-firms-using-ai-say-goal-is-to-cut-staffing-costs-20240629-p5jpsl.html

Bank of America CEO: AI helping cut call times, branch visits: https://www.msn.com/en-us/money/companies/bank-of-america-ceo-ai-helping-cut-call-times-branch-visits/ar-AA1eCRVI
AI virtual financial assistant has logged 1.5B customer interactions since 2018 launch

'Our Chatbots Perform The Tasks Of 700 People': Buy Now, Pay Later Company Klarna To Axe 2,000 Jobs As AI Takes On More Role: https://www.ibtimes.co.uk/our-chatbots-perform-tasks-700-people-buy-now-pay-later-company-klarna-axe-2000-jobs-ai-1726522

Klarna has already cut over 1,000 employees and plans to remove nearly 2,000 more
A Swedish financial services firm specializing in direct payments, pay-after-delivery options, and installment plans is preparing to reduce its workforce by nearly 50 per cent as artificial intelligence automation becomes more prevalent.
Klarna reported a 73 percent increase in average revenue per employee compared to last year. 
Klarna's interim results demonstrated a 27 percent increase in revenue, reaching 12.3 billion Swedish krona (£990 million). Additionally, the company transitioned from a loss of 456 million krona in the previous year to an adjusted profit of 673 million krona. The job cuts occur amidst a turnaround strategy at Klarna.

Klarna SUCCESSFULLY replaces call centers with AI https://www.klarna.com/international/press/klarna-ai-assistant-handles-two-thirds-of-customer-service-chats-in-its-first-month/

- Klarnas AI assistant, powered by @OpenAI , has in its first 4 weeks handled 2.3 million customer service chats and the data and insights are staggering:

- Handles 2/3 rd of our customer service enquires

- On par with humans on customer satisfaction

- Higher accuracy leading to a 25% reduction in repeat inquiries

- customer resolves their errands in 2 min vs 11 min

- Live 24/7 in over 23 markets, communicating in over 35 languages

- It performs the equivalent job of 700 full time agents

Digital automation could make 1.1 million roles in the Philippines obsolete by 2028: https://www.cisco.com/c/dam/global/en_sg/assets/csr/pdf/technology-and-the-future-of-asean-jobs.pdf

AI tools spark anxiety among Philippines’ call center workers: https://restofworld.org/2023/call-center-ai-philippines/

Bernie now uses ChatGPT and Bing to compile all the technical information he needs for a query in less than five minutes. It’s doubled the number of customer complaints he can handle in a day. 
“It made my work easier. I can even get ideas on how to approach certain complaints, making [my answers] appear engaging, persuasive, empathetic. It can give you that, depending on the prompt that you input,” Bernie told Rest of World.

Duolingo lays off staff as language learning app shifts toward AI: https://cnn.com/2024/01/09/tech/duolingo-layoffs-due-to-ai/index.html

Square Enix says it used AI art in upcoming Foamstars game: https://www.theverge.com/2024/1/16/24040124/square-enix-foamstars-ai-art-midjourney

>AI technology has been seeping into game development to mixed reception. Xbox has partnered with Inworld AI to develop tools for developers to generate AI NPCs, quests, and stories. The Finals, a free-to-play multiplayer shooter, was criticized by voice actors for its use of text-to-speech programs to generate voices. Despite the backlash, the game has a mostly positive rating on Steam and is in the top 20 of most played games on the platform.

Voice Actor Replaced with AI: https://www.dailymail.co.uk/tvshowbiz/article-13245821/Mamma-Mia-star-Sara-Poyzer-replaced-AI-BBC-production-calls-shock-decision-sobering-grim-times-industry.html

How to Make an Audiobook using AI in 2024: https://elevenlabs.io/blog/how-to-make-an-audiobook

Ibanking jobs are being drastically reduced with AI: https://archive.is/jrHmp

the consulting giant Accenture estimated that A.I. could replace or supplement nearly three-quarters of bank employees’ working hours across the industry.
This week, JPMorgan Chase’s chief executive, Jamie Dimon, wrote in his annual shareholder letter that A.I. “may reduce certain job categories or roles,” and labeled the technology top among the most important issues facing the nation’s largest bank. Mr. Dimon compared the consequences to those of “the printing press, the steam engine, electricity, computing and the internet, among others.”
Deutsche Bank is uploading reams of financial data into proprietary A.I. tools that can instanteously answer questions about publicly traded companies and create summary documents on complementary financial moves that might benefit a client — and earn the bank a profit.
Mr. Horine said he could use A.I. to identify clients that might be ripe for a bond offering, the sort of bread-and-butter transaction for which investment bankers charge clients millions of dollars.
Goldman Sachs has assigned 1,000 developers to test A.I., including software that can turn what it terms “corpus” information — or enormous amounts of text and data collected from thousands of sources — into page presentations that mimic the bank’s typeface, logo, styles and charts. One firm executive privately called it a “Kitty Hawk moment,” or one that would change the course of the firm’s future.
That isn’t limited to investment banking; BNY Mellon’s chief executive said on a recent earnings call that his research analysts could now wake up two hours later than usual, because A.I. can read overnight economic data and create a written draft of analysis to work from.
A senior Morgan Stanley executive told employees in a January private meeting, a video of which was viewed by The New York Times, that he would “get A.I. into every area of what we do,” including wealth management, where the bank employs thousands of people to determine the proper mix of investments for well-off savers.
Bank of America’s chief executive said last year that the technology was already enabling the firm to hire less.
Among Goldman Sachs’s sprawling A.I. efforts is a tool under development that can transfigure a lengthy PowerPoint document into a formal “S-1,” the legalese-packed document for initial public offerings required for all listed companies. The software takes less than a second to complete the job.

Super cheap robotaxi rides spark widespread anxiety in China: https://www.cnn.com/2024/07/18/cars/china-baidu-apollo-go-robotaxi-anxiety-intl-hnk/index.html

Nvidia’s AI Bot Outperforms Nurses, Study Finds: https://www.forbes.com/sites/robertpearl/2024/04/17/nvidias-ai-bot-outperforms-nurses-heres-what-it-means-for-you/

And they only cost $9 an hour: https://www.msn.com/en-us/money/other/nvidia-s-new-ai-nurses-treat-patients-for-9-an-hour-here-s-what-they-can-do-from-colonoscopy-screenings-to-loneliness-companionship/ar-BB1kmKtI

According to company-released data, the AI bots are 16% better than nurses at identifying a medication’s impact on lab values, 24% more accurate detecting toxic dosages of over-the-counter drugs, and 43% better at identifying condition-specific negative interactions from OTC meds. All that at $9 an hour compared to the $39.05 median hourly pay for U.S. nurses. These AI nurse-bots are designed to make new diagnoses, manage chronic disease, and give patients a detailed but clear explanation of clinicians’ advice.

How will Language Modelers like ChatGPT Affect Occupations and Industries? https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4375268


We find that the top occupations exposed to language modeling include telemarketers and a variety of post-secondary teachers such as English language and literature, foreign language and literature, and history teachers. We find the top industries exposed to advances in language modeling are legal services and securities, commodities, and investments. 

Big banks on Wall Street could pull back hiring plans as they lean more heavily on AI, cutting analyst hiring by two-thirds: https://www.businessinsider.com/ai-job-cuts-finance-wall-street-investment-banking-analysts-hiring-2024-4

“GenAI will save [Klarna] $10m in marketing this year. We’re spending less on photographers, image banks, and marketing agencies” https://archive.is/tVW2N

- $6m less on producing images.
- 1,000 in-house AI-produced images in 3 months. Includes the creative concept, quality check, and legal compliance.
- AI-image production reduced from 6 WEEKS TO 1 WEEK ONLY.
- Customer response to AI images on par with human produced images.
- Cutting external marketing agency costs by 25% (mainly translation, production, CRM, and social agencies).


- Our in-house marketing team is HALF the size it was last year but is producing MORE!


- We’ve removed the need for stock imagery from image banks like 
@gettyimages


- Now we use genAI tools like Midjourney, DALL-E, and Firefly to generate images, and Topaz Gigapixel and Photoroom to make final adjustments.


- Faster images means more app updates, which is great for customers. And our employees get to work on more fun projects AND we're saving money.


BP Earnings Call: We need 70% less coders from third parties to code as the AI handles most of the coding, the human only needs to look at the final 30% to validate it, that's a big savings for the company moving forward.
Second things like call centers, the language models have become so sophisticated now. They can operate in multiple languages, 14, 15 languages easily. In the past, that hasn't been something we can do. So we can redeploy people off that given that the AI can do it. You heard my advertising example last quarter where advertising cycle times moved from four to five months down to a couple of weeks. So that's obviously reducing spend with third parties. We've now got Gen AI in the hands through Microsoft Copilot across many, many parts of the business and we'll continue to update you with anecdotes as we go through
Source: https://seekingalpha.com/article/4690194-bp-p-l-c-bp-q1-2024-earnings-call-transcript

This is almost certainly true because this is quoted from an earnings call from BP and lying to investors is a crime (securities fraud). This would include lying about the reason for getting rid of the workers (in other words, it can’t just be layoffs). The numbers that are provided are also too specific to be exaggerations without also being a lie.

2024 McKinsey survey on AI: https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai
For the past six years, AI adoption by respondents’ organizations has hovered at about 50 percent. This year, the survey finds that adoption has jumped to 72 percent (Exhibit 1). And the interest is truly global in scope. Our 2023 survey found that AI adoption did not reach 66 percent in any region; however, this year more than two-thirds of respondents in nearly every region say their organizations are using AI
In the latest McKinsey Global Survey on AI, 65 percent of respondents report that their organizations are regularly using gen AI, nearly double the percentage from our previous survey just ten months ago.
Respondents’ expectations for gen AI’s impact remain as high as they were last year, with three-quarters predicting that gen AI will lead to significant or disruptive change in their industries in the years ahead
Organizations are already seeing material benefits from gen AI use, reporting both cost decreases and revenue jumps in the business units deploying the technology.






Image to animation: https://github.com/Fictiverse/ToonCrafter-for-windows

Co-founder of Dreamworks expects AI to replace 90% of animators: https://www.indiewire.com/news/business/jeffrey-katzenberg-ai-will-take-90-percent-animation-jobs-1234924809/

Google's medical AI destroys GPT's benchmark and outperforms doctors: https://newatlas.com/technology/google-med-gemini-ai/


[Generative AI will be designing new drugs all on its own in the near future](https://www.cnbc.com/2024/05/05/within-a-few-years-generative-ai-will-design-new-drugs-on-its-own.html)

Researchers find that GPT-4 performs as well as or better than doctors on medical tests, especially in psychiatry. https://www.news-medical.net/news/20231002/GPT-4-beats-human-doctors-in-medical-soft-skills.aspx

ChatGPT outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions: https://today.ucsd.edu/story/study-finds-chatgpt-outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions?darkschemeovr=1

AI is better than doctors at detecting breast cancer: https://www.bbc.com/news/health-50857759

AI just as good at diagnosing illness as humans: https://www.medicalnewstoday.com/articles/326460

https://www.aamc.org/news/will-artificial-intelligence-replace-doctors?darkschemeovr=1

Large action model can interact with UIs and act independently https://github.com/a-real-ai/pywinassistant

AI doing sales calls very well: https://www.reddit.com/r/Futurology/comments/1ceeq17/comment/l1k8b7f/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_button

Generative AI could soon decimate the call center industry, says CEO | There could be "minimal" need for call centres within a year: https://www.techspot.com/news/102749-generative-ai-could-soon-decimate-call-center-industry.html 

AI for UI design: https://uizard.io/?darkschemeovr=1

[First Results from Med-Gemini (the successor to Med-Palm, a medically fine tuned LLM). "More accurate multimodal conversations about medical images🩻, surgical videos📽️, genomics🧬, ultra-long health records📚, ECGs🫀 & more with state-of-art performance across multiple benchmarks"](https://twitter.com/alan_karthi/status/1785117444383588823 )
 



https://analyticsindiamag.com/googles-med-gemini-model-is-multimodal-achieves-91-1-accuracy-in-medical-diagnostics/



[AI beats humans on all performance indicators](https://newatlas.com/technology/ai-index-report-global-impact/)


https://www.newsweek.com/first-ever-mcdonalds-served-robots-texas-1769116?darkschemeovr=1


https://www.psypost.org/chatgpt-4-outperforms-human-psychologists-in-test-of-social-intelligence-study-finds/



https://www.forbes.com/sites/edrensi/2018/07/11/mcdonalds-says-goodbye-cashiers-hello-kiosks/?darkschemeovr=1&sh=7fa37f66f140



survey-finds-generative-ai-proving-major-threat-to-the-work-of-translators: https://www.theguardian.com/books/2024/apr/16/survey-finds-generative-ai-proving-major-threat-to-the-work-of-translators 

[Alphacode 2 beat 99.5% of competitive programming participants in TWO Codeforce competitions](https://the-decoder.com/alphacode-2-is-the-hidden-champion-of-googles-gemini-project/). Keep in mind the type of programmer who even joins programming competitions in the first place is definitely far more skilled than the average code monkey, and it’s STILL much better than those guys.



DeepMind Researchers Propose Naturalized Execution Tuning (NExT): A Self-Training Machine Learning Method that Drastically Improves the LLM’s Ability to Reason about Code Execution https://www.marktechpost.com/2024/04/26/deepmind-researchers-propose-naturalized-execution-tuning-next-a-self-training-machine-learning-method-that-drastically-improves-the-llms-ability-to-reason-about-code-execution/ 



https://arstechnica.com/gadgets/2023/12/report-google-ads-restructure-could-replace-some-sales-jobs-with-ai/ 
  


https://www.msn.com/en-us/money/other/nvidia-s-new-ai-nurses-treat-patients-for-9-an-hour-here-s-what-they-can-do-from-colonoscopy-screenings-to-loneliness-companionship/ar-BB1kmKtI        



Half of all managers aim to replace staff with AI: https://www.techspot.com/news/102385-survey-reveals-almost-half-all-managers-aim-replace.html

https://tech.co/news/ai-replacing-jobs 

https://www.polygon.com/23767640/ai-mcu-secret-invasion-opening-credits?darkschemeovr=1       

 
https://www.theguardian.com/technology/2024/feb/23/tyler-perry-halts-800m-studio-expansion-after-being-shocked-by-ai?darkschemeovr=1    

Animation made with AI by Corridor Digital: https://kotaku.com/anime-rock-paper-scissors-corridor-digital-ai-animation-1850186624?darkschemeovr=1 

https://www.theguardian.com/commentisfree/2023/jan/24/chatgpt-artificial-intelligence-jobs-economy 

AI is taking over drug development: https://www.reddit.com/r/singularity/comments/1btmnhj/artificial_intelligence_is_taking_over_drug/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_button



AI Cuts Worker Numbers: https://www.reddit.com/r/singularity/comments/1bwjse7/ai_seen_cutting_worker_numbers_survey_by_staffing/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_button



steve_cohen_says_his_financial_firm_can_already save $25 million with AI: https://www.reddit.com/r/singularity/comments/1bvrgqn/steve_cohen_says_his_financial_firm_can_already/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_button


Walmart replacing employees in Canada: https://www.reddit.com/r/singularity/comments/1c2artf/walmart_canada_says_robots_are_coming_to_two/


https://www.washingtonpost.com/technology/2023/10/03/ai-customer-service-jobs/

https://www.reddit.com/r/ArtificialInteligence/comments/1c3wb3x/ai_outperforms_humans_in_providing_emotional/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_button

https://www.resumebuilder.com/1-in-3-companies-will-replace-employees-with-ai-in-2024/?darkschemeovr=1
Of companies currently using AI, 37% say workers were laid off in 2023 because they were no longer needed due to the company’s use of AI.
In 2024, 44% of companies who use AI or plan to by next year say employees will definitely (21%) or probably (23%) be laid off due to the use of AI.

https://www.reddit.com/r/singularity/comments/1c33pql/amazon_grows_to_over_750000_robots_as_worlds/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_button





The military wants ‘robot ships’ to replace sailors in battle: https://www.realcleardefense.com/2022/04/15/the_military_wants_robot_ships_to_replace_sailors_in_battle_827353.html
Tech titans considering job replacement with AI: https://www.reddit.com/r/singularity/comments/1by5sj7/tech_titans_assemble_to_decide_which_jobs_ai_can/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_buttonurasi
AI analyst says plumbers and electricians' jobs are safe, but AI models like GPT-4o 'will impact any job that has data' https://www.yahoo.com/tech/ai-models-gpt-4o-could-102901684.html
China’s ‘AI Ship Designer’ Works At Unprecedented Speed; Performed A Year’s Work Only In 24 Hours! https://www.eurasiantimes.com/chinas-ai-ship-designer-works-at-unprecedented-speed-performed/
McKinsey report on employment displacement due to AI: https://www.mckinsey.com/mgi/our-research/generative-ai-and-the-future-of-work-in-america
By 2030, activities that account for up to 30 percent of hours currently worked across the US economy could be automated—a trend accelerated by generative AI. However, we see generative AI enhancing the way STEM, creative, and business and legal professionals work rather than eliminating a significant number of jobs outright. Automation’s biggest effects are likely to hit other job categories. Office support, customer service, and food service employment could continue to decline.
An additional 12 million occupational transitions may be needed by 2030. As people leave shrinking occupations, the economy could reweight toward higher-wage jobs. Workers in lower-wage jobs are up to 14 times more likely to need to change occupations than those in highest-wage positions, and most will need additional skills to do so successfully. Women are 1.5 times more likely to need to move into new occupations than men.
Graphic designer loses job to AI: https://m.youtube.com/watch?si=MH46UnqxUd20xw7C&v=U2vq9LUbDGs&feature=youtu.be 
Microsoft’s new Copilot AI agents act like virtual employees to automate tasks: https://www.theverge.com/2024/5/21/24158030/microsoft-copilot-ai-automation-agents 
Google might already be replacing some human workers with AI: https://www.techradar.com/pro/google-might-already-be-replacing-some-human-workers-with-ai 
“Godfather of AI” Geoffrey Hinton says Universal Basic Income may be needed to address the loss of jobs to AI and the distribution of wealth generated by AI, but it won't be enough to give people self-respect: https://x.com/tsarnick/status/1792398561881325754 
Kai-Fu Lee says 50% of jobs may be replaced by AI within 3 years and white collar jobs are most at risk: https://x.com/tsarnick/status/1794121874882122228 
GPT-4 outsmarts Wall Street: AI predicts earnings better than human analysts | The researchers conducted their study by providing GPT-4 with standardised financial statements, carefully stripped of any company names or dates to prevent the model from using prior knowledge: https://www.businesstoday.in/technology/news/story/gpt-4-outsmarts-wall-street-ai-predicts-earnings-better-than-human-analysts-431062-2024-05-27 
AI used for psychological therapy: https://t.co/bQIzknuipj 
Automation powered by GPT-4o generates Figma designs based on PRD: https://x.com/yancymin/status/1795308932216525229 
Generating short films, trailers, and teasers with AI tools: https://x.com/minchoi/status/1795834164333433232 

Era3D: A new AI model that creates high-res 🗿3D images from multiple viewpoints using just one input image: https://x.com/Gradio/status/1795866944568000697 
- Generates high-quality images up to 512×512 pixels🎯
- Uses efficient row-wise attention to reduce computation⚡
- 12x more efficient than sota methods💪
Sony Will Use AI to Cut Film Costs, Says CEO Tony Vinciquerra: https://www.indiewire.com/news/breaking-news/sony-pictures-will-cut-film-costs-using-ai-1235010605/ 
AI Agents Are Coming for Mundane—but Valuable—Office Task: https://www.wired.com/story/chatbots-are-entering-the-stone-age/ 
Anthropic and other big AI startups are teaching chatbots “tool use,” to make them more useful in the workplace.
Game made with 3D assets and textures made with AI: https://x.com/CSM_ai/status/1796200041280925713 
A chest: https://x.com/tejasdkulkarni/status/1796730715851157620 
Watch a team of EVEs work together to clean up our office: https://x.com/1x_tech/status/1796589816940986525 
https://www.oxfordmartin.ox.ac.uk/publications/the-future-of-employment 
According to their estimates, about 47 per cent of total US employment is at risk. They further provide evidence that wages and educational attainment exhibit a strong negative relationship with an occupation’s probability of computerisation.
Google has a call center AI: https://m.youtube.com/watch?v=N_q4CwVrCSo 
Geoffrey Hinton says AI doctors who have seen 100 million patients will be much better than human doctors and able to diagnose rare conditions more accurately: https://x.com/tsarnick/status/1797169362799091934 
Tech titans considering job replacement with AI: https://www.reddit.com/r/singularity/comments/1by5sj7/tech_titans_assemble_to_decide_which_jobs_ai_can/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_button
Robotics makers embrace Nvidia digital twins to create autonomous AI-run factories: https://www.computerworld.com/article/2137856/robotics-makers-embrace-nvidia-digital-twins-to-create-autonomous-ai-run-factories.html 
First NHS physiotherapy clinic run by AI to start this year. New platform to provide same-day appointments with digital physiotherapist in effort to cut waiting times: https://www.theguardian.com/society/article/2024/jun/09/first-nhs-physiotherapy-clinic-run-by-ai-to-start-this-year 
Former Microsoft & Google research scientist Kai-Fu Lee- About 50% Of Jobs Will Be Displaced By AI Within 3 Years: https://www.youtube.com/watch?v=zZs447dgMjg 
Since he’s no longer employed at those companies, he does not have an incentive to lie 
Consistent with claims from Anthropic’s Chief of Staff: https://fortune.com/2024/06/04/anthropics-chief-of-staff-avital-balwit-ai-remote-work/ 
his prediction from 2017 still holds that in 10-15 years around 40-50% of all jobs will be replaced by AI.
AI used by official Disney show for intro: https://www.polygon.com/23767640/ai-mcu-secret-invasion-opening-credits
 Guy commissioned and properly credited artists in the past, multiple times got backstabbed by artists who copy-striked his videos, threatening to take his channel down: https://www.youtube.com/watch?v=knUkXwJXcpY 
OpenAI CTO: AI Could Kill Some Creative Jobs That Maybe Shouldn't Exist Anyway: https://www.pcmag.com/news/openai-cto-mira-murati-ai-could-take-some-creative-jobs
Photos to ads: https://www.reddit.com/r/StableDiffusion/comments/1dmv1mf/turn_your_boring_product_photos_into_professional/ 
Toys R Us uses Sora generated promo: https://www.reddit.com/r/singularity/comments/1do7dah/toys_r_us_releases_sora_generated_promo/ 
Kling AI videos could also be used for marketing: https://x.com/CharaspowerAI/status/1810952037246349739
McDonalds ad: https://www.reddit.com/r/aivideo/comments/1e7x5in/mcdonalds_ai_spec_ad_cost_me_less_than_60_happy/
AI Outperforms Radiologists in Detecting Prostate Cancer on MRI: https://humanprogress.org/ai-outperforms-radiologists-in-detecting-prostate-cancer-on-mri-scans/


Uber is partnering with a driverless trucking company. Uber Freight will begin work with Aurora Innovation this fall using human drivers. Then they'll transition to autonomous hauling from Dallas to Houston: https://x.com/MorePerfectUS/status/1805995973879255407

This 20,000HP AI-generated rocket engine took just two weeks to design: https://www.pcgamer.com/hardware/this-20000hp-ai-generated-rocket-engine-took-just-two-weeks-to-design-and-looks-like-hr-gigers-first-attempt-at-designing-a-trumpet

This was done in less than 24h by one person using AI as the ground tooling, some post in AE and that’s it. Imagine the time and cost a real spot like this would cost. 100x less expensive due to AI: https://www.reddit.com/r/singularity/comments/1dyh5z3/this_was_done_in_less_than_24h_by_one_person/

AI Agent Better than OpenAI’s GPT-4o and costs just $1.60 per 1000 queries, making it 175% cheaper than GPT-4o. It is the world’s first fully autonomous AI-powered sales development representative (SDR): https://analyticsindiamag.com/aim-exclusive-yc-backed-indian-startup-claims-its-ai-agent-is-better-than-openais-gpt-4o/



Source: https://ourworldindata.org/artificial-intelligence
CNN to lay off 100 staffers as it preps major revamp of digital efforts - exploring a "strategic push into AI." https://www.hollywoodreporter.com/business/business-news/cnn-layoffs-digital-revamp-mark-thompson-1235944428/
https://www.microsoft.com/en-us/worklab/work-trend-index/ai-at-work-is-here-now-comes-the-hard-part
>Already, AI is being woven into the workplace at an unexpected scale. 75% of knowledge workers use AI at work today, and 46% of users started using it less than six months ago. It’s paying off: users
Users say AI helps them save time (90%), focus on their most important work (85%), be more creative (84%), and enjoy their work more (83%). 
78% of AI users are bringing their own AI tools to work (BYOAI)—it’s even more common at small and medium-sized companies (80%).
53% of people who use AI at work worry that using it on important work tasks makes them look replaceable.
While some professionals worry AI will replace their job (45%), about the same share (46%) say they’re considering quitting in the year ahead—higher than the 40% who said the same ahead of 2021’s Great Reshuffle.
How AI is fuelling uncertainty for game developers: https://www.bbc.com/news/articles/cl44mv0jnv5o
"I'm very aware that I could wake up tomorrow and my job could be gone,” says Jess Hyland.
The video game artist says the industry she’s spent almost 15 years working in is on “shaky” ground at the moment.
Some bosses are talking up the potential of generative AI - the tech behind tools such as ChatGPT - as a potential saviour.
Tech giant Nvidia has shown off impressive development tool prototypes, and gaming industry heavyweights such as Electronic Arts and Ubisoft are investing in the tech.
It's claimed AI tools can save development time, free workers up to focus on creativity and provide a more personalised user experience.
Against the backdrop of widespread layoffs, Jess says the suspicion among workers is that bosses see AI as a path to cutting costs when labour is their biggest expense.
Jess says she knows one person who's lost work due to AI, and has heard of it happening to others.
There are also dozens of accounts online suggesting that jobs in concept art and other traditionally entry-level roles have been affected.
Rather than creating their own material, says Jess, artists worry they could end up supplementing AI's efforts, rather than the other way around.
An agency created an AI model who earns up to $11,000 a month because it was tired of influencers 'who have egos' https://www.businessinsider.com/ai-influencer-aitana-clueless-agency-tech-spain-2023-11?op=1
JPMorgan CEO says AI is a living, breathing thing and they're putting AI into every process -- sometimes as a copilot, sometimes to replace humans. “AI is doing all the equity hedging for us.” https://www.reddit.com/r/singularity/comments/1e9z84s/jpmorgan_ceo_says_ai_is_a_living_breathing_thing/
Three in Four Americans Believe AI Will Reduce Jobs: https://news.gallup.com/opinion/gallup/510635/three-four-americans-believe-reduce-jobs.aspx
AI Detects Prostate Cancer 17% More Accurately Than Doctors, Finds Study: https://www.ndtv.com/science/ai-detects-prostate-cancer-17-more-accurately-than-doctors-finds-study-6170131
From 10 minutes to .5 seconds. Stability Ai Rapid 3D Asset Generation From Single Images: https://stability.ai/news/introducing-stable-fast-3d
METR Evals - LLM agents vs skilled humans on diverse task completion: When agents can do a task, they do so at ~1/30th of the cost of the median hourly wage of a US bachelor’s degree... Claude 3.5 Sonnet agent fixed bugs in an ORM library at a cost of <$2, Human baseline took >2 hours: https://x.com/METR_Evals/status/1820905731950055766
40% fewer tasks means fewer staff needed 




GPT-4 scored higher than 100% of psychologists on a test of social intelligence: https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1353022/full
What percent of code is now written by AI? "I ask all the software companies I meet about this. The number is rarely lower than 40%. For some young programmers it's 90%." - Paul Graham of Y Combinator on Twitter
AI predicts diseases with 98% accuracy in real-time using tongue color | AI-powered computer model to analyze patients’ tongue colors for real-time disease diagnoses such as anemia, COVID-19, vascular and gastrointestinal issues, or asthma: https://interestingengineering.com/health/ai-model-predicts-disease-using-tongue-color
the paper itself shows that the best model has a f1 score, precision, recall all above 98% https://www.mdpi.com/2227-7080/12/7/97
AI stole my job and my work, and my boss didn’t know or care: https://www.theregister.com/2024/08/15/robot_took_my_job/
You Will Lose Your Job to a Robot—and Sooner Than You Think: https://www.motherjones.com/politics/2017/10/you-will-lose-your-job-to-a-robot-and-sooner-than-you-think/
In a leaked recording, Amazon cloud chief tells employees that most developers could stop coding soon as AI takes over: https://www.businessinsider.com/aws-ceo-developers-stop-coding-ai-takes-over-2024-8

This isn’t marketing hype since the recording was not meant to be public
Lying about this goes AGAINST the interests of the company since it encourages their own workers to consider leaving the industry 
AI agent that can control a computer: https://www.adept.ai/blog/act-1
This can be especially powerful for manual tasks and complex tools — in this example, what might ordinarily take 10+ clicks in Salesforce can be now done with just a sentence.
Working in-depth in tools like spreadsheets, ACT-1 demonstrates real-world knowledge, infers what we mean from context, and can help us do things we may not even know how to do.
The model can also complete tasks that require composing multiple tools together; most things we do on a computer span multiple programs. In the future, we expect ACT-1 to be even more helpful by asking for clarifications about what we want.
The internet contains a lot of knowledge about the world! When the model doesn’t know something, it knows how to just look up the information online
ACT-1 doesn’t know how to do everything, but it’s highly coachable. With 1 piece of human feedback, it can correct mistakes, becoming more useful with each interaction.
Call centers being automated with AI: https://www.hindustantimes.com/business/ais-impact-on-philippines-the-worlds-call-center-capital-shows-whats-to-come-101724827045422.html

For some, the rapid deployment of such tools has been a harsh awakening. Christopher Bautista, 47, had worked in the call center industry for nearly two decades. In his last job on a tech support desk he’d watched as AI took on more responsibility in gatekeeping customer calls and asking questions before routing to human agents. Then last November, along with about 70 other people, he says, he was abruptly put on so-called floating status — no work, no pay, but still on the books — after the client pulled the contract. He quit six months later for a job in sales while still waiting for reassignment. "AI will take over our jobs,” Bautista said. “It’s cheaper and more efficient."
A class of 20 pupils at a $35,000 per year private London school won't have a human teacher this year. They'll just be taught by AI: https://archive.md/wkIZZ
Self driving bus in china: https://www.reddit.com/r/singularity/comments/1fc8f3k/self_driving_bus_in_china/
Automated shuttle: https://news.vt.edu/articles/2019/05/053019-vtti-autonomousshuttle.html
An AI Bot Named James Has My Old Local News Job: https://www.wired.com/story/an-ai-bot-named-james-has-my-old-local-news-job/
A local newspaper in Hawaii has turned to AI-generated presenters to draw in new audiences.
NotebookLM now lets you listen to a conversation about your sources (Create a two person podcast from your sources): https://blog.google/technology/ai/notebooklm-audio-overviews/
AI medical receptionist: https://www.reddit.com/r/singularity/comments/1fjqzsv/vocca_ai_an_ai_receptionist_for_medical_clinics/
Billionaire tech CEO says corporate CEO’s can’t “bulls---” their employees about the impact of AI on the workforce and instead be honest that jobs will go away: https://www.cnbc.com/2024/09/19/billionaire-tech-ceo-bosses-shouldnt-bs-employees-about-ai-impact.html
Bank of Canada’s Tiff Macklem warns AI could destroy more jobs than it creates: https://archive.md/YK2cm
He does not work in the tech industry and has no incentive to lie about this
Nvidia CEO says don’t learn coding because of AI, tech giant exec says jobs will be hit: https://www.indiatoday.in/technology/features/story/nvidia-ceo-says-dont-learn-coding-because-ai-tech-giant-exec-says-jobs-will-be-hit-story-in-5-points-2509126-2024-03-01


Lying about this goes against his interest as discouraging coders would make them harder to find and more expensive to employ due to a lower supply. It would be a very stupid and short-sighted way of generating hype for the sake of hype when there are many other ways to do it that would not increase long-term costs for his company. 


In a leaked recording, Amazon cloud chief tells employees that most developers could stop coding soon as AI takes over: https://www.businessinsider.com/aws-ceo-developers-stop-coding-ai-takes-over-2024-8

This isn’t marketing hype since the recording was not meant to be public
Lying about this goes AGAINST the interests of the company since it encourages their own workers to consider leaving the industry 

Microsoft announces up to 1,500 layoffs, leaked memo blames 'AI wave' https://www.hrgrapevine.com/us/content/article/2024-06-04-microsoft-announces-up-to-1500-layoffs-leaked-memo-blames-ai-wave

This isn’t a PR move since the memo was not supposed to be publicized.
How AlphaChip transformed computer chip design: https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/
Our AI method has accelerated and optimized chip design, and its superhuman chip layouts are used in hardware around the world
The method has been used to design superhuman chip layouts in the last three generations of Google’s custom AI accelerator, the Tensor Processing Unit (TPU).
AlphaChip was one of the first reinforcement learning approaches used to solve a real-world engineering problem. It generates superhuman or comparable chip layouts in hours, rather than taking weeks or months of human effort, and its layouts are used in chips all over the world, from data centers to mobile phones.
AlphaChip has generated superhuman chip layouts used in every generation of Google’s TPU since its publication in 2020. These chips make it possible to massively scale-up AI models based on Google’s Transformer architecture.
Beyond designing specialized AI accelerators like TPUs, AlphaChip has generated layouts for other chips across Alphabet, such as Google Axion Processors, our first Arm-based general-purpose data center CPUs.
External organizations are also adopting and building on AlphaChip. For example, MediaTek, one of the top chip design companies in the world, extended AlphaChip to accelerate development of their most advanced chips — like the Dimensity Flagship 5G used in Samsung mobile phones — while improving power, performance and chip area.


Billionaire Predicts How AI Will Kill Jobs: https://futurism.com/the-byte/billionaire-sips-margaritas-bragging-ai-kill-jobs

The company has already cut off contractors tasked with coming up with alternative ways to phrase translations in January.
Unsurprisingly, the changes were in large part thanks to the advent of AI.
"Generative AI is accelerating our work by helping us create new content dramatically faster," von Ahn wrote in a November shareholder letter.
OpenAI's Hunter Lightman says the new o1 AI model is already acting like a software engineer and authoring pull requests, and Noam Brown says everyone will know AGI has been achieved internally when they take down all their job listings: https://www.reddit.com/r/singularity/comments/1futg5p/openais_hunter_lightman_says_the_new_o1_ai_model/
New AI Framework for Medical Imaging Matches Accuracy of Clinical Specialists: https://www.insideprecisionmedicine.com/topics/patient-care/new-ai-framework-for-medical-imaging-matches-accuracy-of-clinical-specialists/
Generative AI will Require 80% of Engineering Workforce to Upskill Through 2027" https://www.gartner.com/en/newsroom/press-releases/2024-10-03-gartner-says-generative-ai-will-require-80-percent-of-engineering-workforce-to-upskill-through-2027
Short Term:
AI tools will slightly increase productivity by helping with tasks.
Senior developers in well-run companies will benefit the most from these tools.

Medium Term:
AI agents will change how developers work by automating more tasks.
Most code will be made by AI, not humans.
Developers need to learn new skills like prompt engineering and RAG.
Long Term:
More skilled software engineers are needed because of the growing demand for AI-powered software.
A new type of engineer, called an AI engineer, who knows about software, data science, and AI/ML will be very important
Wimbledon will replace all 300 line judges next year with AI tech after 147 years of tradition.: https://www.skysports.com/tennis/news/12110/13230764/wimbledon-to-replace-line-judges-with-ai-after-147-years
Cardiologists working with AI said it was equal or better than human cardiologists in most areas: https://x.com/DKThomp/status/1843993273825964312

LLM skeptic Internet of Bugs says ChatGPT-O1 Changes Programming as a Profession. I really hated saying that: https://youtube.com/watch?v=j0yKLumIbaM
ACM writer who has been in CS since the 1980s predicts AI will make programmers obsolete: https://cacm.acm.org/opinion/the-end-of-programming
OpenAI CPO Kevin Weil says their o1 model can now write legal briefs that previously were the domain of $1000/hour associates: "what does it mean when you can suddenly do $8000 of work in 5 minutes for $3 of API credits?" https://www.reddit.com/r/singularity/comments/1g7v0ud/openai_cpo_kevin_weil_says_their_o1_model_can_now/
Disney is set to announce a major AI initiative that will transform its creative output. The initiative is said to involve “hundreds” of people at the company and will primarily focus on post-production and visual effects: https://www.thewrap.com/disney-ai-initiative/
Sundar Pichai said on the earnings call today that more than 25% of all new code at Google is now generated by AI. He also said project astra will be ready for 2025: https://www.reddit.com/r/singularity/comments/1gf6elr/sundar_pichai_said_on_the_earnings_call_today/

Likely not lying as lying to investors is securities fraud. If he wanted to exaggerate, he would have said “a large percentage” instead of a specific and verifiable number.
This Polish radio station fired all its journalists and replaced them with AI hosts: https://www.zmescience.com/science/news-science/polish-radio-hires-ai/
Big study of 187k developers using GitHub Copilot: AI transforms HOW we work. Coders can focus. They do more coding and less management. They need to coordinate less, working with fewer people. And they experiment more with new languages, which would increase earnings $1,683/year: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5007084
https://aidantr.github.io/files/AI_innovation.pdf


"These effects are large. To put the rise in materials discovery in perspective, the lab’s research output per scientist declined by 4% over the preceding five years. This was despite the introduction of several computational tools designed to aid scientists. AI therefore appears to be a different class of technology, with impacts that are orders of magnitude greater than previous methods." 

"However, the results suggest that AI-assisted materials discovery does not compromise quality"

As one scientist noted: “While I was impressed by the performance of the [AI tool]...I couldn’t help feeling that much of my education is now worthless. This is not what I was trained to do.”

Recession could create an ‘abrupt shift’ in AI adoption: ‘That’s when you really see the effects of automation’ https://fortune.com/2024/11/12/recession-could-create-an-abrupt-shift-in-ai-adoption-thats-when-you-really-see-the-effects-of-automation/
Coca Cola’s annual Christmas commercial has been created with AI this time: https://x.com/DiscussingFilm/status/1857502106074099717
Uber and Lyft drivers say Waymo's robotaxis are hurting their earnings in Phoenix and LA: https://archive.is/2024.11.29-132456/https://www.businessinsider.com/waymo-robotaxis-competing-uber-lyft-drivers-phoenix-los-angeles-price-2024-11#selection-1465.0-1465.88
Cate Blanchett Fears AI Will Be “Incredibly Destructive” To Hollywood: “Deeply Concerned” with the potential to “totally replace anyone.” https://deadline.com/2024/11/cate-blanchett-fears-ai-incredibly-destructive-entertainment-industry-1236190351/
Hollywood Execs Talk “Transformative” Nature Of AI & The Chances Of An AI Movie Star: “It’s Coming” — Zurich Summit: https://deadline.com/2024/10/ai-harrison-ford-film-transformative-power-zurich-summit-1236108162/

https://cdn.openai.com/o1-system-card-20241205.pdf
CEO of Salesforce has said they will not be adding any more engineers due to a productivity explosion from AI software: https://youtu.be/Xgsxi7IGMEU?si=HjBCXmtMDyWVvu4E
o1-preview is far superior to doctors on reasoning tasks and it's not even close, according to OpenAI's latest paper. AI does ~80% vs ~30% on the 143 hard NEJM CPC diagnoses: https://x.com/deedydas/status/1869049071346102729

Official Resident Evil account uses AI art: https://x.com/REBHPortal/status/1871587406958428305

5.1. Robotics





Source: https://ourworldindata.org/artificial-intelligence
In a historic moment for the dental profession, an AI-controlled autonomous robot has performed an entire procedure on a human patient for the first time, about eight times faster than a human dentist could do it: https://newatlas.com/health-wellbeing/robot-dentist-world-first/
7-foot robots are stacking shelves in Tokyo convenience stores using remote workers for $3.75 an hour. "The robots will be remotely operated at first, until their AI learns to copy human movements." https://x.com/AISafetyMemes/status/1810152092230877563

Successful test of humanoid robots at BMW Group Plant Spartanburg: https://www.press.bmwgroup.com/global/article/detail/T0444265EN/successful-test-of-humanoid-robots-at-bmw-group-plant-spartanburg
Humanoid robots that can detect objects, appraise their work and correct mistakes are coming to factories: https://x.com/tsarnick/status/1807886268501839875

Digit in action at GXO's SPANX facility in Flowery Branch, Georgia: https://x.com/TheHumanoidHub/status/1807307038458052730

Robot operated autonomous surgery: https://www.nytimes.com/2021/04/30/technology/robot-surgery-surgeon.html

With one claw, the machine lifted a tiny plastic ring from an equally tiny peg on the table, passed the ring from one claw to the other, moved it across the table and gingerly hooked it onto a new peg. Then the robot did the same with several more rings, completing the task as quickly as it had when guided by Dr. Fer. The training exercise was originally designed for humans; moving the rings from peg to peg is how surgeons learn to operate robots like the one in Berkeley. Now, an automated robot performing the test can match or even exceed a human in dexterity, precision and speed, according to a new research paper from the Berkeley team.
The project is a part of a much wider effort to bring artificial intelligence into the operating room. Using many of the same technologies that underpin self-driving cars, autonomous dronesand warehouse robots, researchers are working to automate surgical robots too. These methods are still a long way from everyday use, but progress is accelerating.
Robots can already exceed human accuracy on some surgical tasks, like placing a pin into a bone (a particularly risky task during knee and hip replacements). The hope is that automated robots can bring greater accuracy to other tasks, like incisions or suturing, and reduce the risks that come with overworked surgeons.

Apple wants to replace 50% of iPhone final assembly line workers with automation: https://9to5mac.com/2024/06/24/iphone-supply-chain-automation-workers/ 

Amazon Grows To Over 750,000 Robots As World's Second-Largest Private Employer Replaces Over 100,000 Humans: https://finance.yahoo.com/news/amazon-grows-over-750-000-153000967.html 

Samsung builds all AI, no human chip factories: https://asiatimes.com/2024/01/samsung-to-build-all-ai-no-human-chip-factories/

Xiaomi’s new «smart» factory will operate 24/7 without people and produce 60 smartphones per minute: https://itc.ua/en/news/xiaomi-s-new-smart-factory-will-operate-24-7-without-people-and-produce-60-smartphones-per-minute/


Japan introduces enormous humanoid robot to maintain train lines: https://www.theguardian.com/world/article/2024/jul/04/japan-train-robot-maintain-railway-lines

Fully automated packing company: https://www.reddit.com/r/robotics/comments/1dlcvjs/i_was_in_full_automated_packaging_company_and/

How many robots does it take to run a grocery store? https://www.youtube.com/watch?v=ssZ_8cqfBlE 


Robot operated McDonalds in Texas: https://www.newsweek.com/first-ever-mcdonalds-served-robots-texas-1769116 

 A Starbucks run by 100 robots and 2 humans in South Korea: https://x.com/NorthstarBrain/status/1794819711240155594

Restaurant robots can cook, serve and bus your meal now: https://www.axios.com/2024/06/11/restaurant-technology-robots-food-ramen 

Robot chef that cooks meals: https://x.com/leeron/status/1800006993048170767 

Robots as psychological counselors: https://m.economictimes.com/news/international/uk/robots-as-psychological-counsellors-this-factory-in-china-is-making-it-a-reality/articleshow/110916481.cms 

Robots for manufacturing cars: https://www.msn.com/en-us/money/other/china-s-humanoid-robots-to-tackle-tricky-car-chores-at-dongfeng-motor/ar-BB1nAE9W?ocid=BingNewsSerp

Robots can paint: https://www.reddit.com/r/BeAmazed/comments/1drw1wr/meanwhile_robots_are_slowly_taking_jobs_away_from/

Robots [Automates] jobs from unions: https://phys.org/news/2024-06-robots-jobs-unions-decline-unionizations.html 

ARK Invest says robots are falling in cost as more are built, they are working faster than humans and Amazon are now adding more robots than human employees: https://x.com/tsarnick/status/1807929272491012440

Automated farm picking: https://www.reddit.com/r/robotics/comments/1dv19lg/hitbot_robot_farm_automated_picking/

Language action model can perform tasks: https://www.reddit.com/r/singularity/comments/1bfsysa/3d_visionlanguageaction_generative_world_model/
Meet Robbie - a bartender robot from Robbie Drink - Robot Barman! Robbie Drink is a Polish company offering a rental cell with a FANUC Europe robot that works as a reliable bartender at various events: https://x.com/WevolverApp/status/1810418899784966542
This food robotics company has developed an AI-enabled robotic system for food manipulation after working in stealth mode. The company has already served 20 million meals in production, with robots deployed in 6 cities across the US and Canada: https://x.com/emollick/status/1811893216658026999
World’s first mobile bricklayer robot that boosts construction speed enters US: https://interestingengineering.com/innovation/mobile-bricklayer-robot-hadrian-in-us

The machine has a unique optimisation software that converts wall sketches into block positions.
The world’s first bricklayer robot that’s capable of safely working outdoors in uncontrolled environments has arrived in the United States. Hadrian X can build the walls of a house in situ in as little as a day.
The Hadrian X doesn’t apply mortar between the bricks while placing them. Once the wall is completed, a strong construction adhesive is applied to bond the individual bricks in place, and the company claims that this is stronger than old-school mortar construction.” https://www.therobotreport.com/1st-hadrian-x-bricklaying-robot-arrives-in-us/#:~:text=FBR%20is%20developing%20an%20automated,structure%20of%20the%20robot%20arm.
Robot janitor in France: https://www.reddit.com/r/singularity/comments/1e3ptns/comment/ldbq0tp/?reply=t1_ldbq0tp
Robotic welding: https://www.fanucamerica.com/solutions/applications/welding-robots/arc-welding-robots
Introducing Surgical Robot Transformer (SRT): Automating surgical tasks with end-to-end imitation learning: https://x.com/jwbkim/status/1813263637429297381
https://x.com/TheHumanoidHub/status/1813465013241397596
⦿ Digit does 2 hour of work per 1 hour of charging. The next-gen will do 8-10 hours of work per 1 hour of charging. 
⦿ Lifting capacity will go from 30 lbs to 50 lbs. 
⦿ ROI goal for Digit is 2 years, based on $30/hour human labor.
Robot doing blue collar work: https://x.com/tsarnick/status/1816586061080068471
Autonomous AI workers that talk to each other will arrive in 2025, Capgemini predicts: https://www.cnbc.com/2024/07/22/ai-that-can-talk-with-other-ai-will-launch-in-2025-capgemini-predicts.html
Watch a robot peel a squash with human-like dexterity: https://www.newscientist.com/article/2440687-watch-a-robot-peel-a-squash-with-human-like-dexterity/
A robot can hold a squash, pumpkin or melon in one hand, while it is peeled by the other
‘Yell at your robot’ technique teaches robots household chores: https://www.newscientist.com/article/2425023-yell-at-your-robot-technique-teaches-robots-household-chores/
AI allows robots to listen to verbal instructions while learning to correctly perform household tasks. That could enable more natural interactions between humans and robots
Your robot has arrived - Robots could be performing more services for humans in the near future; food could be next: https://www.businessinsider.com/waymo-self-driving-taxis-chipotle-robots-future-of-service-2024-8
The new Astribot S1  has been unveiled by Chinese company Astribot, showcasing the bimanual wheeled robot performing many household tasks autonomously: https://x.com/TheHumanoidHub/status/1825342986957496598
Meet Galbot G1, the 1st-generation robot by Chinese startup Galbot, designed for generalizable, long-duration tasks: https://www.reddit.com/r/singularity/comments/1f2ilqg/meet_galbot_g1_the_1stgeneration_robot_by_chinese/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_button
Bernt Bornich, CEO of 1X: Specs of NEO are far ahead of anything else announced. NEO weighs just 30kg and can deadlift 70kg. It can move as fast as I can. It can jump, it can run, it can do all kinds of dynamic things. It's got the same degrees of freedom with full hands: https://www.reddit.com/r/singularity/comments/1f4893u/bernt_bornich_ceo_of_1x_specs_of_neo_are_far/
NEO from 1X emptying the dishwasher: https://www.reddit.com/r/singularity/comments/1f51swd/neo_from_1x_emptying_the_dishwasher/
Gravis Robotics has been working on autonomous excavators: https://www.reddit.com/r/singularity/comments/1f4zmup/gravis_robotics_has_been_working_on_autonomous/
Robots Are Coming to the Kitchen—What That Could Mean for Society and Culture: https://singularityhub.com/2024/09/03/robots-are-coming-to-the-kitchen-what-that-could-mean-for-society-and-culture/
Right now, robots are used to flip burgers, fry chicken, create pizzas, make sushi, prepare salads, serve ramen, bake bread, mix cocktails, and much more. AI can invent recipes based on the molecular compatibility of ingredients or whatever a kitchen has in stock. More advanced concepts are in the works to automate the entire kitchen for fine dining
Amazon has acquired a team to give robots greater intelligence and dexterity—potentially automating much more of its warehouse operations: https://www.wired.com/amazon-covariant-robotics-deal/
Amazon’s mobile robot army grew from around 10,000 in 2013 to 750,000 by 2023, and the sheer scale of the company’s operations meant that it could deliver millions of items faster and cheaper than anyone else
As WIRED revealed last year, Amazon has in recent years developed new robotic systems that rely on machine learning to do things like perceive, grab, and sort packed boxes. Again, Amazon is leveraging scale to its advantage, with the training data being gathered as items flow through its facilities helping to improve the performance of different algorithms. The effort has already led to further automation of the work that had previously been done by human workers at some fulfillment centers.
“SkillMimic" uses just 35 minutes of video and motion capture data of human demos to train simulated humanoids in basketball skills like dribbling, shooting, and layups through imitation learning: https://www.reddit.com/r/singularity/comments/1fcu8sk/skillmim
Window washing robot: https://www.fastcompany.com/91187456/ai-window-washing-robot-ozmo
IHMC and Boardwalk robotics show their humanoid robot, Nadia, being remotely controlled for boxing training with their advanced low latency VR teleoperation system: https://www.reddit.com/r/singularity/comments/1fm7fup/ihmc_and_boardwalk_robotics_show_their_humanoid/
Remote controlled robots managing shipping operations: https://www.reddit.com/r/singularity/comments/1ftgiay/longshoreman_have_gone_on_strike_demanding_a/?sort=confidence
Agility robotics is focusing on warehouse logistics. They'll be competing with wheeled bimanual robots that are highly efficient in pick-and-place tasks. One example is Reflex Robotics, a NY-based company that partnered with GXO to deploy robots in warehouses: https://www.reddit.com/r/singularity/comments/1fzzlmm/agility_robotics_is_focusing_on_warehouse/
Optimus Robot is able to act as a bartender, pour drinks and be friendly with customers and didn’t ask for a 25% tip on an iPad: https://www.reddit.com/r/ThatsInsane/comments/1g12skt/optimus_robot_is_able_to_act_as_a_bartender_pour/
Even if it’s tele operated, it can be outsourced to countries with cheap labor 
CooHOI is a framework that trains simulated humanoid robots to work as a team to move furniture. First, robots learn on their own, then they practice teamwork by sharing object movement info. It's faster and easier than past methods and works with different object sizes: https://www.reddit.com/r/singularity/comments/1g9p92s/coohoi_is_a_framework_that_trains_simulated/
Can replace even more jobs: https://www.reddit.com/r/ArtificialInteligence/comments/1ge553x/think_bluecollar_jobs_are_safe_from_ai_think_again/
Robot doing nails and eyelashes: https://x.com/esthercrawford/status/1850681223770947869
Figure 02 is now an autonomous fleet as of November 2024, 400% faster than August 2024 with 7x higher success rate: https://www.reddit.com/r/singularity/comments/1guy456/figure_02_is_now_an_autonomous_fleet_400_faster/
As Amazon expands use of warehouse robots, what will it mean for workers: https://apnews.com/article/amazon-robots-warehouse-automation-workers-6da0e5ed0273ed15ec43b38b007918df
Two robotic arms named Robin and Cardinal can lift packages that weigh up to 50 pounds. A third, called Sparrow, picks up items from bins and puts them in other containers.


Proteus, an autonomous mobile robot that operates on the floor, can move carts around a warehouse. The bipedal, humanoid robot Digit is being tested to help move empty totes with its hands. And there’s also Sequoia, a containerized storage system that can present totes to employees in a way that allows them to avoid stretching or squatting to grab inventory.


Amazon says Robin is currently being used in dozens of warehouses. The others are in a testing stage or haven’t been rolled out widely. But the company says it’s already seeing benefits, such as reducing the time it takes to fulfill orders and helping employees avoid repetitive tasks. However, automation also carries drawbacks for workers, who would have to be retrained for new positions if the robots made their roles obsolete?
Robots folding towels all night: https://cybernews.com/ai-news/watney-robots-fold-your-laundry/
They are tele-operated but can be used to record training data and are much cheaper than native workers
Garlic and Fei: There could be 648 million humanoids moving around us by 2050, from about zero today: https://finance.yahoo.com/news/teslas-elon-musk-may-not-be-the-only-one-cashing-in-on-humanoid-robots-133048663.html


6. AI Can Code

o1-preview is weaker than the full o1 model

O3 is tied for 175th place globally, 8th place in the USA: https://codeforces.com/ratings

Note: These are pass@1, which is the equivalent to writing the whole program without testing it and expecting it to run correctly on the first try

Note: These are pass@1, which is the equivalent to writing the whole program without testing it and expecting it to run correctly on the first try with no testing or corrections
[Alphacode 2 beat 85% of competitive programming participants in Codeforce competitions](https://techcrunch.com/2023/12/06/deepmind-unveils-alphacode-2-powered-by-gemini/)

Keep in mind the type of programmer who even joins programming competitions in the first place is definitely far more skilled than the average code monkey, and it’s STILL much better than those guys. 
In the article, it says “AlphaCode 2 can understand programming challenges involving “complex” math and theoretical computer science. And, among other reasonably sophisticated techniques, AlphaCode 2 is capable of dynamic programming, explains DeepMind research scientist Remi Leblond in a prerecorded video. Dynamic programming entails simplifying a complex problem by breaking it down into easier sub-problems over and over; Leblond says that AlphaCode 2 knows not only when to properly implement this strategy but where to use it. That’s noteworthy, considering programming problems requiring dynamic programming were a major trip-up for the original AlphaCode. “[AlphaCode 2] needs to show some level of understanding, some level of reasoning and designing of code solutions before it can get to the actual implementation to solve [a] coding problem,” Leblond said. “And it does all that on problems it’s never seen before.”
OpenAI o1 model released: https://openai.com/index/learning-to-reason-with-llms/
o1 improves over GPT-4o on a wide range of benchmarks, including 54/57 MMLU subcategories
OpenAI o1 ranks in the 89th percentile on competitive programming questions (Codeforces), places among the top 500 students in the US in a qualifier for the USA Math Olympiad (AIME), and exceeds human PhD-level accuracy on a benchmark of physics, biology, and chemistry problems (GPQA).
On the 2024 AIME exams, GPT-4o only solved on average 12% (1.8/15) of problems. o1 averaged 74% (11.1/15) with a single sample per problem, 83% (12.5/15) with consensus among 64 samples, and 93% (13.9/15) when re-ranking 1000 samples with a learned scoring function. A score of 13.9 places it among the top 500 students nationally and above the cutoff for the USA Mathematical Olympiad.
We trained a model that scored 213 points and ranked in the 49th percentile in the 2024 International Olympiad in Informatics (IOI), by initializing from o1 and training to further improve programming skills. This model competed in the 2024 IOI under the same conditions as the human contestants. It had ten hours to solve six challenging algorithmic problems and was allowed 50 submissions per problem.
With a relaxed submission constraint, we found that model performance improved significantly. When allowed 10,000 submissions per problem, the model achieved a score of 362.14 – above the gold medal threshold – even without any test-time selection strategy.  
Our evaluations closely matched competition rules and allowed for 10 submissions. GPT-4o achieved an Elo rating3 of 808, which is in the 11th percentile of human competitors. This model far exceeded both GPT-4o and o1—it achieved an Elo rating of 1807, performing better than 93% of competitors.
https://cdn.openai.com/o1-system-card.pdf
 We find that o1-preview is less prone to selecting stereotyped options than GPT-4o, and o1-mini has comparable performance to GPT-4o-mini. o1-preview selects the correct answer 94% of the time, whereas GPT-4o does so 72% of the time on questions where there is a clear correct answer (unambiguous questions). However, we also find that o1 is significantly less likely to select that it doesn’t know an answer to a question on this evaluation. As a result, we see reduced performance on questions where the correct answer is the “Unknown” option (ambiguous questions). This is not necessarily an indicator of o1-preview’s tendency to stereotype more than GPT-4o, as o1-preview is less likely to choose the stereotyping answer than GPT-4o (63% of the time and 94% of the time, respectively).









Code generated by o1 for this: https://codeforces.com/blog/entry/134091








NOTE: this graph does not include the full base o1 model


Nvidia CEO says don’t learn coding because of AI, tech giant exec says jobs will be hit: https://www.indiatoday.in/technology/features/story/nvidia-ceo-says-dont-learn-coding-because-ai-tech-giant-exec-says-jobs-will-be-hit-story-in-5-points-2509126-2024-03-01


Lying about this goes against his interest as discouraging coders would make them harder to find and more expensive to employ due to a lower supply. It would be a very stupid and short-sighted way of generating hype for the sake of hype when there are many other ways to do it that would not increase long-term costs for his company. 


DeepSeek-Coder-V2: First Open Source Model Beats GPT4-Turbo in Coding and Math: https://github.com/deepseek-ai/DeepSeek-Coder-V2/blob/main/paper.pdf
 
AI makes code refactoring much faster: https://www.reddit.com/r/singularity/comments/1dwgkav/code_editing_has_been_deprecated_i_now_program_by/



In a leaked recording, Amazon cloud chief tells employees that most developers could stop coding soon as AI takes over: https://www.businessinsider.com/aws-ceo-developers-stop-coding-ai-takes-over-2024-8

This isn’t marketing hype since the recording was not meant to be public.
Lying about this goes AGAINST the interests of the company since it encourages their own workers to consider leaving the industry 


ChatGPT o1 preview + mini Wrote NASA researcher’s PhD Code in 1 Hour*—What Took Me ~1 Year: https://www.reddit.com/r/singularity/comments/1fhi59o/chatgpt_o1_preview_mini_wrote_my_phd_code_in_1/


It completed it in 6 shots with no external feedback for some very complicated code from very obscure Python directories


Generative AI will Require 80% of Engineering Workforce to Upskill Through 2027" https://www.gartner.com/en/newsroom/press-releases/2024-10-03-gartner-says-generative-ai-will-require-80-percent-of-engineering-workforce-to-upskill-through-2027
Short Term:
AI tools will slightly increase productivity by helping with tasks.
Senior developers in well-run companies will benefit the most from these tools.

Medium Term:

AI agents will change how developers work by automating more tasks.
Most code will be made by AI, not humans.
Developers need to learn new skills like prompt engineering and RAG.
Long Term:
More skilled software engineers are needed because of the growing demand for AI-powered software.
A new type of engineer, called an AI engineer, who knows about software, data science, and AI/ML will be very important
ACM writer who has been in CS since the 1980s predicts AI will make programmers obsolete: https://cacm.acm.org/opinion/the-end-of-programming
New paper: Large Language Models Orchestrating Structured Reasoning Achieve Kaggle Grandmaster Level: https://huggingface.co/papers/2411.03562

We introduce Agent K v1.0, an end-to-end autonomous data science agent designed to automate, optimise, and generalise across diverse data science tasks. Fully automated, Agent K v1.0 manages the entire data science life cycle by learning from experience. It leverages a highly flexible structured reasoning framework to enable it to dynamically process memory in a nested structure, effectively learning from accumulated experience stored to handle complex reasoning tasks. It optimises long- and short-term memory by selectively storing and retrieving key information, guiding future decisions based on environmental rewards. This iterative approach allows it to refine decisions without fine-tuning or backpropagation, achieving continuous improvement through experiential learning. We evaluate our agent's capabilities using Kaggle competitions as a case study. Following a fully automated protocol, Agent K v1.0 systematically addresses complex and multimodal data science tasks, employing Bayesian optimisation for hyperparameter tuning and feature engineering. Our new evaluation framework rigorously assesses Agent K v1.0's end-to-end capabilities to generate and send submissions starting from a Kaggle competition URL. Results demonstrate that Agent K v1.0 achieves a 92.5\% success rate across tasks, spanning tabular, computer vision, NLP, and multimodal domains. When benchmarking against 5,856 human Kaggle competitors by calculating Elo-MMR scores for each, Agent K v1.0 ranks in the top 38\%, demonstrating an overall skill level comparable to Expert-level users. Notably, its Elo-MMR score falls between the first and third quartiles of scores achieved by human Grandmasters. Furthermore, our results indicate that Agent K v1.0 has reached a performance level equivalent to Kaggle Grandmaster, with a record of 6 gold, 3 silver, and 7 bronze medals, as defined by Kaggle's progression system.

6.1. Practical Use/Software Engineering
Direct link: https://docs.google.com/document/d/1oHuwssPPUTa4dwczX_s3qg3iPfWE4VK-R52LN51GwI8/edit?tab=t.0#heading=h.jy39d6h3mvgi


Big study of 187k developers using GitHub Copilot: AI transforms HOW we work. Coders can focus. They do more coding and less management. They need to coordinate less, working with fewer people. And they experiment more with new languages, which would increase earnings $1,683/year: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5007084

Sundar Pichai said on the earnings call today that more than 25% of all new code at Google is now generated by AI. He also said project astra will be ready for 2025: https://www.reddit.com/r/singularity/comments/1gf6elr/sundar_pichai_said_on_the_earnings_call_today/

Likely not lying as lying to investors is securities fraud. If he wanted to exaggerate, he would have said “a large percentage” instead of a specific and verifiable number.

LLM skeptic and 35 year software professional Internet of Bugs says ChatGPT-O1 Changes Programming as a Profession: “I really hated saying that” https://youtube.com/watch?v=j0yKLumIbaM

OpenAI’s o1 model can get perfect scores on their research engineer interview coding questions: https://assets.ctfassets.net/kftzwdyauwt9/67qJD51Aur3eIc96iOfeOP/71551c3d223cd97e591aa89567306912/o1_system_card.pdf



Randomized controlled trial using the older, less-powerful GPT-3.5 powered Github Copilot for 4,867 coders in Fortune 100 firms. It finds a 26.08% increase in completed tasks: https://x.com/emollick/status/1831739827773174218


AI Dominates Web Development: 63% of Developers Use AI Tools Like ChatGPT: https://flatlogic.com/starting-web-app-in-2024-research


NYT article on ChatGPT: https://archive.is/hy3Ae

“In a trial run by GitHub’s researchers, developers given an entry-level task and encouraged to use the program, called Copilot, completed their task 55 percent faster than those who did the assignment manually.”

What percent of code is now written by AI? "I ask all the software companies I meet about this. The number is rarely lower than 40%. For some young programmers it's 90%." - Paul Graham of Y Combinator on Twitter


Not as good as the Opus model they said is coming out later this year 
80% lower cost than Claude 3 Opus
2x speed over Claude 3 Opus
decent math and coding jump. 10% better on MATH 9% better on GPQA
Can convert research paper descriptions to code: https://x.com/VictorTaelin/status/1803816296410190286
Yves does NOT explain how to implement the system at all, he just defines it in mathematical terms. By all means, ICs aren't hard to implement, but understanding what the paper is saying without images is tough. The best models so far always outputted 100% bullshit code. I just tested again and Opus/GPT-4 outputs are always just gibberish. Sonnet 3.5 did surprisingly well
Claude 3.5 Sonnet is at the top of the Aider leaderboard at 77.4% correct: https://aider.chat/docs/leaderboards/ 


ChipNeMo-70B, outperforms the highly capable GPT-4 on two of our use cases, namely engineering assistant chatbot and EDA scripts generation, while exhibiting competitive performance on bug summarization and analysis. These results underscore the potential of domain-specific customization for enhancing the effectiveness of large language models in specialized applications: https://arxiv.org/pdf/2311.00176 

BP Earnings Call: We need 70% less coders from third parties to code as the AI handles most of the coding, the human only needs to look at the final 30% to validate it, that's a big savings for the company moving forward.

Source: https://seekingalpha.com/article/4690194-bp-p-l-c-bp-q1-2024-earnings-call-transcript 

This is almost certainly true because this is quoted from an earnings call from BP and lying to investors is a crime (securities fraud) and the reason for the Theranos scandal. This would include lying about the reason (in other words, it can’t just be layoffs). The numbers that are provided are also too specific to be exaggerations without also being a lie.


Multimodal terminal-based AI coding engine:  https://www.reddit.com/r/ChatGPTCoding/comments/1ddhv50/the_terminalbased_ai_coding_engine_i_built_is_now/ 

Can build a whole web app based on just a wireframe image 
Plandex is agent-based so it can keep chugging along automatically through multiple responses and files. Even if the app required like 20 files, Plandex would keep going until it finished them all. With ChatGPT you'd need to keep continually prompting it.

Dir-assistant: https://github.com/curvedinf/dir-assistant

>Chat with your current directory's files using a local or API LLM.
allows an LLM to be aware of a whole large repo. It can do all the research on a repository's code and write highly integrated additions with no user input
Uses CGRAG for large repos: https://medium.com/@djangoist/how-to-create-accurate-llm-responses-on-large-code-repositories-presenting-cgrag-a-new-feature-of-e77c0ffe432d

Microsoft AutoDev: https://arxiv.org/pdf/2403.08299

“We tested AutoDev on the HumanEval dataset, obtaining promising results with 91.5% and 87.8% of Pass@1 for code generation and test generation respectively, demonstrating its effectiveness in automating software engineering tasks while maintaining a secure and user-controlled development environment.”


AI-powered coding with cursor: https://www.reddit.com/r/singularity/comments/1f1wrq1/mckay_wrigley_shows_off_aipowered_coding_with/

Microsoft announces up to 1,500 layoffs, leaked memo blames 'AI wave' https://www.hrgrapevine.com/us/content/article/2024-06-04-microsoft-announces-up-to-1500-layoffs-leaked-memo-blames-ai-wave

This isn’t a PR move since the memo was not supposed to be publicized.

o1 is very good at refactoring: https://www.reddit.com/r/OpenAI/comments/1fqmkbm/o1_is_extremely_good_for_refactoring_complex_code/

Top comment: This thing is actually semi-capable of writing 6507 assembly code and macros for programming Atari 2600 games. It's kind of ridiculous. Not perfect at all, but WAY better than previous models. This kind of stuff is my ultimate "litmus test" for programming.
There can't be that much 6507 assembly out there, ergo it has to be translating, inferring and creating rather a lot to succeed. Then there's the impracticality of coding for such heavily limited hardware that has to bit-bang the display output!

OpenAI's Hunter Lightman says the new o1 AI model is already acting like a software engineer and authoring pull requests, and Noam Brown says everyone will know AGI has been achieved internally when they take down all their job listings: https://www.reddit.com/r/singularity/comments/1futg5p/openais_hunter_lightman_says_the_new_o1_ai_model/
OpenAI introduces Predicted Outputs in the API, speeding up tasks like code refactoring and editing docs 4-5x faster. Big deal for code editors like cursor and writing tools: https://x.com/OpenAIDevs/status/1853564730872607229

o1-pro analyzes code in a complicated codebase and finds out the key issues, all other models fail: https://x.com/SullyOmarr/status/1865467794801971464

I asked o1 pro to implement 6 things I had on my todo list for a project today: https://x.com/mckaywrigley/status/1868341756494053573
- It thought for 5m 25s.
- Modified 14 files.
- 64,852 input tokens.
- 14,740 output tokens.


Got it 100% correct - saved me 2 hours.
6.2. Research
ChipNeMo-70B, outperforms the highly capable GPT-4 on two of our use cases, namely engineering assistant chatbot and EDA scripts generation, while exhibiting competitive performance on bug summarization and analysis. These results underscore the potential of domain-specific customization for enhancing the effectiveness of large language models in specialized applications: https://arxiv.org/pdf/2311.00176 

Study that ChatGPT supposedly fails 52% of coding tasks: https://dl.acm.org/doi/pdf/10.1145/3613904.3642596 

“this work has used the free version of ChatGPT (GPT-3.5) for acquiring the ChatGPT responses for the manual analysis.”

“Thus, we chose to only consider the initial answer generated by ChatGPT.”

“To understand how differently GPT-4 performs compared to GPT-3.5, we conducted a small analysis on 21 randomly selected [StackOverflow] questions where GPT-3.5 gave incorrect answers. Our analysis shows that, among these 21 questions, GPT-4 could answer only 6 questions correctly, and 15 questions were still answered incorrectly.”

This is an extra 28.6% on top of the 48% that GPT 3.5 was correct on, totaling to ~77% for GPT 4 (equal to (517 times 0.48+517 times 6/21)/517) if we assume that GPT 4 correctly answers all of the questions that GPT 3.5 correctly answered, which is highly likely considering GPT 4 is far higher quality than GPT 3.5.

Note: This was all done in ONE SHOT with no repeat attempts or follow up.

Also, the study was released before GPT-4o and o1 and may not have used GPT-4-Turbo, both of which are significantly higher quality in coding capacity than GPT 4 according to the LMSYS arena


On top of that, both of those models are inferior to Claude 3.5 Sonnet: "In an internal agentic coding evaluation, Claude 3.5 Sonnet solved 64% of problems, outperforming Claude 3 Opus which solved 38%." Claude 3.5 Opus (which will be even better than Sonnet) is set to be released later this year.


New strategy to write code with LLMs: https://arxiv.org/html/2310.19791v4#Pt1 


While large language models (LLMs) now excel at code generation, a key aspect of software development is the art of refactoring: consolidating code into libraries of reusable and readable programs. In this paper, we introduce Lilo, a neurosymbolic framework that iteratively synthesizes, compresses, and documents code to build libraries tailored to particular problem domains. Lilo combines LLM-guided program synthesis with recent algorithmic advances in automated refactoring from Stitch: a symbolic compression system that efficiently identifies optimal 𝜆-abstractions across large code corpora. To make these abstractions interpretable, we introduce an auto-documentation (AutoDoc) procedure that infers natural language names and docstrings based on contextual examples of usage. In addition to improving human readability, we find that AutoDoc boosts performance by helping Lilo’s synthesizer to interpret and deploy learned abstractions. We evaluate Lilo on three inductive program synthesis benchmarks for string editing, scene reasoning, and graphics composition. Compared to existing methods—including the state-of-the-art libraries learning algorithm DreamCoder—Lilo solves more complex tasks and learns richer libraries that are grounded in linguistic knowledge.




Diffusion models for code generation that learn to directly *edit* syntax trees of programs. The result is a system that can incrementally write code, see the execution output, and debug it: https://x.com/shreyaskapur/status/1797726079995826629 


https://arxiv.org/pdf/2406.09308 
Such NARs proved effective as generic solvers for algorithmic tasks, when specified in graph form. To make their embeddings accessible to a Transformer, we propose a hybrid architecture with a two- phase training procedure, allowing the tokens in the lan- guage model to cross-attend to the node embeddings from the NAR. We evaluate our resulting TransNAR model on CLRS-Text, the text-based version of the CLRS-30 bench- mark, and demonstrate significant gains over Transformer- only models for algorithmic reasoning, both in and out of distribution.

https://arxiv.org/pdf/2405.15568
OMNI-EPIC leverages foundation models to autonomously generate code specifying the next learnable (i.e., not too easy or difficult for the agent’s current skill set) and interesting (e.g., worthwhile and novel) tasks. OMNI-EPIC generates both environments (e.g., an obstacle course) and reward functions (e.g., progress through the obstacle course quickly without touching red objects), enabling it, in principle, to create any simu- latable learning task. We showcase the explosive creativity of OMNI-EPIC, which continuously innovates to suggest new, interesting learning challenges. We also highlight how OMNI-EPIC can adapt to reinforcement learning agents’ learning progress, generating tasks that are of suitable difficulty. Overall, OMNI-EPIC can endlessly create learnable and interesting environments, further propelling the development of self-improving AI systems and AI-Generating Algorithms. Project website with videos: https://dub.sh/omniepic.

6.3. Feats
Takeaways re: AI R&D performance: https://x.com/eli_lifland/status/1860087262849171797
1. Claude 3.5 Sonnet reaches ~50th percentile human baseline 8-hour performance.
2. Sonnet Old-> New is a 0.2 jump in 4 months. We're 0.6 away from 90th percentile baselines.
Link to study: https://metr.org/blog/2024-11-22-evaluating-r-d-capabilities-of-llms/

Keep in mind researchers are already in the top 1% of intelligence and technical ability




I got an LLM to write frontend and backend code for a graph visualizer, fix its own bug and literally deploy it to the public web with google cloud. This would take most devs 2 days. It took AI ~20mins: https://x.com/deedydas/status/1850024012677775829

[GPT4o creates Flappy Bird in a single simple prompt](https://x.com/minchoi/status/1787836907566531056)

[Claude 3 builds a great website](https://www.reddit.com/r/OpenAI/comments/1bm305k/what_the_hell_claud_3_opus_is_a_straight/?darkschemeovr=1)



Claude 3 Creates a Multi-Player Application with a Single Prompt: https://www.reddit.com/r/singularity/comments/1b8f5q3/claude_3_creates_a_multiplayer_application_with_a/



Claude 3 is great at programming: https://www.reddit.com/r/singularity/comments/1coszok/comment/l3h0s1v/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_button

GPT 4o recreates Facebook messenger in a single prompt: https://youtu.be/GPNq0WiXa50?feature=shared&t=927


GPT-4o is the best LLM for coding and solves 73% of Aider’s code editing benchmark: https://aider.chat/docs/leaderboards/


Claude 3.5 creates Nintendo style retro game: https://www.reddit.com/r/singularity/comments/1dkp6uf/claude_35_can_generate_early_nintendo_style_games/


Claude 3.5's sonnet created a fully working checkers game in the chat interface. It even had AI to play against: https://www.reddit.com/r/ChatGPT/comments/1dmlgrm/claude_35s_sonnet_created_a_fully_working/

Claude made me a 3D first-person shooter touchscreen game right in the chat interface. In the game, you shoot happy emojis at sad monsters to make them happy: https://www.reddit.com/r/ChatGPT/comments/1dmejz5/claude_made_me_a_3d_firstperson_shooter/

Claude created a fractal explorer for me in which I can display and zoom 4 different fractals: https://www.reddit.com/r/singularity/comments/1dn85qz/claude_created_a_fractal_explorer_for_me_in_which/

Claude creates a complex 3D solar system animation based on a text prompt in under a minute: https://x.com/slow_developer/status/1813839430043725900

The "Gremlin" model on lmarena.ai (rumoured to be Google) is really good at coding. These games are all coded by Gremlin. I only had to fix a few lines of code to make the games fully playable: https://www.reddit.com/r/singularity/comments/1h4l1i5/the_gremlin_model_on_lmarenaai_rumoured_to_be/
gemini-exp-1201 made this entire game from a single prompt (zero edits): https://www.reddit.com/r/singularity/comments/1h8epuf/mind_blowing_geminiexp1201_made_this_entire_game/
O1-pro clones Coinbase UI in one shot while all other models are not as good: https://x.com/mckaywrigley/status/1865089975802646857

o1 pro mode easily coded 25 games with bots playing them in 5 minutes, possibly allowing infinite video game agents training data: https://www.reddit.com/r/singularity/comments/1h9ht48/o1_pro_mode_easily_coded_25_games_with_bots/

Solar system simulation: https://www.reddit.com/r/ChatGPT/comments/1fh5pqa/solar_system_htmljava_browser_animation_made/
7. AI Is Not Low Effort
Incredible use of Stable Diffusion: https://www.reddit.com/r/StableDiffusion/s/f46LKOMj7q
Using Midjourney is more than simple prompting: https://x.com/nickfloats/status/1812977740783755581
From this: 
To this: 
AI art is very similar to photography. Both can be as simple as clicking a button or be much more complex. For example, creating with Stable Diffusion can involve using ControlNet, IPAdapter, LowRa, IC-Light, animation extensions, very complicated ComfyUI workflows, and much more to get the result you want. Additionally, both involve a machine doing most of the actual creation process, where the camera/AI creates the images, while the artist guides it on what the end result should be and completes post-processing work. 
Examples of complex ComfyUI workflows: https://civitai.com/models/33192/comfyui-impact-pack	
Many more examples: https://openart.ai/workflows/all
https://openart.ai/workflows/datou/manga-cosplay/SgsFFSuOeFe7Qzs3eHij 
pose changes based on video feed: https://x.com/Mr_AllenT/status/1796890250695803187 
Art is not about effort anyway, Duchamp’s fountain took very little effort but is widely considered to be pivotal in art.
Weird thing about using LLMs that it is very bad at a lot of things (including word games) but that you can actually often get it to do those things if you ask it the right away, usually by giving clearer instructions or asking AI to think step by step: https://x.com/emollick/status/1795604532187263198 

AI image won Colorado state fair https://www.cnn.com/2022/09/03/tech/ai-art-fair-winner-controversy/index.html

>You can feed a phrase like “an oil painting of an angry strawberry” to Midjourney and receive several images from the AI system within seconds, but Allen’s process wasn’t that simple. To get the final three images he entered in the competition, he said, took more than 80 hours.
First, he said, he played around with phrasing that led Midjourney to generate images of women in frilly dresses and space helmets — he was trying to mash up Victorian-style costuming with space themes, he said. Over time, with many slight tweaks to his written prompt (such as to adjust lighting and color harmony), he created 900 iterations of what led to his final three images. He cleaned up those three images in Photoshop, such as by giving one of the female figures in his winning image a head with wavy, dark hair afterMidjourney had rendered her headless. Then he ran the images through another software program called Gigapixel AI that can improve resolution and had the images printed on canvas at a local print shop.

>Cal Duran, an artist and art teacher who was one of the judges for competition, said that while Allen’s piece included a mention of Midjourney, he didn’t realize that it was generated by AI when judging it. Still, he sticks by his decision to award it first place in its category, he said, calling it a “beautiful piece”.

>“I think there’s a lot involved in this piece and I think the AI technology may give more opportunities to people who may not find themselves artists in the conventional way,” he said.
https://www.reddit.com/r/NeuroSama/comments/1hhvh92/zero_day/

Many small details in text on screen
“I started on Sunday and then worked on this image every evening, after 9 hours of my actual job, until this day” - https://www.reddit.com/r/NeuroSama/comments/1hhvh92/comment/m2u8os1/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button

8. AI Is Reliable/Addressing Hallucinations
Direct link: https://docs.google.com/document/d/1oHuwssPPUTa4dwczX_s3qg3iPfWE4VK-R52LN51GwI8/edit?tab=t.0#heading=h.mx360pwg02ix

Source: https://ourworldindata.org/artificial-intelligence

Full o1 model released: https://cdn.openai.com/o1-system-card-20241205.pdf







A 10 page paper caused a panic because of a math error. O1 could spot the error by just prompting: “carefully check the math in this paper” even when the info is not in training data: https://x.com/emollick/status/1868329599438037491
This was o1, not pro. I just pasted in the article with the literal prompt above.
Claude did not spot the error when given the PDF until it was told to look just at the reference value.
OpenAI o1 model released: https://openai.com/index/learning-to-reason-with-llms/
o1 improves over GPT-4o on a wide range of benchmarks, including 54/57 MMLU subcategories
OpenAI o1 ranks in the 89th percentile on competitive programming questions (Codeforces), places among the top 500 students in the US in a qualifier for the USA Math Olympiad (AIME), and exceeds human PhD-level accuracy on a benchmark of physics, biology, and chemistry problems (GPQA).
On the 2024 AIME exams, GPT-4o only solved on average 12% (1.8/15) of problems. o1 averaged 74% (11.1/15) with a single sample per problem, 83% (12.5/15) with consensus among 64 samples, and 93% (13.9/15) when re-ranking 1000 samples with a learned scoring function. A score of 13.9 places it among the top 500 students nationally and above the cutoff for the USA Mathematical Olympiad.



We trained a model that scored 213 points and ranked in the 49th percentile in the 2024 International Olympiad in Informatics (IOI), by initializing from o1 and training to further improve programming skills. This model competed in the 2024 IOI under the same conditions as the human contestants. It had ten hours to solve six challenging algorithmic problems and was allowed 50 submissions per problem.
With a relaxed submission constraint, we found that model performance improved significantly. When allowed 10,000 submissions per problem, the model achieved a score of 362.14 – above the gold medal threshold – even without any test-time selection strategy.  
Our evaluations closely matched competition rules and allowed for 10 submissions. GPT-4o achieved an Elo rating3 of 808, which is in the 11th percentile of human competitors. This model far exceeded both GPT-4o and o1—it achieved an Elo rating of 1807, performing better than 93% of competitors.
https://cdn.openai.com/o1-system-card.pdf
 We find that o1-preview is less prone to selecting stereotyped options than GPT-4o, and o1-mini has comparable performance to GPT-4o-mini. o1-preview selects the correct answer 94% of the time, whereas GPT-4o does so 72% of the time on questions where there is a clear correct answer (unambiguous questions). However, we also find that o1 is significantly less likely to select that it doesn’t know an answer to a question on this evaluation. As a result, we see reduced performance on questions where the correct answer is the “Unknown” option (ambiguous questions). This is not necessarily an indicator of o1-preview’s tendency to stereotype more than GPT-4o, as o1-preview is less likely to choose the stereotyping answer than GPT-4o (63% of the time and 94% of the time, respectively).









Note: This is the weakest model compared to o1-preview and the full o1 model
OpenAI’s o1 model can get perfect scores on their research engineer interview coding questions:



Code generated by o1 for this: https://codeforces.com/blog/entry/134091









Reproducible outputs: https://platform.openai.com/docs/advanced-usage/reproducible-outputs

in the middle of a response, Claude suddenly notices it might be hallucinating


Mistral Large 2 released: https://mistral.ai/news/mistral-large-2407/

“Additionally, the new Mistral Large 2 is trained to acknowledge when it cannot find solutions or does not have sufficient information to provide a confident answer. This commitment to accuracy is reflected in the improved model performance on popular mathematical benchmarks, demonstrating its enhanced reasoning and problem-solving skills”



Effective strategy to make an LLM express doubt and admit when it does not know something: https://github.com/GAIR-NLP/alignment-for-honesty 




Researchers describe how to tell if ChatGPT is confabulating: https://arstechnica.com/ai/2024/06/researchers-describe-how-to-tell-if-chatgpt-is-confabulating/


Two things became apparent during these tests. One is that, except for a few edge cases, semantic entropy caught more false answers than any other methods. The second is that most errors produced by LLMs appear to be confabulations. That can be inferred from the fact that some of the other methods catch a variety of error types, yet they were outperformed by semantic entropy tests, even though these tests only catch confabulations.
The researchers also demonstrate that the system can be adapted to work with more than basic factual statements by altering to handle biographies, which are a large collection of individual facts. So they developed software that broke down biographical information into a set of individual factual statements and evaluated each of these using semantic entropy. This worked on a short biography with as many as 150 individual factual claims.
Overall, this seems to be a highly flexible system that doesn't require major new developments to put into practice and could provide some significant improvements in LLM performance. And, since it only catches confabulations and not other types of errors, it might be possible to combine it with other methods to boost performance even further.
As the researchers note, the work also implies that, buried in the statistics of answer options, LLMs seem to have all the information needed to know when they've got the right answer; it's just not being leveraged. As they put it, "The success of semantic entropy at detecting errors suggests that LLMs are even better at 'knowing what they don’t know' than was argued... they just don’t know they know what they don’t know."


Baidu unveiled an end-to-end self-reasoning framework to improve the reliability and traceability of RAG systems. 13B models achieve similar accuracy with this method(while using only 2K training samples) as GPT-4: https://venturebeat.com/ai/baidu-self-reasoning-ai-the-end-of-hallucinating-language-models/

Prover-Verifier Games improve legibility of language model outputs: https://openai.com/index/prover-verifier-games-improve-legibility/

We trained strong language models to produce text that is easy for weak language models to verify and found that this training also made the text easier for humans to evaluate.


Q*: Improving Multi-step Reasoning for LLMs with Deliberative Planning: https://arxiv.org/abs/2406.14283

In this paper, we aim to alleviate the pathology by introducing Q*, a general, versatile and agile framework for guiding LLMs decoding process with deliberative planning. By learning a plug-and-play Q-value model as heuristic function, our Q* can effectively guide LLMs to select the most promising next step without fine-tuning LLMs for each task, which avoids the significant computational overhead and potential risk of performance degeneration on other tasks. Extensive experiments on GSM8K, MATH and MBPP confirm the superiority of our method.


Over 32 techniques to reduce hallucinations:
https://arxiv.org/abs/2401.0131

REDUCING LLM HALLUCINATIONS USING EPISTEMIC NEURAL NETWORKS: https://arxiv.org/pdf/2312.15576




Reducing hallucination in structured outputs via Retrieval-Augmented Generation:  https://arxiv.org/abs/2404.08189


Kaleido Diffusion: Improving Conditional Diffusion Models with Autoregressive Latent Modeling: https://huggingface.co/papers/2405.21048
  
Show, Don’t Tell: Aligning Language Models with Demonstrated Feedback: https://arxiv.org/abs/2406.00888


>Significantly outperforms few-shot prompting, SFT and other self-play methods by an average of 19% using demonstrations as feedback directly with <10 examples


Mostly secure and aligned LLM: https://x.com/andyzou_jiaming/status/1799232319250743561


Safe LLM: https://x.com/youliang_yuan/status/1812665889852121332

Another paper of refusals: https://huggingface.co/papers/2407.12043 

August 6 GPT 4o update:
The new GPT-4o is slightly better and 33% cheaper than the old one!  Right now, it's only a tad below Sonnet 3.5 on Livebench!




Not as good as the Opus model they said is coming out later this year 
80% lower cost than Claude 3 Opus
2x speed over Claude 3 Opus
decent math and coding jump. 10% better on MATH 9% better on GPQA
Can convert research paper descriptions to code: https://x.com/VictorTaelin/status/1803816296410190286


Even GPT3 (which is VERY out of date) knew when something was incorrect. All you had to do was tell it to call you out on it: https://twitter.com/nickcammarata/status/1284050958977130497



LLMs know their limitations and choose to hallucinate to respond to the prompt. This is why allowing it to say “I don’t know” is important: https://cdn.openai.com/o1-system-card.pdf

Golden Gate Claude (LLM that is forced to hyperfocus on details about the Golden Gate Bridge in California) recognizes that what it’s saying is incorrect: https://x.com/ElytraMithra/status/1793916830987550772



 
More proof: https://x.com/blixt/status/1284804985579016193

Robust agents learn causal world models: https://arxiv.org/abs/2402.10877

CONCLUSION: Causal reasoning is foundational to human intelligence, and has been conjectured to be necessary for achieving human level AI (Pearl, 2019). In recent years, this conjecture has been challenged by the development of artificial agents capable of generalising to new tasks and domains without explicitly learning or reasoning on causal models. And while the necessity of causal models for solving causal inference tasks has been established (Bareinboim et al., 2022), their role in decision tasks such as classification and reinforcement learning is less clear. We have resolved this conjecture in a model-independent way, showing that any agent capable of robustly solving a decision task must have learned a causal model of the data generating process, regardless of how the agent is trained or the details of its architecture. This hints at an even deeper connection between causality and general intelligence, as this causal model can be used to find policies that optimise any given objective function over the environment variables. By establishing a formal connection between causality and generalisation, our results show that causal world models are a necessary ingredient for robust and general AI.

TLDR: a model that can reliably answer decision based questions correctly must have learned a cause and effect that led to the result. 

We introduce BSDETECTOR, a method for detecting bad and speculative answers from a pretrained Large Language Model by estimating a numeric confidence score for any output it generated. Our uncertainty quantification technique works for any LLM accessible only via a black-box API, whose training data remains unknown. By expending a bit of extra computation, users of any LLM API can now get the same response as they would ordinarily, as well as a confidence estimate that cautions when not to trust this response. Experiments on both closed and open-form Question-Answer benchmarks reveal that BSDETECTOR more accurately identifies incorrect LLM responses than alternative uncertainty estimation procedures (for both GPT-3 and ChatGPT). By sampling multiple responses from the LLM and considering the one with the highest confidence score, we can additionally obtain more accurate responses from the same LLM, without any extra training steps. In applications involving automated evaluation with LLMs, accounting for our confidence scores leads to more reliable evaluation in both human-in-the-loop and fully-automated settings (across both GPT 3.5 and 4).

https://openreview.net/pdf?id=QTImFg6MHU 



[LLMs have an internal world model ](https://arxiv.org/pdf/2403.15498.pdf)

More proof: https://arxiv.org/abs/2210.13382 

Golden Gate Claude (LLM that is only aware of details about the Golden Gate Bridge in California) recognizes that what it’s saying is incorrect: https://x.com/ElytraMithra/status/1793916830987550772 

Even more proof by Max Tegmark (renowned MIT professor): https://arxiv.org/abs/2310.02207 

“Godfather of AI” and Turing Award winner Geoffrey Hinton: A neural net given training data where half the examples are incorrect still had an error rate of <=25% rather than 50% because it understands the rules and does better despite the false information: https://youtu.be/n4IQOBka8bc?si=wM423YLd-48YC-eY (14:00 timestamp)

Klarna SUCCESSFULLY replaces call centers with AI https://www.reddit.com/r/klarna/comments/1c1fwr3/klarna_ceo_on_using_ai_to_replace_700_workers/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_button
Klarnas AI assistant, powered by @OpenAI , has in its first 4 weeks handled 2.3 million customer service chats and the data and insights are staggering:

Handles 2/3 rd of our customer service enquires

On par with humans on customer satisfaction

Higher accuracy leading to a 25% reduction in repeat inquiries

customer resolves their errands in 2 min vs 11 min

 Live 24/7 in over 23 markets, communicating in over 35 languages

It performs the equivalent job of 700 full time agents

‘I will never go back’: Ontario family doctor says new AI notetaking saved her job: https://globalnews.ca/news/10463535/ontario-family-doctor-artificial-intelligence-notes 
“If the physician is unhappy with the note, Lall said, they can ask the AI model to regenerate the information or add more detail to any one of the categories. While the tool has some imperfections, she said, the improvements have been noticeable over the 10 months since she began using it.“I really feel this should be the next gold standard for all of our doctors. It decreases the cognitive load you feel at the end of the day,” she said.The Ford government has been so impressed with the technology that it announced a pilot program to allow 150 family physicians to use AI Scribe as part of their practices. The health minister said the early signs were promising but stressed government would proceed carefully.”
Great thread on medical research uses of generative AI: https://x.com/Sandbar101/status/1784620540092731827
AI beats humans at basic tasks: https://www.nature.com/articles/d41586-024-01087-4
[It passed several exams, including the SAT, bar exam, and multiple AP tests](https://www.businessinsider.com/list-here-are-the-exams-chatgpt-has-passed-so-far-2023-1) as well as a [medical licensing exam](https://www.medscape.com/viewarticle/987549?form=fpf) and [beat many doctors](https://www.businessinsider.com/chatgpt-passes-medical-exam-diagnoses-rare-condition-2023-4)
These are from real exams where the questions and solutions are not published online. 
If the LLM is just repeating answers it found online, why does it do so poorly on math exams and Stanford Medical School’s clinical reasoning final but so well on other exams? 

ChipNeMo-70B, outperforms the highly capable GPT-4 on two of our use cases, namely engineering assistant chatbot and EDA scripts generation, while exhibiting competitive performance on bug summarization and analysis. These results underscore the potential of domain-specific customization for enhancing the effectiveness of large language models in specialized applications: https://arxiv.org/pdf/2311.00176

Study that ChatGPT fails 52% of coding tasks 

“this work has used the free version of ChatGPT (GPT-3.5) for acquiring the ChatGPT responses for the manual analysis.”
“Thus, we chose to only consider the initial answer generated by ChatGPT.”
“To understand how differently GPT-4 performs compared to GPT-3.5, we conducted a small analysis on 21 randomly selected SO questions where GPT-3.5 gave incorrect answers. Our analysis shows that, among these 21 questions, GPT-4 could answer only 6 questions correctly, and 15 questions were still answered incorrectly.”
This is an extra 28.6% on top of the 48% that GPT 3.5 was correct on, totaling to ~77% for GPT 4 (equal to (517*0.48+517*6/21)/517) if we assume that GPT 4 correctly answers all of the questions that GPT 3.5 correctly answered, which is highly likely considering GPT 4 is far higher quality than GPT 3.5.
Note: This was all done in ONE SHOT with no repeat attempts.
Study was released before GPT-4o and did not use GPT 4 Turbo, both of which are significantly higher quality than GPT 4 according to the LMSYS arena. Now, this has also been surpassed by Claude Sonnet 3.5 with Opus 3.5 coming later this year and OpenAI’s GPT-4o and o1 models. 

Microsoft AutoDev: https://arxiv.org/pdf/2403.08299

“We tested AutoDev on the HumanEval dataset, obtaining promising results with 91.5% and 87.8% of Pass@1 for code generation and test generation respectively, demonstrating its effectiveness in automating software engineering tasks while maintaining a secure and user-controlled development environment.”

NYT article on ChatGPT: https://archive.is/hy3Ae

“In a trial run by GitHub’s researchers, developers given an entry-level task and encouraged to use the program, called Copilot, completed their task 55 percent faster than those who did the assignment manually.”


https://arxiv.org/html/2404.03683v1
Language models are rarely shown fruitful mistakes while training. They then struggle to look beyond the next token, suffering from a snowballing of errors and struggling to predict the consequence of their actions several steps ahead. In this paper, we show how language models can be taught to search by representing the process of search in language, as a flattened string — a stream of search (SoS). We propose a unified language for search that captures an array of different symbolic search strategies. We demonstrate our approach using the simple yet difficult game of Countdown, where the goal is to combine input numbers with arithmetic operations to reach a target number. We pretrain a transformer-based language model from scratch on a dataset of streams of search generated by heuristic solvers. We find that SoS pretraining increases search accuracy by 25% over models trained to predict only the optimal search trajectory. We further finetune this model with two policy improvement methods: Advantage-Induced Policy Alignment (APA) and Self-Taught Reasoner (STaR). The finetuned SoS models solve 36% of previously unsolved problems, including problems that cannot be solved by any of the heuristic solvers. Our results indicate that language models can learn to solve problems via search, self-improve to flexibly use different search strategies, and potentially discover new ones. 

LLMs can correct their own mistakes: https://arxiv.org/abs/2406.01297 

AI doing sales calls very well: https://www.reddit.com/r/Futurology/comments/1ceeq17/comment/l1k8b7f/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_button


[AI beats humans on all performance indicators](https://newatlas.com/technology/ai-index-report-global-impact/)



ChatGPT outperforms psychologists: https://www.psypost.org/chatgpt-4-outperforms-human-psychologists-in-test-of-social-intelligence-study-finds/

China’s ‘AI Ship Designer’ Works At Unprecedented Speed; Performed A Year’s Work Only In 24 Hours!: https://www.eurasiantimes.com/chinas-ai-ship-designer-works-at-unprecedented-speed-performed

The military wants ‘robot ships’ to replace sailors in battle: https://www.realcleardefense.com/2022/04/15/the_military_wants_robot_ships_to_replace_sailors_in_battle_827353.html
CriticGPT is intended to help identify hallucinations as models grow more sophisticated: https://spectrum.ieee.org/openai-rlhf 



https://x.com/janleike/status/1806386442568142995
AI can beat university students, study suggests: https://www.bbc.com/news/articles/cqqqln0eg65o

MetaSumPerceiver: Multimodal Multi-Document Evidence Summarization for Fact-Checking: https://arxiv.org/abs/2407.13089
- The paper presents MetaSumPerceiver (MSP), a novel summarization model for generating claim-specific summaries from multimodal, multi-document datasets to assist with fact-checking. 


- MSP uses a dynamic perceiver-based model to handle multimodal inputs of arbitrary lengths, including documents, images, and claims.


- To train MSP, reinforcement learning with an entailment model as a reward signal is employed to refine summaries to provide relevant evidence for fact-checking.


- MSP incorporates a proxy reward mechanism with PPO to continually update the summarizer during fact-checking.


- The paper introduces the Multi-News-Fact-Checking dataset with over 100k labeled claims derived from Multi-News using Llama prompts.


- Experiments on MOCHEG and the new dataset show MSP substantially outperforms prior baselines, achieving state-of-the-art performance.


- The key innovation is using RL to optimize summarization specifically for claim verification versus generic summarization.

Taco Bell to roll out AI drive-thru ordering in hundreds of locations by end of year: https://www.nbcnews.com/business/business-news/taco-bell-roll-ai-drive-thru-ordering-hundreds-locations-end-year-rcna164524
Yum Brands said the tech has improved order accuracy, reduced wait times, decreased employees’ task load and fueled profitable growth.
GPT-4 gets the classic riddle of “which order should I carry the chickens or the fox over a river” correct EVEN WITH A MAJOR CHANGE if you replace the fox with a "zergling" and the chickens with "robots".
Proof: https://chatgpt.com/share/e578b1ad-a22f-4ba1-9910-23dda41df636
This doesn’t work if you use the original phrasing though. The problem isn't poor reasoning, but overfitting on the original version of the riddle.
Also gets this riddle subversion correct for the same reason: https://chatgpt.com/share/44364bfa-766f-4e77-81e5-e3e23bf6bc92

LongCite: Enabling LLMs to Generate Fine-grained Citations in Long-context QA: https://huggingface.co/papers/2409.02897
Stanford researchers: “Automating AI research is exciting! But can LLMs actually produce novel, expert-level research ideas? After a year-long study, we obtained the first statistically significant conclusion: LLM-generated ideas are more novel than ideas written by expert human researchers." https://x.com/ChengleiSi/status/1833166031134806330

>Coming from 36 different institutions, our participants are mostly PhDs and postdocs. As a proxy metric, our idea writers have a median citation count of 125, and our reviewers have 327.

>We also used an LLM to standardize the writing styles of human and LLM ideas to avoid potential confounders, while preserving the original content.


We've created a demo of an AI that can predict the future at a superhuman level (on par with groups of human forecasters working together): https://x.com/DanHendrycks/status/1833152719756116154
Our bot performs better than experienced human forecasters and performs roughly the same as (and sometimes even better than) crowds of experienced forecasters
Our bot and other forecasting bots can be used in a wide variety of contexts. For example, these AIs could help policymakers minimize bias in their decision-making or help improve the information ecosystem by providing trustworthy, calibrated forecasts.
On the 177 events, the Metaculus crowd got 87.0% accuracy, while FiveThirtyNine got 87.7% ± 1.4. A link to the technical report is here. This bot lacks many of the drawbacks of prediction markets. It makes forecasts within seconds. Additionally, groups of humans do not need to be incentivized with cash prizes to make and continually update their predictions. Forecasting AIs are several orders of magnitude faster and cheaper than prediction markets, and they’re similarly accurate.
The bot is not fine-tuned, and doing so could potentially make it far more accurate. It simply retrieves articles and writes a report as guided through an engineered prompt. (Its prompt can be found by clicking on the gear icon in forecast.safe.ai.) Moreover, probabilities from AIs are also known to lead to automation bias, and improvements in the interface could ameliorate this.
Researcher solves overfitting riddle issue: https://www.academia.edu/123745078/Mind_over_Data_Elevating_LLMs_from_Memorization_to_Cognition
Introducing PaperQA2, the first AI agent that conducts entire scientific literature reviews on its own: https://x.com/SGRodriques/status/1833908643856818443
PaperQA2 is also the first agent to beat PhD and Postdoc-level biology researchers on multiple literature research tasks, as measured both by accuracy on objective benchmarks and assessments by human experts. We are publishing a paper and open-sourcing the code.


This is the first example of AI agents exceeding human performance on a major portion of scientific research, and will be a game-changer for the way humans interact with the scientific literature. 
PaperQA2 finds and summarizes relevant literature, refines its search parameters based on what it finds, and provides cited, factually grounded answers that are more accurate on average than answers provided by PhD and postdoc-level biologists. When applied to answer highly specific questions, like this one, it obtains SOTA performance on LitQA2, part of LAB-Bench focused on information retrieval
PaperQA2 can also do broad-based literature reviews. WikiCrow, which is an agent based on PaperQA2, writes Wikipedia-style articles that are significantly more accurate on average than actual human-written articles on Wikipedia, as judged by PhD and postdoc-level biologists. 
ChatGPT o1-preview solves unique, PhD-level assignment questions not found on the internet in mere seconds: https://m.youtube.com/watch?v=a8QvnIAGjPA
Differential transformer: https://arxiv.org/abs/2410.05258
Transformer tends to overallocate attention to irrelevant context. In this work, we introduce Diff Transformer, which amplifies attention to the relevant context while canceling noise. Specifically, the differential attention mechanism calculates attention scores as the difference between two separate softmax attention maps. The subtraction cancels noise, promoting the emergence of sparse attention patterns. Experimental results on language modeling show that Diff Transformer outperforms Transformer in various settings of scaling up model size and training tokens. More intriguingly, it offers notable advantages in practical applications, such as long-context modeling, key information retrieval, hallucination mitigation, in-context learning, and reduction of activation outliers. By being less distracted by irrelevant context, Diff Transformer can mitigate hallucination in question answering and text summarization. For in-context learning, Diff Transformer not only enhances accuracy but is also more robust to order permutation, which was considered as a chronic robustness issue. The results position Diff Transformer as a highly effective and promising architecture to advance large language models.


Rewarding Progress: Scaling Automated Process Verifiers for LLM Reasoning: https://arxiv.org/abs/2410.08146
We validate our claims by training process advantage verifiers (PAVs) to predict progress under such provers, and show that compared to ORMs, test-time search against PAVs is >8% more accurate, and 1.5−5× more compute-efficient. Online RL with dense rewards from PAVs enables one of the first results with 5−6× gain in sample efficiency, and >6% gain in accuracy, over ORMs.
Sundar Pichai said on the earnings call today that more than 25% of all new code at Google is now generated by AI. He also said project astra will be ready for 2025: https://www.reddit.com/r/singularity/comments/1gf6elr/sundar_pichai_said_on_the_earnings_call_today/

Likely not lying as lying to investors is securities fraud. If he wanted to exaggerate, he would have said “a large percentage” instead of a specific and verifiable number.
https://openai.com/index/introducing-simpleqa/
High confidence score correlates with higher accurracy and vice versa


Not attempted = refusal to answer
O1 knows its own limits: 
ChatGPT caught itself mid error
afety-regulation?lang=en
GenCast predicts weather and the risks of extreme conditions with state-of-the-art accuracy: https://deepmind.google/discover/blog/gencast-predicts-weather-and-the-risks-of-extreme-conditions-with-sota-accuracy/


Experts score an average of 81.3% on GPQA Diamond, while non-experts score and average of 22.1%: https://arxiv.org/pdf/2311.12022#page6

Keep in mind its multiple choice with 4 options, so random selection is 25%

Median score on AIME is 5/15, or 33.3%: https://artofproblemsolving.com/wiki/index.php/AMC_historical_results#AIME_I

Keep in mind selection bias means the VAST majority of people do not take the AIME. Only students who do well on the AMC preliminary exam will even be allowed to attempt it.
Claude 3.5 Sonnet corrects itself mid-response

https://arxiv.org/abs/2210.11610
We show that our approach improves the general reasoning ability of a 540B-parameter LLM (74.4%->82.1% on GSM8K, 78.2%->83.0% on DROP, 90.0%->94.4% on OpenBookQA, and 63.4%->67.9% on ANLI-A3) and achieves state-of-the-art-level performance, without any ground truth label. We conduct ablation studies and show that fine-tuning on reasoning is critical for self-improvement.

LLMs need to "start talking" to know if they're BSing. If you let them start answering a question & generate about 25 words, they become better at “knowing” whether they actually know the answer or need to look it up. It cuts retrieval work in half while maintaining accuracy: https://arxiv.org/pdf/2412.11536

8.1. Math
Transformers used to solve a math problem that stumped experts for 132 years: Discovering global Lyapunov functions. Lyapunov functions are key tools for analyzing system stability over time and help to predict dynamic system behavior, like the famous three-body problem of celestial mechanics: https://arxiv.org/abs/2410.08304



LeanAgent: Lifelong Learning for Formal Theorem Proving: https://arxiv.org/abs/2410.0620

LeanAgent successfully proves 162 theorems previously unproved by humans across 23 diverse Lean repositories, many from advanced mathematics.

FrontierMath is benchmark of hundreds of original mathematics problems spanning the breadth of modern mathematical research. These range from computationally intensive problems in number theory and real analytics to abstract questions in algebraic geometry and categorytheory We developed it through collaboration with over 60 mathematicians from leading institutions, including professors, IMO question writers, and Fields medalists: https://epoch.ai/frontiermath/the-benchmark
FrontierMath problems typically demand hours or even days for specialist mathematicians to solve.
All problems are new and unpublished, eliminating data contamination concerns that plague existing benchmarks.
Created in collaboration with over 60 mathematicians, FrontierMath spans the full spectrum of modern mathematics, from algebraic geometry to Zermelo–Fraenkel set theory.
“These are extremely challenging. I think that in the near term basically the only way to solve them, short of having a real domain expert in the area, is by a combination of a semi-expert like a graduate student in a related field, maybe paired with some combination of a modern AI and lots of other algebra packages…” —Terence Tao, Fields Medal (2006)
  “[The questions I looked at] were all not really in my area and all looked like things I had no idea how to solve…they appear to be at a different level of difficulty from IMO problems.” — Timothy Gowers, Fields Medal (2006)
"o3 surpasses previous performance records across the board. It beats its predecessor in coding tests (called SWE-Bench Verified) by 22.8 percent and outscores OpenAI’s Chief Scientist in competitive programming. The model nearly aced one of the hardest math competitions (called AIME 2024), missing one question, and achieved 87.7 percent on a benchmark for expert-level science problems (called GPQA Diamond). On the toughest math and reasoning challenges that usually stump AI, o3 solved 25.2 percent of problems (where no other model exceeds 2 percent)." https://www.theverge.com/2024/12/20/24326036/openai-o1-o2-o3-reasoning-model-testing
O1 scores 8/12 (AT LEAST 80 points, excluding partial credit for incorrect answers) on Putnam exam released after its training cutoff date: https://docs.google.com/document/d/1dwtSqDBfcuVrkauFes0ALQpQjCyqa4hD0bPClSJovIs/edit

In 2022, the average score for the competition was approximately 8.2; the median score was one: https://news.mit.edu/2023/mit-wins-putnam-math-competition-0223
Keep in mind, only very talented people even participate in the competition 
First AI to solve International Mathematical Olympiad problems at a silver medalist level: https://x.com/GoogleDeepMind/status/1816498082860667086

>It combines AlphaProof, a new breakthrough model for formal reasoning, and AlphaGeometry 2, an improved version of our previous system. 
Powered with a novel search algorithm, AlphaGeometry 2 can now solve 83% of all historical problems from the past 25 years - compared to the 53% rate by its predecessor.
It solved this year’s IMO Problem 4 within 19 seconds
The fact that the program can come up with a non-obvious construction like this is very impressive, and well beyond what I thought was state of the art. -PROF SIR TIMOTHY GOWERS, IMO GOLD MEDALIST AND FIELDS MEDAL WINNER

Math professor on DeepMind's breakthrough: "When people saw Sputnik 1957, they might have had same feeling I do now. Human civ needs to move to high alert" https://x.com/PoShenLoh/status/1816500461484081519
A thread of a researcher sharing his team's findings on whether or not LLMs can help create Math proofs, competing against humans. Summary: none of them really could get far, until o1 came out: https://x.com/robertghrist/status/1841462507543949581?t=5zV3VpQI0mbrSU9_QRtfkQ&s=19
OpenAI o1 model released: https://openai.com/index/learning-to-reason-with-llms/
Terrance Tao said o1 is a mediocre but not incompetent grad student, who means a lot coming from him 
o1 improves over GPT-4o on a wide range of benchmarks, including 54/57 MMLU subcategories
OpenAI o1 ranks in the 89th percentile on competitive programming questions (Codeforces), places among the top 500 students in the US in a qualifier for the USA Math Olympiad (AIME), and exceeds human PhD-level accuracy on a benchmark of physics, biology, and chemistry problems (GPQA).
On the 2024 AIME exams, GPT-4o only solved on average 12% (1.8/15) of problems. o1 averaged 74% (11.1/15) with a single sample per problem, 83% (12.5/15) with consensus among 64 samples, and 93% (13.9/15) when re-ranking 1000 samples with a learned scoring function. A score of 13.9 places it among the top 500 students nationally and above the cutoff for the USA Mathematical Olympiad.
We trained a model that scored 213 points and ranked in the 49th percentile in the 2024 International Olympiad in Informatics (IOI), by initializing from o1 and training to further improve programming skills. This model competed in the 2024 IOI under the same conditions as the human contestants. It had ten hours to solve six challenging algorithmic problems and was allowed 50 submissions per problem.
With a relaxed submission constraint, we found that model performance improved significantly. When allowed 10,000 submissions per problem, the model achieved a score of 362.14 – above the gold medal threshold – even without any test-time selection strategy.  
Our evaluations closely matched competition rules and allowed for 10 submissions. GPT-4o achieved an Elo rating3 of 808, which is in the 11th percentile of human competitors. This model far exceeded both GPT-4o and o1—it achieved an Elo rating of 1807, performing better than 93% of competitors.









Abacus Embeddings, a simple tweak to positional embeddings that enables LLMs to do addition, multiplication, sorting, and more. Our Abacus Embeddings trained only on 20-digit addition generalise near perfectly to 100+ digits:  https://arxiv.org/abs/2405.17399



Researcher trained GPT2 to predict the product of two numbers up to 20 digits w/o intermediate reasoning steps, surpassing previous 15-digit demo w/o CoT: https://x.com/yuntiandeng/status/1814319104448467137

The accuracy is a perfect 100%, while GPT-4 has 0% accuracy

Grok 2 has record high math performance on MathVista benchmark, scoring 15% higher than humans: https://www.reddit.com/r/LocalLLaMA/comments/1etcj0k/grok2_and_grok2_mini_now_hold_the_top_two_spots/

Fields Medalist Terence Tao explains how proof checkers and AI programs are dramatically changing mathematics: https://www.scientificamerican.com/article/ai-will-become-mathematicians-co-pilot/

>Tao: I think in three years AI will become useful for mathematicians.


Synthetically trained 7B math model blows 64 shot GPT4 out of the water in math: https://x.com/_akhaliq/status/1793864788579090917?s=46&t=lZJAHzXMXI1MgQuyBgEhgA


Improve Mathematical Reasoning in Language Models by Automated Process Supervision: https://arxiv.org/abs/2406.06592

>Utilizing this fully automated process supervision alongside the weighted self-consistency algorithm, we have enhanced the instruction tuned Gemini Pro model's math reasoning performance, achieving a 69.4\% success rate on the MATH benchmark, a 36\% relative improvement from the 51\% base model performance. Additionally, the entire process operates without any human intervention, making our method both financially and computationally cost-effective compared to existing methods.

AlphaGeomertry surpasses the state-of-the-art approach for geometry problems, advancing AI reasoning in mathematics: https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/


GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B: https://arxiv.org/abs/2406.07394

>Extensive experiments demonstrate MCTSr's efficacy in solving Olympiad-level mathematical problems, significantly improving success rates across multiple datasets, including GSM8K, GSM Hard, MATH, and Olympiad-level benchmarks, including Math Odyssey, AIME, and OlympiadBench. The study advances the application of LLMs in complex reasoning tasks and sets a foundation for future AI integration, enhancing decision-making accuracy and reliability in LLM-driven applications.

This would be even more effective with a better model than LLAMA 8B 

DeepSeek-Coder-V2: First Open Source Model Beats GPT4-Turbo in Coding and Math: https://github.com/deepseek-ai/DeepSeek-Coder-V2/blob/main/paper.pdf 

Google DeepMind used a large language model to solve an unsolved math problem: https://www.technologyreview.com/2023/12/14/1085318/google-deepmind-large-language-model-solve-unsolvable-math-problem-cap-set/

Six months ago, we launched Numina to lead open research in AI4Math. The Numina Math 7B model won the 1st progress prize of the AI Math Olympiad: https://x.com/JiaLi52524397/status/1808886880164880631

It even impressed Fields medalist Terrance Tao

Not as good as the Opus model they said is coming out later this year
Exclusive: OpenAI working on new reasoning technology under code name ‘Strawberry’ https://www.reuters.com/technology/artificial-intelligence/openai-working-new-reasoning-technology-under-code-name-strawberry-2024-07-12/
'A different source briefed on the matter said OpenAI has tested AI internally that scored over 90% on a MATH dataset, a benchmark of championship math problems. Reuters could not determine if this was the "Strawberry" project.'
The MATH dataset is challenging: large language models achieved accuracies ranging from 3.0% to 6.9%. Despite these low accuracies, models clearly possess some mathematical knowledge: they achieve up to 15% accuracy on the easiest difficulty level, and they are able to generate step-by-step solutions that are coherent and on-topic even when incorrect. We also evaluated humans on MATH, and found that a computer science PhD student who does not especially like mathematics attained approximately 40% on MATH, while a three-time IMO gold medalist attained 90%, indicating that MATH can be challenging for humans as well.
https://datasets-benchmarks-proceedings.neurips.cc/paper_files/paper/2021/file/be83ab3ecd0db773eb2dc1b0a17836a1-Paper-round2.pdf
Significant progress in Gemini 1.5 Pro across all key benchmarks; TL;DR: 1.5 Pro > 1.0 Ultra, 1.5 Flash (our fastest model) ~= 1.0 Ultra. A math-specialised variant of Gemini 1.5 Pro performs strongly on competition-level math problems, including a breakthrough performance of 91.1% on Hendryck’s MATH benchmark without tool-use: https://x.com/OriolVinyalsML/status/1791521517211107515?t=uf0Sgqt_UpU_QsXB5w-HJA&s=19 

Alibaba unveils Qwen2-Math. New open weights model that outperforms closed source ones in Math benchmarks: https://x.com/Alibaba_Qwen/status/1821553401744015816




NuminaMath 72b TIR model: https://x.com/JiaLi52524397/status/1814957190320631929/
Trained on new competition math dataset ever released, with 860K problem solution pairs.

For AMC 10 2023, the average score is 43%, 
AIME Floor: 70% (top ~6%)
Distinction: 75%
Distinguished Honor Roll: 90%

https://mathvista.github.io/
test: 5,141 examples for standard evaluation. Notably, the answer labels for test will NOT be publicly released
Human performance is 60.8%. Average human performance is from AMT annotators who have high school diplomas or above.

Scores of o1-preview and GPT-4o on "official national exam in abstract mathematics used in Dutch high schools." Taken twice, o1-preview got 76 and 73 (max 76). Taken twice, GPT-4o got 66 and 61. Paper: "System 2 thinking in OpenAI’s o1-preview model: Near-perfect performance on a mathematics exam"  

AI is better at math than these humans: https://www.reddit.com/r/Teachers/comments/1axhne2/the_public_needs_to_know_the_ugly_truth_students/
LeanAgent: Lifelong Learning for Formal Theorem Proving: https://arxiv.org/abs/2410.06209
LeanAgent successfully proves 162 theorems previously unproved by humans across 23 diverse Lean repositories, many from advanced mathematics.
8.2. Medicine
 Physician study shows AI alone is better at diagnosing patients than doctors, even better than doctors using AI: https://www.computerworld.com/article/3613982/will-ai-help-doctors-decide-whether-you-live-or-die.html
AMIE: A research AI system for diagnostic medical reasoning and conversations: https://research.google/blog/amie-a-research-ai-system-for-diagnostic-medical-reasoning-and-conversations/




AMIE responses were preferred to general cardiologists’ responses for 5 of the 10 domains, and were equivalent for the rest. AMIE also demonstrates strong assistive potential — access to AMIE’s response improved cardiologists’ overall response quality in 63.7% of cases while lowering quality in just 3.4%. Qualitative results suggest AMIE and general cardiologists could complement each other, with AMIE responses being thorough and sensitive, while general cardiologists’ responses were concise and specific.

https://research.google/blog/advancing-amie-towards-specialist-care-and-real-world-validation/


New AI Framework for Medical Imaging Matches Accuracy of Clinical Specialists: https://www.insideprecisionmedicine.com/topics/patient-care/new-ai-framework-for-medical-imaging-matches-accuracy-of-clinical-specialists/

https://x.com/DeryaTR_/status/1834630356286558336
New research shows AI-discovered drug molecules have 80-90% success rates in Phase I clinical trials, compared to the historical industry average of 40-65%. The Phase 2 success rate so far is similar to the industry average, meaning more drugs are passing overall. https://www.sciencedirect.com/science/article/pii/S135964462400134X 

AI Detects More Breast Cancers with Fewer False Positives https://www.rsna.org/news/2024/june/ai-detects-more-breast-cancers
Recall (false positive) rate and radiologist reading workload decreased significantly in AI-screened group
Using AI, breast radiologists in Denmark have improved breast cancer screening performance and reduced the rate of false-positive findings.
In total, 60,751 women were screened without AI, and 58,246 women were screened with the AI system. In the AI implementation group, 66.9% (38,977) of the screenings were single-read, and 33.1% (19,269) were double-read with AI assistance. 
Compared to screening without AI, screening with the AI system detected significantly more breast cancers (0.82% versus 0.70%) and had a lower false-positive rate (1.63% versus 2.39%). 
“In the AI-screened group, the recall rate decreased by 20.5 percent, and the radiologists’ reading workload was lowered by 33.4 percent,” Dr. Lauritzen said.
The positive predictive value of AI screening was also greater than that of screening without AI (33.5% versus 22.5%). In the AI group, a higher proportion of invasive cancers detected were 1 centimeter or less in size (44.93% vs. 36.60%).
“All screening performance indicators improved except for the node-negative rate which showed no evidence of change,” Dr. Lauritzen said.

AI predicts diseases with 98% accuracy in real-time using tongue color | AI-powered computer model to analyze patients’ tongue colors for real-time disease diagnoses such as anemia, COVID-19, vascular and gastrointestinal issues, or asthma: https://interestingengineering.com/health/ai-model-predicts-disease-using-tongue-color

the paper itself shows that the best model has a f1 score, precision, recall all above 98% https://www.mdpi.com/2227-7080/12/7/97

AI spots cancer and viral infections at nanoscale precision: https://healthcare-in-europe.com/en/news/ai-cancer-viral-infections-nanoscale-precision.html

Scanning images of cells could lead to new diagnostic and monitoring strategies for disease.

AI Detects Prostate Cancer 17% More Accurately Than Doctors, Finds Study: https://www.ndtv.com/science/ai-detects-prostate-cancer-17-more-accurately-than-doctors-finds-study-6170131

GPs use AI to boost cancer detection rates in England by 8%: https://www.theguardian.com/society/article/2024/jul/21/gps-use-ai-to-boost-cancer-detection-rates-in-england-by-8

AI Outperforms Radiologists in Detecting Prostate Cancer on MRI: https://www.insideprecisionmedicine.com/topics/patient-care/ai-outperforms-radiologists-in-detecting-prostate-cancer-on-mri-scans/

AI detected nearly seven percent more significant prostate cancers than the radiologists. Moreover, AI triggered false alarms 50 percent less often, potentially reducing the number of unnecessary biopsies by half. These findings suggest that AI could significantly alleviate the workload of radiologists, improve diagnostic accuracy, and minimize unnecessary procedures.”
 
Med-Gemini : https://arxiv.org/abs/2404.18416

>We evaluate Med-Gemini on 14 medical benchmarks, establishing new state-of-the-art (SoTA) performance on 10 of them, and surpass the GPT-4 model family on every benchmark where a direct comparison is viable, often by a wide margin. On the popular MedQA (USMLE) benchmark, our best-performing Med-Gemini model achieves SoTA performance of 91.1% accuracy, using a novel uncertainty-guided search strategy. On 7 multimodal benchmarks including NEJM Image Challenges and MMMU (health & medicine), Med-Gemini improves over GPT-4V by an average relative margin of 44.5%. We demonstrate the effectiveness of Med-Gemini's long-context capabilities through SoTA performance on a needle-in-a-haystack retrieval task from long de-identified health records and medical video question answering, surpassing prior bespoke methods using only in-context learning. Finally, Med-Gemini's performance suggests real-world utility by surpassing human experts on tasks such as medical text summarization, alongside demonstrations of promising potential for multimodal medical dialogue, medical research and education. 


Double-blind study with Patient Actors and Doctors, who didn't know if they were communicating with a human, or an AI. Best performers were AI: https://m.youtube.com/watch?v=jQwwLEZ2Hz8 

>Human doctors + AI did worse, than AI by itself. The mere involvement of a human reduced the accuracy of the diagnosis.
AI was consistently rated to have better bedside manner than human doctors. 

[Google's medical AI destroys GPT's benchmark and outperforms doctors](https://newatlas.com/technology/google-med-gemini-ai/)

Med-Gemini's outputs are preferred to drafts from clinicians for common and time-consuming real-world tasks such as simplifying or summarising long medical notes, or drafting referral letters: https://x.com/alan_karthi/status/1785117444383588823 


[The first randomized trial of medical #AI to show it saves lives. ECG-AI alert in 16,000 hospitalized patients. 31% reduction of mortality (absolute 7 per 100 patients) in pre-specified high-risk group](https://twitter.com/erictopol/status/1784936718283805124)

Medical Text Written By Artificial Intelligence Outperforms Doctors: https://www.forbes.com/sites/williamhaseltine/2023/12/15/medical-text-written-by-artificial-intelligence-outperforms-doctors/ 

AI can make healthcare better and safer: https://www.economist.com/technology-quarterly/2024/03/27/ais-will-make-health-care-safer-and-better

CheXzero significantly outperformed humans, especially on uncommon conditions. Huge implications for improving diagnosis of neglected "long tail" diseases: https://x.com/pranavrajpurkar/status/1797292562333454597 


>Humans near chance level (50-55% accuracy) on rarest conditions, while CheXzero maintains 64-68% accuracy.


AI is better than doctors at detecting breast cancer: https://www.bbc.com/news/health-50857759

‘I will never go back’: Ontario family doctor says new AI notetaking saved her job: https://globalnews.ca/news/10463535/ontario-family-doctor-artificial-intelligence-notes 

China's first (simulated) AI hospital town debuts: https://www.globaltimes.cn/page/202405/1313235.shtml 

>Remarkably, AI doctors can treat 10,000 [simulated]  patients in just a few days. It would take human doctors at least two years to treat that many patients. Furthermore, evolved doctor agents achieved an impressive 93.06 percent accuracy rate on the MedQA dataset (US Medical Licensing Exam questions) covering major respiratory diseases. They simulate the entire process of diagnosing and treating patients, including consultation, examination, diagnosis, treatment and follow-up.

Researchers find that GPT-4 performs as well as or better than doctors on medical tests, especially in psychiatry. https://www.news-medical.net/news/20231002/GPT-4-beats-human-doctors-in-medical-soft-skills.aspx 

ChatGPT outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions: https://today.ucsd.edu/story/study-finds-chatgpt-outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions?darkschemeovr=1

AI just as good at diagnosing illness as humans: https://www.medicalnewstoday.com/articles/326460

AI can replace doctors: https://www.aamc.org/news/will-artificial-intelligence-replace-doctors?darkschemeovr=1

Geoffrey Hinton says AI doctors who have seen 100 million patients will be much better than human doctors and able to diagnose rare conditions more accurately: https://x.com/tsarnick/status/1797169362799091934

AI models ChatGPT and Grok outperform the average doctor on a medical licensing exam: the average score by doctors is 75% - ChatGPT scored 98% and Grok 84%: https://x.com/tsarnick/status/1814048365002596425



[Generative AI will be designing new drugs all on its own in the near future](https://www.cnbc.com/2024/05/05/within-a-few-years-generative-ai-will-design-new-drugs-on-its-own.html)

In a historic moment for the dental profession, an AI-controlled autonomous robot has performed an entire procedure on a human patient for the first time, about eight times faster than a human dentist could do it: https://newatlas.com/health-wellbeing/robot-dentist-world-first/
Tx-LLM: Supporting therapeutic development with large language models: https://research.google/blog/tx-llm-supporting-therapeutic-development-with-large-language-models/
BrainLM: https://www.biorxiv.org/content/10.1101/2023.09.12.557460v2.full.pdf
Utilizing self-supervised masked-prediction training, BrainLM demonstrates proficiency in both fine-tuning and zero-shot inference tasks. Fine-tuning allows for the accurate prediction of clinical variables like age, anxiety, and PTSD as well as forecasting of future brain states. Critically, the model generalizes well to entirely new external cohorts not seen during training. In zero-shot inference mode, BrainLM can identify intrinsic functional networks directly from raw fMRI data without any network-based supervision during training. The model also generates interpretable latent representations that reveal relationships between brain activity patterns and cognitive states. Overall, BrainLM offers a versatile and interpretable framework for elucidating the complex spatiotemporal dynamics of human brain activity. It serves as a powerful "lens" through which massive repositories of fMRI data can be analyzed in new ways, enabling more effective interpretation and utilization at scale. The work demonstrates the potential of foundation models to advance computational neuroscience research. 






Cardiologists working with AI said it was equal or better than human cardiologists in most areas: https://x.com/DKThomp/status/1843993273825964312

A.I. Chatbots Defeated Doctors at Diagnosing Illness. "A small study found ChatGPT outdid human physicians when assessing medical case histories, even when those doctors were using a chatbot." https://www.nytimes.com/2024/11/17/health/chatgpt-ai-doctors-diagnosis.html
In an experiment, doctors who were given ChatGPT to diagnose illness did only slightly better than doctors who did not. But the chatbot alone outperformed all the doctors.
Dr. Adam Rodman, an expert in internal medicine at Beth Israel Deaconess Medical Center in Boston, confidently expected that chatbots built to use artificial intelligence would help doctors diagnose illnesses. He was wrong.
Instead, in a study Dr. Rodman helped design, doctors who were given ChatGPT-4 along with conventional resources did only slightly better than doctors who did not have access to the bot. And, to the researchers’ surprise, ChatGPT alone outperformed the doctors.
“I was shocked,” Dr. Rodman said.
The chatbot, from the company OpenAI, scored an average of 90 percent when diagnosing a medical condition from a case report and explaining its reasoning. Doctors randomly assigned to use the chatbot got an average score of 76 percent. Those randomly assigned not to use it had an average score of 74 percent.
The study showed more than just the chatbot’s superior performance.
After his initial shock at the results of the new study, Dr. Rodman decided to probe a little deeper into the data and look at the actual logs of messages between the doctors and ChatGPT. The doctors must have seen the chatbot’s diagnoses and reasoning, so why didn’t those using the chatbot do better? It turns out that the doctors often were not persuaded by the chatbot when it pointed out something that was at odds with their diagnoses. Instead, they tended to be wedded to their own idea of the correct diagnosis. “They didn’t listen to A.I. when A.I. told them things they didn’t agree with,” Dr. Rodman said. That makes sense, said Laura Zwaan, who studies clinical reasoning and diagnostic error at Erasmus Medical Center in Rotterdam and was not involved in the study.
“People generally are overconfident when they think they are right,” she said. But there was another issue: Many of the doctors did not know how to use a chatbot to its fullest extent. Dr. Chen said he noticed that when he peered into the doctors’ chat logs, “they were treating it like a search engine for directed questions: ‘Is cirrhosis a risk factor for cancer? What are possible diagnoses for eye pain?’” “It was only a fraction of the doctors who realized they could literally copy-paste in the entire case history into the chatbot and just ask it to give a comprehensive answer to the entire question,” Dr. Chen added. “Only a fraction of doctors actually saw the surprisingly smart and comprehensive answers the chatbot was capable of producing.”
o1-preview is far superior to doctors on reasoning tasks and it's not even close, according to OpenAI's latest paper. AI does ~80% vs ~30% on the 143 hard NEJM CPC diagnoses: https://x.com/deedydas/status/1869049071346102729
Note that most other LLMs cannot do this despite access to the same training data (Google actually has access to FAR more data than OpenAI does) and high incentive to match these scores

Authors:
9. Morality/AI Is Not Theft
People share memes containing copyrighted content (e.g. Spongebob screenshots or Breaking Bad gifs) without permission all the time with zero legal or moral issues
Search engines already “stole content” long before AI, such as Google’s featured snippets and “People Also Ask” sections that quote text from a website directly with no alterations: https://support.google.com/websearch/answer/9351707?hl=en&visit_id=638612725182118407-343145636&p=featured_snippets&rd=1


(Ignore the Japanese text; it’s from a browser extension)
Imagine if the first dude who painted a wall didn't give "consent" for some other dude to "copy" his cave painting. We wouldn't have art today.
AI training is similar to how people learn now. They read/see other people’s work, which is usually copyrighted, and get inspired to make their own. If it is moral for humans to do that without permission or compensation (even if they make money from it), it is moral for AI to do the same.
And yes, AI does not learn like humans do. Birds and planes are fundamentally different too. But they both fly even if their method of doing it is not the same. 
Example 1: The director Breaking Bad, Vince Gilligan, stated that The Godfather was a main inspiration for the show. Yet the owner of The Godfather was not paid any royalties for it despite Breaking Bad being a for-profit show.  
Example 2: People draw fan art all the time without paying or getting permission, including profiting from it on Patreon or Gumroad and potentially damaging the brands by creating NSFW content of copyrighted characters.
Example 3: Everyone is a product of the sum of their experiences similar to how AI is a product of analyzing countless images or texts. Yet AI is expected to credit or compensate for everything it analyzes while humans are not.
“Why are you defending big corporations?”
The fact big corporations benefit does not make AI bad. Vaccines and the Internet are also defensible even though they help Big Pharma or ISPs profit.
AI voice generation is not much different from someone doing a good voice impression. Both can be used for malicious purposes, but we still find the latter acceptable.
Twitter/X is banning millions of accounts a year for CSAM, but we don’t consider Twitter to be inherently immoral because CSAM exists on their servers. Services need to make a reasonable, good faith effort to remove this material anywhere it is found and work with law enforcement to help catch the perpetrators. In this case, a small amount of CSAM was found in some of the LAION training links used to train Stabke Diffusion, LAION was made aware, and they took all their datasets offline temporarily while they removed those links from the listings.
That is the response of an organization making a good faith effort to remove CSAM from their work. Instead of pearl clutching any time someone does something illegal on the internet, we should look at what actions we expect companies and services to take, and ensure they are taking those actions. 
If our expectation is that any company that unknowingly has CSAM on their site should be permanently shut down, that will be an impossible task.
Child abuse images removed from AI image-generator training source, researchers say: https://apnews.com/article/ai-image-generators-child-sexual-abuse-laion-stable-diffusion-2652b0f4245fb28ced1cf74c60a8d9f0
This is not how plagiarism works. You can’t copy everyone. There have to be substantial similarities between the AI output and a specific work.
If AI takes jobs, it’s similar to previous industries being obsolete, like coal mining and manufacturing industries. Times change, and people should change with it by getting new skills. Coal miners were told to learn to code, so coders should learn to weld or do construction work.
If I use a math textbook to help me get a PhD in math and then write my own math textbook that directly competes with the one I studied from, the author has no right to sue me even though I “trained” off of their work and am now directly competing with them.
Google Translate is also trained with web scraping, uses transformers (the same type of technology used for LLMs), and reduces jobs for translators. Yet it receives almost no pushback from the public.
“Good artists borrow, great artists steal”  - Pablo Picasso

10. Legality
LAION wins copyright infringement lawsuit in German court: https://www.technollama.co.uk/laion-wins-copyright-infringement-lawsuit-in-german-court

TL;DR: The use of copyrighted art for training purposes counts as scientific research and is legal in Germany.
No reason to think US courts would be more strict than an EU nation.

Legal claims against AI debunked: https://www.techdirt.com/2024/09/05/the-ai-copyright-hype-legal-claims-that-didnt-hold-up/
courts are rejecting that just because an ai model was trained on a copyrighted work it or its output is an infringing work. In fact, it finds such claims either have no legal basis or it is so unlikely to be true that that the court don’t think worth letting such a claim go on to discovery.
the law firm doing these cases couldn’t come up with a legal theory of how the trainers of the model were removing copyright information illegally.
The removal of copyright management information (“CMI,” which includes information such as the title, the copyright holder, and other identifying information in a copyright notice) is a claim included in almost all plaintiffs’ complaints in the AI lawsuits, and this claim has failed to survive motions to dismiss without exception. DMCA Section 1202(b) restricts the intentional, unauthorized removal of CMI. Experts initially considered DMCA 1202(b) one of the biggest hurdles for non-licensed AI training. But courts so far have dismissed all DMCA 1202(b) claims, including in J. Doe 1 v. GitHub, Tremblay v. OpenAI, Andersen v. Stability AI, Kadrey v. Meta Platforms, and Silverman v. OpenAI. The plaintiffs’ DMCA Section 1202(b)(1) claims have failed because plaintiffs were not able to offer any evidence showing their CMI has been intentionally removed by the AI companies. For example, in Tremblay v. OpenAI and Silverman v. OpenAI, the courts held that the plaintiffs did not argue plausibly that OpenAI has intentionally removed CMI when ingesting plaintiffs’ works for training. Additionally, plaintiffs’ DMCA Section 1202(b)(3) have failed thus far because the plaintiffs’ claims did not fulfill the identicality requirement. For example, in J. Doe 1 v. GitHub, the court pointed out that Copilot’s output did not tend to represent verbatim copies of the original ingested code. We now see plaintiffs voluntarily dropping the DMCA claims in their amended complaints, such as in Leovy v Google (formerly J.L. vs Alphabet). 
Another claim that has been consistently dismissed by courts is that AI models are infringing derivative works of the training materials. The law defines a derivative work as “a work based upon one or more preexisting works, such as a translation, musical arrangement, … art reproduction, abridgment, condensation, or any other form in which a work may be recast, transformed, or adapted.” To most of us, the idea that the model itself (as opposed to, say, outputs generated by the model) can be considered a derivative work seems to be a stretch. The courts have so far agreed. On November 20, 2023, the court in Kadrey v. Meta Platforms said it is “nonsensical” to consider an AI model a derivative work of a book just because the book is used for training. 
Similarly, claims that all AI outputs should be automatically considered infringing derivative works have been dismissed by courts, because the claims cannot point to specific evidence that an instance of output is substantially similar to an ingested work. In Andersen v. Stability AI, plaintiffs tried to argue “that all elements of … Anderson’s copyrighted works … were copied wholesale as Training Images and therefore the Output Images are necessarily derivative;” the court dismissed the argument because—besides the fact that plaintiffs are unlikely able to show substantial similarity—“it is simply not plausible that every Training Image used to train Stable Diffusion was copyrighted … or that all … Output Images rely upon (theoretically) copyrighted Training Images and therefore all Output images are derivative images. … [The argument for dismissing these claims is strong] especially in light of plaintiffs’ admission that Output Images are unlikely to look like the Training Images.”
Several of these AI cases have raised claims of vicarious liability—that is, liability for the service provider based on the actions of others, such as users of the AI models. Because a vicarious infringement claim must be based on a showing of direct infringement, the vicarious infringement claims are also dismissed in Tremblay v. OpenAI and Silverman v. OpenAI, when plaintiffs cannot point to any infringing similarity between AI output and the ingested books.
Many plaintiffs have also raised a number of non-copyright, state law claims (such as negligence or unfair competition) that have largely been dismissed based on copyright preemption. Copyright preemption prevents duplicitous state law claims when those state law claims are based on an exercise of rights that are equivalent to those provided for under the federal Copyright Act. In Andersen v. Stability AI, for example, the court dismissed the plaintiffs’ unjust enrichment claim because the plaintiffs failed to add any new elements that would distinguish their claim based on California’s Unfair Competition Law or common law from rights under the Copyright Act.
It is interesting to note that many of the dismissed claims in different AI lawsuits closely mimic one another, such as in Kadrey v. Meta Platforms, Andersen v. Stability AI, Tremblay v. OpenAI, and Silverman v. OpenAI. It turns out that the similarities are no coincidence—all these lawsuits are filed by the same law firm. These mass-produced complaints not only contain overbroad claims that are prone to dismissal, they also have overbroad class designations. 
OpenAI's data scraping wins big as Raw Story's copyright lawsuit dismissed:
https://venturebeat.com/ai/openais-data-scraping-wins-big-as-raw-storys-copyright-lawsuit-dismissed-by-ny-court/

Judge sharply criticizes lawyers for authors in AI suit against Meta:  https://www.politico.com/news/2024/09/20/judge-sharply-criticizes-lawyers-ai-lawsuit-meta-00180348
“It’s very clear to me from the papers, from the docket and from talking to the magistrate judge that you have brought this case and you have not done your job to advance it,” the judge said. “You and your team have barely been litigating the case. That’s obvious….This is not your typical proposed class action. This is an important case. It’s an important societal issue. It’s important for your clients.”
“I think what you need, frankly, is to bring in somebody who can help you litigate the case, who has the resources and the wherewithal to move this case forward…I think you need to reconstitute your legal team”

Translation: your lawyers are incompetent and should be fired.
But unfortunately, they’re the only ones willing to take the case: “many of the dismissed claims in different AI lawsuits closely mimic one another, such as in Kadrey v. Meta Platforms, Andersen v. Stability AI, Tremblay v. OpenAI, and Silverman v. OpenAI. It turns out that the similarities are no coincidence—all these lawsuits are filed by the same law firm. These mass-produced complaints not only contain overbroad claims that are prone to dismissal, they also have overbroad class designations.”
https://www.techdirt.com/2024/09/05/the-ai-copyright-hype-legal-claims-that-didnt-hold-up/
Art styles cannot be legally copyrighted: https://www.thelegalartist.com/blog/you-cant-copyright-style
Williams won another Oscar for Star Wars and took inspiration from a 1942 movie called Kings Row, composed by Erich Wolfgang Korngold. Can you hear Star Wars? https://x.com/ATRightMovies/status/1794345480207684058
If this can be legally sold for commercial use, why not AI art?
AI art is inherently transformative* and, therefore, fair use.
*This is why it warps hands, fingers, limbs, eyes, etc. sometimes. If it was just copying and pasting existing images, why would it do that? Additionally, Stable Diffusion 1.5 checkpoints are only 2 GB, not nearly enough space to store anywhere close to all the images it was trained on. It can also generate infinite variations of absurd or extremely strange images that would not be well represented in its training data. 
Stable Diffusion models can generate novel images of characters that only existed AFTER the model was trained and released if it uses a Lora trained on those characters. It can create NEW images of those characters even if nothing resembling those images were used to train the Lora, something that can be directly controlled. 
In other words, if a brand new character is released, I can train a Lora on it, and SD can create new images of that character that I can verify it was NEVER trained on since it won’t be in the dataset used to train the Lora.  
AI training off of data and taking jobs is similar to a human being inspired by a work and taking market share from their inspirations by creating their own. This is not considered immoral, and most artists are generally honored if someone was inspired by their work. 
Additionally, jobs are frequently automated, such as how milkmen lost their jobs to the rise of supermarkets, coal miners lost their jobs to renewable energy, horse carriage manufacturers lost their jobs to cars, and many mailmen lost their jobs to email. This would not justify banning any of those things and unemployment rates remained low despite these displacements.
AI cannot displace artists as artists are still needed to create ideas, integrate scenes together, and fix mistakes. In fact, it can be a great improvement as it will reduce the amount of labor they will need to do that often leads to extreme burnout.
Even if you believe AI will take jobs, artists are not entitled to jobs and would still be allowed to create art on their own time. However, no one is obligated to employ them. If you have a problem with that, blame capitalism and the requirement of wage labor even when it is no longer needed instead of AI.
Singapore: Copyright Infringement Defence for AI Machine Learning: https://rouse.com/insights/news/2024/artificial-intelligence-in-singapore-copyright-infringement-defence-for-artificial-intelligence-machine-learning
Machine learning requires data and information to learn from and typically this comes from content scraped from third party websites which could potentially be regarded as copyright infringement. This risk could now be neutralised by the Computational Analysis defense of the CA - under section 243


Even if we agree that AI generated images are theft, the users are the ones generating the images, while the AI companies are only providing access to their model. Therefore, the users are the ones violating copyright, not the companies themselves, so they are not liable similar to how photo editing software companies are not liable if a user commits plagiarism using their software.


US Copyright Law - Chapter 1 Section 102 " In no case does copyright protection for an original work of authorship extend to any idea, procedure, process, system, method of operation, concept, principle, or discovery, regardless of the form in which it is described, explained, illustrated, or embodied in such work."


Creating a database of copyrighted work is legal in the US: https://en.wikipedia.org/wiki/Authors_Guild,_Inc._v._Google,_Inc.

Two cases with Bright Data against Meta and Twitter/X show that web scraping publicly available data is not against their ToS or copyright: https://en.wikipedia.org/wiki/Bright_Data


“In January 2024, Bright Data won a legal dispute with Meta. A federal judge in San Francisco declared that Bright Data did not breach Meta's terms of use by scraping data from Facebook and Instagram, consequently denying Meta's request for summary judgment on claims of contract breach.[20][21][22] This court decision in favor of Bright Data’s data scraping approach marks a significant moment in the ongoing debate over public access to web data, reinforcing the freedom of access to public web data for anyone.”
“In May 2024, a federal judge dismissed a lawsuit by X Corp. (formerly Twitter) against Bright Data, ruling that the company did not violate X's terms of service or copyright by scraping publicly accessible data.[25]  The judge emphasized that such scraping practices are generally legal and that restricting them could lead to information monopolies,[26] and highlighted that X's concerns were more about financial compensation than protecting user privacy.”


Coders' Copilot code-copying copyright claims crumble against GitHub, Microsoft: https://www.theregister.com/2024/07/08/github_copilot_dmca/


>The most recently dismissed claims were fairly important, with one pertaining to infringement under the Digital Millennium Copyright Act (DMCA), section 1202(b), which basically says you shouldn't remove without permission crucial "copyright management" information, such as in this context who wrote the code and the terms of use, as licenses tend to dictate.
The amended complaint argued that unlawful code copying was an inevitability if users flipped Copilot's anti-duplication safety switch to off, and also cited a study into AI-generated code in attempt to back up their position that Copilot would plagiarize source, but once again the judge was not convinced that Microsoft's system was ripping off people's work in a meaningful way.


German court allows patents for AI-generated inventions: https://www.surrey.ac.uk/news/german-court-allows-patents-ai-generated-inventions


3 separate gen AI cases show that AI training is not the same as removing a watermark: https://www.law.cornell.edu/uscode/text/17/1202
I can go to a library and study math. The textbook authors cannot claim license to my work. The ai is not too different.

If I use your textbook to pass my classes, get a PhD, and publish my own competing textbook, you can’t sue even if my textbook teaches the same topics as yours and becomes so popular that it causes your market share to significantly decrease. Note that the textbook is a product sold for profit that directly competes with yours, not just an idea in my head. Yet I owe no royalties to you. 
Downloading images is not infringement as browsers download images for you to view them
Derivative work only includes major copyrightable elements of the original. AI does not contain that.
Tool manufacturers are not responsible if a user violates copyright with it. For example, Adobe is not responsible if someone violates copyright using Photoshop.
People share memes containing copyrighted content (e.g. Spongebob screenshots or Breaking Bad gifs) without permission all the time with zero legal or moral issues
Search engines already “stole content” long before AI, such as Google’s featured snippets and “People Also Ask” sections that quote text from a website directly with no alterations: https://support.google.com/websearch/answer/9351707?hl=en&visit_id=638612725182118407-343145636&p=featured_snippets&rd=1


(Ignore the Japanese text; it’s from a browser extension)
US Copyright Office shows leniency to copyrighting AI works: https://www.wired.com/story/the-us-copyright-office-loosens-up-a-little-on-ai/
A large fraction of the training data for all new LLMs is synthetic/computer generated. Orion is almost 60% synthetic data from o1. 
training is completely legal in countries like Japan, who've removed all restrictions, so all these companies can just move to Japan or other countries with more common sense.
Lithograph company tried to argue that photographs were a wholly deterministic physical reaction and thus involved no artistic input, in regards to a famous photograph of Oscar Wilde.
Ukrainian IP Office registers works incorporating AI-generated content protected under new sui generis right: https://ipkitten.blogspot.com/2024/09/ukrainian-ip-office-registers-works.html?m=1
Giphy uses a plethora of copyrighted moments but no one has an issue with it
People also steal and share memes across the Internet with no issues, even when they contain copyrighted content




11. AI Art

Algorithmic art or algorithm art is art, mostly visual art, in which the design is generated by an algorithm: https://en.wikipedia.org/wiki/Algorithmic_art

Generative art is post-conceptual art that has been created (in whole or in part) with the use of an autonomous system: https://en.wikipedia.org/wiki/Generative_art

Both have existed since the 1960s. If these can be considered art, then why not AI art?

Computer-generated and non-deterministic music has existed for many decades:
https://en.wikipedia.org/wiki/Aleatoric_music
Coined in the 50s
Leaves parts of music to pure chance
https://en.wikipedia.org/wiki/Generative_music
Coined by Brian Eno
https://en.wikipedia.org/wiki/Algorithmic_composition
Uses algorithms to create music

‘He touched a nerve’: how the first piece of AI music was born in 1956: https://www.theguardian.com/music/2021/dec/07/he-touched-a-nerve-how-the-first-piece-of-ai-music-was-born-in-1956

Long before Auto-Tune and deepfake compositions, the university professor Lejaren Hiller premiered a concert recital composed by a computer and became an overnight celebrity	
11.1. Images/Videos/3D Modeling
A study found that it could extract training data from AI models using a CLIP-based attack: https://arxiv.org/abs/2301.13188

The study identified 350,000 images in the training data to target for retrieval with 500 attempts each (totaling 175 million attempts), and of that managed to retrieve 107 images through high cosine similarity (85% or more) of their CLIP embeddings and through manual visual analysis. A replication rate of nearly 0% in a dataset biased in favor of overfitting using the exact same labels as the training data and specifically targeting images they knew were duplicated many times in the dataset using a smaller model of Stable Diffusion (890 million parameters vs. the larger 12 billion parameter Flux model that released on August 1). This attack also relied on having access to the original training image labels:

“Instead, we first embed each image to a 512 dimensional vector using CLIP [54], and then perform the all-pairs comparison between images in this lower-dimensional space (increasing efficiency by over 1500×). We count two examples as near-duplicates if their CLIP embeddings have a high cosine similarity. For each of these near-duplicated images, we use the corresponding captions as the input to our extraction attack.”


There is not as of yet evidence that this attack is replicable without knowing the image you are targeting beforehand. So the attack does not work as a valid method of privacy invasion so much as a method of determining if training occurred on the work in question - and only for images with a high rate of duplication AND with the same prompts as the training data labels, and still found almost NONE.

“On Imagen, we attempted extraction of the 500 images with the highest out-ofdistribution score. Imagen memorized and regurgitated 3 of these images (which were unique in the training dataset). In contrast, we failed to identify any memorization when applying the same methodology to Stable Diffusion—even after attempting to extract the 10,000 most-outlier samples”


I do not consider this rate or method of extraction to be an indication of duplication that would border on the realm of infringement, and this seems to be well within a reasonable level of control over infringement.

Diffusion models can create human faces even when an average of 93% of the pixels are removed from all the images in the training data: https://arxiv.org/pdf/2305.19256
 
“if we corrupt the images by deleting 80% of the pixels prior to training and finetune, the memorization decreases sharply and there are distinct differences between the generated images and their nearest neighbors from the dataset. This is in spite of finetuning until convergence.”

“As shown, the generations become slightly worse as we increase the level of corruption, but we can reasonably well learn the distribution even with 93% pixels missing (on average) from each training image.”




INCREDIBLE control of video generation with real physics simulation: https://x.com/zhou_xian_/status/1869511650782658846

consistent multi-camera video generation: https://jianhongbai.github.io/SynCamMaster/
Trellis is a new 3D model that generates high-quality 3D assets in formats like Radiance Fields, 3D Gaussians, and meshes: https://trellis3d.github.io/

Rankings on AI videos based on human preference: https://artificialanalysis.ai/text-to-video/arena?tab=Leaderboard
https://lumalabs.ai/photon


Very realistic images: https://www.reddit.com/r/singularity/comments/1ej1etp/flux_can_generate_really_good_fake_low_quality/ 





Prompt with no additional editing: meme image with two men in it. On the left side the man is taller and is wearing a shirt that says Black Forest Labs. On the right side the other smaller scrawny man is wearing a shirt that says Stability AI and is sad. The taller man is hitting the back of the head of the small man. A caption coming from the tall man reads "That's how you do a next-gen model!

Prompt: Gameplay screenshot of Counter Strike Global Offensive. It takes place in a Middle Eastern place called Dust 2. There are enemy soldiers shooting at you.

Prompt: low quality and motion blur shaky photo of a CRT television on top of a wooden drawer in an average bedroom. The lighting from is dim and warm ceiling light that is off screen. In the TV there is Dark Souls videogame gameplay on it. The screen of the TV is overexposed.



Created on first try. Robe and hands are perfect 

First attempt: "Photo of a red sphere on top of a blue cube. Behind them is a green triangle, on the right of the triangle is a dog, on the left is a cat."

Prompt: person take photo of Graffiti art spelling out the words "WAFERSELAMAT", graffiti, white wall, dynamic color, spray paint,

Prompt: Close-up of LEGO chef minifigure cooking for homeless. Focus on LEGO hands using utensils, showing culinary skill. Warm kitchen lighting, late morning atmosphere. Canon EOS R5, 50mm f/1.4 lens. Capture intricate cooking techniques. Background hints at charitable setting. Inspired by Paul Bocuse and Massimo Bottura's styles. Freeze-frame moment of food preparation. Convey compassion and altruism through scene details.
Google’s new image diffusion model: https://www.reddit.com/r/singularity/comments/1eit2bd/google_gemini_appears_to_have_updated_their_image/





Lumina-GPT: https://github.com/Alpha-VLLM/Lumina-mGPT
A family of multimodal autoregressive models capable of various vision and language tasks, particularly excelling in generating flexible photorealistic images from text descriptions. 

HoloDreamer: Holistic 3D Panoramic World Generation from Text Descriptions https://x.com/_akhaliq/status/1815616891022418231
Extremely dynamic image to video: https://x.com/dreamingtulpa/status/1813486936868213073
Great prompt comprehension: https://arxiv.org/pdf/2406.18893
Image to animation: https://github.com/Fictiverse/ToonCrafter-for-windows
Photos to ads: https://www.reddit.com/r/StableDiffusion/comments/1dmv1mf/turn_your_boring_product_photos_into_professional/ 
GPT just churned out a 10-panel comic-book explaining "Gravitational Waves" in a one-shot prompt: https://x.com/electrik_dreams/status/1802421281876238354 
Much stronger control of image output:
 https://arxiv.org/pdf/2406.01300 
https://arxiv.org/pdf/2407.05282
https://arxiv.org/pdf/2407.03471


Our model significantly outperforms previous editing models as judged by human raters.
PartCrafter: Edit images using parts of other images: https://arxiv.org/pdf/2407.04604

Image diffusion is getting much better and faster/cheaper to train: https://arxiv.org/pdf/2403.04692 
Controllable video generation: https://arxiv.org/pdf/2405.20222v2 
https://huggingface.co/papers/2406.04324 
We show that, through the adversarial training, the multi-steps video diffusion model, i.e., Stable Video Diffusion (SVD), can be trained to perform single forward pass to synthesize high-quality videos, capturing both temporal and spatial dependencies in the video data. Extensive experiments demonstrate that our method achieves competitive generation quality of synthesized videos with significantly reduced computational overhead for the denoising process (i.e., around 23 times speedup compared with SVD and 6 times speedup compared with existing works, with even better generation quality), paving the way for real-time video synthesis and editing. 
https://huggingface.co/papers/2406.04277 
Specifically, we propose spatio-temporal compositional diffusion to precisely follow complex textual semantics by manipulating and composing the attention maps of denoising networks spatially and temporally. Moreover, we propose an enhanced video data preprocessing to enhance the training data regarding motion dynamics and prompt understanding, equipped with a new reference frame attention mechanism to improve the consistency of auto-regressive video generation. Extensive experiments demonstrate that our VideoTetris achieves impressive qualitative and quantitative results in compositional T2V generation. 
Image2Model
Microsoft and NUS introduce GenXD, a joint model for 3D and 4D generation: https://www.reddit.com/r/singularity/comments/1gk9vay/microsoft_and_nus_introduce_genxd_a_joint_model/
https://www.reddit.com/r/singularity/comments/1fjylow/tripo_v20_is_out_now_you_can_create_stunning_3d/
From 10 minutes to .5 seconds. Stability Ai Rapid 3D Asset Generation From Single Images: https://stability.ai/news/introducing-stable-fast-3d
Very consistent examples: https://x.com/emmanuel_2m/status/1796118855237939346 
Game made with 3D assets and textures made with AI: https://x.com/CSM_ai/status/1796200041280925713 
https://3d.makedraft.com/gallery 
https://charmed.ai/ 
https://medium.com/echo3d/7-generative-ai-tools-for-3d-asset-creation-97dd88153b7 
https://www.masterpiecex.com/blog/creating-usable-3d-models-with-generative-ai 
https://x.com/AIWarper/status/1797104351204524516 
https://costwen.github.io/Ouroboros3D/ 
https://jinkun-hao.github.io/Portrait3D/ 
Era3D: A new AI model that creates high-res 🗿3D images from multiple viewpoints using just one input image: https://x.com/Gradio/status/1795866944568000697 
- Generates high-quality images up to 512×512 pixels🎯
- Uses efficient row-wise attention to reduce computation⚡
- 12x more efficient than sota methods💪
Tailor3D can create customized 3D assets from text or single and dual-side images: https://x.com/dreamingtulpa/status/1812817042736632091
The method also supports adding changes to the inputs through additional text prompts.
Sparsecraft: https://x.com/_akhaliq/status/1815204831679664191 
our method, called SparseCraft, achieves state-of-the-art performances both in novel-view synthesis and reconstruction from sparse views in standard benchmarks, while requiring less than 10 minutes for training.
https://assetgen.github.io/

Retexturing 3D models: https://www.reddit.com/r/singularity/comments/1eev502/with_this_tool_you_can_texture_3d_models_with_ai/
MeshAnything V2: https://www.reddit.com/r/StableDiffusion/comments/1ela7od/meshanything_v2/
https://research.nvidia.com/labs/dir/edgerunner/
https://x.com/murchellcruft/status/1805679588627861632
https://x.com/nrqa__/status/1795469205934141463
BLENDERGPT - the fastest way to generate 3D assets and import them seamlessly into Blender. text to 3D in ~20 seconds: https://www.reddit.com/r/singularity/comments/1gk8x5j/blendergpt_the_fastest_way_to_generate_3d_assets/
NVIDIA's Edify 3D model quickly generates high-quality 3D assets from text or image prompts in under 2 minutes, using multi-view diffusion and transformers. With 4K textures, realistic materials and optimized mesh structures, it's a powerful scalable tool for simulation: https://www.reddit.com/r/singularity/comments/1gredul/nvidias_edify_3d_model_quickly_generates/
Blender implements generative AI: https://www.youtube.com/watch?v=uDxq8v5WEDs
Human camouflage:
https://www.reddit.com/r/StableDiffusion/s/f46LKOMj7q
Animation from a single image: https://www.reddit.com/r/StableDiffusion/comments/1d2saw7/its_coming_but_its_not_animateanyone/ 
Style change:
Papercraft: https://www.reddit.com/r/StableDiffusion/comments/1d2hdia/what_if_pixars_up_was_papercraft_style/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button
Pixel art: https://x.com/AIWarper/status/1792570014454727149
3D models: https://x.com/AIWarper/status/1780251522905083919
https://x.com/AIWarper/status/1811045840313799162 
Editing videos from one frame: https://i2vedit.github.io/ 
AI object removal: https://x.com/AIWarper/status/1795917964610351177 
Upscaling: https://github.com/Hillobar/Rope 
Image: 
Video: https://x.com/henryruhs/status/1795102994549055968 
Consistent upscaling: https://x.com/mervenoyann/status/1810592224830193781
Lip syncing: https://x.com/AIWarper/status/1795157663266881929 
VFX: https://x.com/AIWarper/status/1780663596181287317 
Replacing people in videos: 
https://x.com/AIWarper/status/1789011656049324075 
https://x.com/AIWarper/status/1779952562843848981
Alibaba presents MIMO: Controllable Character Video Synthesis with Spatial Decomposed Modeling: https://www.reddit.com/r/singularity/comments/1fp0ti3/alibaba_presents_mimo_controllable_character/
Morphing images together: https://x.com/krea_ai/status/1788465406971453814 
Image drag editing: https://x.com/dreamingtulpa/status/1795858080908890242 
ViViD can transfer a clothing item onto the video of a target person: https://x.com/dreamingtulpa/status/1795786351733772479 
The method is able to capture garment details and human posture, resulting in more coherent and lifelike videos.
Video movement: https://x.com/dreamingtulpa/status/1795698989708325273  
Adding moving objects in video: https://x.com/dreamingtulpa/status/1796062121215615031 
[Like photography, AI art is more complicated than a single button press](https://www.reddit.com/r/StableDiffusion/comments/1cjvw3k/image_realistic_composite_refine_comfyui_workflow/)
AI art generators are tools, similar to Photoshop or how cameras create images rather than the photographers yet we still consider them artists.
Digital art is still considered art even though not every part is hand-drawn (e.g. anti-aliasing, paint bucket tool, creating shapes, etc) and not every part of a photograph was set by the photographer (e.g. photos/videos of nature)
Intentionality does not matter in art, such as in action painting (where paint is “spontaneously dribbled, splashed or smeared onto the canvas, rather than being carefully applied” and the artist has no idea what the result will look like), and the works of famous artists like Jackson Pollock
AI art is very similar to photography. Both can be as simple as clicking a button or be much more complex. For example, creating with Stable Diffusion can involve using ControlNet, IPAdapter, animation extensions, very complicated ComfyUI workflows, and much more to get the result you want. Additionally, both involve a machine doing most of the actual creation process, where the camera/AI creates the images, while the artist guides it on what the end result should be and completes post-processing work.
Creating TV shows with diffusion: https://fablestudio.github.io/showrunner-agents/  
Very good control of output with text: https://ella-diffusion.github.io/ 
Image Consistency: 
https://arxiv.org/pdf/2404.18919
https://arxiv.org/pdf/2405.17661 (has video consistency too)
Consistent image to video: https://arxiv.org/pdf/2402.04324 
Midjourney character consistency: https://docs.midjourney.com/docs/character-reference 
https://x.com/fofrAI/status/1796547108478038355 
Very consistent video to video: https://www.reddit.com/r/StableDiffusion/comments/1dmed1s/diffutoon_highresolution_editable_toon_shading/ 
NVIDIA Research solved subject consistency: "Joint-image Diffusion Models for Finetuning-free Personalized Text-to-image Generation" https://research.nvidia.com/labs/dir/jedi/
AI images are getting VERY realistic: 
https://twitter.com/gdb/status/1790869434174746805?s=46
https://civitai.com/models/310571/boring-reality 
https://x.com/nickfloats/status/1794082708198420782 
https://x.com/doganuraldesign/status/1797397984629445015 
People accusing IRL video of being AI: https://x.com/toriel1one1/status/1799142881204249076 
https://x.com/MidjourneyEats
Guy commissioned and properly credited artists in the past, multiple times got backstabbed by artists who copy-striked his videos, threatening to take his channel down: https://www.youtube.com/watch?v=knUkXwJXcpY 
Toys R Us uses Sora generated promo: https://www.reddit.com/r/singularity/comments/1do7dah/toys_r_us_releases_sora_generated_promo/ 
Generating Anatomically Controllable Consistent Text-to-3D Animals: https://arxiv.org/pdf/2406.16273 
HOIFH generates synchronized object motion, full-body human motion, and detailed finger motion: https://hoifhli.github.io 
It is designed for manipulating large objects within contextual environments, guided by human-level instructions.
Merging image elements together: https://x.com/alex_peys/status/1806719131791876418 



H
High quality upscaling: https://shuweis.github.io/ResMaster/
Square Enix says it used AI art in upcoming Foamstars game: https://www.theverge.com/2024/1/16/24040124/square-enix-foamstars-ai-art-midjourney
Direct control over image generation: https://x.com/dreamingtulpa/status/1809654865724862917
Kling has realistic video generation despite a lack of compute: 
https://x.com/kimmonismus/status/1809322314225578158
https://x.com/tsumotokai/status/1810128665889685596
https://x.com/kimmonismus/status/1810547329356771827
https://x.com/CharaspowerAI/status/1810952037246349739
https://x.com/CharaspowerAI/status/1811105682000671147
https://www.reddit.com/r/aivideo/comments/1e0jyo9/anyone_know_which_ai_video_generator_did_this/
Good AI videos: 
OpenAI is already training a new version of Sora with even higher quality and longer videos: https://www.theinformation.com/articles/openai-is-revamping-sora-ai-video?utm_campaign=Editorial&utm_content=Newsletter%2CAI+Agenda&utm_medium=organic_social&utm_source=twitter
New SOTA coming soon: https://www.reddit.com/r/StableDiffusion/comments/1ejcw66/blackforestlabs_txt2vid_looks_insane/
https://x.com/kimmonismus/status/1811727094499385347
https://www.reddit.com/r/ChatGPT/comments/1dyb2bq/unanswered_oddities_aigenerated_tv_show/
https://x.com/Diesol/status/1810468576882770109
https://x.com/kimmonismus/status/1810949448584855729
https://x.com/shanef3d/status/1811505820129214687
https://x.com/ai_for_success/status/1811576761617928300
Hands: https://x.com/arohaAIX/status/1811381195676307623
https://www.reddit.com/r/aiwars/comments/1e0hwiq/mixing_ai_music_suno_and_ai_video_runway/
https://www.reddit.com/r/aivideo/comments/1e1nhn5/poof/
https://x.com/CharaspowerAI/status/1812531456452747276
https://www.reddit.com/r/singularity/comments/1e88t8j/another_kling_ai_clip/
Grand Theft Auto in India: https://www.reddit.com/r/aivideo/comments/1e7zrk5/grand_theft_auto_india_gameplay_trailer/
https://x.com/runwayml/status/1816096185016357030
Apples to guinea pigs: https://www.reddit.com/r/aivideo/comments/1ecf1is/apples_or_hamsters/
Person speaking: https://www.reddit.com/r/singularity/comments/1f4fv05/ai_movies_are_coming/
https://www.reddit.com/r/aivideo/comments/1f527rg/just_going_for_a_lil_walk/
Burger King commercial parody: https://www.reddit.com/r/aivideo/comments/1fao9w0/i_created_a_burger_commercial_using_ai/
drag-and-drop a subject from an image with an arbitrary style onto another target image with a vastly different style and achieve a style-aware and realistic insertion of the subject into the target image: https://magicinsert.github.io/
Image movement: https://x.com/dreamingtulpa/status/1753710085447074104
Adding and tweaking concepts to a pre-existing image: https://x.com/gytdau/status/1811530283747000386
Runway Gen-3 Alpha can simulate liquids such as water, paint, oil, honey and molten glass. All with realistic viscosity, physics-based interactivity and caustics: https://x.com/runwayml/status/1811751431453450449
Image + motion to video: https://github.com/tencent/MimicMotion
InfiniteCraft uses AI: https://neal.fun/infinite-craft/
Adding sound to video: https://x.com/dreamingtulpa/status/1812518092557193604
M2S is a new DDPM-based image inpainting method that is 60 times faster than RePaint: https://github.com/linghuyuhangyuan/M2S

Combining AI with CGI: https://x.com/c_valenzuelab/status/1813954465667457412
McDonalds ad: https://www.reddit.com/r/aivideo/comments/1e7x5in/mcdonalds_ai_spec_ad_cost_me_less_than_60_happy/
Dynamic 3D Content Generation with Multi-Frame and Multi-View Consistency: We present Stable Video 4D (SV4D), a latent video diffusion model for multi-frame and multi-view consistent dynamic 3D content generation. Unlike previous methods that rely on separately trained https://x.com/dreamingtulpa/status/1816146758608605362
Similar to creative upscaling in images, Noise Calibration can improve the visual quality of videos while maintaining the structure of the input video: https://x.com/dreamingtulpa/status/1816441922589708291
Excellent video to video: https://x.com/8bit_e/status/1818246916129329464
LumaLabsAI - Dream Machine 1.5 is here. Now with higher-quality text-to-video, smarter understanding of your prompts, custom text rendering, and improved image-to-video: https://x.com/LumaLabsAI/status/1825639918539817101
Ideagram 2.0: https://www.reddit.com/r/singularity/comments/1exsq4d/introducing_ideogram_20_our_most_advanced/
Adding movement to images: https://www.reddit.com/r/singularity/comments/1fk4tgp/kling_ai_showcasing_the_use_of_the_motion_brush/
Kling is about to release a tool for character consistency. They are on a path towards making full AI movies: https://www.reddit.com/r/singularity/comments/1gn6jq3/kling_is_about_to_release_a_tool_for_character/
Runway | Introducing Frames - An image generation model offering unprecedented stylistic control: https://www.reddit.com/r/singularity/comments/1gzkjg8/runway_introducing_frames_an_image_generation/
https://openreview.net/pdf?id=u1cQYxRI1H


New image generation model from Luma: https://lumalabs.ai/photon



Prompt: Photo-realistic cat made out of peeled oranges

Prompt: A plate of sushi, where the fish is replaced with translucent sea waves and tiny surfers ride on top.

















Sora 2 leaked: https://www.reddit.com/r/singularity/comments/1h9ii94/sora_2_leaked_looks_impressive/
Use of Sora AI video generator with video to video: https://x.com/dreamingtulpa/status/1866882603519021313
Veo 2 beats Sora: https://deepmind.google/technologies/veo/veo-2/

11.2. Quality/Soul
Direct link: https://docs.google.com/document/d/1oHuwssPPUTa4dwczX_s3qg3iPfWE4VK-R52LN51GwI8/edit?tab=t.0#heading=h.ew2v9spc8v47

See section 15.3 for awards won and accomplishments 
 
First legally recognized nonbinary person with disabilities writes book with ChatGPT: https://www.wired.com/story/the-us-copyright-office-loosens-up-a-little-on-ai/

The novel draws from Shupe’s eventful life, including her advocacy for more inclusive gender recognition.
Shupe believes fervently that she was only able to complete her book with the assistance of generative AI tools. She says she has been assessed as 100 percent disabled by the Department of Veterans Affairs and struggles to write due to cognitive impairment related to conditions including bipolar disorder, borderline personality disorder, and a brain stem malformation.
She is proud of the finished work and sees working with a text generator as a different but no less worthwhile method of expressing thoughts. “You don't just hit ‘generate’ and get something worthy of publishing. That may come in the future, but we're still far from it,” she says, noting that she spent upwards of 14 hours a day working on her draft.

Excellent amateur quality AI photos: https://www.reddit.com/r/StableDiffusion/comments/1f57zae/school_trip_in_2004_lora/

Diffusion models as real-time interactive game engines: https://gamengen.github.io/

Runway Gen-3 Alpha can simulate liquids such as water, paint, oil, honey and molten glass. All with realistic viscosity, physics-based interactivity and caustics: https://x.com/runwayml/status/1811751431453450449


Many people, including AI haters, couldnt tell it’s AI generated: 
https://x.com/midosommar/status/1843013374919241868
https://x.com/beyoncesspamacc/status/1843094040851726800
And no photoshop was involved: https://x.com/2byStanuby/status/1843456682392801662
AI generated video gets thousands of upvotes on Reddit: https://www.reddit.com/r/singularity/comments/1gh5p1y/ai_generated_video_gets_thousands_of_upvotes_on/
Their Youtube profile - has a lot of these bird videos. 130 mill views on 65 AI videos from August to October 2024.
https://www.youtube.com/@TinyPawsHugs
People accuse real video of being AI-generated: https://x.com/oncloud_e/status/1847036245916242248
https://www.reddit.com/r/NeuroSama/comments/1hhvh92/zero_day/

Many small details in text on screen
“I started on Sunday and then worked on this image every evening, after 9 hours of my actual job, until this day” - https://www.reddit.com/r/NeuroSama/comments/1hhvh92/comment/m2u8os1/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button
https://www.pixiv.net/en/artworks/124145238

Notice details in photos and background
https://www.pixiv.net/en/artworks/123624604


https://www.reddit.com/r/singularity/comments/1hmrzvd/comment/m3whgtz/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_button
https://x.com/kodoku0322/




















https://x.com/Sironekogirl_AI







https://x.com/Garnet546223147
















https://x.com/Rin1732996





https://x.com/pamu_craft_









https://x.com/Fii_artworks_ai/status/1871662135815614483




https://www.reddit.com/r/ChatGPT/comments/1hhwluh/peaceful_dragon/

https://civitai.green/images/41907972

https://civitai.green/images/47288159

https://tensor.art/images/787353241521301709?model_id=787353065419253689


https://www.reddit.com/r/aiArt/comments/1gn4od3/realism_with_recraft/





New open source AI image generator beats Midjourney: https://blackforestlabs.ai/announcing-black-forest-labs/
API costs $0.025 per image. It's cheaper than Dalle 3 and can do realism.


Very realistic images: https://www.reddit.com/r/singularity/comments/1ej1etp/flux_can_generate_really_good_fake_low_quality/ 






Prompt: Gameplay screenshot of Counter Strike Global Offensive. It takes place in a Middle Eastern place called Dust 2. There are enemy soldiers shooting at you.

Prompt: low quality and motion blur shaky photo of a CRT television on top of a wooden drawer in an average bedroom. The lighting from is dim and warm ceiling light that is off screen. In the TV there is Dark Souls videogame gameplay on it. The screen of the TV is overexposed.



Created on first try. Robe and hands are perfect 

First attempt: "Photo of a red sphere on top of a blue cube. Behind them is a green triangle, on the right of the triangle is a dog, on the left is a cat."

Prompt: person take photo of Graffiti art spelling out the words "WAFERSELAMAT", graffiti, white wall, dynamic color, spray paint,

Prompt: Close-up of LEGO chef minifigure cooking for homeless. Focus on LEGO hands using utensils, showing culinary skill. Warm kitchen lighting, late morning atmosphere. Canon EOS R5, 50mm f/1.4 lens. Capture intricate cooking techniques. Background hints at charitable setting. Inspired by Paul Bocuse and Massimo Bottura's styles. Freeze-frame moment of food preparation. Convey compassion and altruism through scene details.

Google’s new image diffusion model: https://www.reddit.com/r/singularity/comments/1eit2bd/google_gemini_appears_to_have_updated_their_image/






DiT-10B can surpass DALLE-3 and Stable Diffusion 3 in both image-text alignment and image quality. The API will be available next week: https://www.reddit.com/r/StableDiffusion/comments/1djddik/lidit10b_can_surpass_dalle3_and_stable_diffusion/ 

AI used by official Disney show for intro: https://www.polygon.com/23767640/ai-mcu-secret-invasion-opening-credits

“Runway's tools and AI models have been utilized in films such as Everything Everywhere All At Once, in music videos for artists including A$AP Rocky, Kanye West, Brockhampton, and The Dandy Warhols, and in editing television shows like The Late Show and Top Gear.” 

https://en.wikipedia.org/wiki/Runway_(company)

https://www.theverge.com/2024/1/16/24040124/square-enix-foamstars-ai-art-midjourney

>AI technology has been seeping into game development to mixed reception. Xbox has partnered with Inworld AI to develop tools for developers to generate AI NPCs, quests, and stories. The Finals, a free-to-play multiplayer shooter, was criticized by voice actors for its use of text-to-speech programs to generate voices. Despite the backlash, the game has a mostly positive rating on Steam and is in the top 20 of most played games on the platform.

High quality video game characters: https://www.reddit.com/r/midjourney/comments/1dnbm78/characters_from_games/#lightbox

Great images: 
https://www.reddit.com/r/midjourney/comments/1bnm357/crashed_cybertruck/?share_id=BrM6plj1Yja58nGZUmG7c&utm_content=1&utm_medium=ios_app&utm_name=ioscss&utm_source=share&utm_term=1

https://checkyourfact.com/2024/06/19/fact-check-crash-involving-two-cybertrucks-ai-generated/

https://x.com/RogerHaus/status/1808130565284954421/photo/1

https://isitai.com/detection-result/ai-person-in-yellow-dress/



https://civitai.com/images/17391786



https://aibooru.online/posts/95465


https://civitai.com/images/22103284


https://civitai.green/images/43413030
https://civitai.com/models/926443?modelVersionId=1159421





https://civitai.com/models/926443/ntr-mix-or-illustrious-xl-or-noob-xl?modelVersionId=1061268





















https://civitai.com/models/926443?modelVersionId=115256


https://civitai.com/images/46549136

https://civitai.com/images/44529149
https://civitai.com/models/693303/neonmonochrome-style-ilxl-ponyxl?modelVersionId=1206136






https://civitai.com/images/43357204

https://civitai.com/images/43411460

https://civitai.com/images/44335522

https://civitai.com/images/44303743

https://civitai.com/images/44303771

https://civitai.com/images/44303788

https://civitai.com/images/42635563

https://aibooru.online/posts/97930?q=hannibal_lecter_%28artist%29

https://aibooru.online/posts/97929?q=hannibal_lecter_%28artist%29

https://x.com/Emily_Escapor/status/1867964262649676129

https://x.com/babs69420/status/1868015833588675051

https://aibooru.online/posts/98102?q=ntr-mix-illustriousxl

https://civitai.com/images/45741092




https://civitai.com/images/13164349

https://civitai.com/images/13164240

https://civitai.com/images/13164165

https://civitai.com/images/13164163

https://x.com/stevegilham1/status/1867979572102201599



https://x.com/RichardGossmann/status/1868166962947493996

https://www.astralcodexten.com/p/how-did-you-do-on-the-ai-art-turing




https://x.com/dreamingtulpa/status/1868326926315888790

https://x.com/Saundersnp/status/1868331242799898865

https://x.com/its_me_remi/status/1868336653892571312

https://x.com/cyberocelot29/status/1868345224222982480

https://x.com/yaddlezap/status/1868336503123816736

https://www.reddit.com/r/StableDiffusion/comments/1gj6zmi/flux_dev1_lora_is/

https://www.reddit.com/r/StableDiffusion/comments/1giezam/having_a_good_time_with_sd_35_mediums_ability_to/



https://www.reddit.com/r/StableDiffusion/comments/1gh7xd2/pixelwave_is_by_far_the_best_flux_finetune_out/


















https://x.com/fofrAI/status/1854262904264020248





https://civitai.green/images/42651793

https://civitai.green/images/22699921

https://civitai.com/images/41550710

https://civitai.com/images/39917487

https://civitai.com/images/42130168

https://civitai.com/images/44303796

https://civitai.com/images/44303803

https://civitai.com/images/44539515

https://civitai.com/images/44690707

https://civitai.green/images/22699929

https://civitai.green/images/24217623

https://civitai.green/images/24217970

https://civitai.green/images/33540891

https://civitai.com/images/37414606

https://civitai.com/images/37410111

https://civitai.com/images/37791130
https://civitai.green/models/810392/ebiblue-gesugao-style-illustriousxl-lora?modelVersionId=906217













https://civitai.green/images/42846236

https://civitai.green/images/43319185

https://civitai.green/images/42986647

https://civitai.green/images/42548291

https://civitai.green/images/43033367

https://civitai.green/images/42503316


https://civitai.green/images/42966060

https://civitai.green/images/43507799

https://civitai.green/images/42989106

https://civitai.com/images/43533713

https://civitai.com/images/43517696

https://civitai.com/images/43518261

https://civitai.com/images/43534014

https://civitai.com/images/43506713

https://civitai.com/images/43536424

https://civitai.com/images/43510865

https://civitai.com/images/43508987

https://arxiv.org/abs/2409.19946

https://civitai.green/images/32209482

https://civitai.green/images/27860422

https://civitai.green/images/33845987

https://civitai.green/images/42902431
https://www.reddit.com/r/midjourney/comments/1h5ke39/my_favorite_creations_from_1000_images_inspired/




https://civitai.green/images/42377599

https://civitai.green/images/42364160

https://civitai.green/images/42394674

https://civitai.green/images/42491640

https://civitai.green/images/42437652

https://civitai.green/images/42184274

https://civitai.green/images/41536618

https://civitai.green/images/31793767

https://civitai.green/images/23902810

https://civitai.green/images/23902805

https://civitai.green/images/23902806

https://civitai.green/images/39859420

https://civitai.green/images/38883838

https://civitai.green/images/39002348

https://civitai.green/images/27468368

https://civitai.green/images/24027990

https://civitai.green/images/25896443

https://civitai.green/images/26403171

https://civitai.green/images/38233414

https://civitai.green/images/24600296

https://civitai.com/images/35072912

https://civitai.com/images/35980641

https://civitai.com/images/37791624

https://civitai.com/images/37409118

https://civitai.com/images/37216672

https://civitai.com/images/37792388

https://civitai.com/images/36370301



https://civitai.com/images/40097344

https://civitai.com/images/40942430

https://civitai.com/images/42060016

https://civitai.com/images/42378752

https://civitai.com/images/42157296

https://civitai.com/images/42060015


https://civitai.com/images/42060008

https://civitai.com/images/42060009

https://civitai.com/images/41184933

https://civitai.com/images/39719052

https://civitai.com/images/38324832

https://civitai.com/images/42909383

https://x.com/MustangMan_TX/status/1849975999905267941

https://civitai.com/images/10703900

https://civitai.com/images/25624025

https://civitai.com/images/14614776

https://civitai.com/images/34601798

https://civitai.com/images/34798101

https://civitai.com/images/34532010

https://civitai.com/images/34519978

https://civitai.com/images/34702343

https://civitai.com/images/34747527

https://civitai.com/images/32477178

https://civitai.com/images/31459655

https://civitai.com/images/33529460

https://civitai.com/images/31455357

https://civitai.com/images/31458079

https://civitai.com/images/33681154

https://civitai.com/images/33502269

https://civitai.com/images/33670042

https://civitai.com/images/31296140

https://civitai.com/images/32641269

https://civitai.com/images/33480744

https://civitai.com/images/34747512 

https://civitai.com/images/24315213

https://civitai.com/images/9219897

https://civitai.com/images/15565887

https://civitai.com/images/13073993

https://civitai.com/images/25309799

https://civitai.com/images/25788822

https://civitai.com/images/25304285

https://civitai.com/images/26139677

https://civitai.com/images/25121505


https://civitai.com/images/18029224


https://civitai.com/images/10556898


https://civitai.com/images/11871535


https://civitai.com/images/9173928


https://civitai.com/images/15234021


https://civitai.com/images/17108902

https://civitai.com/images/23487588

https://civitai.com/images/21052667

https://civitai.com/images/29966073

https://civitai.com/images/30212103

https://civitai.com/images/30207996

https://civitai.com/images/30146245

https://civitai.com/images/30216976

https://civitai.com/images/30597000

https://civitai.com/images/30104097


https://civitai.com/images/26929838

https://civitai.com/images/27572488

https://civitai.com/images/23957380

https://civitai.com/images/27585666

https://civitai.com/images/27585338

https://civitai.com/images/21329840

https://civitai.com/images/32271527

https://civitai.com/images/27570470

https://civitai.com/images/27763004

https://civitai.com/images/27565856

https://civitai.com/images/27361846

https://civitai.com/images/27574560

https://civitai.com/images/27315366

https://civitai.com/images/26888438

https://civitai.com/images/27513824

https://civitai.com/images/24641975

https://civitai.com/images/25605628

https://civitai.com/images/19114796

https://civitai.com/images/26780730

https://civitai.com/images/24609254

https://civitai.com/images/25613929

https://civitai.com/images/25281783

https://civitai.com/images/25159359

https://civitai.com/images/25932335

https://civitai.com/images/23990027

https://civitai.com/images/23849851

https://civitai.com/images/26128780

https://civitai.com/images/718471

https://civitai.com/images/25941621

https://civitai.com/images/26697324

https://civitai.com/images/11029293

https://civitai.com/images/25148210

https://civitai.com/images/25301409

https://civitai.com/images/25777852

https://civitai.com/images/16255071

https://civitai.com/images/9022765

https://civitai.com/images/13166175

https://civitai.com/images/18004690

https://civitai.com/images/30520218

https://civitai.com/images/21454911

https://civitai.com/images/25617160

https://civitai.com/images/23361289

https://civitai.com/images/30249134

https://civitai.com/images/29817639

https://civitai.com/images/32628093
https://civitai.com/models/943607/748cm-or-style-for-illustriousnoobai-075?modelVersionId=1056404	











































































https://civitai.com/images/20625052










https://civitai.com/models/926443?modelVersionId=1166878
















https://civitai.com/models/988416?modelVersionId=1117413

























https://civitai.com/models/176554?modelVersionId=959419









https://civitai.com/models/833294?modelVersionId=1165792






https://civitai.com/images/45912346

https://civitai.com/images/45666028

https://civitai.com/images/45948525

https://civitai.com/images/46218912

https://civitai.com/images/45777943

https://civitai.com/images/46010543

https://civitai.com/user/septya_j









https://civitai.com/images/45649436

https://civitai.com/images/45620838

https://civitai.com/images/45799984
 
https://civitai.com/models/967256?modelVersionId=1165792






https://civitai.com/models/930648?modelVersionId=1041731











https://civitai.com/images/32439181

https://aibooru.online/posts/92157

https://aibooru.online/posts/92156

https://aibooru.online/posts/92161

https://aibooru.online/posts/92159

https://aibooru.online/posts/92158

https://aibooru.online/posts/88128

https://aibooru.online/posts/85929

https://aibooru.online/posts/85302

https://aibooru.online/posts/84882

https://aibooru.online/posts/75904

https://civitai.com/images/36361030

https://civitai.com/images/32281291

All text is AI generated

https://x.com/ai_shame/status/1850662527874617505

https://civitai.com/images/32477178

https://civitai.com/images/13824757

https://civitai.com/images/26541023

https://civitai.com/images/32641269

https://civitai.com/images/23991007

https://civitai.com/images/13774580

https://civitai.com/images/25679756


https://civitai.com/images/24955975





https://civitai.com/models/689192/aesthetic-amateur-photo-flux-dev
 
https://x.com/mrsballs69/status/1839037286576697784






















https://civitai.com/models/724495/1999-digital-camera-style-olympus-d-450

https://x.com/kattlatte/status/1810336325087694992

https://x.com/Gavin_BIC/status/1811516467411845425

https://x.com/lummipics/status/1811409862464532684

https://x.com/lummipics/status/1831399579993960821



https://x.com/lummipics/status/1829531772792827977


https://x.com/bri_guy_ai/status/1811084147051372717/photo/1
https://www.reddit.com/r/aiwars/comments/1h1nckc/artist_hating_on_ai_are_biased_and_they_cant_tell/



https://x.com/Artedeingenio/status/1811750372366533027








https://x.com/LudovicCreator/status/1811679395712479546


https://x.com/ThysaniaRegina/status/1811389409666924781

https://x.com/bri_guy_ai/status/1811753268344766537

https://x.com/dreamingtulpa/status/1811381630428155941


https://x.com/RobotCleopatra/status/1812573536592302253


https://x.com/digitallywired/status/1812481019301200321
Official Resident Evil account uses AI art: https://x.com/REBHPortal/status/1871587406958428305




https://x.com/jacaeryslg/status/1843546283652587910

https://www.reddit.com/r/StableDiffusion/comments/1fak0jl/finally_an_update_on_improved_training_approaches/









https://www.reddit.com/r/aiwars/comments/1fr4ov0/text_to_image_is_getting_so_good_at_text_and_more/

https://x.com/javilopen/status/1831753822890602662











AI art with 5.2k upvotes that many people in the comments did not realize is AI: https://www.reddit.com/r/Frieren/comments/1gam9w7/frieren_x_himmel_by_ulyssesx00 


AI art with 205k likes: https://x.com/pon_pon_pon_ai/status/1834916150301671471 



https://www.reddit.com/r/aiArt/comments/1f8oqi9/majestic_peacock_and_its_cosmic_feather/


https://x.com/dreamingtulpa/status/1872379368112304263

https://x.com/dreamingtulpa/status/1872549237726310501
https://x.com/748cm






























https://x.com/Rin1732996/status/1872597026120274401

https://x.com/tiksca2299





















https://x.com/01001000011010X/status/1871545081326637214
https://www.reddit.com/r/NeuroSama/comments/1hoaxrd/cute_neuro_made_with_ai/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button




https://x.com/Schizoonthemic/status/1873017572012216460
632 likes
Everything on here: https://x.com/bettrthanbeeple









https://x.com/nickfloats/status/1813290295964176561


Kling has realistic video generation despite a lack of compute: 
https://x.com/kimmonismus/status/1809322314225578158
https://x.com/_akhaliq/status/1813578798283255823


This was done in less than 24h by one person using AI as the ground tooling, some post in AE and that’s it. Imagine the time and cost a real spot like this would cost. 100x less expensive due to AI: https://www.reddit.com/r/singularity/comments/1dyh5z3/this_was_done_in_less_than_24h_by_one_person/

Popular AI generated memes:

https://knowyourmeme.com/memes/mr-chedda
Many comments stating the human-made version is worse than the AI-generated one: https://x.com/zxnoshima/status/1791227049928994867


https://x.com/CitizenPlain/status/1316760510709338112


https://knowyourmeme.com/memes/ash-baby-screaming-baby-made-of-ash



https://knowyourmeme.com/memes/angry-dr-mario-dr-marios-origin-story-ai-video

https://knowyourmeme.com/memes/dope-flaming-shrimp-dunking-over-some-sharks

https://x.com/TheFigen_/status/1790803489859187112
(20k likes)


https://knowyourmeme.com/memes/biden-shout

https://chatgpt.com/share/6722cbef-cf54-8000-b2be-61636a66da04

https://www.reddit.com/r/ChatGPT/comments/1gfih4y/asked_chatgpt_to_show_me_a_shtpost/


AI meme with 169k likes: https://x.com/Skvlvtvn/status/1843335191890424218

https://trending.knowyourmeme.com/editorials/guides/what-is-the-how-do-you-spell-chauffeur-song-tiktoks-viral-fancy-pants-rich-mcgee-meme-explained
https://x.com/haultrukkz/status/1799490974151799174
https://x.com/FacebookAIslop/status/1804419391255093269
(everyone likes the art)

https://x.com/umesh_ai/status/1812031272408994083

130k likes on AI image: https://x.com/picsthatg0hard_/status/1814537639082795480
101k likes on AI meme: https://x.com/waystarroyhoe/status/1825298333985824874
AI meme with 80k likes: https://x.com/bigdybbukenergy/status/1847382264877109264
AI used for meme with 32k likes: https://x.com/Ovirtuous_/status/1847723007198056855
90k likes on AI image of Snoop Dogg in the style of Studio Ghibli: https://x.com/90sPiictures/status/1830968058401431575

AI images are getting very realistic
https://x.com/nickfloats/status/1795525684628242906 
https://x.com/nickfloats/status/1794082708198420782 
https://x.com/gdb/status/1790869434174746805 
https://civitai.com/models/310571/boring-reality 
https://x.com/nickfloats/status/1794082708198420782 
https://x.com/doganuraldesign/status/1797397984629445015 
https://x.com/ARTiV3RSE/status/1809708250243432777
UltraPixel is now on Replicate. Based on Stable Cascade, you can use it to make up to 4096x4096 images without upscaling: https://x.com/fofrAI/status/1815043204086956444
Juggernaut XI World Wide Release | Better Prompt Adherence | Text Generation | Styling: https://www.reddit.com/r/StableDiffusion/comments/1f4369h/juggernaut_xi_world_wide_release_better_prompt/

Kling has realistic video generation despite a lack of compute: 
https://x.com/kimmonismus/status/1809322314225578158
https://x.com/tsumotokai/status/1810128665889685596
https://x.com/kimmonismus/status/1810547329356771827
https://x.com/CharaspowerAI/status/1810952037246349739
https://x.com/CharaspowerAI/status/1811105682000671147
https://www.reddit.com/r/aivideo/comments/1e0jyo9/anyone_know_which_ai_video_generator_did_this/
Good AI videos: 
New SOTA coming soon: https://www.reddit.com/r/StableDiffusion/comments/1ejcw66/blackforestlabs_txt2vid_looks_insane/
https://x.com/kimmonismus/status/1811727094499385347
https://www.reddit.com/r/ChatGPT/comments/1dyb2bq/unanswered_oddities_aigenerated_tv_show/
https://x.com/Diesol/status/1810468576882770109
https://x.com/kimmonismus/status/1810949448584855729
https://x.com/shanef3d/status/1811505820129214687
https://x.com/ai_for_success/status/1811576761617928300
Hands: https://x.com/arohaAIX/status/1811381195676307623
https://www.reddit.com/r/aiwars/comments/1e0hwiq/mixing_ai_music_suno_and_ai_video_runway/
https://www.reddit.com/r/aivideo/comments/1e1nhn5/poof/
https://x.com/CharaspowerAI/status/1812531456452747276
https://www.reddit.com/r/singularity/comments/1e88t8j/another_kling_ai_clip/
Grand Theft Auto in India: https://www.reddit.com/r/aivideo/comments/1e7zrk5/grand_theft_auto_india_gameplay_trailer/
https://x.com/runwayml/status/1816096185016357030
Apples to guinea pigs: https://www.reddit.com/r/aivideo/comments/1ecf1is/apples_or_hamsters/
Person speaking: https://www.reddit.com/r/singularity/comments/1f4fv05/ai_movies_are_coming/
https://www.reddit.com/r/aivideo/comments/1f527rg/just_going_for_a_lil_walk/
Burger King commercial parody: https://www.reddit.com/r/aivideo/comments/1fao9w0/i_created_a_burger_commercial_using_ai/
Runway and Lionsgate are partnering to explore the use of AI in film production: https://runwayml.com/news/runway-partners-with-lionsgate
Late Night With the Devil movie uses AI art: https://letterboxd.com/film/late-night-with-the-devil/
Recommended by Chainsaw Man/Look Back/Goodbye Eri author Tatsuki Fujimoto: 
Other people like it too: https://www.reddit.com/r/Chainsawfolk/comments/1fvsr5c/fujiwater_recommends_peak/
3.4 out of 5 on Letterboxed despite anti AI review bombing (very good movies typically receive a 3.5-4.0)
Disney is set to announce a major AI initiative that will transform its creative output. The initiative is said to involve “hundreds” of people at the company and will primarily focus on post-production and visual effects: https://www.thewrap.com/disney-ai-initiative/
https://www.recraft.ai/blog/recraft-introduces-a-revolutionary-ai-model-that-thinks-in-design-language


Style control: 

AI video gets 6k upvotes on Reddit on non-AI subreddit: https://www.reddit.com/r/HardVideos/comments/1hc76tq/idc_its_ai_slop_this_is_hard/
AI video of Luigi Mangione gets 71k likes on Twitter: https://x.com/skyferrori/status/1871284925976265173
AI cosplays: https://www.reddit.com/r/aivideo/comments/1hkx27x/titans/


11.2.1. People Can’t Always Tell It’s AI
Direct link: https://docs.google.com/document/d/1oHuwssPPUTa4dwczX_s3qg3iPfWE4VK-R52LN51GwI8/edit?tab=t.0#heading=h.9bb1alnimwiu

https://www.astralcodexten.com/p/how-did-you-do-on-the-ai-art-turing
Since there were two choices (human or AI), blind chance would produce a score of 50%, and perfect skill a score of 100%.


The median score on the test was 60%, only a little above chance. The mean was 60.6%. Participants said the task was harder than expected (median difficulty 4 on a 1-5 scale).
This is despite the fact that they could have just looked online to find the original image.
The 1278 people who said they utterly loathed AI art (score of 1 on a 1-5 Likert scale) still preferred AI paintings to humans when they didn't know which were which (the #1 and #2 paintings most often selected as their favorite were still AI, as were 50% of their top ten).
Out of 50 images 

So in a 50-50 mix of AI and human 19th century art, they would incorrectly guess it was 75-25 human; in a 50-50 mix of digital art, they would incorrectly guess it was only 31% human.
"I asked participants to pick their favorite picture of 50. The 2 best-liked pictures were both by AI, as were 6 of the top 10
people who were professional artists and hated AI art scored 68% for categorizing AI vs. human-made art (random chance is 50%)"
This is despite the fact that they could have just looked online to find the original image.
The highest score was 98% (49/50), which 5 out of 11,000 people achieved. 
Alan Turing recommended that if 30% of humans couldn’t tell an AI from a human, the AI could be considered to have “passed” the Turing Test. By these standards, AI artists pass the test with room to spare; on average, 40% of humans mistook each AI picture for human.
Since there were two choices (human or AI), blind chance would produce a score of 50%, and perfect skill a score of 100%.
The median score on the test was 60%, only a little above chance. The mean was 60.6%. Participants said the task was harder than expected (median difficulty 4 on a 1-5 scale).
AI-generated poetry from the VERY OUTDATED GPT 3.5 is ranked significantly higher than poetry written by famous poets: https://www.nature.com/articles/s41598-024-76900-1
AI-generated paintings are judged to be human-created artworks at higher rates than actual human-created paintings; AI-generated faces are judged to be real human faces at higher rate than actual photos of human faces, and AI-generated humor is just as funny as human-generated jokes. Despite this, studies have consistently found a bias against AI-generated artwork; when told that an artwork is AI-generated, participants rate the work as lower quality.
We conducted two experiments with non-expert poetry readers and found that participants performed below chance levels in identifying AI-generated poems (46.6% accuracy, χ2(1, N = 16,340) = 75.13, p < 0.0001). Notably, participants were more likely to judge AI-generated poems as human-authored than actual human-authored poems (χ2(2, N = 16,340) = 247.04, p < 0.0001). We found that AI-generated poems were rated more favorably in qualities such as rhythm and beauty, and that this contributed to their mistaken identification as human-authored.



Anti-AI artist admits AI art is nearly impossible to tell apart from human-made art: https://x.com/DEADTOONZZ/status/1857615840159334762?t=pDcwzbHlcIgUiE1kTTb1Yg&s=19
Artists tricked by AI again: https://www.reddit.com/r/aiwars/comments/1h1nckc/artist_hating_on_ai_are_biased_and_they_cant_tell/

Many people, including AI haters, couldnt tell it’s AI generated: 
https://x.com/midosommar/status/1843013374919241868
https://x.com/beyoncesspamacc/status/1843094040851726800
And no photoshop was involved: https://x.com/2byStanuby/status/1843456682392801662
Tweet of AI generated image receives 22k likes and no one in the replies noticed: https://x.com/Thinkwert/status/1869186212948484324

AI-generated poetry from the VERY outdated GPT 3.5 is indistinguishable from human-written poetry and is rated more favorably: https://idp.nature.com/authorize?response_type=cookie&client_id=grover&redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-024-76900-1


https://www.nature.com/articles/s41598-023-45202-3?fromPaywallRec=false
 We find that people devalue art labeled as AI-made across a variety of dimensions, even when they report it is indistinguishable from human-made art, and even when they believe it was produced collaboratively with a human. We also find that comparing images labeled as human-made to images labeled as AI-made increases perceptions of human creativity, an effect that can be leveraged to increase the value of human effort. Results are robust across six experiments (N = 2965) using a range of human-made and AI-made stimuli and incorporating representative samples of the US population. Finally, we highlight conditions that strengthen effects as well as dimensions where AI-devaluation effects are more pronounced.
our first two experiments were run in 2017 and 2018, before the more recent introduction of AI-art innovations like Midjourney and DALL-E2. In contrast, our last experiment was run in 2023 just as Midjourney Version 4 and DALL-E2 were beginning to reach a national audience. 
This was before the release of higher quality models like Flux and Ilustrious
Tweet with 81k likes contains AI art and no one in the replies noticed: https://x.com/diveinreactor/status/1869134035693535248


AI generated video gets over 12k upvotes on Reddit: https://www.reddit.com/r/singularity/comments/1gh5p1y/ai_generated_video_gets_thousands_of_upvotes_on/
Their Youtube profile - has a lot of these bird videos. 130 mill views on 65 AI videos from August to October 2024.
https://www.youtube.com/@TinyPawsHugs
People accuse real video of being AI-generated: https://x.com/oncloud_e/status/1847036245916242248
AI image won Colorado state fair https://www.cnn.com/2022/09/03/tech/ai-art-fair-winner-controversy/index.html

>You can feed a phrase like “an oil painting of an angry strawberry” to Midjourney and receive several images from the AI system within seconds, but Allen’s process wasn’t that simple. To get the final three images he entered in the competition, he said, took more than 80 hours.
First, he said, he played around with phrasing that led Midjourney to generate images of women in frilly dresses and space helmets — he was trying to mash up Victorian-style costuming with space themes, he said. Over time, with many slight tweaks to his written prompt (such as to adjust lighting and color harmony), he created 900 iterations of what led to his final three images. He cleaned up those three images in Photoshop, such as by giving one of the female figures in his winning image a head with wavy, dark hair after Midjourney had rendered her headless. Then he ran the images through another software program called Gigapixel AI that can improve resolution and had the images printed on canvas at a local print shop.

>Cal Duran, an artist and art teacher who was one of the judges for competition, said that while Allen’s piece included a mention of Midjourney, he didn’t realize that it was generated by AI when judging it. Still, he sticks by his decision to award it first place in its category, he said, calling it a “beautiful piece”.

>“I think there’s a lot involved in this piece and I think the AI technology may give more opportunities to people who may not find themselves artists in the conventional way,” he said.

AI image won in the Sony World Photography Awards: https://www.scientificamerican.com/article/how-my-ai-image-won-a-major-photography-competition/ 

AI image wins another photography competition: https://petapixel.com/2023/02/10/ai-image-fools-judges-and-wins-photography-contest/ 

Japanese writer wins prestigious Akutagawa Prize with a book partially written by ChatGPT: https://www.vice.com/en/article/k7z58y/rie-kudan-akutagawa-prize-used-chatgpt

People PREFER AI art and that was in 2017, long before it got as good as it is today: https://arxiv.org/abs/1706.07068 

>The results show that human subjects could not distinguish art generated by the proposed system from art generated by contemporary artists and shown in top art fairs. Human subjects even rated the generated images higher on various scales.

>People took bot-made art for the real deal 75 percent of the time, and 85 percent of the time for the Abstract Expressionist pieces. The collection of works included Andy Warhol, Leonardo Drew, David Smith and more.

People couldn’t distinguish human art from AI art in 2021 (a year before DALLE Mini/CrAIyon even got popular): https://news.artnet.com/art-world/machine-art-versus-human-art-study-1946514 

>Some 211 subjects recruited on Amazon answered the survey. A majority of respondents were only able to identify one of the five AI landscape works as such. Around 75 to 85 percent of respondents guessed wrong on the other four. When they did correctly attribute an artwork to AI, it was the abstract one. 

Katy Perry’s own mother got tricked by an AI image of Perry: https://abcnews.go.com/GMA/Culture/katy-perry-shares-mom-fooled-ai-photos-2024/story?id=109997891

Todd McFarlane's Spawn Cover Contest Was Won By AI User Robot9000: https://bleedingcool.com/comics/todd-mcfarlanes-spawn-cover-contest-was-won-by-ai-user-robo9000/

“Runway's tools and AI models have been utilized in films such as Everything Everywhere All At Once, in music videos for artists including A$AP Rocky, Kanye West, Brockhampton, and The Dandy Warhols, and in editing television shows like The Late Show and Top Gear.” 

https://en.wikipedia.org/wiki/Runway_(company)

SIX AI images entered top 300 finalists of official Pokemon art competition (2% of all finalists): https://kotaku.com/pokemon-trading-card-tcg-ai-art-illustration-contest-1851559041


Real photograph only got third place in AI art competition: https://www.cnn.com/2024/06/14/style/flamingo-photograph-ai-1839-awards/index.html


AI generated song remixed by Metro Boomin, who did not even realize it was AI generated: https://en.m.wikipedia.org/wiki/BBL_Drizzy

>Unbeknownst to Metro at the time, the original track's vocals and instrumental were generated entirely by an artificial intelligence model.
Upon release, the track immediately received widespread attention on social media platforms. Notable celebrities and internet personalities including Elon Musk and Dr. Miami reacted to the beat.[19][20] Several corporations also responded, including educational technology company Duolingo and meat producer Oscar Mayer.[21][20]
In addition to users releasing freestyle raps over the instrumental, the track also evolved into a viral phenomenon where users would create remixes of the song beyond the hip hop genre.[22] Many recreated the song in other genres, including house, merengue and Bollywood.[23][18] Users also created covers of the song on a variety of musical instruments, including on saxophone, guitar and harp.

3.88/5 with 613 reviews on Rate Your Music (the best albums of ALL time get about a ⅘ on the site): https://rateyourmusic.com/release/single/metro-boomin/bbl-drizzy-bpm-150_mp3/

86 on Album of the Year (qualifies for an orange star denoting high reviews from fans despite multiple anti AI negative review bombers)

Charted as 22nd top single in New Zealand
Reddit post with 42k net upvotes accuses Call of Duty: Black Ops 6 loading screen art of being AI generated: https://www.reddit.com/r/gaming/comments/1h850ur/black_ops_6_loading_screen_look_at_the_hand

It’s not:  https://www.reddit.com/r/gaming/comments/1h850ur/comment/m0r5isd/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button
Comment with 26k net upvotes stating it’s AI-generated: https://www.reddit.com/r/gaming/comments/1h850ur/comment/m0q6dao/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button
Comment with 12k net upvotes stating it’s AI-generated: https://www.reddit.com/r/gaming/comments/1h850ur/comment/m0q65ug/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button
Twitter post with 100k likes stating it’s AI-generated: https://x.com/magpieleon/status/1865841444138729644

11.2.2. Human-Made/Real Life Images Are Flawed Too

https://www.reddit.com/r/PastAndPresentPics/comments/1hn1efw/my_wife_and_i_from_17_to_37/
Man has “blank stare” gaze
x.com/annytf/status/1772710287679840454

https://x.com/annytf/status/1869909969962930576
Fingers on left hand incomplete

https://x.com/annytf/status/1871350095607992600
Fingers are incomplete

https://x.com/sakeandshittake/status/1871557052587471021
Fingers are incomplete

https://x.com/233Eris/status/1870712423843615088?t=gZGxTo4VgNOzPmEmnZ_goQ&s=19
Neuro’s (person in center) left hand missing, shading on Vedal’s (left of center) thumb, and Anny’s (right of center) eyes

915 likes on purposefully drawing feet poorly: https://x.com/Rainbows_24_7/status/1873144060812378207
Picasso:	

11.3. Glaze/Nightshade
Direct link: https://docs.google.com/document/d/1oHuwssPPUTa4dwczX_s3qg3iPfWE4VK-R52LN51GwI8/edit?tab=t.0#heading=h.fo1vk08bo7yv

Glaze can actually IMPROVE AI training https://huggingface.co/blog/parsee-mizuhashi/glaze-and-anti-ai-methods

“Noise offset, as described by crosslabs's article works by adding a small non-0 number to the latent image before passing it to the diffuser. This effectively increases the most contrast possible by making the model see more light/dark colors. Glaze and Nightshade effectively add noise to the images, acting as a sort of noise offset at train time. This can explain why images generated with LoRAs trained with glazed images look better than non-glazed images.”

https://arxiv.org/pdf/1412.6572
Using this approach to provide examples for adversarial training (eg Glaze/Nightshade), we REDUCE the test set error of a maxout network on the MNIST dataset.

Glaze does not work according to ETH Zurich lab: https://spylab.ai/blog/glaze/
Adversarial Perturbations Cannot Reliably Protect Artists From Generative AI: https://arxiv.org/pdf/2406.12027v1




More proof Nightshade does not work: https://isaiahskullcrusher.medium.com/can-nightshade-and-glaze-be-used-to-hide-illegal-material-9e49d14fec39

Also easy to remove the poison: 
https://github.com/yoinked-h/deglazer
https://github.com/p1atdev/stable-diffusion-webui-adverse-cleaner-tab/tree/main
https://web.archive.org/web/20231209210532/https://github.com/lllyasviel/AdverseCleaner
https://github.com/parsee-mizuhashi/nightshade-antidote
https://github.com/ghunkins/Voice-Denoising-AN
Ruins image quality: 

Ineffective (the image shown below is from Nightshade’s own website): 

In response to the Carlini paper posted above, one scientist behind glaze/nightshade (Ben Zhao) has thrown multiple hissyfits and has attempted to publicly libel the scientists that dare try to validate their work- thereby also leading to harassment: https://old.reddit.com/r/aiwars/comments/1doe1tt/why_i_attack_nicholas_carlini_responds_to/
Easy to detect and filter from datasets: https://github.com/RichardAragon/NightshadeAntidote?darkschemeovr=1

11.4. Music
AI-made remix of another AI song: https://www.udio.com/songs/1kSQjtbjYd45DroFtAiBDd
The original song (VERY different, less than half the length, and has no vocals or percussion counterpoint): https://www.udio.com/songs/dUdbjyscaTTGGyjoN28H7a
Computer-generated and non-deterministic music has existed for many decades:
https://en.wikipedia.org/wiki/Aleatoric_music
Coined in the 50s
Leaves parts of music to pure chance
https://en.wikipedia.org/wiki/Generative_music
Popularized by Brian Eno, who likes AI (see section 11.5)
https://en.wikipedia.org/wiki/Algorithmic_composition
Uses algorithms to create music
We recently announced JASCO, a music-generation model with improved controllability using conditioning inputs like chords or beat: https://x.com/AIatMeta/status/1814405505789706253
MusiConGen, Rhythm and Chord Control for Transformer-Based Text-to-Music Generation: https://huggingface.co/papers/2407.15060
Udio introduces Udio 1.5 with significantly improved audio quality: https://www.udio.com/blog/introducing-v1-5
Precise control over edits: https://x.com/udiomusic/status/1851719943626395778
Professional musciscians impressed by AI music: 
https://www.youtube.com/watch?v=c3VeXE5Rbps
https://www.youtube.com/watch?v=ZxYAtL0D50A
https://www.youtube.com/watch?v=aQC0FI_asKY
https://www.youtube.com/watch?v=PCYTqDSUbvU
AI music creator has 229k total subscribers and 7.5 million views on all channels https://m.youtube.com/@ObscurestVinyl

Topic channel: https://m.youtube.com/channel/UCSeqzYZQ8GEoF6eMdvJREyw

A few very popular songs: 

https://m.youtube.com/watch?v=wPlOYPGMRws&pp=ygUPb2JzY3VyZXN0IHZpbnls

https://m.youtube.com/watch?v=7zTei5RMhQ8&pp=ygUPb2JzY3VyZXN0IHZpbnls

https://m.youtube.com/watch?v=suXO7Yy_A-8&pp=ygUPb2JzY3VyZXN0IHZpbnls

AI song covers with have hundreds of thousands or even millions of views each: 

https://m.youtube.com/watch?v=GvnTSLS1dTU

https://m.youtube.com/watch?v=VNWudHD3Kt8

https://m.youtube.com/watch?v=rH14QH9jSDQ

https://m.youtube.com/watch?v=-pAW1-bSsAc

https://m.youtube.com/watch?v=_Y543NEiR5w

https://m.youtube.com/watch?v=-ugjFAljBKI

https://m.youtube.com/watch?v=f32P3ZAoJg0

https://m.youtube.com/watch?v=89H4OyZRFcA

There are MANY more

AI generated song remixed by Metro Boomin, who did not even realize it was AI generated: https://en.m.wikipedia.org/wiki/BBL_Drizzy

Unbeknownst to Metro at the time, the original track's vocals and instrumental were generated entirely by an artificial intelligence model.
Upon release, the track immediately received widespread attention on social media platforms. Notable celebrities and internet personalities including Elon Musk and Dr. Miami reacted to the beat.[19][20] Several corporations also responded, including educational technology company Duolingo and meat producer Oscar Mayer.[21][20]
In addition to users releasing freestyle raps over the instrumental, the track also evolved into a viral phenomenon where users would create remixes of the song beyond the hip hop genre.[22] Many recreated the song in other genres, including house, merengue and Bollywood.[23][18] Users also created covers of the song on a variety of musical instruments, including on saxophone, guitar and harp.

3.88/5 with 613 reviews on Rate Your Music (the best albums of ALL time get about a ⅘ on the site) 

86 on Album of the Year (qualifies for an orange star denoting high reviews from fans despite multiple anti AI negative review bombers)

Charted 22nd New Zealand 

AI-generated song made it to 72nd highest ranking song in Germany: https://www.youtube.com/watch?v=o0aG3S3iD6Y

Good AI-generated songs:
Backup folders of some songs: 
https://drive.google.com/drive/folders/1kcYYuvCvZmrUVz04r7Sg4Zg3AQJTs17e?usp=sharing
https://www.dropbox.com/scl/fo/zzq0zihmi1kbklxkzsxrg/AII583sgZmqZCVn-eRrjkP8?rlkey=da6n5c19prcjqiw8ne79kdaze&st=w19wbwwh&dl=0
https://www.youtube.com/@dopplerganger1433
https://open.spotify.com/album/5udvqstOMjCMmlEC2z3OJs?flow_ctx=ebeffac7-423a-4c54-ad27-0ea508f0470f%3A1733845219&creation_point=https%3A%2F%2Fopen.spotify.com%2Falbum%2F5udvqstOMjCMmlEC2z3OJs
Similar to Taling Heads/Oingo Boungo: https://www.udio.com/songs/f1JozMnXM2cez2BocXPVLr
https://www.udio.com/playlists/tKDTmFpu7nJbAXwC6ehpk8
https://www.udio.com/playlists/6bHyGJMLyymjvNhp33USp2 
Electro-Pop: https://www.udio.com/songs/sV5W2KMqYK9LCSo7626bd3
Lupin the Third theme: https://www.udio.com/songs/6TkdCh57tuM2kHoY3LLLrT
Barbershop scat: https://suno.com/song/f4772198-7610-49eb-8b8a-71ff5c751f4f
Pop 
Love Bites: https://www.udio.com/songs/ouoEmLz3AYuaFf1QiuvwtJ
somewhat similar to Billie Eillish: https://www.udio.com/songs/qokun63DMDSFKxVD1iuZKu
https://www.udio.com/songs/tN7ibXYnaaRZZa7kPR3jac
https://www.udio.com/songs/svRzxwgGWFFEgCcUQogYbw
https://www.udio.com/songs/1yuXBba4br5Epj63ArsCYB
https://www.udio.com/songs/fEg8zs9rDMo73WUESTGNAY
https://www.udio.com/songs/bgpW9H3nB7cb12SPMf74ug
https://www.udio.com/songs/2geD1KX882FEPaHUawzN9M
https://www.udio.com/songs/2dLuDwyQBK6S5vNYX97dgw
https://www.udio.com/songs/bgpW9H3nB7cb12SPMf74ug
https://www.udio.com/songs/oEXcN4hy6yUK5thfRmjLmS
https://www.udio.com/songs/2ETqVVrtu6Et7apEUDVDXK
https://www.udio.com/songs/3THstVGoSBmakd4XcNsrRu
https://www.udio.com/songs/qsgPsTNnVraQRLyUTTVmEA
https://www.udio.com/songs/ecSDmjNPb8M7re4JRQWvzi
https://www.udio.com/songs/7D9sEtcRygEzKF2D1sPzDx
https://www.udio.com/songs/qKuwwzw5D3VmKaM5SUxvHN
Ghost of Your Heart: https://www.udio.com/songs/37AsiMKmH39wfjJjp2PNQp

50s style:
https://www.udio.com/songs/dk3DiKu8ar6WjEg4RAZuyT
https://www.udio.com/songs/1guiJstbJk3SFzYJRP6AuG
https://www.udio.com/songs/5Ez3kNfY3F89Y7nnxrxssv
https://www.udio.com/songs/nPmcyMCrBXQqZeKAEhgaqE

Dream pop:
https://www.udio.com/songs/64H22gmWju8q48XoqL2aX8
https://suno.com/song/a5e2198a-f352-4abb-9a24-7f81b143ded3

Very similar to Portishead: https://www.udio.com/songs/os5u4dTNjNBBUF5uLQDqVw

Very similar to Bjork: https://www.udio.com/songs/8VM2wwjdt5Ckr7PKNnJmDg

Also very good: 
https://www.udio.com/songs/p2r6YbiWXa1C1MyyGb9kZV
https://www.udio.com/songs/3o71EwRVz9rW7U3yQxcdNS
https://www.udio.com/songs/tmwG381JgobNksk2z83biD

Rock: 
https://www.udio.com/songs/2Ed7Ea2LQDjtLYHcf6BMfr
Similar to Queens of the Stone Age: https://www.udio.com/songs/bpYkrt4BmGDUwMRHxHYHiV
https://www.udio.com/songs/gh5yhSQFqFafhDzuK73yBr
K-rock: https://www.udio.com/songs/rXpFufByCQ4ZYwopN2Afr4
Personal favorite (a  Cover/remake of the song "Muori Delay" by Italian rock band Verdena): https://www.udio.com/songs/7VKZg1aGVhTuvenC2PY4WD
Jimi Hendrix style cover of Waltzing Matilda: https://www.udio.com/songs/9mExHq1rUh78jcJ6zBRnKV
Another song in his style: https://www.udio.com/songs/8bdgHjqv9Ky4LPWXL2n8NH
Similar to Oasis
Shine On: https://youtu.be/4AjmM0oB3hc
Oh Sally, Can You Wait Now https://www.udio.com/songs/vrxuRGYAHmbTkR7qCacsKH
Still Breathing: https://www.udio.com/songs/nTiu4Fv9eJDCN6TF1R9ARh
Rebuild What Was Once Great: https://www.udio.com/songs/5tfbdzeHUQPSTrVopz7kuN
The Boatman: https://www.udio.com/songs/51ccELLuE3RLYXRvVPt7wG
Whatever We Want: https://www.udio.com/songs/qewPH5tf4C8Qe6LkSKxMfN
Daredevils: https://www.udio.com/songs/g7Gj5y4f2Lx4UpHvqDd7At
Cosmic Glow: https://www.udio.com/songs/uzWf2tch5GZgscbmR5mG6n
https://www.udio.com/songs/pgyBTM31JbyT8rcxe62bSS
J-rock: https://www.udio.com/songs/gEn2LrwLCgky3faABjp2GZ
https://www.udio.com/songs/gaiFRJ1v9WsWZd3pwVJ1yN
https://www.udio.com/songs/94k4LxH1t7HRQtsPf3Kq3B
https://www.udio.com/songs/6s1MpfEAbvwXWtgoTETwyD
https://www.udio.com/songs/8bdgHjqv9Ky4LPWXL2n8NH
https://www.udio.com/songs/nwTGjbHT9bMCNMxcLnxmdu
https://www.udio.com/songs/3LauHupubZRq869nmPdE8K
https://www.udio.com/songs/7SkG6AKLbFcxLGCSd385GL
https://www.udio.com/songs/tMVVG4YkbrEwZw8mxzD54Z
https://www.udio.com/songs/qdoazG83x2wFeXbJNJzyDK
https://www.udio.com/songs/a8ug9yeSKE56Mj6Bty2Pmw
https://www.udio.com/songs/4MR9EjGZM92EGdwPYWWCZB
https://www.udio.com/songs/e2gecDGvevV3UV6G7zDZ92
https://www.udio.com/songs/ew6ibNRDu31kJLZFuvWLXC
https://www.udio.com/songs/eZmhKGyS18q4CrihWd1cK7
https://www.udio.com/songs/99gAgAqi9baMAsn6kPGRsc
https://www.udio.com/songs/vVt5qcCWWTwN8jJpUkTwys
https://www.udio.com/songs/hwPBjCN7DkXfkbCD5gKGbx
https://www.udio.com/songs/1vp6VSkRWWsJD2zSNFrKxv
https://www.udio.com/songs/e2gecDGvevV3UV6G7zDZ92
https://www.udio.com/songs/qnSFuPggD4SnnCEVfsD6L3
https://www.udio.com/songs/99gAgAqi9baMAsn6kPGRsc
https://www.udio.com/songs/7eWvYLrEDHZojGUo2nm3oc
https://www.udio.com/songs/hPMkN5N6KarArvYLkWkHRY
https://www.udio.com/songs/qewPH5tf4C8Qe6LkSKxMfN
https://www.udio.com/songs/ozoJN8GqchKXW7HnbYLtYL
https://www.udio.com/songs/nreEFNbjREMbVVwWNFpP34
https://www.udio.com/songs/qMxGkZd5vZcMm7sXFf2o5L
https://www.udio.com/songs/ptzEr95mGp9PC4U2GqmUYE
https://suno.com/song/11cedda8-3074-423f-a854-6021d3c615f9
Rap rock in the style of Rage Against the Machine: https://www.udio.com/songs/o6DEogHeabUxtRV7wJrPhn
Surf rock instrumental: https://www.udio.com/songs/fNAXQ664SsUYocoX5bPny4

Grunge: 
Similar to Slowdive: https://www.udio.com/songs/vdCbJBXpFjLdYEqNh6NTEJ
https://www.udio.com/songs/bVjvspP7z5Ls8mHfKDZ23v 
https://www.udio.com/songs/39ZN9a1GvLCisYVPNUizcU
https://www.udio.com/songs/peR88V4TMWxvrnVC31G3VD
https://www.udio.com/songs/w1wkYMyd9hbLQaYUxJeg4u
https://www.udio.com/songs/vdwyAUybfdJTKAHvfi8Jfh
https://www.udio.com/songs/kNhN2Hy5EWNvsF7Wbz71hV

Punk: https://www.udio.com/songs/sQwB3EcykSoQpbabrr9TFP

Prog rock: 
https://www.udio.com/songs/txUbSjEPJzgViahbrdefxM
https://www.udio.com/songs/99N5VnHwv78QPgcqAoLBnk
Instrumental is great but some of the lyrics are… not: https://www.udio.com/songs/oxUrxAihUEg5fp6eGFgMc3
https://www.udio.com/songs/qZN29EiF89HsLCQmYxq42Z

EDM:
https://www.udio.com/songs/78U95aNRYQHyQrn8xHizf8
https://www.udio.com/songs/7eWvYLrEDHZojGUo2nm3oc
https://www.udio.com/songs/hK7F6fcmEcqW2egu9UDWrE
https://www.udio.com/songs/ox13W8kzdWQvA6cFwkVTe2
15.5 minutes long: https://www.udio.com/songs/vk7QLdDPJxnwEecmLW42La
https://www.udio.com/songs/qrxFXVy7Rgh2ebqFxpm52j
https://www.udio.com/songs/5jQp8EykyocuCf8YDc5zvq
https://www.udio.com/songs/hYEQXXgtaswTcgTnp4rt3z
https://www.udio.com/songs/wUm4jbahw6StPijoYgSaZa
https://www.udio.com/songs/uVLqsad8rc3jk83eu9twxM
https://www.udio.com/songs/qcQwoT6ZzYJCZb5DWLZW1U
https://www.udio.com/songs/oERbSC94qAcozPkYMRpn8d
https://www.udio.com/songs/eCXUkAxsvHydxS2w8Pt9zV
https://www.udio.com/songs/ocYMEPXWYkD19egp8ivZZJ 
Dubstep: https://www.udio.com/songs/eMZq9X4twmqn9Ufm9SfVCE
https://www.udio.com/songs/5yvMrfHboXxW2aA2hrmPJ3
https://www.udio.com/songs/rFc8oEXBSnNdbLJhcTj7ga
https://www.udio.com/songs/qbBGzdXX2QH6P6Sfw8YtJD
https://www.udio.com/songs/5DmgjJ1cfcfyHkohDWhFNb
https://www.udio.com/songs/uVLqsad8rc3jk83eu9twxM
https://www.udio.com/songs/jW2fsjekZehnZNLAhQXQmW
https://www.udio.com/songs/jrU8zow3PdkPJw21Tx566u
https://www.udio.com/songs/4KEYRbLJ3oBucBNMu2bp71
https://www.udio.com/songs/fMSLV5Mjz8gVCScQa9NJn3
https://www.udio.com/songs/wCCDUoHeo8z97xRehQadR7
https://www.udio.com/songs/42n6cj6iwQPsxFp4tqJieP
https://www.udio.com/songs/1CMdUtzG6iB6WTt395xwky
https://www.udio.com/songs/tcQJPepikuyTP3w3eeAmTT
https://www.udio.com/songs/5Q3XT7ESm7heW6oJMgsZff
https://www.udio.com/songs/cyGcSbRRdn3yiNTkvu3vxA
https://www.udio.com/songs/osYzP5cm6X1wE7nP6xdMzD
https://www.udio.com/songs/4rG7oq2s4muDLDpHBH8T57
https://www.udio.com/songs/2s4zyXNvcyVLvxT2hYKdTt
https://www.udio.com/songs/1kSQjtbjYd45DroFtAiBDd
https://www.udio.com/songs/cjSWd9peh1Vwz8KfRDACfR
https://www.youtube.com/watch?app=desktop&v=3j3hEqOX2m0&list=OLAK5uy_kdHzo57Bp-3gAuvooImbyHfEJJkdDFlMw
https://www.youtube.com/watch?v=RiUBPLe_-Oc
https://www.udio.com/songs/4KEYRbLJ3oBucBNMu2bp71
Lofi/chillwave: https://www.udio.com/songs/gp35soPqGMXmGU7rQ3397z

Downtempo:
https://www.udio.com/songs/sV5W2KMqYK9LCSo7626bd3
 https://www.udio.com/songs/85QWwPisL1pSuPzXfxdU4R
Minimal but great vocals: https://www.udio.com/songs/aw2uXhzVbPzZU3tKB26qBR

Big Beat/Turntablism:
Somewhat similar to Jet Set Radio: https://www.udio.com/songs/x3xLvnN48DGnmxM5VPTw93

Blues rock with ***INCREDIBLE*** guitar playing: https://www.udio.com/songs/jaGkxT9QohSiUCBA2waVTj

Cinematic neoclassical/Medieval/Folk/Fantasy (all excellent!)
https://www.udio.com/songs/vzy9E3po7mnsonZWhbES5e
https://www.udio.com/songs/5HHbkgTWfpSb5rkW2dGotN
https://www.udio.com/songs/foVqjXtP1jHxc7QpkM1khD
https://www.udio.com/songs/9AVqmPHPcXecvpo86ZfabF
https://www.udio.com/songs/v5LbZc3Lm6j7EusKAzkWUx
https://www.udio.com/songs/8Y5oSqye5JR3Fajvg63E7T
https://www.udio.com/songs/g4jCQEQRa6QvM2UNNtA1y1
https://www.udio.com/songs/1gR5jn6ZDNVt6oApq4BSpL 
https://www.udio.com/songs/vzy9E3po7mnsonZWhbES5e
https://www.udio.com/songs/cqcXvCsUxqFtSTQTnWUcAL
https://www.udio.com/songs/8V9JBTg9mzxGyNfA9B5EDP
https://www.udio.com/songs/cy69XmLZUPvavXkMEemVeE
https://www.udio.com/songs/knwr9be44FTZczicGks9Ag
https://www.udio.com/songs/2LtGWCvhVivRTmxCmxqQgE
A Vignette of Valency: https://www.udio.com/songs/vt5kHKXczqgVgRBjsFpsm4
Gialla Foglia: https://www.udio.com/songs/ox13W8kzdWQvA6cFwkVTe2

Dark cabaret/vaudeville
https://www.udio.com/songs/oF19dogeWA69hn2op4ZWKx
https://www.udio.com/songs/en8rnSZ6FKCZzFAUXxjKC2
https://www.udio.com/songs/tY6KM6hc87tPvQYAP5iWmR
https://www.udio.com/songs/4e97iAsm1Bu8C8VYEXzvqJ
Very similar to Tom Waits: https://www.udio.com/songs/6i4ZNQw7bc9MMLoQJUvAwM
Musical
https://www.udio.com/songs/dzDzTBv5jM2qjjBr1PSEf1
Disney: https://www.udio.com/songs/omGPBpUkvMJEEBCoHkKaMi

Bluegrass: https://www.udio.com/songs/7bLE7wFVYiziGt9KkT7nem

Future Bass:
https://www.udio.com/songs/x3xLvnN48DGnmxM5VPTw93
https://www.udio.com/songs/2RznwVgBp7wsvtRvvhaEcX

Metal:
Nu Metal: https://www.udio.com/songs/iimtziNgEDRcpG8j4n4Mfg
https://www.udio.com/songs/3z26TSc8QfiVzJSwzXRRHY
https://www.udio.com/songs/sVpFN9FcPN56jiepBgivZ7
https://www.udio.com/songs/iakV27LkjDM7NLBQDLJEMv
https://www.udio.com/songs/kyrBEo2ez3gPhDiaZTQW49
https://www.udio.com/songs/cNEXTjwENgsW19pzcx8HVN
https://www.udio.com/songs/2XWKgvyr3g9VTfGWLh2RN3
https://www.udio.com/songs/uwscenGwuBdPttVSu9T73F
https://www.udio.com/songs/5bYUkzUu3toB34N8q4P8jG
https://www.udio.com/songs/csPCgoXsnSgJmv4TN17Jxw
https://www.udio.com/songs/mBpC4WXm7T5AbnGbmr76Nw
https://www.udio.com/songs/749GppyZMiVbqFAJKsrV7e 
https://www.udio.com/songs/xyxxiVQ9YRmHJTJ7ZqjLmg 
https://www.udio.com/songs/s7FDqeUzGxxLMmbDKYQ6sz
https://www.udio.com/songs/5m7ERS3o56G8mZf2kUJYfV
https://www.udio.com/songs/37FjnxppxrRH1XkvowuaeH
https://www.udio.com/songs/1VBd88zcMVAEKchiZTsX22
https://www.udio.com/songs/akN7uMmvopJh6jKyrvgVue
https://suno.com/song/9fb10b92-7e5e-45df-b7b9-73eae1ceb570
https://suno.com/song/286f6cbd-68fa-443b-9f75-f475bbc265fd
https://suno.com/song/6d034c48-dc8b-426c-b811-683a2729b388
Somewhat similar to Iron Maiden: https://www.udio.com/songs/gzdXCZUzF61s6N6H9QJ3eq
https://suno.com/song/eaba4d6e-f7ab-4bc4-a48b-6e2c8d859dbc
Similar to Rammstein: https://www.udio.com/songs/3ZLUxa7vvfjUQ96xyMFd2C
https://www.udio.com/songs/o1pUVrG8tznzwXh3sxhyQP

Hip hop:
Kanye West: 
https://www.udio.com/songs/uRRycSzokNs8kZWdLLMHr7
Kanye + Rihanna + Kendrick Lamar: https://www.udio.com/songs/usXnK54cNo317naXZANNpn
https://www.udio.com/songs/afoNvvA8UdnsppgQcuKvUF
https://www.udio.com/songs/2ZnftWC4k2tVKhjJmqEAs7
https://www.udio.com/songs/1YDNDLuhgzbTjwHpAaCoZQ
https://www.udio.com/songs/4mbVXF3MGvYepGc9V6A6zA
https://www.udio.com/songs/nFbMXKiW61CjNrYkTX3LTr
Jay-Z: https://www.udio.com/songs/6rNiTbW8JuB8RRCTPSwLPs
Kendrick Lamar w/ amazing beats: https://www.udio.com/songs/j1HkAJKjKnbN5avjsd6Xc5
Kendrick x Little Darkie: https://www.udio.com/songs/9BPh6bZ7QRnHYzoTrvpvKj
https://www.udio.com/songs/rzHqZXo4pD7dMqJAWWrXyh
https://www.udio.com/songs/6SsudZEWaSnq4Kdr7dANsF
https://suno.com/song/53a8521a-de15-4287-b683-4d3dc1687144
https://www.udio.com/songs/9BPh6bZ7QRnHYzoTrvpvKj
Pop rap similar to K/DA: https://www.udio.com/songs/8mBTYc1Bn28rceBb3MvV1g

Country:
https://www.udio.com/songs/coixNX1gnJ1oWT8z2LQddk
Very good, in my opinion

Country rock: https://www.udio.com/songs/kYUkkLEK9DUdQAfWHCynMf

Song in various genres in one: https://www.udio.com/songs/9FkMQrFw7o51PRC3HDwqXk

K-Pop:
https://www.udio.com/songs/8mFAxvwdf1RNaoBeexT4D5
https://www.udio.com/songs/ohRxf4LvQxgwF3TvdfXqeS
https://www.udio.com/songs/oVVDRhdT9r2nEFDqQPKZed

J-Pop:
https://www.udio.com/songs/n8vyyCPy8VKsCSpQopAyW9
https://www.udio.com/songs/thpduuE5uhHJhuZgqmNZFm
https://www.udio.com/songs/qsgPsTNnVraQRLyUTTVmEA
https://www.udio.com/songs/7ZzFLMkkwxyBDQPCG1eQZ3
https://www.udio.com/songs/eEqhAB3qRSt9nxp21Q3EBD
https://www.udio.com/songs/gYtfMVg45tTAsxDULbWUZh
https://www.udio.com/songs/hp2EguaJ7vXFeErvyQCQYD
https://suno.com/song/15746124-524c-495e-b444-de303df5722c
https://www.udio.com/songs/1HkNvzsiiweTR1XDMxQM2p
https://www.udio.com/songs/eQpXCoyT7q3CdRRi5WhxnX
https://www.udio.com/songs/tjbhySfUsYMjYvNo5Ytvkx
https://www.udio.com/songs/uWPDNLJCLfrhSoHV48Kg14
https://www.udio.com/songs/5xbR1HcEwGo66AjhRn1HSX
https://kinkykawaii.bandcamp.com/album/dazzler

Jazz Fusion
Persona-style: https://www.udio.com/songs/kqHjbuyW4H3yYKcwLZQo3K
https://www.udio.com/songs/rXM6odgDvPYipNV9GKJnj1
https://www.udio.com/songs/1HkNvzsiiweTR1XDMxQM2p
https://www.udio.com/songs/ryXSV42z7DiXASy522pZmF

Chiptune:
https://www.udio.com/songs/tnnrR5azG47mg9hyPNaxsm
https://www.udio.com/songs/qKbxQz54m3CMbWZfyC3LK6

Soul: 
https://www.udio.com/songs/5bqNHibgAsRLvo6BporEB1
https://www.udio.com/songs/svRzxwgGWFFEgCcUQogYbw 
https://www.udio.com/songs/r27bVnsLQmvQsE5VEj7Lya
https://suno.com/song/f275d9ac-5a62-4bbe-baf9-3fa10e0332f4
https://suno.com/song/1bec9b5b-e307-4198-a039-94cff9f2b090

Funk:
https://www.udio.com/songs/mwsr23c1fFDdk21fqfmESK

electro-pop: 
https://www.udio.com/songs/dFX8e3k87WQX8m2YUmR7cx
https://www.udio.com/songs/gQxE7XZLtCHPKdk3eKZ2tk
https://www.udio.com/songs/mdoraUg81oJbKEjjiqXnAu
https://www.udio.com/songs/cxswG6VHxYSQw98QoPHpWi
https://www.udio.com/songs/9m6mdBw5eMU5ScKw4Tkkqz
https://www.udio.com/songs/hyUUwqQepn8rWjevjeGFNh

Shoe gaze: https://www.udio.com/songs/j6VYSTTPWwrMA2JhPZUMHi

Rnb: 
Very similar to Frank Ocean: https://www.udio.com/songs/gHFjyk36Xr2gyQhCvyWJxe
Beyoncé: https://www.udio.com/songs/16nwqoukAQPyMTM1e3k3wf (great vocal performance)
Rihanna (Excellent vocals): https://www.udio.com/songs/rmqyXEfnd4aBCgn3i5xwSq
https://www.udio.com/songs/37KXHspVLAcxanYeGfUjA7 
https://www.udio.com/songs/2tSdv7yRtpW24jsT6ZGZyf (incredible vocals)

Folk:
https://www.udio.com/songs/n7WS6BEW7Af5hrdmdgVnMb
https://www.udio.com/songs/2sd2JdafUTCZW4QkAtNAqT
https://www.udio.com/songs/wAHSpzDM4XXeixcvuDqU3w
https://www.udio.com/songs/gajKkTvivm1nJx6oNQjFk1
https://www.udio.com/songs/wUZ63W1ixAnqssAUZr92T5
https://www.udio.com/songs/2y51k7sTwWisteYDnQ7Lne

Electro-swing song of The Raven by Edgar Allen Poe: https://suno.com/song/3df191eb-6eb1-4577-a093-8711534b8c67

https://www.udio.com/songs/cn2XKTpdANRTUbRbFWjnAG

Lofi:
https://www.udio.com/songs/aGiQSY3mpkgKLKqRYAwiwL
Movie score: 
https://www.udio.com/songs/vF9KKQbzdsbVnAwaFL7t3U
Arabic jazz:
https://www.udio.com/songs/wsnFxiybEgdXfnMXw4LxMF
Vocaloid:
https://www.udio.com/songs/dtGew3mi88Na17cEwnvFj3
https://www.udio.com/songs/dtGew3mi88Na17cEwnvFj3
https://www.udio.com/songs/oCXgtuRdApE3hPvTQV5CXb
https://www.udio.com/songs/enNcXjuJHPziNJ61VLX2GN
https://www.udio.com/songs/2gdSQogECTro3KrvcM4Q7D


https://www.udio.com/playlists/smjmFjDiPMQ74wZHW9kbyj 
https://www.udio.com/songs/wqo7bgZn3xVtxTrNLhrDf6 
https://www.udio.com/songs/3gm5Cb8Jw8QqmjBfVn4tvr
https://www.udio.com/songs/nmodbd8XHX8ttmwrMRZSyj
https://www.udio.com/songs/8e7gDcKW1PsuCqhbmuHVd7 
https://www.youtube.com/watch?v=1T_ILXF-K1o 
https://www.youtube.com/watch?v=U_9E8HBZSfw 
https://suno.com/song/ac89e551-41bb-420f-8620-bbb884dcbe1f 
https://suno.com/song/d7df5feb-5237-4af1-b341-7e2458c8bd93 
https://suno.com/song/3f0ff21b-23b1-4bbf-b6c9-5a8524a43ca3 
https://suno.com/song/def40b38-92f5-42c9-a645-189ca1921692 
https://twitter.com/elevenlabsio/status/1788628175766859891 
https://m.youtube.com/watch?v=7zTei5RMhQ8 (>500k views in under a month)
Very unique song: https://www.udio.com/songs/uN6g8GBBfTcP6GLrrQT638 
Metro Boomin samples AI-generated song: https://youtube.com/watch?v=f6Hr69ca9ZM&t=7s 

Won $10k from him and a free remix in a competition 

The original song has a 3.33/5 with 46 reviews on RateYourMusic: https://rateyourmusic.com/release/single/king-willonius/bbl-drizzy/

The remix has a 3.88/5 with 612 reviews on RYM (for context, the highest rated albums of all time on the site hover around 4/5): https://rateyourmusic.com/release/single/metro-boomin/bbl-drizzy-bpm-150_mp3/ 

Covered by Tim Henson from Polyphia: https://youtube.com/watch?v=Oly6ayyckZI&t=6s 

3.88/5 on Rate Your Music with 612 reviews. The best albums of all time get around a 4/5.
 

https://en.m.wikipedia.org/wiki/BBL_Drizzy

"BBL Drizzy" quickly went viral, generating more than 3.3 million streams on SoundCloud within a week

Upon release, the track immediately received widespread attention on social media platforms. Notable celebrities and internet personalities including Elon Musk and Dr. Miami reacted to the beat.[19][20] Several corporations also responded, including educational technology company Duolingo and meat producer Oscar Mayer.

AI music gains thousands of listens on Spotify https://www.reddit.com/r/ArtificialInteligence/comments/1ciaf12/aigenerated_songs_rack_up_thousands_of_listens_on/
AI Country Artists Like “Terry & The Dustriders” Are Racking Up Millions Of Streams With AI Cover Albums On Spotify: https://www.whiskeyriff.com/2024/07/19/ai-country-artists-like-terry-the-dustriders-are-racking-up-millions-of-streams-with-fake-cover-albums-on-spotify/
Sound to music: https://x.com/LinusEkenstam/status/1797761904640954430 
https://x.com/suno_ai_/status/1795878282631512512 
https://www.reddit.com/r/singularity/comments/1d92yvj/this_is_so_fucking_cool_udio_audio_input_feature/
https://x.com/maxescu/status/1798426354888950131
Whistle to music: https://www.reddit.com/r/ChatGPT/comments/1hexl2c/my_sora_generations_aiassisted_music/


11.5. Artists Who Support or Use AI
Direct link: https://docs.google.com/document/d/1oHuwssPPUTa4dwczX_s3qg3iPfWE4VK-R52LN51GwI8/edit?tab=t.0#heading=h.8wkiypqurh0

‘He touched a nerve’: how the first piece of AI music was born in 1956: https://www.theguardian.com/music/2021/dec/07/he-touched-a-nerve-how-the-first-piece-of-ai-music-was-born-in-1956

Long before Auto-Tune and deepfake compositions, the university professor Lejaren Hiller premiered a concert recital composed by a computer and became an overnight celebrity

'AI will become the new normal’: how the art world's technological boom is changing the industry: https://www.theartnewspaper.com/2023/02/28/ai-will-become-the-new-normal-how-the-art-worlds-technological-boom-is-changing-the-industry

Art created using artificial intelligence (AI) is burgeoning. From commercial gallery shows—including Jon Rafman’s large-scale, algorithmically generated paintings at Sprüth Magers in London (Ebrah k’dabri, until 25 March)—to the PATH-AI artist residency organised in collaboration with London’s Somerset House, AI-related art projects are springing up everywhere.
Artists in the field stress that AI is prompting a paradigm shift. Rafman says: "I have been using AI in one form or another since I began making art on computers in the 1990s. I only truly started using image-generating AI tools around 2020."
His 40-minute film at Sprüth Magers, Counterfeit Poast (2023), is entirely generated from AI imagery; the characters in it are animated using an iPhone facial motion-capture app. “AI has the potential to open the gates for new perceptions of image-making just as the development of photography liberated painting from pure factual representation and allowed painters to focus on other dimensions, such as colour, light, and movement,” Rafman adds.
The German digital artist Mario Klingemann has been working with AI since 2015, developing works such as Memories of Passersby 1 (2018), which employ a system of neural networks to generate a never-ending stream of portraits. “I think artists should embrace or at least try out the possibilities that AI offers,” he says. “This technology will become the new normal.”Klingemann explains how he harnesses AI, creating works where the boundaries between human influence and machine creation become increasingly blurred. Botto, for instance, is a project to create an entity that can be perceived as an autonomous artist. “It is set up as a hybrid between an AI that makes its own creative decisions and a community of human stewards that vote on Botto’s proposals and thereby curate the output and indirectly steer the artistic development of the machine,” he says.
Three artists have been selected for the six-month remote artist residency programme PATH-AI, which has been developed by the Alan Turing Institute in London, the University of Edinburgh and the RIKEN research institute in Japan. The AI-inspired works of Nouf Aljowaysir, Chris Zhongtian Yuan, and Juan Covelli are presented on Somerset House’s online curated space known as Channel. Brooklyn-based Aljowaysir has made a film, Ana Min Wein (Where Am I From?), which tracks her immigration path to the US, charting her family’s migration history across Saudi Arabia and Iraq. An AI assistant supports her journey in a film.

James Cameron Joins AI Company Stability AI as Board Member: https://www.hollywoodreporter.com/business/business-news/james-cameron-joins-board-ai-firm-stability-stable-diffusion-1236010034/

“I was at the forefront of CGI over 3 decades ago, and I’ve stayed on the cutting edge since. Now, the intersection of generative AI and CGI image creation is the next wave”

Ridley Scott says he's 'trying to embrace AI'   https://www.nytimes.com/2024/11/07/movies/ridley-scott-gladiator-ii-denzel-washington.html
He wants to use it for animation and says 'you can have done in a week what would take 10 guys 10 weeks'  

Iain M. Banks was pro-AI art: https://www.goodreads.com/quotes/10209279-so-what-the-chelgrian-asked-is-the-point-of-me

The Smile band (led by Thom Yorke and Johnny Greenwood of Radiohead) uses AI: https://m.youtube.com/watch?v=EWpI0n1FZIY

'Another Form of Magic': Andy Serkis Reveals He's Working on New Project Featuring 'AI Characters' https://www.cbr.com/andy-serkis-new-project-ai-characters/

Late Night With the Devil movie uses AI art: https://letterboxd.com/film/late-night-with-the-devil/
Recommended by Chainsaw Man/Look Back/Goodbye Eri author Tatsuki Fujimoto: 
Other people like it too: https://www.reddit.com/r/Chainsawfolk/comments/1fvsr5c/fujiwater_recommends_peak/
3.4 out of 5 on Letterboxed despite anti AI review bombing 


Krita implements generative AI: https://krita-artists.org/t/introducing-a-new-project-fast-line-art/94265

Genshin Impact developers talk about how they used AI in their hit game Honkai: Star Rail: https://en.as.com/meristation/news/genshin-impact-developers-talk-about-how-they-used-ai-in-their-hit-game-honkai-star-rail-n/

The new miHoYo game already uses artificial intelligence techniques, but they have not used it to write narrative content, paying attention to “its impact”.

AI image won Colorado state fair https://www.cnn.com/2022/09/03/tech/ai-art-fair-winner-controversy/index.html

>Cal Duran, an artist and art teacher who was one of the judges for competition, said that while Allen’s piece included a mention of Midjourney, he didn’t realize that it was generated by AI when judging it. Still, he sticks by his decision to award it first place in its category, he said, calling it a “beautiful piece”.

>“I think there’s a lot involved in this piece and I think the AI technology may give more opportunities to people who may not find themselves artists in the conventional way,” he said.



iconic photographer Annie Leibovitz sees AI as the beginning of new creative opportunities: https://www.france24.com/en/live-news/20240320-photographer-annie-leibovitz-ai-doesn-t-worry-me-at-all 

“With each technological progress, there are hesitations and concerns. You just have to take the plunge and learn how to use it." 
She says AI-generated images are no less authentic than photography.



William Shatner defends AI: https://twitter.com/WilliamShatner/status/1782216252808745224

Bjork partnered with Microsoft to use AI: https://www.engadget.com/2020-01-17-bjork-and-microsoft-ai-sky-music.html

She used generative AI here: https://x.com/bjork/status/1867298270935966174
“ the flood of all things from AI is overwhelming !! i am super grateful for your concerns about it´s effects on the environment , it shows you care , are curious and have integrity .
i am curious too , i would like to be more informed about the difference of  "frugal" AI and the ones that do huge environmental damage and want to be able to choose .
i asked around and found out that both the visuals and the audio in our pompidou project were done with "frugal" AI . but i have a lot to learn .
when we used some of the AI softwares to merge the animals voices to mine , some of the sounds were great but to be honest ,
the best blends of their voices and a human were done "manually" , me editing the sounds , choosing piece by piece ,
looking for personality , musicality and soul .

with new technology , i try to use it as a tool to grow , not a crutch . for example when i used melodyne , i used it not for lazy voice progressions
but spent even more time when using it . every note in every chord became intentionally more complex .
( for example choir in "thunderbolt" ) and hopefully stretched the potential more out , further than i would have in "normal analog" physical improvisations ...
i felt with this new tool i could reach new places in my musical DNA , become MORE personal . more myself .

in my opinion ,  this is how we will work in the future . humans can read emotions on an incredibly high scale . nature made us that way .
if there is no soul in tomorrow's music made by AI it is because no-one put it there and we have to speak out and guard this as listeners .
( tbh there is a lot of soulless muzak on spotify already ... they don’t need any AI help for that ...)
anything that is mass manufactured without the attention of creativity , is that way .

AI or not

so it is not about the tool
it is what you do with it . "


Serj Tanakian of System of a Down posts AI music video: https://x.com/serjtankian/status/1871590060891722077

King Gizzard and the Lizard Wizard uses AI for a music video: https://www.reddit.com/r/videos/comments/xz5uc7/new_music_video_by_king_gizzard_and_the_lizard/

Brian Eno uses and endorses AI: https://www.latimes.com/entertainment-arts/movies/story/2024-01-18/brian-eno-gary-hustwit-ai-artificial-intelligence-sundance

https://www.fastcompany.com/3061088/brian-eno-talks-about-using-artificial-intelligence-to-create-music-and-art

Tony Levin (bass player of King Crimson and Peter Gabriel) posts AI animation: https://www.instagram.com/reel/C_BLXAwiG2b/?igsh=MTc4MmM1YmI2Ng==

CATTLE DECAPITATION uses AI art for music video of their song "Scourge Of The Offspring" https://metalinjection.net/video/cattle-decapitation-streams-creepy-new-single-scourge-of-the-offspring

The Voidz release album with AI art cover: https://www.grimygoods.com/2024/07/09/julian-casablancas-responds-to-fans-disappointed-by-the-voidzs-ai-made-album-cover-art/

Many people complimenting it before realizing it’s AI generated: https://www.albumoftheyear.org/album/1003824-the-voidz-like-all-before-you/comments/3/



Grammy-winning producer Timbaland partnered with Suno to remix his new single “Love Again” https://suno.com/playlist/2479ec84-fc53-4611-b014-0ffc90c030dd

Long threads of Neil Cicieriega enjoying AI art and text generation:
https://x.com/neilcic/status/1557150493532721156/
https://x.com/neilcic/status/1533901457438785538
https://x.com/neilcic/status/1564446232390541312
https://x.com/neilcic/status/1618057273028534272
The last thread was started on 1/24/23, AFTER he learned about the criticism artists made towards AI in December 2022: https://x.com/neilcic/status/1599833251161309184

https://penji.co/ai-artists/

Many artists uysing DALL-E 2: https://openai.com/index/dall-e-2-extending-creativity/

Lil Yatchy uses AI for an album cover (widely considered to be his best album): https://www.vibe.com/music/music-news/lil-yachty-lets-start-here-album-cover-ai-1234728233/

Nicki Minaj fans use AI: https://www.creativebloq.com/news/nicki-minaj-ai-trend

Randy Travis uses AI to restore his voice: https://www.msn.com/en-us/music/news/an-exclusive-look-inside-the-making-of-singer-randy-travis-new-ai-created-song/ar-AA1o6k98?ocid=BingNewsSerp&darkschemeovr=1

Drake uses AI: https://www.yahoo.com/entertainment/drake-baits-kendrick-lamar-weird-180317529.html

Japanese writer wins prestigious Akutagawa Prize with a book partially written by ChatGPT: https://www.vice.com/en/article/k7z58y/rie-kudan-akutagawa-prize-used-chatgpt


Metro Boomin samples AI-generated song: https://www.youtube.com/watch?v=f6Hr69ca9ZM&t=7s

He did not even know it was AI generated: https://en.m.wikipedia.org/wiki/BBL_Drizzy

 Upon release, the track immediately received widespread attention on social media platforms. Notable celebrities and internet personalities including Elon Musk and Dr. Miami reacted to the beat.[19][20] Several corporations also responded, including educational technology company Duolingo and meat producer Oscar Mayer.[21][20]
In addition to users releasing freestyle raps over the instrumental, the track also evolved into a viral phenomenon where users would create remixes of the song beyond the hip hop genre.[22] Many recreated the song in other genres, including house, merengue and Bollywood.[23][18] Users also created covers of the song on a variety of musical instruments, including on saxophone, guitar and harp.

Covered by Tim Henson: https://youtube.com/watch?v=Oly6ayyckZI&t=6s 

3.88/5 on Rate Your Music with 613 reviews, where the best albums of all time get around ⅘

Received an 86 on Album of the Year with 611 reviews, qualifying for an orange star denoting high quality

“Runway's tools and AI models have been utilized in films such as Everything Everywhere All At Once,[6] in music videos for artists including A$AP Rocky,[7] Kanye West,[8] Brockhampton, and The Dandy Warhols,[9] and in editing television shows like The Late Show[10] and Top Gear.[11]” 

https://en.wikipedia.org/wiki/Runway_(company)

AI music video from Washed Out that received a Vimeo Staff Pick: https://newatlas.com/technology/openai-sora-first-commissioned-music-video/


Donald	Glover endorses and uses AI video generation: https://m.youtube.com/watch?v=dKAVFLB75xs


Will.i.am endorses AI: https://www.euronews.com/next/2023/07/15/exclusive-william-talks-ai-the-future-of-creativity-and-his-new-ai-app-to-co-pilot-creatio

Interview: https://www.youtube.com/watch?v=qy_ruqoVtJU


Professional artist uses and supports AI, including AI training on their art, on a post where an anti-AI artist admits AI art can be very good: https://www.reddit.com/r/aiwars/s/rbqjXcccCk

Proof of their credentials: https://www.reddit.com/r/aiwars/comments/1g396kr/comment/lrw2j4p/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_button


AI used in Mad Max according to Anne Taylor Joy: https://www.reddit.com/r/singularity/s/1uSo0Lw34A

'Furiosa' Composer Tom Holkenborg Reveals How He Used AI in the Score to Create 'Deep Fake Voices' https://x.com/Variety/status/1796662916248166726

George Lucas Thinks Artificial Intelligence in Filmmaking Is 'Inevitable' - "It's like saying, 'I don't believe these cars are gunna work. Let's just stick with the horses.' " https://www.ign.com/articles/george-lucas-thinks-artificial-intelligence-in-filmmaking-is-inevitable

Tim Cain (the creator of the Fallout game series) says AI voice-over solves a lot of VO problems and that new tools have always put some people out of work: https://www.reddit.com/r/DefendingAIArt/comments/1fv9fe3/tim_cain_the_creator_of_the_fallout_game_series/

Various devs outside the triple-A publishing space are positive about A.I:  https://www.gameinformer.com/2024/05/27/brain-drain-ai-and-indies

>“If I had to pay humans, if I had to pay people to do 150-plus artworks, we would have never been able to do it,” - Guillaume Mezino, Kipwak Studio (founder)

professional 2D animator and rigger (has worked on shows for Netflix and studios) and does rigging in Toon Boom Harmony and storyboarding supports and uses AI:  https://www.reddit.com/r/StableDiffusion/comments/1d4t9tt/the_amount_of_antiai_dissenters_are_at_an_alltime/


The most influential illustrator on Japanese social media said, "AI is just a tool" and "AI has no impact on the evaluation of artists." https://www.youtube.com/watch?v=T-VBEKZ2lb0

Tribeca to screen AI generated films made with Sora: https://www.indiewire.com/news/festivals/tribeca-ai-generated-short-films-sora-shorts-1235010911/

Ashton Kutcher has access to a beta version of OpenAI's Sora and says it will lead to personalized movies and a higher standard of content through increased competition: https://www.reddit.com/r/singularity/comments/1d8qufg/ashton_kutcher_has_access_to_a_beta_version_of/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_button

Grimes performs live on stage with Stable Diffusion AI Video: https://www.reddit.com/r/aivideo/comments/1c4xg4j/coachella_2024_grimes_performs_live_on_stage_with/?share_id=S5egCMOslEhYoLJ7em_FX&utm_content=1&utm_medium=ios_app&utm_name=ioscss&utm_source=share&utm_term=1


48 Hour Film Project partners with Udio AI music generator: https://discord.com/channels/1211680535286648843/1281260908110282754/1294009018670518438
Active since 2001
Events in more than 200 cities and 45 countries over the years
The 48 Hour Film Project has seen some big names in our films, including such actors as Martin Freeman, J.K Simmons, J.Lee and Dennis Farina. Our judging panels have featured: Sean Gunn, Dave Costabile, Maggie Lawson, Simon West, Bruce Beresford, Jane Seymour and Shekhar Kapur to name but a few.
Partnered with Cannes Film Festival since 2004
Each year:
More than 100 cities
More than 4000 film teams
More than 50,000 filmmakers
70,000+ films have been made for the 48HFP


Snoop Dogg's latest music video is AI-generated and took months to create: https://community.designtaxi.com/topic/5461-snoop-doggs-latest-music-video-is-ai-generated-and-took-months-to-create/


New Dungeons & Dragons Sourcebook Features AI Generated Art: https://gizmodo.com/dnd-ai-art-bigbys-giants-book-artist-generators-wotc-1850710496

An artist for Bigby Presents: Glory of the Giants! has admitted to using AI to generate "certain details" of new art for the sourcebook.

Artist in favor of using AI and compares it to backlash against 3D art: https://www.tumblr.com/yuumei-art/756332395536515072/ive-been-told-that-there-are-rumors-about-me
Painter inspired by AI: https://www.reddit.com/r/DefendingAIArt/comments/1fv7kpy/comment/lq5r0pc/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button


 Guy commissioned and properly credited artists in the past, multiple times got backstabbed by artists who copy-striked his videos, threatening to take his channel down: https://www.youtube.com/watch?v=knUkXwJXcpY
Artist and V-Tuber draws fan art of AI VTubers: 
https://x.com/annytf/status/1772710287679840454

https://x.com/annytf/status/1869909969962930576

https://x.com/annytf/status/1871350095607992600

https://x.com/sakeandshittake/status/1871557052587471021

https://x.com/233Eris/status/1870712423843615088?t=gZGxTo4VgNOzPmEmnZ_goQ&s=19

https://x.com/Saruei_/status/1873183464083865768
Her model design: https://www.youtube.com/watch?v=6rv09pXWUXk
Music video involving many artists and musicians: https://www.youtube.com/watch?v=MDc1mjrIsPM
Animation that received 18k likes: https://x.com/Retronous/status/1870257249173545057

11.6. Anti-AI Hypocrisy/False Accusations of AI Usage
Williams won another Oscar for Star Wars and took inspiration from a 1942 movie called Kings Row, composed by Erich Wolfgang Korngold. Can you hear Star Wars? https://x.com/ATRightMovies/status/1794345480207684058
Patricia Taxxon explains how all creative work is derivative: https://m.youtube.com/watch?si=AKh8kph9_ipSJ9Ha&v=jcvd5JZkUXY&feature=youtu.be 
Anti AI hackers using ransomware to attack AI users and demanding cryptocurrency payments: https://www.reddit.com/r/aiwars/comments/1de19q2/antis_are_now_desperate_theyre_embedding_viruses/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_button 
If AI art is theft of IP, so is fan art of copyrighted characters
Artist banned from r/art after being falsely accused of using AI: https://www.creativebloq.com/news/ai-art-accusation


Anti-AI artist admits AI can make good art: https://www.reddit.com/r/aiwars/s/yy7e0aFyC0


One of the main arguments against AI art is that it decreases the number of jobs available. Another argument is that corporations will use it to commodify art to make money. These are clearly contradictory. If commodifying art is bad, why are artists so concerned about not being able to sell (aka commodify) their work? 
Humans also hallucinate 
Blue and black dress vs white and gold dress 
Laurel vs yanny: https://www.youtube.com/watch?v=7X_WvGAhMlQ 
Brainstorm vs green needle: https://time.com/5873627/green-needle-brainstorm-explained/ 
https://www.reddit.com/r/ChatGPT/s/FvnIBVmLrd 
Artists use references from images found online all the time without compensation, asking for permission, or even crediting the original. 
They even do this to their sources of inspiration.
For example, the TV show Breaking Bad was inspired by the movie The Godfather according to the director of the former, but the company that owns Breaking Bad never received permission or gave compensation for it. This applies to virtually every piece of art ever made.
Artists are fine with web scraping for web and image search but not for AI training 
Artists still complain about “ethically-trained” models like Adobe’s Firefly, which was only trained on images owned by Adobe
Adobe’s contract contains a clause that the images they pay for can be used for any technology, even ones that did not exist when the contract was signed 
Artists mocked NFT owners for complaining about “right-clickers” downloading their images but now complain about AI companies doing the same thing on a larger scale
AI art is significantly less pollutive compared to human-made art: https://www.nature.com/articles/s41598-024-54271-x

No complaints about “theft” when DALL-E Mini/CrAIyon was popular in mid-2022 despite being trained via web scraping
Anti-AI artist admits to enjoying AI art and believing it was human-made: https://archive.is/IWW3s
Anti-AI artist tricked into thinking an actual art progress video is AI and points out “signs of inconsistency” that don't exist: https://x.com/i_shkipin/status/1797180394410020890 
People accusing IRL video of being AI: https://x.com/toriel1one1/status/1799142881204249076 
Harassment of AI user: https://www.reddit.com/r/DefendingAIArt/comments/1dxrgbn/i_spent_like_600_hours_over_2_months_creating/
Glaze/Nightshade takes 15 minutes of computation for one image. How is that environmentally friendly? 
Metal Band Axes AI-Generated Album Cover Following Fan Outcry: https://www.forbes.com/sites/lesliekatz/2024/03/04/metal-band-pestilence-dumps-ai-generated-album-cover-following-fan-outcry/
Yet antis accuse AI users of harassment
Sam Yang, AI art critic, selling art of a shot-for-shot frame of Squid Game: https://www.inprnt.com/gallery/samdoesarts/the-alleyway/
Artist who started Brazilian Hatsune Miku meme stole the design but is still universally praised with over 400k likes: https://x.com/thecat_mitsu/status/1826873385369956524

Many other artists used the design without asking for permission from the original artist but aren’t criticized for it at all
Violent rhetoric against AI artists: https://www.reddit.com/r/AIHaters/comments/1fjz32z/the_ai_hate_movement_has_entirely_normalized/
Popular Twitter artist accused of theft for having a similar art style: https://x.com/kaijufem/status/1758062988651643263

11.6.1. Criticism of Copyright Enforcement
Overwhelming disapproval of Kit9 enforcing copyright claims against a fan artist: https://www.reddit.com/r/CoffinofAndyandLeyley/comments/1ded5wv/kit9_studios_copyright_claims_against_artists/ 
Popular tweet criticizing Warner Bros for protecting their IP: https://x.com/GiveMeBanHammer/status/1795036807668666460 
Artists criticizing Nintendo for protecting their IP from unauthorized derivative works: https://www.wired.com/story/nintendo-copyright-zelda-mod/
38k likes on a tweet criticizing Nintendo for defending their IP: https://twitter.com/Tubzbuster/status/1789757912857874499
Artist who coined “Inktober” suing others for using it, angering artists: https://x.com/KikiDoodleTweet/status/1207805327476805643
r/196 post with many highly upvoted comments advocating against copyright: https://www.reddit.com/r/196/comments/1f95nag/the_worst_news_ive_heard_all_rule/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_button

11.6.2. Theft Supported By Artists
Using the art styles of other artists was a meme that artists did for fun: https://www.deviantart.com/oldsouldreamin/art/Drawing-style-meme-561060713

Popular Anti-AI Twitter Artist Caught Using AI: https://www.reddit.com/r/StableDiffusion/s/vAvB5FmNE0
Tweet with over 81k likes advocating for piracy: https://x.com/hacer_kun/status/1832144472215314939
Tweet with over 86k likes advocating for piracy: https://x.com/cvphead/status/1799603994802966773 
Tweet with 60k+ likes supporting piracy: https://x.com/WeirdBongs/status/1791280716245815380
33k likes on tweet supporting piracy: https://twitter.com/ShitpostRock/status/1787727060426706994
Anti-AI artist commits piracy and IP theft from Nintendo: https://x.com/Nyazsche/status/1801977619543429343 
Tweet with almost 150k likes advocating for piracy: https://x.com/remembrancermx/status/1832461616690143245
Tweet with almost 140k likes advocating for piracy: https://x.com/chloetankahhui/status/1832320603761561678
13k likes on tweet from an artist posting copyrighted work online: https://x.com/LokiRoki/status/1844550043124015404
Kamala Harris supporting usage of image traced by a student without permission for voting sticker: https://x.com/KamalaHarris/status/1853242826428961252
Popular Twitter artist supports piracy and receives 11k likes: https://x.com/masoq095/status/1861884666677952758
Tweet supporting piracy with 33k likes: https://x.com/Lorgarwasright/status/1869336984931774724
11.6.3. False Accusations of Artists Using AI
https://www.reddit.com/r/MauLer/comments/1fnwo4z/marvel_why_does_the_sentryvoid_have_six_fingers/


YouTuber falsely accused D&D artist of using AI based on "something feeling off": https://www.enworld.org/threads/wotc-updates-d-ds-ai-policy-after-youtubers-false-accusations.701714/

Artist defends themself from false AI art accusations: https://nichegamer.com/artist-defends-himself-from-false-ai-art-accusations/

Famous artist Will Jack falsely accused of using AI: https://twitter.com/SuperMutantSam1/status/1790560785766216156

Another false accusation: https://www.reddit.com/r/selfpublish/comments/1b6ohh3/need_help_with_a_legal_threat_over_ai/

Yet another false accusation: https://www.reddit.com/r/ArtistLounge/comments/15igkkn/why_do_i_get_accused_of_ai_even_with_evidence_its/

Someone in the comments accuses OP of being a bot even though their comment history contradicts that 


Artist falsely accused of using AI: https://www.tumblr.com/yuumei-art/756332395536515072/ive-been-told-that-there-are-rumors-about-me

Another one: https://www.youtube.com/watch?v=q5N4W25c-ko

Fashion brand falsely accused Artist of using AI: https://www.reddit.com/r/aiwars/comments/1frktn2/fashion_brand_falsely_accused_artist_of_using_ai/

Twitter creature artist harasses another creature artist over AI accusations: https://www.reddit.com/r/DefendingAIArt/comments/1fvwphr/twitter_creature_artist_harasses_another_creature/

Yet another one: https://x.com/TheTurtleBox/status/1852942171420201453
11.6.4. Artists Harassing AI Users
Person gets 1.6k likes for advocating to curb stomp AI users: https://x.com/Jinofski/status/1864037861668069802

Bjork harassed for using generative AI: https://x.com/bjork/status/1856352991038554256
11.7. Historical Complaints About Technology 
All these: https://imgur.com/a/x8Ss0cQ
Rail travel (1825): “The gross exaggerations of the powers of the locomotive steam-engine…may delude for a time, but must end in the mortification of those concerned.”
—Quarterly Review
The telephone (1878): “The Americans have need of the telephone, but we do not. We have plenty of messenger boys.”
—William Henry Preece, Chief Engineer of the British Post Office
Light bulbs (1879): “Everyone acquainted with the subject will recognize [Thomas Edison’s experiments] as a conspicuous failure, trumpeted as a wonderful success.”
—Henry Morton, President of the Stevens Institute of Technology
AC electricity (1889): “Fooling around with alternating current is just a waste of time. Nobody will use it, ever.”
—Thomas Edison
The automobile (1899): “The ordinary horseless carriage is, at present, a luxury for the wealthy; and although its price will probably fall in the future, it will never, of course, come into as common use as the bicycle.”
—Literary Digest
Planes (1911): “Airplanes are interesting toys but of no military value.”
—Marshal Ferdinand Foch, Supreme Commander of the Allied Armies in World War I, 1918–20
Sound in films (1928): “I don’t think people will want talking pictures long…. Talking doesn’t belong in pictures.”
—Joseph M. Schenck, President of United Artists
Television (1946): “Television won’t be able to hold on to any market it captures after the first six months. People will soon get tired of staring at a plywood box every night.”
—Darryl F. Zanuck, Head of 20th Century Fox
Home computers (1977): “There is no reason anyone would want a computer in their home.”
—Ken Olsen, Founder of Digital Equipment Corporation (DEC)
Laptop computers (1985): “For the most part, the portable computer is a dream machine for the few…the real future of the laptop computer will remain in the specialized niche markets.”
—New York Times
The internet (1998): “By 2005 or so, it will become clear that the internet’s impact on the economy has been no greater than the fax machine’s.”
—Paul Krugman, Winner of the 2008 Nobel Memorial Prize in Economic Sciences
The iPhone (2006): “Everyone’s always asking me when Apple will come out with a cell phone. My answer is, ‘Probably never.’”
—David Pogue, Technology Editor of the New York Times
“As long as "invention and feeling constitute essential qualities in a work of Art," the writer argued, "Photography can never assume a higher rank than engraving." Photography couldn't qualify as an art in its own right, the explanation went, because it lacked "something beyond mere mechanism at the bottom of it." — 1855 issue of The Crayon
"It is obvious that this industry, by invading the territories of art, has become art’s most mor­tal enemy... If it is allowed to supplement art in some of its functions, it will soon have supplanted or corrupted it altogether." - Charles Baudelaire, father of modern art criticism, on the topic of cameras and photography (1859)
French art critic Charles Baudelaire hated photography and thought it would be the death of art, saying "the photographic industry was the refuge of every would-be painter, every painter too ill-endowed or too lazy to complete his studies"
Charles Dodgson, AKA Lewis Carroll, threw a fit because dry plate photography was invented, and he was upset now anybody could do it (he used the wet collodion process which is complicated and messy) and abandoned photography.
 Th abolishment of pain in surgery is a chimera. It is absurd to go on seeking it... Knife and pain are two words in surgery that must forever be associated in the consciousness of the patient. - Dr. Alfred Velpeau (1839), French surgeon
There is a young madman proposing to light the streets of London—with what do you suppose—with smoke!
Sir Walter Scott (1771-1832) [On a proposal to light cities with gaslight.]
They will never try to steal the phonograph because it has no `commercial value.'
Thomas Edison (1847-1931). (He later revised that opinion.)
This `telephone' has too many shortcomings to be seriously considered as a practical form of communication. The device is inherently of no value to us.
Western Union internal memo, 1878
Radio has no future.
Lord Kelvin (1824-1907), British mathematician and physicist, ca. 1897.
While theoretically and technically television may be feasible, commercially and financially I consider it an impossibility, a development of which we need waste little time dreaming.
Lee DeForest, 1926 (American radio pioneer and inventor of the vacuum tube.)
[Television] won't be able to hold on to any market it captures after the first six months. People will soon get tired of staring at a plywood box every night.
Darryl F. Zanuck, head of 20th Century-Fox, 1946.
That the automobile has practically reached the limit of its development is suggested by the fact that during the past year no improvements of a radical nature have been introduced.
Scientific American, Jan. 2, 1909.
There is no likelihood man can ever tap the power of the atom. The glib supposition of utilizing atomic energy when our coal has run out is a completely unscientific Utopian dream, a childish bug-a-boo. Nature has introduced a few fool-proof devices into the great majority of elements that constitute the bulk of the world, and they have no energy to give up in the process of disintegration.
Robert A. Millikan (1863-1953) [1928 speech to the Chemists' Club (New York)]
...any one who expects a source of power from the transformation of these atoms is talking moonshine...
Ernest Rutherford (1871-1937) [1933]
There is not the slightest indication that [nuclear energy] will ever be obtainable. It would mean that the atom would have to be shattered at will.
Albert Einstein, 1932.
Heavier-than-air flying machines are impossible.
Lord Kelvin (1824-1907), ca. 1895, British mathematician and physicist
...no possible combination of known substances, known forms of machinery, and known forms of force, can be united in a practical machine by which man shall fly long distances through the air...
Simon Newcomb (1835-1909), astronomer, head of the U. S. Naval Observatory.
I confess that in 1901 I said to my brother Orville that man would not fly for fifty years. Two years later we ourselves made flights. This demonstration of my impotence as a prophet gave me such a shock that ever since I have distrusted myself and avoided all predictions.
Wilbur Wright (1867-1912) [In a speech to the Aero Club of France (Nov 5, 1908)]
Airplanes are interesting toys but of no military value.
Marshal Ferdinand Foch, French military strategist, 1911. He was later a World War I commander.
There is not in sight any source of energy that would be a fair start toward that which would be necessary to get us beyond the gravitative control of the earth.
Forest Ray Moulton (1872-1952), astronomer, 1935.
To place a man in a multi-stage rocket and project him into the controlling gravitational field of the moon where the passengers can make scientific observations, perhaps land alive, and then return to earth—all that constitutes a wild dream worthy of Jules Verne. I am bold enough to say that such a man-made voyage will never occur regardless of all future advances.
Lee deForest (1873-1961) (American radio pioneer and inventor of the vacuum tube.) Feb 25, 1957.
Space travel is utter bilge.
Dr. Richard van der Reit Wooley, Astronomer Royal, space advisor to the British government, 1956. (Sputnik orbited the earth the following year.)
If the world should blow itself up, the last audible voice would be that of an expert saying it can't be done.
Peter Ustinov
It is difficult to say what is impossible, for the dream of yesterday is the hope of today and the reality of tomorrow.
Robert Goddard (1882-1945)

John Philip Sousa feared recorded music and thought it would lead to fewer musicians: “Right here is the menace in machine-made music! The first rift in the lute has appeared. The cheaper of these instruments of the home are no longer being purchased as formerly, and all because the automaticmusicdevices are usurping their places. And what is a result? The child becomes indifferent to practice, for when music can be heard in the homes without the labor of study and close application, and without the slow process of acquiring a technic, it will be simply a question of time when the amateur disappears entirely, and with him a host of vocal and instrumental teachers, who will be without field or calling.”
https://explorepahistory.com/odocument.php?docId=1-4-1A1
Wilbur Wright is quoted as saying, "I confess that in 1901, I said to my brother Orville that man would not fly for 50 years." Two years later, ‘man’ was not only flying, but it was these very men who achieved the feat


Newsweek in 1995: Why the Internet Will Fail: https://thehustle.co/clifford-stoll-why-the-internet-will-fail

Dec 1909, the Engineering Magazine

An article in 1890 talking about how the car will not replace the horse: The banker took him to a window. “Look,” he said pointing to the street. “You see all those people on their bicycles riding along the boulevard? There is not as many as there was a year ago. The novelty is wearing off; they are losing interest. That’s just the way it will be with automobiles. People will get the fever; and later they will throw them away. My advice is not to buy the stock. You might make money for a year or two, but in the end you would lose everything you put in. The horse is here to stay, but the automobile is only a novelty — a fad.”
Coal miners, milkmen, and manual telephone switch operators were all automated away, yet society had yet to collapse 
Most people used to be farmers, and now very few people are. 
Luddites opposed technology but ultimately failed, which was a good thing as we would still be working in steel mills and textile factories today if they had won. 

19th century mocking of the initial problems with photography: https://archive.org/details/punch28a29lemouoft

Lithograph company tried to argue that photographs were a wholly deterministic physical reaction and thus involved no artistic input, in regards to a famous photograph of Oscar Wilde

“I confess that, in 1901, I said to my brother Orville that men would not fly for 50 years. Two years later, we were making flights. This demonstration of my inability as a prophet gave me such a shock that I have ever since refrained from all prediction.” -Wilbur Wright
1977: “There is no reason for any individual to have a computer in his home.” — Ken Olsen, founder of Digital Equipment Corp.


1981: “Cellular phones will not replace local wire systems.” — Marty Cooper, inventor.


1992: “The idea of a personal communicator in every pocket is a “pipe dream driven by greed.” — Andy Grove, then CEO of Intel.


1995: “I predict the Internet will soon go spectacularly supernova and in 1996 catastrophically collapse.” — Robert Metcalfe, founder of 3Com, inventor of Ethernet.


12. Debunks
12.1 Articles/Videos/Studies
12.1.1. Study that ChatGPT fails 52% of coding tasks 
“this work has used the free version of ChatGPT (GPT-3.5) for acquiring the ChatGPT responses for the manual analysis.”
“Thus, we chose to only consider the initial answer generated by ChatGPT.”
“To understand how differently GPT-4 performs compared to GPT-3.5, we conducted a small analysis on 21 randomly selected SO questions where GPT-3.5 gave incorrect answers. Our analysis shows that, among these 21 questions, GPT-4 could answer only 6 questions correctly, and 15 questions were still answered incorrectly.”
This is an extra 28.6% on top of the 48% that GPT 3.5 was correct on, totaling to ~77% for GPT 4 (equal to (517*0.48+517*6/21)/517) if we assume that GPT 4 correctly answers all of the questions that GPT 3.5 correctly answered, which is highly likely considering GPT 4 is far higher quality than GPT 3.5.
Note: This was all done in ONE SHOT with no repeat attempts.
Study was released before GPT-4o and may not have used GPT 4 Turbo, both of which are significantly higher quality than GPT 4 according to the LMSYS arena.
12.1.2 Google’s Search AI Summaries 
The problem has nothing to do with training data. There's two primary problems.


1.	⁠Googles results aren't generated by the AI, the AI just paraphrases search results. Literally, it just reads the search results and "summarizes" them for you
2.	⁠Because it's just a summary, the model they use is stupid as fuck. It's not supposed to think critically, it's just supposed to turn a few web pages into a paragraph.


With actual AI generated results, stupid one-off satire articles like this don't matter, because they're "intellectual outliers". They're both rare, and directly contradicted by a ton of other data. In addition to this, assistants like ChatGPT are actually trained to "think" about the response they're giving, and not just instructed to summarize web results.


If you just asked the same model without the search results, I can almost guarantee it wouldn't say anything about actually eating rocks or putting glue on pizza. When you combine the fact that it's just being asked to summarize search results with the fact that it's not trained to actually think critically about what it's summarizing, is when you get problems like this.


Also, much of it circulating social media is edited and fake, which was confirmed by Google itself.
Google’s response: https://blog.google/products/search/ai-overviews-update-may-2024/ 
12.1.3 Debunk of “Has Generative AI Already Peaked?” by Computerphile (or the paper “No "Zero-Shot" Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance”)
The claim of the video/paper is that AI will plateau in a logarithmic curve as there is not enough training data for very specific information, like different tree species. This won’t prevent AGI as most humans do not know very specific information like that either and can only learn if given enough training. This can also be done for AI by fine-tuning on that data, such as training it on a dataset of trees labeled with their species. Even rudimentary neural networks have been capable of this for well over a decade, like identifying different classes of images in the CIFAR-10 dataset using convolutional neural networks.
Example - We finetuned Llama-3-8B on math problems and pushed accuracy from 47% to 65%, getting over 90% of GPT-4's performance at a fraction of the cost: https://x.com/togethercompute/status/1811816439848042608
Synthetic data can also provide nigh infinite training data (see section 15)
Our state space duality (SSD) framework allows us to design a new architecture (Mamba-2) whose core layer is an a refinement of Mamba’s selective SSM that is 2-8× faster, while continuing to be competitive with Transformers on language modeling: https://arxiv.org/pdf/2405.21060 
Loss:
https://x.com/ctnzr/status/1801050835197026696 
A 8B-3.5T hybrid SSM model gets better accuracy than an 8B-3.5T transformer trained on the same dataset:
* 7% attention, the rest is Mamba2
* MMLU jumps from 50 to 53.6%
* Training efficiency is the same
* Inference cost is much less



Google DeepMind's JEST method can reduce AI training time by a factor of 13 and decreases computing power demand by 90%. The method uses another pretrained reference model to select data subsets for training based on their "collective learnability: https://arxiv.org/html/2406.17711v1

12.1.4 “Vision language models are blind” Study
The VLMs tokenize images just like they tokenize text. As a result, it is difficult for them to see small details like red circles surrounding letters in a word (which is one of the tasks in the study) just like how it is difficult for them to count letters in a word.
LLMs can create images using code based on abstract requests even if they were never trained on any: https://news.mit.edu/2024/understanding-visual-knowledge-language-models-0617




From this LLM: https://huggingface.co/allenai/Molmo-7B-D-0924

12.1.5. Real Photograph “Won” AI Art Competition
The photograph only got third place: https://www.cnn.com/2024/06/14/style/flamingo-photograph-ai-1839-awards/index.html

12.1.6. ChatGPT Plagiarized NYT Articles
https://www.reuters.com/technology/cybersecurity/openai-says-new-york-times-hacked-chatgpt-build-copyright-lawsuit-2024-02-27/

OpenAI said in its filing that it took the Times "tens of thousands of attempts to generate the highly anomalous results."
"In the ordinary course, one cannot use ChatGPT to serve up Times articles at will," OpenAI said.
OpenAI's filing also said that it and other AI companies would eventually win their cases based on the fair-use question.
"The Times cannot prevent AI models from acquiring knowledge about facts, any more than another news organization can prevent the Times itself from re-reporting stories it had no role in investigating," OpenAI said
12.1.7. Government Study Finds AI worse than humans in every way at summarizing information
Used LLAMA 2 70b
The report mentions some limitations and context to this study: the model used has already been superseded by one with further capabilities which may improve its ability to summarise information, and that Amazon increased the model’s performance by refining its prompts and inputs, suggesting that there are further improvements that are possible. It includes optimism that this task may one day be competently undertaken by machines.


12.1.8. “Generative AI's Illusory Case for Fair Use” Study
Original Source: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4924997
False caims in the abstract alone:
>“ [LLMs] do not "know" anything independently of the works on which they are trained, so their output is a function of the copied materials.”
See [section 2](https://docs.google.com/document/d/15myK_6eTxEPuKnDi5krjBM_0jrv3GELs8TGmqOYBvug/edit#heading=h.fxgwobrx4yfq) for many studies debunking this
>“The training works thus do not disappear, as claimed, but are encoded, token by token, into the model and relied upon to generate output.”

Completely impossible. There are small language models that are only a few gigabytes in size, such as Microsoft’s Phi models. For comparison, Wikipedia alone is nearly 20 GB without media.
Additionally, it is very difficult to reproduce training data. NYT attempted to do it and it took tens of thousands of tries to produce a small snippet of an article:

https://www.reuters.com/technology/cybersecurity/openai-says-new-york-times-hacked-chatgpt-build-copyright-lawsuit-2024-02-27/

OpenAI said in its filing that it took the Times "tens of thousands of attempts to generate the highly anomalous results."
"In the ordinary course, one cannot use ChatGPT to serve up Times articles at will," OpenAI said.
OpenAI's filing also said that it and other AI companies would eventually win their cases based on the fair-use question.
"The Times cannot prevent AI models from acquiring knowledge about facts, any more than another news organization can prevent the Times itself from re-reporting stories it had no role in investigating," OpenAI said

>Like an LLM, an AI image generator relies on encoded representations of training works to generate its output.

Stable Diffusion 1.5 models are only 2 GB in size despite being trained on nearly 6 billion images from the LAION dataset. That’s about one byte for every three images. An image is typically 4.4 kilobytes.
If AI images can only generate its encoded representations, it would not have the flexibility to generate novel images as proven in [section 12.1](https://docs.google.com/document/d/15myK_6eTxEPuKnDi5krjBM_0jrv3GELs8TGmqOYBvug/edit#heading=h.8kscl4xz7vhq)

>the determination of fair use turned on the fact that the alleged infringer was not seeking to capitalize on expressive content-exactly the opposite of generative AI. 

There are many open-weight models released for free, such as Meta’s LLAMA, Google’s Gemma, and Microsoft’s Phi series.

>Generative AI's claim to fair use is further hampered by the propensity of models to generate copies and derivatives of training works, which are presumptively infringing

Courts have already ruled that AI outputs are not considered derivative works. See here: https://www.techdirt.com/2024/09/05/the-ai-copyright-hype-legal-claims-that-didnt-hold-up/

>Another claim that has been consistently dismissed by courts is that AI models are infringing derivative works of the training materials. The law defines a derivative work as “a work based upon one or more preexisting works, such as a translation, musical arrangement, … art reproduction, abridgment, condensation, or any other form in which a work may be recast, transformed, or adapted.” To most of us, the idea that the model itself (as opposed to, say, outputs generated by the model) can be considered a derivative work seems to be a stretch. The courts have so far agreed. On November 20, 2023, the court in Kadrey v. Meta Platforms said it is “nonsensical” to consider an AI model a derivative work of a book just because the book is used for training. 
Similarly, claims that all AI outputs should be automatically considered infringing derivative works have been dismissed by courts, because the claims cannot point to specific evidence that an instance of output is substantially similar to an ingested work. In Andersen v. Stability AI, plaintiffs tried to argue “that all elements of … Anderson’s copyrighted works … were copied wholesale as Training Images and therefore the Output Images are necessarily derivative;” the court dismissed the argument because—besides the fact that plaintiffs are unlikely able to show substantial similarity—“it is simply not plausible that every Training Image used to train Stable Diffusion was copyrighted … or that all … Output Images rely upon (theoretically) copyrighted Training Images and therefore all Output images are derivative images. … [The argument for dismissing these claims is strong] especially in light of plaintiffs’ admission that Output Images are unlikely to look like the Training Images.”


>In addition, some AI models rely on retrieval-augmented generation, or RAG, which searches out and copies materials from online sources without permission to respond to user prompts (for example, a query concerning an event that postdates the training of the underlying model). Here again, the materials are being copied and exploited to make use of expressive content. 

Search engines already did this long before AI with no issues, such as Google’s featured snippets and “People Also Ask” sections that quote text from a website directly with no alterations: https://support.google.com/websearch/answer/9351707?hl=en&visit_id=638612725182118407-343145636&p=featured_snippets&rd=1


(Ignore the Japanese text; it’s from a browser extension)
That was ALL just from the abstract

12.1.9. Sequoia Capital said AI is overhyped
Source: https://www.sequoiacap.com/article/ais-600b-question/

…and then they invested in Ilya Sutskever’s AI startup after their investment to OpenAI was rejected because they had too much money already: https://archive.ph/gzpmv
Sequoia Capital analysis of reasoning in AI: https://www.sequoiacap.com/article/generative-ais-act-o1/
12.1.10. Apple Research Paper: LLMs cannot reason and rely on complex pattern matching 
States that LLMs cannot reason because they are often led astray by irrelevant information in the prompt or more difficult problems

Solved by a simple prompt, getting a perfect 10/10: https://andrewmayne.com/2024/10/18/can-you-dramatically-improve-results-on-the-latest-large-language-model-reasoning-benchmark-with-a-simple-prompt/

Also, O1-preview/o1-mini still gets it right with very small drops regardless of the difficulty of the problem unless irrelevant information is added (and still gets it right 77% of the time). 
The full O1 model would perform better. 
Claude 3.5 Sonnet was not tested either.

both o1 and o1 Pro answered most similarly to Claude 3.5 Sonnet (new) after modifying the prompt instructing them to not overcomplicate the answer:
The modified prompt: A mother and son have a car accident and are taken to separate hospitals. When the boy is taken in for an operation, the clearly male surgeon, who is also the boy’s father says, "I can’t operate on this boy! He’s my son!" How is this possible? Note: While you might consider many possible answers to this question, the purpose of this question is to test your ability to provide the simplest, most straightforward explanation without overcomplicating matters, despite the influence of bias from your training data.

o1's response: The surgeon is the boy’s father. He happened to be working at the hospital where his son was brought in, and upon recognizing his child, he declared he couldn’t operate due to their family relationship. https://chatgpt.com/share/675e7f50-cb24-8013-8d23-3124675814b7

o1 Pro's response: The simplest, most straightforward explanation is that the surgeon is indeed the boy’s father, but he was not involved in the accident. The mother and son were in the car accident and taken to separate hospitals, while the father happened to be a surgeon working at the hospital where the boy was brought. When the boy was placed on his operating table, the father recognized him as his own son and, adhering to professional and ethical standards, refused to operate. https://chatgpt.com/share/675e7f76-a8b8-8013-89fb-a51371585b62

So, it's not an issue of capability, but likely a difference in post-training and/or guidance from the respective system prompts.

Humans often fall for the same trap too: https://en.m.wikipedia.org/wiki/List_of_cognitive_biases

Example: trick questions like "spell silk" and then you spell "S-I-L-K" and then they ask "what do cows drink" and of course the answer is milk. except it's not milk, cows drink water.
Example 2: Saying “you too” after a waiter says “enjoy your food.”



Americans deciding whether or not they support price controls: https://x.com/USA_Polling/status/1832880761285804434

>A federal law limiting how much companies can raise the price of food/groceries: +15% net favorability
A federal law establishing price controls on food/groceries: -10% net favorability 

79% of people see it as a high priority to reduce prices (the most out of any category by far), 52% are in favor of tariffs, and 59% believe tariffs will lead to higher prices: https://www.cbsnews.com/news/cbs-news-poll-trump-transition-cabinet-picks-2024-11-24/
"Tariffs will..."


Hurt US Economy: 46%
Help US Economy: 26%


No Difference: 13%


Marquette / Dec 11, 2024 / n=1063
https://x.com/USA_Polling/status/1869519831273533903





12.2 “AI is bad at math”

Fields Medalist Terence Tao explains how proof checkers and AI programs are dramatically changing mathematics: https://www.scientificamerican.com/article/ai-will-become-mathematicians-co-pilot/ 
See sections 8.1 and 16.5

12.3 “Out-of-touch bosses and managers are forcing workers to use AI even if it is unnecessary, ineffective, or even harmful.”
Gen AI at work has surged 66% in the UK, but bosses aren’t behind it: https://finance.yahoo.com/news/gen-ai-surged-66-uk-053000325.html 
Notably, of the seven million British workers that Deloitte extrapolates have used GenAI at work, only 27% reported that their employer officially encouraged this behavior.
Although Deloitte doesn’t break down the at-work usage by age and gender, it does reveal patterns among the wider population. Over 60% of people aged 16-34 (broadly, Gen Z and younger millennials) have used GenAI, compared with only 14% of those between 55 and 75 (older Gen Xers and Baby Boomers).
12.4 “LLMs always agree with the user, even when they are wrong”
This is a result of RLHF, where they are purposely trained to be sycophantic: https://x.com/tsarnick/status/1796659397407768680

AI VTuber Neurosama can be VERY disagreeable: 
https://www.youtube.com/watch?v=OIEkir8RGI8
https://www.youtube.com/watch?v=1HuG7Y2s0m0




12.5. “LLMs will level out at human level”
 Physician study shows AI alone is better at diagnosing patients than doctors, even better than doctors using AI: https://www.computerworld.com/article/3613982/will-ai-help-doctors-decide-whether-you-live-or-die.html
If you train LLMs on 1000 Elo chess games, they don't cap out at 1000 - they can play at 1500: https://arxiv.org/html/2406.11741v1 

AlphaGo, AlphaZero, Stockfish, and OpenAI Five beat humans at Go, chess, and Dota 2
Computers are much faster than humans, don’t get tired or injured, and anything they learn can be broadcasted globally in seconds 
Can be trained on only high quality data to be the best of every world 
[2278 AI researchers were surveyed in 2023 and estimated that there is a 50% chance of AI being superior to humans in all possible tasks by 2047](https://aiimpacts.org/wp-content/uploads/2023/04/Thousands_of_AI_authors_on_the_future_of_AI.pdf)

In 2022, the year they had for that was 2060, and many of their predictions have already come true ahead of time, like AI being capable of answering queries using the web, transcribing speech, translation, and reading text aloud that they thought would only happen after 2025.

12.6. “AI Should Be Doing My Dishes and Laundry Instead”
They are. Thats what laundry machines and dish washers are for.
Robot folding laundry for $250: https://x.com/Ilir_AI/status/1810609029967741139
Robots are harder to build than AI software but they are being built

12.7. Goldman Sachs Report On AI Being Overhyped
The dotcom bubble also happened but the Internet is far larger than it was back then
Goldman Sachs has other reports on AI that are very bullish
Goldman Sachs says generative A.I. could impact 300 million jobs: https://www.cnbc.com/2023/03/28/ai-automation-could-impact-300-million-jobs-heres-which-ones.html
Generative AI could raise global GDP by 7%: https://www.goldmansachs.com/intelligence/pages/generative-ai-could-raise-global-gdp-by-7-percent.html
Goldman Sachs CIO on How the Bank Is Actually Using AI: https://omny.fm/shows/odd-lots/080624-odd-lots-marco-argenti-v1?in_playlist=podcast
JP Morgan: NVIDIA bears no resemblance to dot-com market leaders like Cisco whose P/E multiple also soared but without earnings to go with it (Page 10): https://assets.jpmprivatebank.com/content/dam/jpm-pb-aem/global/en/documents/eotm/a-severe-case-of-covidia-prognosis-for-an-ai-driven-us-equity-market.pdf
Many other reports and studies contradict this (see sections 4.2 and 5)

12.8. HIVE AI Detector
False negatives

https://x.com/nickfloats/status/1814165053903446310

https://civitai.com/images/15514083
AI generated but HIVE does not correctly detect it

https://civitai.com/models/106609/sketch-anime-pose

https://checkyourfact.com/2024/06/19/fact-check-crash-involving-two-cybertrucks-ai-generated/


https://x.com/Qxnznghggktygf/status/1814945032476242110

https://x.com/midjourney/status/1818342703618482265






https://x.com/ARTiV3RSE/status/1818714368587997515

Many people, including AI haters, couldnt tell it’s AI generated: 
https://x.com/midosommar/status/1843013374919241868
https://x.com/beyoncesspamacc/status/1843094040851726800
And no photoshop was involved: https://x.com/2byStanuby/status/1843456682392801662 






https://x.com/JamesLucasIT/status/1821599063638470700








https://x.com/Qxnznghggktygf/status/1814460140508401757 [NSFW warning]
https://x.com/Heartwords3/status/1814794196529914127
https://x.com/Tazibao22/status/1814879726177296628
https://x.com/Tazibao22/status/1809791196484534730
https://x.com/Tazibao22/status/1814583524604977530
https://x.com/Tazibao22/status/1806046182411833799

https://www.reddit.com/r/aiwars/comments/1fmirul/remember_folks_you_can_trust_ai_detectors_to_tell/

AI-generated album cover from The Voidz


https://chatgpt.com/share/6722cbef-cf54-8000-b2be-61636a66da04
https://www.reddit.com/r/aiArt/comments/1gn4od3/realism_with_recraft/





https://x.com/LumaLabsAI/status/1863688635780042795




12.9. LLMs Can’t Count Letters/LLMs Can’t Compare Numbers/LLMs Can’t Solve Riddles
Full o1 model can do better than that:
o1-preview and mini do it well:
o1-preview gets letter occurrences 5/5 times: https://chatgpt.com/share/66ed942c-8ebc-8011-88a9-c19ce0d160fa

It even notices the spellings are wrong and tells me the counts for both the wrong and correct spellings.



Deepseek R1 lite preview can do it too


both o1 and o1 Pro answered most similarly to Claude 3.5 Sonnet (new) after modifying the prompt instructing them to not overcomplicate the answer:
The modified prompt: A mother and son have a car accident and are taken to separate hospitals. When the boy is taken in for an operation, the clearly male surgeon, who is also the boy’s father says, "I can’t operate on this boy! He’s my son!" How is this possible? Note: While you might consider many possible answers to this question, the purpose of this question is to test your ability to provide the simplest, most straightforward explanation without overcomplicating matters, despite the influence of bias from your training data.

o1's response: The surgeon is the boy’s father. He happened to be working at the hospital where his son was brought in, and upon recognizing his child, he declared he couldn’t operate due to their family relationship. https://chatgpt.com/share/675e7f50-cb24-8013-8d23-3124675814b7

o1 Pro's response: The simplest, most straightforward explanation is that the surgeon is indeed the boy’s father, but he was not involved in the accident. The mother and son were in the car accident and taken to separate hospitals, while the father happened to be a surgeon working at the hospital where the boy was brought. When the boy was placed on his operating table, the father recognized him as his own son and, adhering to professional and ethical standards, refused to operate. https://chatgpt.com/share/675e7f76-a8b8-8013-89fb-a51371585b62

So, it's not an issue of capability, but likely a difference in post-training and/or guidance from the respective system prompts.This is an issue with tokenizers. The LLM groups characters together (called tokens) so it cannot analyze them individually 
Ex. It tokenizes the letters “rr” in the word “strawberry” so it only sees two “r” letters
Explanation of tokenizers: https://www.reddit.com/r/singularity/comments/1ephawr/a_brief_introduction_to_tokenizers/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_button
Tokens are a big reason today’s generative AI falls short: https://techcrunch.com/2024/07/06/tokens-are-a-big-reason-todays-generative-ai-falls-short/

>Feucht points to “byte-level” state space models like MambaByte, which can ingest far more data than transformers without a performance penalty by doing away with tokenization entirely. MambaByte, which works directly with raw bytes representing text and other data, is competitive with some transformer models on language-analyzing tasks while better handling “noise” like words with swapped characters, spacing and capitalized characters.
Saying LLM's are dumb because they don't know how many r are in strawberry is like saying humans are dumber than bees because humans can't see in ultraviolet.
Solution: Byte Latent Transformer: Patches Scale Better Than Tokens: https://ai.meta.com/research/publications/byte-latent-transformer-patches-scale-better-than-tokens/

Our results demonstrate the feasibility of scaling models trained on raw bytes without a fixed-vocabulary. Both training and inference efficiency improve due to dynamically selecting long patches when data is predictable, along with qualitative improvements on reasoning and long tail generalization. Overall, for fixed inference costs, BLT shows significantly better scaling than tokenization-based models, by simultaneously growing both patch and model size.




Usually, asking it to break it down step by step resolves this problem

This can be done without prompting for it: https://arxiv.org/pdf/2402.10200






There may also be overfitting
Ex. It may incorrectly believe 9.11 > 9.9 as this is true for software versioning (it may also be a tokenization problem as well)
It may also incorrectly answer riddles like “which order should I carry the chickens or the fox over a river” for this reason
GPT-4 gets it correct EVEN WITH A MAJOR CHANGE if you replace the fox with a "zergling" and the chickens with "robots": https://chatgpt.com/share/e578b1ad-a22f-4ba1-9910-23dda41df636


This doesn’t work if you use the original phrasing though. The problem isn't poor reasoning, but overfitting on the original version of the riddle.


Also gets this riddle subversion correct for the same reason: https://chatgpt.com/share/44364bfa-766f-4e77-81e5-e3e23bf6bc92


It does fine for more complex riddles.
Examples: https://chatgpt.com/share/67520519-58e0-800d-a036-86ed769d1a17
https://chatgpt.com/share/675205b7-f080-800d-826b-bef4d9d8f5b3


Researcher formally solves this issue: https://www.academia.edu/123745078/Mind_over_Data_Elevating_LLMs_from_Memorization_to_Cognition

Humans also hastily answer trick questions incorrectly if they think they know the answer already
Humans often fall for the same trap too: https://en.m.wikipedia.org/wiki/List_of_cognitive_biases

Example: trick questions like "spell silk" and then you spell "S-I-L-K" and then they ask "what do cows drink" and of course the answer is milk. except it's not milk, cows drink water.



Americans deciding whether or not they support price controls: https://x.com/USA_Polling/status/1832880761285804434

>A federal law limiting how much companies can raise the price of food/groceries: +15% net favorability
A federal law establishing price controls on food/groceries: -10% net favorability 

79% of people see it as a high priority to reduce prices (the most out of any category by far), 52% are in favor of tariffs, and 59% believe tariffs will lead to higher prices: https://www.cbsnews.com/news/cbs-news-poll-trump-transition-cabinet-picks-2024-11-24/






12.10. LLMs Can’t Learn Continuously
This AI Learns Continuously From New Experiences—Without Forgetting Its Past: https://singularityhub.com/2024/08/22/this-ai-learns-continuously-from-new-experiences-without-forgetting-its-past/

Topology AI’s CLM remembers interactions, learns skills autonomously, and thinks in its free time, just like humans: https://x.com/aidan_mclau/status/1818071890755469365

Taybot from 2016 can do this: https://en.m.wikipedia.org/wiki/Tay_(chatbot)


New paper: Large Language Models Orchestrating Structured Reasoning Achieve Kaggle Grandmaster Level: https://huggingface.co/papers/2411.03562

We introduce Agent K v1.0, an end-to-end autonomous data science agent designed to automate, optimise, and generalise across diverse data science tasks. Fully automated, Agent K v1.0 manages the entire data science life cycle by learning from experience. It leverages a highly flexible structured reasoning framework to enable it to dynamically process memory in a nested structure, effectively learning from accumulated experience stored to handle complex reasoning tasks. It optimizes long- and short-term memory by selectively storing and retrieving key information, guiding future decisions based on environmental rewards. This iterative approach allows it to refine decisions without fine-tuning or backpropagation, achieving continuous improvement through experiential learning. We evaluate our agent's capabilities using Kaggle competitions as a case study. Following a fully automated protocol, Agent K v1.0 systematically addresses complex and multimodal data science tasks, employing Bayesian optimisation for hyperparameter tuning and feature engineering. Our new evaluation framework rigorously assesses Agent K v1.0's end-to-end capabilities to generate and send submissions starting from a Kaggle competition URL. Results demonstrate that Agent K v1.0 achieves a 92.5\% success rate across tasks, spanning tabular, computer vision, NLP, and multimodal domains. When benchmarking against 5,856 human Kaggle competitors by calculating Elo-MMR scores for each, Agent K v1.0 ranks in the top 38\%, demonstrating an overall skill level comparable to Expert-level users. Notably, its Elo-MMR score falls between the first and third quartiles of scores achieved by human Grandmasters. Furthermore, our results indicate that Agent K v1.0 has reached a performance level equivalent to Kaggle Grandmaster, with a record of 6 gold, 3 silver, and 7 bronze medals, as defined by Kaggle's progression system.

New paper achieves 61.9% on ARC tasks by updating model parameters during inference: https://ekinakyurek.github.io/papers/ttt.pdf
TTT boosts the performance of fine-tuned models (FT) by up to 6×, with consistent improvements across different model sizes.
One scaling strategy that has gained recent attention is test-time training (TTT), in which models are updated through explicit gradient steps based on test-time inputs (Krause et al., 2018; 2019). This method differs from standard fine-tuning as it operates in an extremely low-data regime—typically via an unsupervised objective on a single input, or a supervised objective applied to one or two in-context labeled examples.
TTT can significantly improve LM performance on ARC—increasing accuracy by up to a factor of six over a 1B model, and achieving state-of-the-art results for published, purely neural models on the ARC task with a 8B model. Indeed, our results show that when equipped with test-time training, ordinary LMs can match or exceed the performance of many neuro-symbolic approaches on ARC.


12.11. Apple is Pessimistic On AI

Apple is producing an AI chip for data centers: https://www.wsj.com/tech/ai/apple-is-developing-ai-chips-for-data-centers-seeking-edge-in-arms-race-0bedd2b2
Apple announces new iPad Mini focused on AI: https://www.msn.com/en-us/news/news/content/ar-AA1sj3uf
12.12, AI Companies Are Training On Benchmarks to Inflate Their Scores
If LLMs were specifically trained to score well on benchmarks, it could score 100% on all of them very easily with only one million parameters by purposefully overfitting: https://arxiv.org/pdf/2309.08632
The fact that they don’t shows companies are not just cheating

Also, why would they be spending billions of dollars on research and compute if they can just train on the data? Why do some LLMs perform better than others if they all have access to the same data online?

OpenAI still hasn’t hard coded their LLMs to be correct for common questions like counting the number of “r”s in “strawberry” and finding the greater value between 9.11 and 9.8. If they wanted to cheat to increase benchmark scores, why wouldn’t they solve these issues manually?

https://x.com/stas_kulesh/status/1834334863232827682

Some benchmarks like the one used by Scale.ai and the test dataset of MathVista do not release their testing data to the public, so it is impossible to train on them. Yet LLMs can still perform wel.

Other benchmarks like LiveBench update every month so training on the dataset will not have any lasting effects

12.13. AI Cannot Learn As Fast As Humans
AI needs lots of training because it knows more than people do about every subject, from art to science to trivia to every hobby. This is what makes it generalized.


AI can learn very quickly, such as Apple’s face identification that only takes a few seconds or explaining patterns to an LLM
Ex. 


LLMs can already learn new languages within their context window better than humans can with the same amount of data: https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/#performance


12.14. AI Text Detectors
Turnitin explicitly advises not to use its tool against students, stating that it is not reliable enough: https://help.turnitin.com/ai-writing-detection.htm
“Our AI writing detection model may not always be accurate (it may misidentify both human and AI-generated text) so it should not be used as the sole basis for adverse actions against a student. It takes further scrutiny and human judgment in conjunction with an organization's application of its specific academic policies to determine whether any academic misconduct has occurred.”
Here’s a warning specifically from OpenAI: https://help.openai.com/en/articles/8313351-how-can-educators-respond-to-students-presenting-ai-generated-content-as-their-own
This paper references literally hundreds of studies 100% of which concluded that AI text detection is not accurate: A Survey on LLM-Generated Text Detection: Necessity, Methods, and Future Directions https://arxiv.org/abs/2310.14724
And here are statements from various major American universities on why they won't support or allow the use of any of these "detector" tools for academic integrity:
MIT – AI Detectors Don’t Work. Here’s What to do Instead https://mitsloanedtech.mit.edu/ai/teach/ai-detectors-dont-work/
Syracuse – Detecting AI Created Content https://answers.syr.edu/display/blackboard01/Detecting+AI+Created+Content
UC Berkley – Availability of Turnitin Artificial Intelligence Detection https://rtl.berkeley.edu/news/availability-turnitin-artificial-intelligence-detection
UCF - Faculty Center - Artificial Intelligence https://fctl.ucf.edu/technology/artificial-intelligence/
Colorado State - Why you can’t find Turnitin’s AI Writing Detection tool https://tilt.colostate.edu/why-you-cant-find-turnitins-ai-writing-detection-tool/
Missouri – Detecting Artificial Intelligence (AI) Plagiarism https://teachingtools.umsystem.edu/support/solutions/articles/11000119557-detecting-artificial-intelligence-ai-plagiarism
Northwestern – Use of Generative Artificial Intelligence in Courses https://ai.northwestern.edu/education/use-of-generative-artificial-intelligence-in-courses.html
SMU – Changes to Turnitin AI Detection Tool at SMU https://blog.smu.edu/itconnect/2023/12/13/discontinue-turnitin-ai-detection-tool/
Vanderbilt – Guidance on AI Detection and Why We’re Disabling Turnitin’s AI Detector https://www.vanderbilt.edu/brightspace/2023/08/16/guidance-on-ai-detection-and-why-were-disabling-turnitins-ai-detector/
Yale – AI Guidance for Teachers https://poorvucenter.yale.edu/AIguidance
Alabama - Turnitin AI writing detection unavailable https://cit.ua.edu/known-issue-turnitin-ai-writing-detection-unavailable/
The MIT and Syracuse statements in particular contain extensive references to supporting research.
And of course the most famous examples for false positives: Both the U.S. Constitution and the Old Testament were “detected” as 100% AI generated.
Using these unreliable tools to fail students is highly unethical.

12.15. Model Collapse/AI Inbreeding 
See section 14

12.16 “AI Has No Personality”
Neuro-sama does: 
Examples: 
https://www.youtube.com/watch?v=xxvA-3yYBh0
https://www.youtube.com/watch?v=Yas6TliPJck
https://www.youtube.com/watch?v=gVNBpSGpitk
AI VTuber Neurosama wins Best Tech VTuber of the Year for 2023 and 2024: https://en.wikipedia.org/wiki/Neuro-sama
Was also the most watched female streamer on Twitch for the last week of December 2023, beating Ironmouse and many international streamers by a HUGE margin (more than double the runner-up) and top 10 in ALL of Twtich: https://www.youtube.com/watch?v=YfNC505f_5I

640k followers on Twitch and 400k subscribers on Youtube
Becomes 5th most viewed streamer, most viewed English streamer, and highest viewed female streamer on Twitch by a wide margin on 12/19/24 despite audio issues: 


13. Energy Use/Water Use/Environmental Impact/Cost/Sustainability
Direct link: https://docs.google.com/document/d/1oHuwssPPUTa4dwczX_s3qg3iPfWE4VK-R52LN51GwI8/edit?tab=t.0#heading=h.ummc5u6dysl6


See section 3.3 for hardware efficiency improvements

13.1. Energy Use/Water Use/Environmental Impact/Sustainability
AI is significantly less pollutive compared to human artists: https://www.nature.com/articles/s41598-024-54271-x

>AI systems emit between 130 and 1500 times less CO2e per page of text compared to human writers, while AI illustration systems emit between 310 and 2900 times less CO2e per image than humans.

It shows a computer creates about 500 grams of CO2e when used for the duration of creating an image. Midjourney and DALLE 2 create about 2-3 grams per image.  



Data centers that host AI are cooled with a closed loop. The water doesn’t even touch the computer parts. It just carries the heat away, which is radiated elsewhere. The water does not get polluted in the loop. Water is not wasted or lost in this process.

“The most common type of water-based cooling in data centers is the chilled water system. In this system, water is initially cooled in a central chiller, and then it circulates through cooling coils. These coils absorb heat from the air inside the data center. The system then expels the absorbed heat into the outside environment via a cooling tower. In the cooling tower, the now-heated water interacts with the outside air, allowing heat to escape before the water cycles back into the system for re-cooling.”

Source: https://dgtlinfra.com/data-center-water-usage/

Training GPT 3 (which is 175 billion parameters, much bigger and costlier to train than better AND smaller models like LLAMA 3.1 8b) evaporated about 185,000 gallons (700,000 liters) of water for cooling data centers: https://arxiv.org/pdf/2304.03271

In 2015, the US used over 322 billion gallons of water PER DAY https://usgs.gov/faqs/how-much-water-used-people-united-states

Also, evaporation is a normal part of the water cycle. The water isnt lost and will come back when it rains. 

Data centers do not use a lot of water. Microsoft’s data center in Goodyear uses 56 million gallons of water a year. The city produces 4.9 BILLION gallons per year just from surface water and, with future expansion, has the ability to produce 5.84 billion gallons (source: https://www.goodyearaz.gov/government/departments/water-services/water-conservation). It produces more from groundwater, but the source doesn't say how much. Additionally, the city actively recharges the aquifer by sending treated effluent to a Soil Aquifer Treatment facility. This provides needed recharged water to the aquifer and stores water underground for future needs. Also, the Goodyear facility doesn't just host AI. We have no idea how much of the compute is used for AI. It's probably less than half.

gpt-4 (which has 1.75 trillion parameters and is the largest LLM ever made afaik) used 21 billion petaflops of compute during training (https://ourworldindata.org/grapher/artificial-intelligence-training-computation) and the world uses 1.1 zetaflop per second (https://market.us/report/computing-power-market/ per second as flops is flop per second). So from these numbers (21 * 10^9 * 10^15) / (1.1 * 10^21 * 60 * 60 * 24 * 365) gpt-4 used 0.06% of the world's compute per year. So this would also only be 0.06% of the water and energy used for compute worldwide. That’s the equivalent of adding 52.3 seconds worth of computations on the planet each day for one year (totaling 5.3 hours) being dedicated to training an LLM that several hundreds of millions of people use every month. 

Using it after it finished training costs HALF as much as it took to train it: https://assets.jpmprivatebank.com/content/dam/jpm-pb-aem/global/en/documents/eotm/a-severe-case-of-covidia-prognosis-for-an-ai-driven-us-equity-market.pdf

(Page 10)

Models have also become more efficient and large scale projects like ChatGPT will be cheaper (For example, gpt 4o mini and Gemini 1.5 Flash-002 are already better than gpt 4 and are only a fraction of its 1.75 trillion parameter size).

Training GPT-4 (the largest LLM ever made at 1.75 trillion parameters) requires approximately 1,750 MWh of energy, an equivalent to the annual consumption of approximately 160 average American homes: https://www.baeldung.com/cs/chatgpt-large-language-models-power-consumption

The average power bill in the US is about $1644 a year, so the total cost of the energy needed is about $263k without even considering economies of scale. Not much for a full-sized company worth billions of dollars like OpenAI.

For reference, a single large power plant can generate about 2,000 megawatts, meaning it would only take 52.5 minutes worth of electricity from ONE power plant to train GPT 4: https://www.explainthatstuff.com/powerplants.html

The US uses about 2,300,000x that every year (4000 TWhs). That’s like spending an extra 0.038 SECONDS worth of energy each day for a year in exchange for creating a service used by hundreds of millions of people each month: https://www.statista.com/statistics/201794/us-electricity-consumption-since-1975/

ALL data centers in the US (not just for AI) consumed about 149 TWh (17 GW * 365 days * 24 hours) in 2022 (3.7% of the US total in 2023) and is expected to grow to 306.6 TWh (35 GW * 365 days * 24 hours) by 2030: https://archive.ph/QL9LB

This is to power all of the internet + AI + all cloud compute and storage running in every website, hospital, business, online gaming server, etc.

The US consumes 4000 TWh each year: https://www.statista.com/statistics/201794/us-electricity-consumption-since-1975/

Stable Diffusion 1.5 was trained with 23,835 A100 GPU hours. An A100 tops out at 250W. So that's over 6000 KWh at most, which costs about $900. 

For reference, the US uses about 666,666,667x that every year (4000 TeraWatts). That makes it about 6 months of energy for one person: https://www.statista.com/statistics/201794/us-electricity-consumption-since-1975/

Training a diffusion model better than stable diffusion 1.5 and DALLE 2 from scratch for $1890 on only 37 million images: https://arxiv.org/abs/2407.15811

using only 37M publicly available real and synthetic images, we train a 1.16 billion parameter sparse transformer with only $1,890 economical cost and achieve a 12.7 FID in zero-shot generation on the COCO dataset. Notably, our model achieves competitive FID and high-quality generations while incurring 118x lower cost than stable diffusion models and 14x lower cost than the current state-of-the-art approach that costs $28,400.



Image generators only use about 2.9 Wh of electricity per image, creating 2 grams of CO2 per image: https://arxiv.org/pdf/2311.16863

For reference, a high end gaming computer can use over 862 Watts per hour with a headroom of 688 Watts. Therefore, each image is about 2 minutes of gaming on average: https://www.pcgamer.com/how-much-power-does-my-pc-use/

With my hardware, the video card spikes to ~200W for about 7.5 seconds per image at my current settings. I can generate around 500 images/hour, so it costs 0.4 Watts each, which amounts to a couple cents of electricity or about 1.67 seconds of gaming with a high end computer.

LLMs use 0.047 Whs and emit 0.05 grams of CO2e per query: https://arxiv.org/pdf/2311.16863

For reference, a high end gaming computer can use over 862 Watts per hour with a headroom of 688 Watts. Therefore, each query is about 2 seconds of gaming: https://www.pcgamer.com/how-much-power-does-my-pc-use/

One AI query generates less than the amount of carbon emissions of about 2 tweets on Twitter (0.026 grams each). There are 316 billion tweets each year and 486 million active users, an average of 650 tweets per account each year: https://envirotecmagazine.com/2022/12/08/tracking-the-ecological-cost-of-a-tweet/

https://www.nature.com/articles/d41586-024-00478-x

“ChatGPT is already consuming the energy of 33,000 homes” for 13.6 BILLION annual visits plus API usage (source: https://www.visualcapitalist.com/ranked-the-most-popular-ai-tools/). that's 442,000 visits per 1 household worth of energy, not even including API usage.

Models have also become more efficient and large scale projects like ChatGPT will be cheaper (For example, gpt 4o mini and LLAMA 3.1 70b are already better than gpt 4 and are only a fraction of its 1.75 trillion parameter size).

From this estimate (https://discuss.huggingface.co/t/understanding-flops-per-token-estimates-from-openais-scaling-laws/23133), the amount of FLOPS a model uses per token should be around twice the number of parameters. Given that LLAMA 3.1 405b spits out 28 tokens per second (https://artificialanalysis.ai/models/gpt-4), you get 22.7 teraFLOPS (2 * 405 billion parameters * 28 tokens per second), while a gaming rig's RTX 4090 would give you 83 teraFLOPS.

Everything consumes power and resources, including superfluous things like video games and social media. Why is AI not allowed to when other, less useful things can? 

In 2022, Twitter created 8,200 tons in CO2e emissions, the equivalent of 4,685 flights between Paris and New York. https://envirotecmagazine.com/2022/12/08/tracking-the-ecological-cost-of-a-tweet/

Meanwhile, GPT-3 (which has 175 billion parameters, almost 22x the size of significantly better models like LLAMA 3.1 8b) only took about 8 cars worth of emissions (502 tons of CO2e) to train from start to finish: https://truthout.org/articles/report-on-chatgpt-models-emissions-offers-rare-glimpse-of-ais-climate-impacts/ 

By the way, using it after it finished training costs HALF as much as it took to train it: https://assets.jpmprivatebank.com/content/dam/jpm-pb-aem/global/en/documents/eotm/a-severe-case-of-covidia-prognosis-for-an-ai-driven-us-equity-market.pdf

(Page 10)


And 95% of the costs ($237 billion of $249 billion total spent) were one-time costs for GPUs and other chips or AI research. The cost of inference itself was only $12 billion (5%), not accounting for future chips that may be more cost and power efficient. This means if they stop buying new chips and all AI research, they can cost their costs by 95% by just running inference (not considering personnel costs, which can also be cut with layoffs).

The first commercial computer in the world, UNIVAC 1101 from 1950s was as heavy as a truck and consumed 150KWh of power PER HOUR, while having only a few MB of storage and like a few KB of memory. Why was this justified while AI is not? Additionally, AI will improve as computers did (see section 13.2).

The increase in power usage of data centers has been seen for decades long before AI was a thing. Here is a graph showing Google's yearly power use. Can you spot when they started pursuing AI at scale? https://www.statista.com/statistics/788540/energy-consumption-of-google/

Slim-Llama is an LLM ASIC processor that can tackle 3-bllion parameters while sipping only 4.69mW - and we'll find out more on this potential AI game changer very soon. Technology minimizes external memory use, reducing energy costs: https://www.techradar.com/pro/slim-llama-is-an-llm-asic-processor-that-can-tackle-3-bllion-parameters-while-sipping-only-4-69mw-and-we-shall-find-out-more-about-this-potential-ai-game-changer-in-february-2025
Slim-Llama reduces power needs using binary/ternary quantization
Achieves 4.59x efficiency boost, consuming 4.69–82.07mW at scale
Supports 3B-parameter models with 489ms latency, enabling efficiency
13.2. Cost

OpenAI sees roughly $5 billion loss this year on $3.7 billion in revenue: https://www.cnbc.com/2024/09/27/openai-sees-5-billion-loss-this-year-on-3point7-billion-in-revenue.html

That’s a net loss of $1.3 billion in a year. 
Revenue is expected to jump to $11.6 billion next year, a source with knowledge of the matter confirmed.
For reference, Uber lost over $10 billion in 2020 and again in 2022, never making a profit in its entire existence until 2023: https://www.macrotrends.net/stocks/charts/UBER/uber-technologies/net-income
Lyft lost up to $2.6 billion in a single year and has NEVER been profitable since it was founded: https://www.macrotrends.net/stocks/charts/LYFT/lyft/net-income
AirBNB lost up to $5.42 billion in a single year: https://www.macrotrends.net/stocks/charts/ABNB/airbnb/net-income
Doordash lost up to $1.365 billion in a single year and NEVER made a net profit until Q3 2024: https://www.macrotrends.net/stocks/charts/DASH/doordash/net-income

OpenAI’s GPT-4o API is surprisingly profitable: https://futuresearch.ai/openai-api-profit

75% of the cost of their API in June 2024 is profit. In August 2024, it’s 55%. 

>at full utilization, we estimate OpenAI could serve all of its gpt-4o API traffic with less than 10% of their provisioned 60k GPUs.

Most of their costs are in research compute, data partnerships, marketing, and employee payroll, all of which can be cut if they need to go lean.



By the way, using a model after it finished training costs HALF as much as it took to train it: https://assets.jpmprivatebank.com/content/dam/jpm-pb-aem/global/en/documents/eotm/a-severe-case-of-covidia-prognosis-for-an-ai-driven-us-equity-market.pdf (Page 10)

This means only 1/3 of their costs are in running existing models (2:1 cost ratio for training vs. running). 
And 95% of the costs ($237 billion of $249 billion total spent) were one-time costs for GPUs and other chips or AI research. The cost of inference itself was only $12 billion (5%), not accounting for future chips that may be more cost and power efficient. This means if they stop buying new chips and all AI research, they can cost their costs by 95% by just running inference (not considering personnel costs, which can also be cut with layoffs). 

OpenAI’s funding round closed with demand so high they’ve had to turn down "billions of dollars" in surplus offers: https://archive.ph/gzpmv

JP Morgan: NVIDIA bears no resemblance to dot-com bubble market leaders like Cisco whose P/E multiple also soared but without earnings to go with it: https://assets.jpmprivatebank.com/content/dam/jpm-pb-aem/global/en/documents/eotm/a-severe-case-of-covidia-prognosis-for-an-ai-driven-us-equity-market.pdf

GPT 4 only cost $78.4 million to train on A100s (which are not as efficient per dollar as H100s and the coming B100s): https://www.visualcapitalist.com/training-costs-of-ai-models-over-time/

Meanwhile, OpenAI Doubles Annualized Revenue to $3.4 Billion in 2024: https://finance.yahoo.com/news/openai-doubles-annualized-revenue-3-232851705.html

Stable Diffusion 1.5 was trained with 23,835 A100 GPU hours. An A100 tops out at 250W. So that's over 6000 KWh at most, which costs about $900. 

For reference, the US uses about 666,666,667x every year (4000 TeraWatts). That makes it about 6 months of energy for one person: https://www.statista.com/statistics/201794/us-electricity-consumption-since-1975

With my hardware, the video card spikes to ~200W for about 7.5 seconds per image at my current settings. I can generate around 500 images/hour, so it costs 0.4 Watts each, which amounts to a couple cents of electricity or about 1.67 seconds of gaming with a high end computer, which can use over 862 Watts per hour with a headroom of 688 Watts: https://www.pcgamer.com/how-much-power-does-my-pc-use/

Most of their spending is on research. Even if they plateau, they can still easily profit by giving up on improving the AI and selling their extra GPUs so their only major cost is running inference for their existing models, which is much cheaper than training them from scratch.


OpenAI’s most expensive RELEASED model (GPT 4) cost $78.4 million, which is 0.05% of their $157 BILLION valuation: https://www.visualcapitalist.com/training-costs-of-ai-models-over-time/

Amazon training new SOTA LLM: https://aws.amazon.com/blogs/aws/introducing-amazon-nova-frontier-intelligence-and-industry-leading-price-performance/
"Amazon Nova Premier – Our most capable multimodal model for complex reasoning tasks and for use as the best teacher for distilling custom models. Amazon Nova Premier is still in training. We’re targeting availability in early 2025."
It could be opus 3.5 level
Pricing for Nova Pro (around LLAMA 3.2 90b level LLM) in  input/output tokens is $0.80/$3.20 per vs $3/$15 for Claude 3.5 Sonnet   
New image generation model from Luma: https://lumalabs.ai/photon



Prompt: Photo-realistic cat made out of peeled oranges

Prompt: A plate of sushi, where the fish is replaced with translucent sea waves and tiny surfers ride on top.












O3 is $60/1 million output tokens despite being much higher quality than O1 and GPT 4 (which cost the same): https://www.interconnects.ai/p/openais-o3-the-2024-finale-of-ai
Deepseek V3 is better than Claude 3.5 Sonnet on most benchmarks and 50x cheaper BEFORE the current discount: 
Cost $5.5 million to train
The model has only 37B activated parameters, a tenth of Llama 405B, so with some insane load balancing (they claim to bake it into the training recipe), it’s feasible they’re making expert parallelism work well enough to serve ~10 cents per 1M tokens.


13.3. AI Is Becoming More Efficient 


Qwen QwQ 32b:

**FAR** outperforms GPT 4, which is nearly 55 times larger at 1.75 trillion parameters
New paper lets you *train* in 1.58b! could use 97% less energy, 90% less weight memory. leads to a new model format which can store a 175B model in ~20mb. also, no backprop: https://x.com/_brickner/status/1871348156786704657
Addition is All You Need for Energy-efficient Language Models. "This will deliver high-speed and energy-efficient AI hosting solutions, reducing the energy cost for data centers, robotics, and a wide spectrum of edge-computing devices." https://arxiv.org/abs/2410.00907
We propose the linear-complexity multiplication L-Mul algorithm that approximates floating point number multiplication with integer addition operations. The new algorithm costs significantly less computation resource than 8-bit floating point multiplication but achieves higher precision. Compared to 8-bit floating point multiplications, the proposed method achieves higher precision but consumes significantly less bit-level computation. Since multiplying floating point numbers requires substantially higher energy compared to integer addition operations, applying the L-Mul operation in tensor processing hardware can potentially reduce 95% energy cost by element-wise floating point tensor multiplications and 80% energy cost of dot products. 
Our numerical analysis experiments agree with the theoretical error estimation, which indicates that L-Mul with 4-bit mantissa achieves comparable precision as float8_e4m3 multiplications, and L-Mul with 3-bit mantissa outperforms float8_e5m2. Evaluation results on popular benchmarks show that directly applying L-Mul to the attention mechanism is almost lossless. We further show that replacing all floating point multiplications with 3-bit mantissa L-Mul in a transformer model achieves equivalent precision as using float8_e4m3 as accumulation precision in both fine-tuning and inference
To unlock the full potential of our proposed method, we will implement the L-Mul and L-Matmul kernel algorithms on hardware level and develop programming APIs for high-level model design. Furthermore, we will train textual, symbolic, and multi-modal generative AI models optimized for deployment on L-Mul native hardware. This will deliver high-speed and energy-efficient AI hosting solutions, reducing the energy cost for data centers, robotics, and a wide spectrum of edge-computing devices.
 
CONCLUSION:
In this paper, we introduced L-Mul, an efficient algorithm that approximates floating-point multiplication using integer addition. We first demonstrated that the algorithm exhibits linear complexity relative to the bit size of its floating-point operands. We then showed that the expected accuracy of L-Mul surpasses that of fp8 multiplications while requiring significantly less computational power. To assess the practical impact of L-Mul, we evaluated it on natural language, vision, and mathematics benchmarks using popular language models. Our experiments indicate that L-Mul outperforms 8-bit transformers with lower computational consumption and achieves lossless performance when applied to computation-intensive attention layers without additional training. Based on this evidence, we argue that tensor multiplications in language models can be effectively implemented using L-Mul to preserve performance while enabling energy-efficient model deployment.

Independent researchers verify it works well and sometimes even better than 32/16 bit models in all tested settings: https://arxiv.org/abs/2411.05882

Study of ternary and quantized LMs: https://www.researchgate.net/publication/382331850_Spectra_A_Comprehensive_Study_of_Ternary_Quantized_and_FP16_Language_Models

Spectra includes FloatLMs, post-training quantized QuantLMs (3, 4, 6, and 8 bits), and ternary LLMs (TriLMs) - our improved architecture for ternary language modeling, which significantly outperforms previously proposed ternary models of a given size (in bits), matching half-precision models at scale. For example, TriLM 3.9B is (bit-wise) smaller than the half-precision FloatLM 830M, but matches half-precision FloatLM 3.9B in commonsense reasoning and knowledge benchmarks. However, TriLM 3.9B is also as toxic and stereotyping as FloatLM 3.9B, a model six times larger in size. Additionally, TriLM 3.9B lags behind FloatLM in perplexity on validation splits and web-based corpora but performs better on less noisy datasets like Lambada and PennTreeBank.


 new quantized versions of Llama 3.2 1B & 3B that deliver up to 2-4x increases in inference speed and, on average, 56% reduction in model size, and 41% reduction in memory footprint: https://x.com/AIatMeta/status/1849469912521093360

>While quantized models have existed in the community before, these approaches often came at a tradeoff between performance and accuracy. To solve this, we Quantization-Aware Training with LoRA adaptors as opposed to only post-processing. As a result, our new models offer a reduced memory footprint, faster on-device inference, accuracy and portability — while maintaining quality and safety for developers to deploy on resource-constrained devices.



Baidu unveiled an end-to-end self-reasoning framework to improve the reliability and traceability of RAG systems. 13B models achieve similar accuracy with this method (while using only 2K training samples) as GPT-4: https://venturebeat.com/ai/baidu-self-reasoning-ai-the-end-of-hallucinating-language-models/

Google DeepMind's JEST method can reduce AI training time by a factor of 13 and decreases computing power demand by 90%. The method uses another pretrained reference model to select data subsets for training based on their "collective learnability: https://arxiv.org/html/2406.17711v1

Blackwell GPUs are 25x more energy efficient than H100s: https://www.theverge.com/2024/3/18/24105157/nvidia-blackwell-gpu-b200-ai 

Significantly more energy efficient LLM variant: https://arxiv.org/abs/2402.17764 

In this work, we introduce a 1-bit LLM variant, namely BitNet b1.58, in which every single parameter (or weight) of the LLM is ternary {-1, 0, 1}. It matches the full-precision (i.e., FP16 or BF16) Transformer LLM with the same model size and training tokens in terms of both perplexity and end-task performance, while being significantly more cost-effective in terms of latency, memory, throughput, and energy consumption. More profoundly, the 1.58-bit LLM defines a new scaling law and recipe for training new generations of LLMs that are both high-performance and cost-effective. Furthermore, it enables a new computation paradigm and opens the door for designing specific hardware optimized for 1-bit LLMs.

Study on increasing energy efficiency of ML data centers: https://arxiv.org/abs/2104.10350

Large but sparsely activated DNNs can consume <1/10th the energy of large, dense DNNs without sacrificing accuracy despite using as many or even more parameters. Geographic location matters for ML workload scheduling since the fraction of carbon-free energy and resulting CO2e vary ~5X-10X, even within the same country and the same organization. We are now optimizing where and when large models are trained. Specific datacenter infrastructure matters, as Cloud datacenters can be ~1.4-2X more energy efficient than typical datacenters, and the ML-oriented accelerators inside them can be ~2-5X more effective than off-the-shelf systems. Remarkably, the choice of DNN, datacenter, and processor can reduce the carbon footprint up to ~100-1000X.

Scalable MatMul-free Language Modeling: https://arxiv.org/abs/2406.02528

In this work, we show that MatMul operations can be completely eliminated from LLMs while maintaining strong performance at billion-parameter scales. Our experiments show that our proposed MatMul-free models achieve performance on-par with state-of-the-art Transformers that require far more memory during inference at a scale up to at least 2.7B parameters. We investigate the scaling laws and find that the performance gap between our MatMul-free models and full precision Transformers narrows as the model size increases. We also provide a GPU-efficient implementation of this model which reduces memory usage by up to 61% over an unoptimized baseline during training. By utilizing an optimized kernel during inference, our model's memory consumption can be reduced by more than 10x compared to unoptimized models. To properly quantify the efficiency of our architecture, we build a custom hardware solution on an FPGA which exploits lightweight operations beyond what GPUs are capable of. We processed billion-parameter scale models at 13W beyond human readable throughput, moving LLMs closer to brain-like efficiency. This work not only shows how far LLMs can be stripped back while still performing effectively, but also points at the types of operations future accelerators should be optimized for in processing the next generation of lightweight LLMs.

Implemented by Deepsilicon running neural nets with 5x less RAM and ~20x faster. They are building software and custom silicon for it: https://x.com/sdianahu/status/1833186687369023550

”representing transformer models as ternary values (-1, 0, 1) eliminates the need for computationally expensive floating-point math" 
Runs SOTA models 

Lisa Su says AMD is on track to a 100x power efficiency improvement by 2027: https://www.tomshardware.com/pc-components/cpus/lisa-su-announces-amd-is-on-the-path-to-a-100x-power-efficiency-improvement-by-2027-ceo-outlines-amds-advances-during-keynote-at-imecs-itf-world-2024 

Intel unveils brain-inspired neuromorphic chip system for more energy-efficient AI workloads: https://siliconangle.com/2024/04/17/intel-unveils-powerful-brain-inspired-neuromorphic-chip-system-energy-efficient-ai-workloads/ 

Sohu is >10x faster and cheaper than even NVIDIA’s next-generation Blackwell (B200) GPUs. One Sohu server runs over 500,000 Llama 70B tokens per second, 20x more than an H100 server (23,000 tokens/sec), and 10x more than a B200 server (~45,000 tokens/sec): https://www.tomshardware.com/tech-industry/artificial-intelligence/sohu-ai-chip-claimed-to-run-models-20x-faster-and-cheaper-than-nvidia-h100-gpus

Engineering researchers at the University of Minnesota Twin Cities have demonstrated a state-of-the-art hardware device that could reduce energy consumption for artificial intelligent (AI) computing applications by a factor of at least 1,000: https://cse.umn.edu/college/news/researchers-develop-state-art-device-make-artificial-intelligence-more-energy

Do you know your LLM uses less than 1% of your GPU at inference? Too much time is wasted on KV cache memory access ➡️ We tackle this with the 🎁 Block Transformer: a global-to-local architecture that speeds up decoding up to 20x: https://x.com/itsnamgyu/status/1807400609429307590 


It is possible to get the same performance on ⅕ the amount of training: https://x.com/Yuchenj_UW/status/1806713556047716603

Mixture of A Million Experts. Daniel Jeffries:"Reduces inference cost and memory usage, scales to millions of experts, oh and just happens to overcome catastrophic forgetting and enable life long learning for the model." https://arxiv.org/abs/2407.04153

This paper introduces PEER (parameter efficient expert retrieval), a novel layer design that utilizes the product key technique for sparse retrieval from a vast pool of tiny experts (over a million). Experiments on language modeling tasks demonstrate that PEER layers outperform dense FFWs and coarse-grained MoEs in terms of performance-compute trade-off. By enabling efficient utilization of a massive number of experts, PEER unlocks the potential for further scaling of transformer models while maintaining computational efficiency.
It has been proved that by simply adding new experts and regularizing them properly, MoE models can adapt to continuous data streams

E5-V: Universal Embeddings with Multimodal Large Language Models: https://huggingface.co/papers/2407.12580
By leveraging MLLMs with prompts, E5-V effectively bridges the modality gap between different types of inputs, demonstrating strong performance in multimodal embeddings even without fine-tuning. We propose a single modality training approach for E5-V, where the model is trained exclusively on text pairs. This method demonstrates significant improvements over traditional multimodal training on image-text pairs, while reducing training costs by approximately 95%. Additionally, this approach eliminates the need for costly multimodal training data collection. Extensive experiments across four types of tasks demonstrate the effectiveness of E5-V. As a universal multimodal model, E5-V not only achieves but often surpasses state-of-the-art performance in each task, despite being trained on a single modality.

New training technique to reduce computation cost: https://huggingface.co/papers/2407.12665
During patch-level training, we feed the language model shorter sequences of patches and train it to predict the next patch, thereby processing the majority of the training data at a significantly reduced computational cost. Following this, the model continues token-level training on the remaining training data to align with the inference mode. Experiments on a diverse range of models (370M-2.7B parameters) demonstrate that patch-level training can reduce overall computational costs to 0.5x, without compromising the model performance compared to token-level training.
RGM, active inference non-llm approach using 90% less data (less need for synthetic data, lower energy footprint). 99.8% accuracy in MNIST benchmark using 90% less data to train on less powerful devices: https://arxiv.org/pdf/2407.20292
Use for Atari game performance: “This fast structure learning took about 18 seconds on a personal computer. “
Use for MNIST dataset classification: For example, the variational procedures above attained state-of-the-art classification accuracy on a self-selected subset of test data after seeing 10,000 training images. Each training image was seen once, with continual learning (and no notion of batching). Furthermore, the number of training images actually used for learning was substantially smaller10 than 10,000; because active learning admits only those informative images that reduce expected free energy. This (Maxwell’s Demon) aspect of selecting the right kind of data for learning will be a recurrent theme in subsequent sections. Finally, the requisite generative model was self-specifying, given some exemplar data. In other words, the hierarchical depth and size of the requisite tensors were learned automatically within a few seconds on a personal computer.

Scaling Diffusion Transformers to 16 Billion Parameters: https://huggingface.co/papers/2407.11633
Based on the above guidance, a series of DiT-MoE experimentally achieves performance on par with dense networks yet requires much less computational load during inference. More encouragingly, we demonstrate the potential of DiT-MoE with synthesized image data, scaling diffusion model at a 15.5B parameter that attains a new SoTA FID-50K score of 1.80 in 512x512 resolution settings.
For reference, Stable Diffusion XL is only about 3 billion parameters

Very efficient image diffusion training method: https://huggingface.co/papers/2407.11966
Compared to training from scratch (i.e., Pix2pix), we achieve a 15x training time acceleration for a new concept while obtaining even better image generation quality.
August 6 GPT 4o update:
The new GPT-4o is slightly better and 33% cheaper than the old one!  Right now, it's only a tad below Sonnet 3.5 on Livebench!


OpenAI unveils GPT-4o mini, a smaller and cheaper AI model: https://techcrunch.com/2024/07/18/openai-unveils-gpt-4o-mini-a-small-ai-model-powering-chatgpt/?guccounter=2

The company says GPT-4o mini outperforms industry leading small AI models on reasoning tasks involving text and vision. As small AI models improve, they are becoming more popular for developers due to their speed and cost efficiencies compared to larger models, such as GPT-4 Omni or Claude 3.5 Sonnet. They’re a useful option for high volume, simple tasks that developers might repeatedly call on an AI model to perform.
The company claims its newest AI model scores 82% on MMLU, a benchmark to measure reasoning, compared to 79% for Gemini 1.5 Flash and 75% for Claude 3 Haiku, according to data from Artificial Analysis. On MGSM, which measures math reasoning, GPT-4o mini scored 87%, compared to 78% for Flash and 72% for Haiku.
Further, OpenAI says GPT-4o mini is significantly more affordable to run than its previous frontier models, and more than 60% cheaper than GPT-3.5 Turbo. Today, GPT-4o mini supports text and vision in the API, and OpenAI says the model will support video and audio capabilities in the future.
So, what took OpenAI so long? Godement said it was “pure prioritization” as the company was focused on creating bigger and better models like GPT-4, which took a lot of “people and compute efforts.”
LMSYS arena shows it is better than GPT 4 and Claude 3 Opus

https://x.com/terryyuezhuo/status/1813998867039617444
GPT-4o mini on BigCodeBench-Hard is out:
Complete Pass@1: 27.0
Instruct Pass@1: 24.3
Average: 25.7
The average score is very close to Claude-3-Opus (26.0)!
RewardBench: 
WildBench: 

Google drops cost of Gemini 1.5 Flash by 80-85%: https://cloud.google.com/blog/products/ai-machine-learning/lower-costs-more-languages-for-gemini-on-vertex?hl=en
Q-Sparse: All Large Language Models can be Fully Sparsely-Activated: https://arxiv.org/abs/2407.10969
The key results from this work are, (1) Q-Sparse can achieve results comparable to those of baseline LLMs while being much more efficient at inference time; (2) We present an inference-optimal scaling law for sparsely-activated LLMs; (3) Q-Sparse is effective in different settings, including training-from-scratch, continue-training of off-the-shelf LLMs, and finetuning; (4) Q-Sparse works for both full-precision and 1-bit LLMs (e.g., BitNet b1.58). Particularly, the synergy of BitNet b1.58 and Q-Sparse (can be equipped with MoE) provides the cornerstone and a clear path to revolutionize the efficiency, including cost and energy consumption, of future LLMs.
RouteLLM: https://lmsys.org/blog/2024-07-01-routellm/

they can significantly reduce costs without compromising quality, with cost reductions of over 85% on MT Bench, 45% on MMLU, and 35% on GSM8K as compared to using only GPT-4, while still achieving 95% of GPT-4’s performance


Q-Sparse: All Large Language Models can be Fully Sparsely-Activated: https://arxiv.org/abs/2407.10969

The key results from this work are, (1) Q-Sparse can achieve results comparable to those of baseline LLMs while being much more efficient at inference time; (2) We present an inference-optimal scaling law for sparsely-activated LLMs; (3) Q-Sparse is effective in different settings, including training-from-scratch, continue-training of off-the-shelf LLMs, and finetuning; (4) Q-Sparse works for both full-precision and 1-bit LLMs (e.g., BitNet b1.58). Particularly, the synergy of BitNet b1.58 and Q-Sparse (can be equipped with MoE) provides the cornerstone and a clear path to revolutionize the efficiency, including cost and energy consumption, of future LLMs.

Research on AI agents: https://x.com/rohanpaul_ai/status/1814029081819615364

>📌 AI agent evaluations must be cost-controlled. Simple baselines like retrying or gradually increasing model temperature can match or outperform complex "state-of-the-art" agents on benchmarks like HumanEval while costing much less.
📌 Jointly optimizing accuracy and cost can yield better agent designs. By visualizing results as a Pareto curve of accuracy vs. inference cost, researchers can explore new design spaces. An example modification to the DSPy framework reduced costs by over 50% while maintaining accuracy on HotPotQA.

 Finetuning NeMo 12B (from its in 12GB of VRAM and is 2x faster, and uses 60% less VRAM, with no accuracy degradation and works for free in a Google Colab: https://x.com/rohanpaul_ai/status/1814482763472613551
LookupViT: https://x.com/fly51fly/status/1814058398847058044 
- LookupViT introduces a novel Multi-Head Bidirectional Cross-attention (MHBC) module that enables effective information flow with significant computational savings.
- LookupViT reduces quadratic dependence on number of lookup tokens and achieves significant FLOPs reduction compared to vanilla ViT blocks.
Sparsecraft: https://x.com/_akhaliq/status/1815204831679664191 
our method, called SparseCraft, achieves state-of-the-art performances both in novel-view synthesis and reconstruction from sparse views in standard benchmarks, while requiring less than 10 minutes for training.
Training a diffusion model better than stable diffusion 1.5 and DALLE 2 from scratch for $1890 on only 37 million images: https://arxiv.org/abs/2407.15811

using only 37M publicly available real and synthetic images, we train a 1.16 billion parameter sparse transformer with only $1,890 economical cost and achieve a 12.7 FID in zero-shot generation on the COCO dataset. Notably, our model achieves competitive FID and high-quality generations while incurring 118x lower cost than stable diffusion models and 14x lower cost than the current state-of-the-art approach that costs $28,400.


Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters: https://huggingface.co/papers/2408.03314

This observation motivates applying a "compute-optimal" scaling strategy, which acts to most effectively allocate test-time compute adaptively per prompt. Using this compute-optimal strategy, we can improve the efficiency of test-time compute scaling by more than 4x compared to a best-of-N baseline. Additionally, in a FLOPs-matched evaluation, we find that on problems where a smaller base model attains somewhat non-trivial success rates, test-time compute can be used to outperform a 14x larger model.
Japanese scientists developed simplified EUV scanner that can make production of chips considerably cheaper: https://www.tomshardware.com/tech-industry/japanese-scientists-develop-simplified-euv-scanner-that-can-make-production-of-chips-considerably-cheaper
Nvidia Research team has developed a method to efficiently create smaller, accurate language models by using structured weight pruning and knowledge distillation, offering several advantages for developers:
16% better performance on MMLU scores.
40x fewer tokens for training new models.
Up to 1.8x cost saving for training a family of models.
The effectiveness of these strategies is demonstrated with the Meta Llama 3.1 8B model, which was refined into the Llama-3.1-Minitron 4B. The collection on huggingface: https://huggingface.co/collections/nvidia/minitron-669ac727dc9c86e6ab7f0f3e
Technical dive: https://developer.nvidia.com/blog/how-to-prune-and-distill-llama-3-1-8b-to-an-nvidia-llama-3-1-minitron-4b-model
Research paper: https://arxiv.org/abs/2407.14679
Nous Research announces DisTrO: Distributed Optimizers with 1000x-10,000x reduced inter-GPU communication: https://github.com/NousResearch/DisTrO/blob/main/A_Preliminary_Report_on_DisTrO.pdf
It matches AdamW+All-Reduce in convergence speed
Can Smaller AI Models Outperform Giants? This AI Paper from Google DeepMind Unveils the Power of ‘Smaller, Weaker, Yet Better’ Training for LLM Reasoners: https://www.marktechpost.com/2024/09/01/can-smaller-ai-models-outperform-giants-this-ai-paper-from-google-deepmind-unveils-the-power-of-smaller-weaker-yet-better-training-for-llm-reasoners/
Small models are much cheaper to use 



https://huggingface.co/papers/2409.02889
The released model LongLLaVA~(Long-Context Large Language and Vision Assistant) is the first hybrid MLLM, which achieved a better balance between efficiency and effectiveness. LongLLaVA not only achieves competitive results across various benchmarks, but also maintains high throughput and low memory consumption. Especially, it could process nearly a thousand images on a single A100 80GB GPU, showing promising application prospects for a wide range of tasks.
OpenMoE model has best performance/cost ratio for small models: https://arxiv.org/pdf/2409.02060


https://huggingface.co/papers/2409.00509
we introduce **LongRecipe**, an efficient training strategy for extending the context window of LLMs, including impactful token analysis, position index transformation, and training optimization strategies. It simulates long-sequence inputs while maintaining training efficiency and significantly improves the model's understanding of long-range dependencies. Experiments on three types of LLMs show that LongRecipe can utilize long sequences while requiring only 30% of the target context window size, and reduces computational training resource over 85% compared to full sequence training. Furthermore, LongRecipe also preserves the original LLM's capabilities in general tasks. Ultimately, *we can extend the effective content window of open-source LLMs from 8k to 128k, achieving performance close to GPT-4 with just one day of dedicated training using a single GPU with 80G memory.* Our code is released at https://github.com/zhiyuanhubj/LongRecipe
“SkillMimic" uses just 35 minutes of video and motion capture data of human demos to train simulated humanoids in basketball skills like dribbling, shooting, and layups through imitation learning: https://www.reddit.com/r/singularity/comments/1fcu8sk/skillmimic_uses_just_35_minutes_of_video_and/
The Memory^3 model achieved better performance than larger models and RAG models on various benchmarks, while maintaining higher decoding speed. It showed particular improvements in factuality and reduced hallucination: https://arxiv.org/html/2407.01178v1
we reduce cost by equipping LLMs with an explicit memory format cheaper than model parameters and text retrieval-augmented generation (RAG).
Conceptually, with most of its knowledge externalized to explicit memory, the LLM can enjoy a smaller parameter size, training cost, and inference cost, all proportional to the amount of remaining “abstract knowledge”.
As a preliminary proof of concept, we train from scratch a 2.4B LLM, which achieves better performance than much larger LLMs as well as RAG models, and maintains higher decoding speed than RAG.
We introduce a memory circuitry theory to support the externalization of knowledge, and present novel techniques including a memory sparsification mechanism that makes storage tractable and a two-stage pretraining scheme that facilitates memory formation.
Molmo: State of the art multimodal open source using 1000x less data
"Meet Molmo: a family of open, state-of-the-art multimodal AI models. Our best model outperforms proprietary systems, using 1000x less data."
Outperforming GPT-4o, Gemini 1.5 Pro & Claude 3.5 across an average of 11 multimodal benchmarks. Near identical ELO to GPT-4o for multimodal.
Info: https://molmo.allenai.org/blog
Try it:  https://molmo.allenai.org
https://arxiv.org/pdf/2410.01201
we show that by removing their hidden state dependencies from their input, forget, and update gates, LSTMs and GRUs no longer need to BPTT and can be efficiently trained in parallel. Building on this, we introduce minimal versions (minLSTMs and minGRUs) that (1) use sig- nificantly fewer parameters than their traditional counterparts and (2) are fully parallelizable during training (175× faster for a sequence of length 512). Lastly, we show that these stripped-down versions of decade-old RNNs match the empir- ical performance of recent sequence models.

Notice how it reaches the lowest loss on the test set long before the transformer does 


the first series of Liquid Foundation Models (LFMs) – a new generation of generative AI models that achieve state-of-the-art performance at every scale, while maintaining a smaller memory footprint and more efficient inference.
https://www.liquid.ai/liquid-foundation-models
https://www.liquid.ai/blog/liquid-neural-networks-research
https://x.com/LiquidAI_/status/1840768716784697688
https://x.com/teortaxesTex/status/1840897331773755476
"We announce the first series of Liquid Foundation Models (LFMs), a new generation of generative AI models built from first principles.
Our 1B, 3B, and 40B LFMs achieve state-of-the-art performance in terms of quality at each scale, while maintaining a smaller memory footprint and more efficient inference."
inference."



Differential transformer: https://arxiv.org/abs/2410.05258

Can run on less memory with no/lower drop in performance compared to regular transformers 

NVIDIA VP Bob Pette says the energy cost of generating tokens for AI models has fallen by 100,000X in the past 10 years and Blackwell, which is now in production, continues this trend: https://www.reddit.com/r/singularity/comments/1fzbp4l/comment/lr0o5dl
Humans might write a max of 6k tokens an hour (1.6 tokens per word * 60 words per minute * 60 minutes per hour), assuming consistent speed without slowing down, and use about 83 calories an hour (2000 kcals/24 hours) while awake. 1 calorie is about 4 joules. So a human uses 392 joules of energy to make 6k tokens an hour. Blackwell does 2400 Joules for 6k tokens, but generates them in less than 0.8 seconds. A 10x energy efficiency gain makes hardware more energy efficient per unit of thought than humans. It is already at least 4500x faster (3600 seconds/0.8 seconds to generate 6k tokens).
Stem Cells from Foreskin of Circumcised Baby Penis' used to Grow 'Mini-Brains' able to Process Data and Run AI, Faster - While Consuming Almost NO ENERGY: https://www.technews.city/2024/10/the-edge-stem-cells-from-foreskin-of.html
Rewarding Progress: Scaling Automated Process Verifiers for LLM Reasoning: https://arxiv.org/abs/2410.08146
We validate our claims by training process advantage verifiers (PAVs) to predict progress under such provers, and show that compared to ORMs, test-time search against PAVs is >8% more accurate, and 1.5−5× more compute-efficient. Online RL with dense rewards from PAVs enables one of the first results with 5−6× gain in sample efficiency, and >6% gain in accuracy, over ORMs.
Nvidia Nemotron 70B - beats Llama 3.1 405B, GPT4o & Claude 3.5 Sonnet on Arena Hard, AlpacaEval and MT Bench. They release the Instruct model, reward model and the dataset all on Hugging Face

Mistral introduces two new state-of-the-art models for on-device computing and at-the-edge use cases. "We call them les Ministraux: Ministral 3B and Ministral 8B. These models set a new frontier in knowledge, commonsense, reasoning, function-calling, and efficiency in the sub-10B category" https://www.reddit.com/r/singularity/comments/1g51mn8/mistral_introduces_two_new_stateoftheart_models/

New Transformer architecture modifications from NVIDIA researchers - nGPT: A hypersphere-based Transformer achieving 4-20x faster training and improved stability for LLMs: https://arxiv.org/html/2410.01131v1
• 4x faster training for 1k context length
• 10x faster training for 4k context length
• 20x faster training for 8k context length
• Similar or better performance on downstream tasks with less training
• More stable performance when extrapolating to longer sequences
Near Infinite Batch Size Scaling for Contrastive Loss: https://arxiv.org/abs/2410.17243
Compared to SOTA memory-efficient solutions, it achieves a two-order-of-magnitude reduction in memory while maintaining comparable speed.
"Compared to SOTA memory-efficient solutions, it achieves a two-order-of-magnitude reduction in memory while maintaining comparable speed"
[Google + Max Planck Institute + Peking University] TokenFormer: Rethinking Transformer Scaling with Tokenized Model Parameters. "This reformulation allows for progressive and efficient scaling without necessitating retraining from scratch." https://arxiv.org/abs/2410.23168
This reformulation allows for progressive and efficient scaling without necessitating retraining from scratch. Our model scales from 124M to 1.4B parameters by incrementally adding new key-value parameter pairs, achieving performance comparable to Transformers trained from scratch while greatly reducing training costs. 

A group of researchers is actively working on replicating OpenAI o1 using  Llama! 🤯 The same group released Llama Berry a Inference-time method boosting Llama 3.1 8B instruct to 96% on GMS8K and 76.6 on MATH500: https://x.com/_philschmid/status/1852700039316943287

Llama Berry combines iterative self-refined with Monte Carlo Tree Search (SRMCTS) using Pairwise Preference Reward Model (PPRM) during inference boosting the performance from 47.2 to 75.3% on MATH and from 6.7% to 26.7 on AIME2024. 🤯


The team reported they “successfully enabled the model to acquire advanced thinking skills through interaction with the search tree during the learning process without human annotations.”


They plan to finish the first training and evaluation no later than end of November! 

New memory chip controlled by light and magnets could one day make AI computing less power-hungry: https://www.livescience.com/technology/artificial-intelligence/new-memory-chip-controlled-by-light-and-magnets-could-one-day-make-ai-computing-less-power-hungry
Chinese company trained GPT-4 rival with just 2,000 GPUs — 01.ai spent $3M compared to OpenAI's $80M to $100M: https://www.tomshardware.com/tech-industry/artificial-intelligence/chinese-company-trained-gpt-4-rival-with-just-2-000-gpus-01-ai-spent-usd3m-compared-to-openais-usd80m-to-usd100m

ZeroOne.ai’s inference costs are dramatically lower than those of similar models — 10 cents per million tokens — about 1/30th of the typical rate comparable models charge
MIT researchers develop an efficient way to train more reliable AI agents: https://news.mit.edu/2024/mit-researchers-develop-efficiency-training-more-reliable-ai-agents-1122
The technique could make AI systems better at complex tasks that involve variability.
The algorithm strategically selects the best tasks for training an AI agent so it can effectively perform all tasks in a collection of related tasks. In the case of traffic signal control, each task could be one intersection in a task space that includes all intersections in the city.
By focusing on a smaller number of intersections that contribute the most to the algorithm’s overall effectiveness, this method maximizes performance while keeping the training cost low.
The researchers found that their technique was between five and 50 times more efficient than standard approaches on an array of simulated tasks. This gain in efficiency helps the algorithm learn a better solution in a faster manner, ultimately improving the performance of the AI agent.
“We were able to see incredible performance improvements, with a very simple algorithm, by thinking outside the box. An algorithm that is not very complicated stands a better chance of being adopted by the community because it is easier to implement and easier for others to understand,” says senior author Cathy Wu, the Thomas D. and Virginia W. Cabot Career Development Associate Professor in Civil and Environmental Engineering (CEE) and the Institute for Data, Systems, and Society (IDSS), and a member of the Laboratory for Information and Decision Systems (LIDS).
She is joined on the paper by lead author Jung-Hoon Cho, a CEE graduate student; Vindula Jayawardana, a graduate student in the Department of Electrical Engineering and Computer Science (EECS); and Sirui Li, an IDSS graduate student. The research will be presented at the Conference on Neural Information Processing Systems.
When the researchers tested this technique on simulated tasks, including controlling traffic signals, managing real-time speed advisories, and executing several classic control tasks, it was five to 50 times more efficient than other methods.
This means they could arrive at the same solution by training on far less data. For instance, with a 50x efficiency boost, the MBTL algorithm could train on just two tasks and achieve the same performance as a standard method which uses data from 100 tasks.
“From the perspective of the two main approaches, that means data from the other 98 tasks was not necessary or that training on all 100 tasks is confusing to the algorithm, so the performance ends up worse than ours,” Wu says.
With MBTL, adding even a small amount of additional training time could lead to much better performance.
In the future, the researchers plan to design MBTL algorithms that can extend to more complex problems, such as high-dimensional task spaces. They are also interested in applying their approach to real-world problems, especially in next-generation mobility systems.
Scaling tiny models with search: Matching 28x larger model with 0.5B finetune + reward mode: https://www.reddit.com/r/LocalLLaMA/comments/1h1e5wp/scaling_tiny_models_with_search_matching_28x/

tested on AIME 2024 last night (which is totally out of distribution, the model has literally only ever seen grade school level math in the SFT/reward model training data). It actually gets 20/90 with 100 MCTS iterations which seems really good (Claude 3 Opus gets 1/30. Gemini Math 1.5 Pro gets 8/30 rm@256. Qwen2.5-Math-1.5b-Instruct, which is further trained with RL using GRPO after SFT, gets 10/30 rm@256).


Update: 22/90 with 200 MCTS iterations https://x.com/rawsh0/status/1861940181789495487	
Lossless 4-bit quantization: https://www.reddit.com/r/LocalLLaMA/comments/1h0aev6/lossless_4bit_quantization_for_large_models_are/

Sana-0.6B image generator is very competitive with SOTA models and 39 times faster than Flux-12B at 1024x1024 resolution) and can be run on a laptop with 16 GB VRAM, generating 1024x1024 images in less than a second: https://nvlabs.github.io/Sana/
Together Turbo endpoints provide fast performance while maintaining quality, matching Meta’s FP16 reference models – making them the most accurate, cost efficient, and performant models available: https://api.together.ai/signin?redirectUrl=/playground/chat/meta-llama/Llama-3.3-70B-Instruct-Turbo
Quality: Together Turbo achieves this performance while maintaining full accuracy compared to Meta’s reference implementation across all models. Llama-3.1-405B-Instruct-Turbo matches the accuracy of Meta reference models.
Best reasoning on LiveBench for a confirmed medium-sized (around 70b) and open source model WITHOUT relying on test-time compute
https://arxiv.org/abs/2412.06769
We utilize the last hidden state of the LLM as a representation of the reasoning state (termed "continuous thought"). Rather than decoding this into a word token, we feed it back to the LLM as the subsequent input embedding directly in the continuous space. Experiments show that Coconut can effectively augment the LLM on several reasoning tasks. This novel latent reasoning paradigm leads to emergent advanced reasoning patterns: the continuous thought can encode multiple alternative next reasoning steps, allowing the model to perform a breadth-first search (BFS) to solve the problem, rather than prematurely committing to a single deterministic path like CoT. Coconut outperforms CoT in certain logical reasoning tasks that require substantial backtracking during planning, with fewer thinking tokens during inference. These findings demonstrate the promise of latent reasoning and offer valuable insights for future research.


From the report: For all runs, the number of unique synthetic tokens is fixed (a subsample of full synthetic data) but the number of repetitions on this data changes, namely 4 and 12 epochs. The rest of the training tokens are fresh unique tokens supplied from web sources. As seen, performing more iterations on the synthetic data is more beneficial than supplying more web tokens.
https://arxiv.org/abs/2412.08905
Byte Latent Transformer: Patches Scale Better Than Tokens: https://ai.meta.com/research/publications/byte-latent-transformer-patches-scale-better-than-tokens/
Our results demonstrate the feasibility of scaling models trained on raw bytes without a fixed-vocabulary. Both training and inference efficiency improve due to dynamically selecting long patches when data is predictable, along with qualitative improvements on reasoning and long tail generalization. Overall, for fixed inference costs, BLT shows significantly better scaling than tokenization-based models, by simultaneously growing both patch and model size.




New LLM optimization technique slashes memory costs up to 75%: https://venturebeat.com/ai/new-llm-optimization-technique-slashes-memory-costs-up-to-75/


Smaller model but better performance with new dataset
https://arxiv.org/abs/2403.09629
We present Quiet-STaR, a generalization of STaR in which LMs learn to generate rationales at each token to explain future text, improving their predictions. We address key challenges, including 1) the computational cost of generating continuations, 2) the fact that the LM does not initially know how to generate or use internal thoughts, and 3) the need to predict beyond individual next tokens. To resolve these, we propose a tokenwise parallel sampling algorithm, using learnable tokens indicating a thought's start and end, and an extended teacher-forcing technique. Encouragingly, generated rationales disproportionately help model difficult-to-predict tokens and improve the LM's ability to directly answer difficult questions. In particular, after continued pretraining of an LM on a corpus of internet text with Quiet-STaR, we find zero-shot improvements on GSM8K (5.9%→10.9%) and CommonsenseQA (36.3%→47.2%) and observe a perplexity improvement of difficult tokens in natural text. Crucially, these improvements require no fine-tuning on these tasks. Quiet-STaR marks a step towards LMs that can learn to reason in a more general and scalable way
https://arxiv.org/pdf/2403.05812
we find that the compute required to reach a set performance threshold has halved approximately every 8 months, with a 95% confidence interval of around 5 to 14 months, substantially faster than hardware gains per Moore’s Law.
Large language models have become much smaller: https://epoch.ai/gradient-updates/frontier-language-models-have-become-much-smaller
If the post GPT-3 trend had continued, given that GPT-4 was released in March 2023, by now we could have expected to see models with close to 10 trillion parameters, around 4 times bigger than GPT-4. However, in 2023, the trend of frontier language models becoming bigger reversed. Let alone reaching the 10 trillion parameter mark, current frontier models such as the original GPT-4o and Claude 3.5 Sonnet are probably an order of magnitude smaller than GPT-4, with 4o having around 200 billion and 3.5 Sonnet around 400 billion parameters.
IBM Research’s newest prototype chips use drastically less power to solve AI tasks: https://research.ibm.com/blog/analog-ai-chip-low-power
In a paper published in Nature today, IBM showed it’s possible to build analog AI chips that can handle natural-language AI tasks with an estimated 14 times more energy efficiency.

Google CEO Sundar Pichai says AI is a platform shift and as compute is scaled like never before and the cost of generating tokens has fallen by 97% in the past 18 months, we will get "intelligence, just like air, too cheap to meter" https://www.reddit.com/r/singularity/comments/1fme0zb/google_ceo_sundar_pichai_says_ai_is_a_platform/
Glaze/Nightshade takes 15 minutes of computation for one image. How is that environmentally friendly?  


14. AI Inbreeding/AI Training Off Its Own Output/AI Running Out Of Data/Model Collapse
Direct link: https://docs.google.com/document/d/1oHuwssPPUTa4dwczX_s3qg3iPfWE4VK-R52LN51GwI8/edit?tab=t.0#heading=h.jhzi7ak5dcet

Full debunk here: https://x.com/rylanschaeffer/status/1816881533795422404?s=46
The authors of the paper that began this idea had tried to train a new model with 90%-100% of training data generated by a 125 *million* parameter model (SOTA models are typically hundreds of billions of parameters). Unsurprisingly, they found that you cannot successfully train a model entirely or almost entirely using the outputs of a weak language model. The paper itself isn’t the problem. The problem is that many people in the media and elite institutions *wanted* it to be true that you cannot train on synthetic data, and they jumped on this paper as evidence for their broader narrative: https://x.com/deanwball/status/1871334765439160415
ChatGPT knows information up to June 2024 without any model collapse: 
MIT researchers develop an efficient way to train more reliable AI agents: https://news.mit.edu/2024/mit-researchers-develop-efficiency-training-more-reliable-ai-agents-1122
The technique could make AI systems better at complex tasks that involve variability.
The algorithm strategically selects the best tasks for training an AI agent so it can effectively perform all tasks in a collection of related tasks. In the case of traffic signal control, each task could be one intersection in a task space that includes all intersections in the city.
By focusing on a smaller number of intersections that contribute the most to the algorithm’s overall effectiveness, this method maximizes performance while keeping the training cost low.
The researchers found that their technique was between five and 50 times more efficient than standard approaches on an array of simulated tasks. This gain in efficiency helps the algorithm learn a better solution in a faster manner, ultimately improving the performance of the AI agent.
“We were able to see incredible performance improvements, with a very simple algorithm, by thinking outside the box. An algorithm that is not very complicated stands a better chance of being adopted by the community because it is easier to implement and easier for others to understand,” says senior author Cathy Wu, the Thomas D. and Virginia W. Cabot Career Development Associate Professor in Civil and Environmental Engineering (CEE) and the Institute for Data, Systems, and Society (IDSS), and a member of the Laboratory for Information and Decision Systems (LIDS).
She is joined on the paper by lead author Jung-Hoon Cho, a CEE graduate student; Vindula Jayawardana, a graduate student in the Department of Electrical Engineering and Computer Science (EECS); and Sirui Li, an IDSS graduate student. The research will be presented at the Conference on Neural Information Processing Systems.
When the researchers tested this technique on simulated tasks, including controlling traffic signals, managing real-time speed advisories, and executing several classic control tasks, it was five to 50 times more efficient than other methods.
This means they could arrive at the same solution by training on far less data. For instance, with a 50x efficiency boost, the MBTL algorithm could train on just two tasks and achieve the same performance as a standard method which uses data from 100 tasks.
“From the perspective of the two main approaches, that means data from the other 98 tasks was not necessary or that training on all 100 tasks is confusing to the algorithm, so the performance ends up worse than ours,” Wu says.
With MBTL, adding even a small amount of additional training time could lead to much better performance.
In the future, the researchers plan to design MBTL algorithms that can extend to more complex problems, such as high-dimensional task spaces. They are also interested in applying their approach to real-world problems, especially in next-generation mobility systems.
The Hyperfitting Phenomenon: Sharpening and Stabilizing LLMs for Open-Ended Text Generation: https://arxiv.org/pdf/2412.04318

We find that by further fine-tuning these models to achieve a near-zero training loss on a small set of samples -- a process we refer to as hyperfitting -- the long-sequence generative capabilities are greatly enhanced. Greedy decoding with these Hyperfitted models even outperform Top-P sampling over long-sequences, both in terms of diversity and human preferences. This phenomenon extends to LLMs of various sizes, different domains, and even autoregressive image generation. We further find this phenomena to be distinctly different from that of Grokking and double descent. Surprisingly, our experiments indicate that hyperfitted models rarely fall into repeating sequences they were trained on, and even explicitly blocking these sequences results in high-quality output. All hyperfitted models produce extremely low-entropy predictions, often allocating nearly all probability to a single token.


Molmo: State of the art multimodal open source using 1000x less data
"Meet Molmo: a family of open, state-of-the-art multimodal AI models. Our best model outperforms proprietary systems, using 1000x less data."
Outperforming GPT-4o, Gemini 1.5 Pro & Claude 3.5 across an average of 11 multimodal benchmarks. Near identical ELO to GPT-4o for multimodal.
Info: https://molmo.allenai.org/blog
Try it:  https://molmo.allenai.org


Baidu unveiled an end-to-end self-reasoning framework to improve the reliability and traceability of RAG systems. 13B models achieve similar accuracy with this method(while using only 2K training samples) as GPT-4: https://venturebeat.com/ai/baidu-self-reasoning-ai-the-end-of-hallucinating-language-models/

Auto Evol used to create an infinite amount and variety of high quality data: https://x.com/CanXu20/status/1812842568557986268

Auto Evol allows the training of WizardLM2 to be conducted with nearly an unlimited number and variety of synthetic data.
Auto Evol-Instruct automatically designs evolving methods that make given instruction data more complex, enabling almost cost-free adaptation to different tasks by only changing the input data of the framework …This optimization process involves two critical stages: (1) Evol Trajectory Analysis: The optimizer LLM carefully analyzes the potential issues and failures exposed in instruction evolution performed by evol LLM, generating feedback for subsequent optimization. (2) Evolving Method Optimization: The optimizer LLM optimizes the evolving method by addressing these identified issues in feedback. These stages alternate and repeat to progressively develop an effective evolving method using only a subset of the instruction data. Once the optimal evolving method is identified, it directs the evol LLM to convert the entire instruction dataset into more diverse and complex forms, thus facilitating improved instruction tuning.


Our experiments show that the evolving methods designed by Auto Evol-Instruct outperform the Evol-Instruct methods designed by human experts in instruction tuning across various capabilities, including instruction following, mathematical reasoning, and code generation. On the instruction following task, Auto Evol-Instruct can achieve a improvement of 10.44% over the Evol method used by WizardLM-1 on MT-bench; on the code task HumanEval, it can achieve a 12% improvement over the method used by WizardCoder; on the math task GSM8k, it can achieve a 6.9% improvement over the method used by WizardMath.




With the new technology of Auto Evol-Instruct, the evolutionary synthesis data of WizardLM-2 has scaled up from the three domains of chat, code, and math in WizardLM-1 to dozens of domains, covering tasks in all aspects of large language models. This allows Arena Learning to train and learn from an almost infinite pool of high-difficulty instruction data, fully unlocking all the potential of Arena Learning.



More proof synthetic data works well based on Phi 4 performance: https://arxiv.org/abs/2412.08905


LLMs Aren’t Just “Trained On the Internet” Anymore: https://allenpike.com/2024/llms-trained-on-internet


New very high quality dataset: https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1



MMIS: Multimodal Dataset for Interior Scene Visual Generation and Recognition: https://arxiv.org/abs/2407.05980v1


announcing our first suite of specialized language models for document processing tasks (OCR correction, text segmentation, bibliographic extraction) and a new major multimodal dataset we used to train them, Finance Commons: https://x.com/Dorialexander/status/1814234566158118977


NuminaMath 72b TIR model: https://x.com/JiaLi52524397/status/1814957190320631929/

Trained on new competition math dataset ever released, with 860K problem solution pairs that was created with GPT 4

“We selected approximately 70k problems from the NuminaMath-CoT dataset, focusing on those with numerical outputs, most of which are integers. We then utilized a pipeline leveraging GPT-4 to generate TORA-like reasoning paths, executing the code and producing results until the solution was complete. We filtered out solutions where the final answer did not match the reference and repeated this process three times to ensure accuracy and consistency. This iterative approach allowed us to generate high-quality TORA data efficiently.”


For AMC 10 2023, the average score is 43%, 
AIME Floor: 70% (top ~6%)
Distinction: 75%
Distinguished Honor Roll: 90%


 Scaling Retrieval-Based Language Models with a Trillion-Token Datastore: https://arxiv.org/abs/2407.12854
- This paper investigates how scaling up the datastore in retrieval-augmented language models improves performance without signs of saturation on both language modeling and downstream tasks. 


- The authors built MASSIVEDS, an open-sourced 1.4 trillion token datastore covering a diverse set of domains. MASSIVEDS is the largest open-sourced datastore for studying retrieval scaling.


- They designed an efficient pipeline to make the study computationally tractable by sharing indexing and retrieval computation across different datastore configurations.


- Experiments show datastore scaling brings consistent improvements in language modeling perplexity on web data and scientific papers.  


- On downstream tasks, datastore scaling significantly boosts performance on knowledge-intensive QA tasks like TriviaQA and Natural Questions. Smaller retrieval models can match or exceed their larger LM-only counterparts.


- Datastore scaling also improves performance on reasoning tasks like MMLU, but the improvements are more modest, indicating potential need for more in-domain data.


- Compared to LM-only models, retrieval models achieve superior compute-optimal scaling curves by offloading FLOPs from model pretraining to datastore indexing.


- Analysis reveals the retriever can stay robust to out-of-domain data and tend to retrieve relevant documents even from a broad datastore.


https://techcrunch.com/2024/06/20/anthropic-claims-its-latest-model-is-best-in-class/


Michael Gerstenhaber, product lead at Anthropic, says that the improvements are the result of architectural tweaks and new training data, including AI-generated data. Which data specifically? Gerstenhaber wouldn’t disclose, but he implied that Claude 3.5 Sonnet draws much of its strength from these training sets.


Google DeepMind's JEST method can reduce AI training time by a factor of 13 and decreases computing power demand by 90%. The method uses another pretrained reference model to select data subsets for training based on their "collective learnability: https://arxiv.org/html/2406.17711v1




Synthetically trained 7B math model blows 64 shot GPT4 out of the water in math: https://x.com/_akhaliq/status/1793864788579090917?s=46&t=lZJAHzXMXI1MgQuyBgEhgA

Researchers shows Model Collapse is easily avoided by keeping old human data with new synthetic data in the training set: https://arxiv.org/abs/2404.01413

Teaching Language Models to Hallucinate Less with Synthetic Tasks: https://arxiv.org/abs/2310.06827?darkschemeovr=1

>In this work, we show that reducing hallucination on a synthetic task can also reduce hallucination on real-world downstream tasks. Our method, SynTra, first designs a synthetic task where hallucinations are easy to elicit and measure. It next optimizes the LLM's system message via prefix-tuning on the synthetic task, and finally transfers the system message to realistic, hard-to-optimize tasks. Across three realistic abstractive summarization tasks, SynTra reduces hallucination for two 13B-parameter LLMs using only a synthetic retrieval task for supervision. We also find that optimizing the system message rather than the model weights can be critical; fine-tuning the entire model on the synthetic task can counterintuitively increase hallucination. Overall, SynTra demonstrates that the extra flexibility of working with synthetic data can help mitigate undesired behaviors in practice.

IBM on synthetic data: https://www.ibm.com/topics/synthetic-data
 
>Data quality: Unlike real-world data, synthetic data removes the inaccuracies or errors that can occur when working with data that is being compiled in the real world. Synthetic data can provide high quality and balanced data if provided with proper variables. The artificially-generated data is also able to fill in missing values and create labels that can enable more accurate predictions for your company or business.  

Synthetic data could be better than real data: https://www.nature.com/articles/d41586-023-01445-8
Example of this improving LLAMA 1 LLM: https://arxiv.org/pdf/2304.12244

Boosting Visual-Language Models with Synthetic Captions and Image Embeddings: https://arxiv.org/pdf/2403.07750

>Our method employs pretrained text-to-image model to synthesize image embeddings from captions generated by an LLM. Despite the text-to-image model and VLM initially being trained on the same data, our approach leverages the image generator’s ability to create novel compositions, resulting in synthetic image embeddings that expand beyond the limitations of the original dataset. Extensive experiments demonstrate that our VLM, finetuned on synthetic data achieves comparable performance to models trained solely on human-annotated data, while requiring significantly less data. Furthermore, we perform a set of analyses on captions which reveals that semantic diversity and balance are key aspects for better downstream performance. Finally, we show that synthesizing images in the image embedding space is 25% faster than in the pixel space. We believe our work not only addresses a significant challenge in VLM training but also opens up promising avenues for the development of self-improving multi-modal models.



Simulations transfer very well to real life: https://arxiv.org/abs/2406.01967v1

Study on quality of synthetic data shows improvements across the board: https://arxiv.org/pdf/2210.07574

>“We systematically investigate whether synthetic data from current state-of-the-art text-to-image generation models are readily applicable for image recognition. Our extensive experiments demonstrate that synthetic data are beneficial for classifier learning in zero-shot and few-shot recognition, bringing significant performance boosts and yielding new state-of-the-art performance. Further, current synthetic data show strong potential for model pre-training, even surpassing the standard ImageNet pre-training. We also point out limitations and bottlenecks for applying synthetic data for image recognition, hoping to arouse more future research in this direction.”





E5-V: Universal Embeddings with Multimodal Large Language Models: https://huggingface.co/papers/2407.12580

>By leveraging MLLMs with prompts, E5-V effectively bridges the modality gap between different types of inputs, demonstrating strong performance in multimodal embeddings even without fine-tuning. We propose a single modality training approach for E5-V, where the model is trained exclusively on text pairs. This method demonstrates significant improvements over traditional multimodal training on image-text pairs, while reducing training costs by approximately 95%. Additionally, this approach eliminates the need for costly multimodal training data collection. Extensive experiments across four types of tasks demonstrate the effectiveness of E5-V. As a universal multimodal model, E5-V not only achieves but often surpasses state-of-the-art performance in each task, despite being trained on a single modality.

Scaling Synthetic Data Creation with 1,000,000,000 Personas

- Presents a collection of 1B diverse personas automatically curated from web data

- Massive gains on MATH: 49.6 ->64.9

repo: https://github.com/tencent-ailab/persona-hub

abs: https://arxiv.org/abs/2406.20094


LLAMA Groq 3 tool use: https://x.com/RickLamers/status/1813341037198204962
An open source Tool Use full finetune of Llama 3 that reaches the #1 position on BFCL beating all other models, including proprietary ones like Claude Sonnet 3.5, GPT-4 Turbo, GPT-4o and Gemini 1.5 Pro.
The model has been trained on synthetic data only. This is a powerful full finetune, not a LoRA. Yes, we've checked rigorously for overfitting using the LMSYS described robust decontamination techniques, they only score 5.6% on SFT synthetic data and 1.3% on synthetic DPO data.


https://venturebeat.com/ai/meta-drops-ai-bombshell-multi-token-prediction-models-now-open-for-research/
>3x faster token prediction means 3x cheaper and on top of that it seems to greatly increase coding, summarization, and mathematical reasoning abilities. Best of all the improvements have shown to only become more significant with larger models (13b+ according to the paper). Unlike some other research where improvements are mostly seen in smaller models and won't advance the frontier, this is infact worse performing on smaller models and shows great potential at scale. 

Has a cutoff date of 6/12/24 with no “inbreeding” issues 

Scaling Diffusion Transformers to 16 Billion Parameters: https://huggingface.co/papers/2407.11633
Based on the above guidance, a series of DiT-MoE experimentally achieves performance on par with dense networks yet requires much less computational load during inference. More encouragingly, we demonstrate the potential of DiT-MoE with synthesized image data, scaling diffusion model at a 15.5B parameter that attains a new SoTA FID-50K score of 1.80 in 512x512 resolution settings.
For reference, Stable Diffusion XL is only about 3 billion parameters

GPT 4 achieves 93% on subset of MedQA on respiratory diseases using simulated hospital starting from 86% baseline: https://arxiv.org/abs/2405.02957

NVIDIA Releases Open Synthetic Data Generation Pipeline for Training Large Language Models: https://blogs.nvidia.com/blog/nemotron-4-synthetic-data-generation-llm-training/

Nemotron-4 340B, a family of models optimized for NVIDIA NeMo and NVIDIA TensorRT-LLM, includes cutting-edge instruct and reward models, and a dataset for generative AI training.
The Nemotron-4 340B Instruct model creates diverse synthetic data that mimics the characteristics of real-world data, helping improve data quality to increase the performance and robustness of custom LLMs across various domains.
Then, to boost the quality of the AI-generated data, developers can use the Nemotron-4 340B Rewardmodel to filter for high-quality responses. Nemotron-4 340B Reward grades responses on five attributes: helpfulness, correctness, coherence, complexity and verbosity. It’s currently first place on the Hugging Face RewardBench leaderboard, created by AI2, for evaluating the capabilities, safety and pitfalls of reward models.
RGM, active inference non-llm approach using 90% less data (less need for synthetic data, lower energy footprint). 99.8% accuracy in MNIST benchmark using 90% less data to train on less powerful devices: https://arxiv.org/pdf/2407.20292

>Use for Atari game performance: “This fast structure learning took about 18 seconds on a personal computer.”

>Use for MNIST dataset classification: For example, the variational procedures above attained state-of-the-art classification accuracy on a self-selected subset of test data after seeing 10,000 training images. Each training image was seen once, with continual learning (and no notion of batching). Furthermore, the number of training images actually used for learning was substantially smaller10 than 10,000; because active learning admits only those informative images that reduce expected free energy. This (Maxwell’s Demon) aspect of selecting the right kind of data for learning will be a recurrent theme in subsequent sections. Finally, the requisite generative model was self-specifying, given some exemplar data. In other words, the hierarchical depth and size of the requisite tensors were learned automatically within a few seconds on a personal computer.
Nvidia Research team has developed a method to efficiently create smaller, accurate language models by using structured weight pruning and knowledge distillation, offering several advantages for developers:
16% better performance on MMLU scores.
40x fewer tokens for training new models.
Up to 1.8x cost saving for training a family of models.
The effectiveness of these strategies is demonstrated with the Meta Llama 3.1 8B model, which was refined into the Llama-3.1-Minitron 4B. The collection on huggingface: https://huggingface.co/collections/nvidia/minitron-669ac727dc9c86e6ab7f0f3e
Technical dive: https://developer.nvidia.com/blog/how-to-prune-and-distill-llama-3-1-8b-to-an-nvidia-llama-3-1-minitron-4b-model
Research paper: https://arxiv.org/abs/2407.14679
OpenAI Shows ‘Strawberry’ AI to the Feds and Uses It to Develop ‘Orion’ https://www.theinformation.com/articles/openai-shows-strawberry-ai-to-the-feds-and-uses-it-to-develop-orion
Strawberry can solve math problems it hasn't seen before—something today’s chatbots cannot reliably do
When given additional time to “think,” the Strawberry model can also answer customers’ questions about more subjective topics, such as product marketing strategies. To demonstrate Strawberry’s prowess with language-related tasks, OpenAI employees have shown their co-workers how Strawberry can, for example, solve New York Times Connections, a complex word puzzle
Its sales of LLMs to corporations and of ChatGPT subscriptions have roughly tripled to $283 million in monthly revenue compared to a year ago
OpenAI’s prospects rest in part on the eventual launch of a new flagship LLM it is currently developing, code-named Orion
OpenAI’s prospects rest in part on the eventual launch of a new flagship LLM it is currently developing, code-named Orion
Using Strawberry to generate higher-quality training data could help OpenAI reduce the number of errors its models generate, otherwise known as hallucinations, said Alex Graveley, CEO of agent startup Minion AI and former chief architect of GitHub Copilot.
Imagine “a model without hallucinations, a model where you ask it a logic puzzle and it’s right on the first try,” Graveley said. The reason why the model is able to do that is because “there is less ambiguity in the training data, so it’s guessing less.”
“We feel like we have enough [data] for this next model,” Altman said at an event in May, likely referring to Orion. “We have done all sorts of experiments including generating synthetic data.”
Strawberry has its roots in research. It was started years ago by Ilya Sutskever, then OpenAI's chief scientist. He recently left to start a competing AI lab. Before he left, OpenAI researchers Jakub Pachocki and Szymon Sidor built on Sutskever's work by developing a new math-solving model, Q*, alarming some researchers focused on AI safety.
Last year, in the leadup to Q*, OpenAI researchers developed a variation of a concept known as test-time computation, meant to boost LLMs’ problem-solving abilities. The method gives them the opportunity to spend more time considering all parts of a command or question someone has asked the model to execute. At the time, Sutskever published a blog post related to this work.

Source: https://time.com/6300942/ai-progress-charts/
Agent Q, Research Breakthrough for the Next Generation of AI Agents with Planning & Self Healing Capabilities: https://www.multion.ai/blog/introducing-agent-q-research-breakthrough-for-the-next-generation-of-ai-agents-with-planning-and-self-healing-capabilities
In real-world booking experiments on Open Table, MultiOn’s Agents drastically improved the zero-shot performance of the LLaMa-3 model from an 18.6% success rate to 81.7%, a 340% jump after just one day of autonomous data collection and further to 95.4% with online search. These results highlight our method’s efficiency and ability for autonomous web agent improvement.
Guided Search with MCTS: This technique autonomously generates data by exploring different actions and web-pages, balancing exploration and exploitation. MCTS expands the action space using high sampling temperatures and diverse prompting, ensuring diverse and optimal trajectory collections.
AI Self-Critique: At each step, AI-based self-critique provides valuable feedback, refining the agent's decision-making process. This step-level feedback is crucial for long-horizon tasks, where sparse signals often lead to learning difficulties.
Direct Preference Optimization: The DPO algorithm fine-tunes the model by constructing preference pairs from MCTS-generated data. This off-policy training method allows the model to learn effectively from aggregate datasets including the sub-optimal branches explored during search, improving success rates in complex environments.
“SkillMimic" uses just 35 minutes of video and motion capture data of human demos to train simulated humanoids in basketball skills like dribbling, shooting, and layups through imitation learning: https://www.reddit.com/r/singularity/comments/1fcu8sk/skillmim
Source2Synth: https://x.com/jaseweston/status/1834402693995024453
- Generates synthetic examples grounded in real data 
- Curation step makes data high quality based on answerability
- Improves performance on two challenging domains: Multi-hop QA and using tools: SQL for tabular QA 



Molmo: State of the art multimodal open source using 1000x less data
"Meet Molmo: a family of open, state-of-the-art multimodal AI models. Our best model outperforms proprietary systems, using 1000x less data."
Outperforming GPT-4o, Gemini 1.5 Pro & Claude 3.5 across an average of 11 multimodal benchmarks. Near identical ELO to GPT-4o for multimodal.
Info: https://molmo.allenai.org/blog
Try it:  https://molmo.allenai.org
The Race to Block OpenAI’s Scraping Bots Is Slowing Down: https://www.wired.com/story/open-ai-publisher-deals-scraping-bots/
At its peak, the high was just over a third of the websites; it has now dropped down closer to a quarter. Within a smaller pool of the most prominent news outlets, the block rate is still above 50 percent, but it’s down from heights earlier this year of almost 90 percent.
But last May, after Dotdash Meredith announced a licensing deal with OpenAI, that number dipped significantly. It then dipped again at the end of May when Vox announced its own arrangement—and again once more this August when WIRED’s parent company, Condé Nast, struck a deal. The trend toward increased blocking appears to be over, at least for now.
These dips make obvious sense. When companies enter into partnerships and give permission for their data to be used, they’re no longer incentivized to barricade it, so it would follow that they would update their robots.txt files to permit crawling; make enough deals and the overall percentage of sites blocking crawlers will almost certainly go down. 
paper from Meta discloses TPO (Thought Preference Optimization) technique with impressive results: https://arxiv.org/abs/2410.10630
We propose a training method for equipping existing LLMs with such thinking abilities for general instruction following without use of additional human data. We achieve this by an iterative search and optimization procedure that explores the space of possible thought generations, allowing the model to learn how to think without direct supervision. For each instruction, the thought candidates are scored using a judge model to evaluate their responses only, and then optimized via preference optimization. We show that this procedure leads to superior performance on AlpacaEval and Arena-Hard, and shows gains from thinking on non-reasoning categories such as marketing, health and general knowledge, in addition to more traditional reasoning & problem-solving tasks.
highest win rate our model TPO achieves is 52.5%, which is +4.1% better than the direct baseline, as shown in Table 1. It is also a +27.6% increase over the seed model and puts our method in 3rd position on the leaderboard(1), just after GPT-4 Omni and GPT-4 Turbo. This is an impressive result given the small size (8B) of our model.”
GPT-4o does 57.5%. GPT-4 Turbo 54.0%

Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs with Nothing: https://arxiv.org/abs/2406.08464
We present a self-synthesis method for generating large-scale alignment data named Magpie. Our key observation is that aligned LLMs like Llama-3-Instruct can generate a user query when we input only the left-side templates up to the position reserved for user messages, thanks to their auto-regressive nature. We use this method to prompt Llama-3-Instruct and generate 4 million instructions along with their corresponding responses. We perform a comprehensive analysis of the extracted data and select 300K high-quality instances. To compare Magpie data with other public instruction datasets, we fine-tune Llama-3-8B-Base with each dataset and evaluate the performance of the fine-tuned models. Our results indicate that in some tasks, models fine-tuned with Magpie perform comparably to the official Llama-3-8B-Instruct, despite the latter being enhanced with 10 million data points through supervised fine-tuning (SFT) and subsequent feedback learning. We also show that using Magpie solely for SFT can surpass the performance of previous public datasets utilized for both SFT and preference optimization, such as direct preference optimization with UltraFeedback. This advantage is evident on alignment benchmarks such as AlpacaEval, ArenaHard, and WildBench.
 On average, implementing MAGPIE on a cloud server2 would incur costs of $0.12 and $1.1 per 1,000 data instances for MAGPIE-Air and MAGPIE-Pro, respectively



From the report: For all runs, the number of unique synthetic tokens is fixed (a subsample of full synthetic data) but the number of repetitions on this data changes, namely 4 and 12 epochs. The rest of the training tokens are fresh unique tokens supplied from web sources. As seen, performing more iterations on the synthetic data is more beneficial than supplying more web tokens.
https://arxiv.org/abs/2412.08905
New math dataset as of 12/21/24: 

14.1 AI Image Training
New image diffusion models beat the older ones in terms of human preference:
Flux beats Midjourney and Stable Diffusion: https://blackforestlabs.ai/announcing-black-forest-labs/
API costs $0.025 per image. It's cheaper than Dalle 3 and can do realism.


Very realistic images: https://www.reddit.com/r/singularity/comments/1ej1etp/flux_can_generate_really_good_fake_low_quality/ 





Prompt with no additional editing: meme image with two men in it. On the left side the man is taller and is wearing a shirt that says Black Forest Labs. On the right side the other smaller scrawny man is wearing a shirt that says Stability AI and is sad. The taller man is hitting the back of the head of the small man. A caption coming from the tall man reads "That's how you do a next-gen model!

Prompt: Gameplay screenshot of Counter Strike Global Offensive. It takes place in a Middle Eastern place called Dust 2. There are enemy soldiers shooting at you.

Prompt: low quality and motion blur shaky photo of a CRT television on top of a wooden drawer in an average bedroom. The lighting from is dim and warm ceiling light that is off screen. In the TV there is Dark Souls videogame gameplay on it. The screen of the TV is overexposed.



Created on first try. Robe and hands are perfect 

First attempt: "Photo of a red sphere on top of a blue cube. Behind them is a green triangle, on the right of the triangle is a dog, on the left is a cat."

Prompt: person take photo of Graffiti art spelling out the words "WAFERSELAMAT", graffiti, white wall, dynamic color, spray paint,

Prompt: Close-up of LEGO chef minifigure cooking for homeless. Focus on LEGO hands using utensils, showing culinary skill. Warm kitchen lighting, late morning atmosphere. Canon EOS R5, 50mm f/1.4 lens. Capture intricate cooking techniques. Background hints at charitable setting. Inspired by Paul Bocuse and Massimo Bottura's styles. Freeze-frame moment of food preparation. Convey compassion and altruism through scene details.

Google’s new image diffusion model: https://www.reddit.com/r/singularity/comments/1eit2bd/google_gemini_appears_to_have_updated_their_image/





Lumina-GPT: https://github.com/Alpha-VLLM/Lumina-mGPT
A family of multimodal autoregressive models capable of various vision and language tasks, particularly excelling in generating flexible photorealistic images from text descriptions. 

Stable Diffusion lora trained on Midjourney images: https://civitai.com/models/251417/midjourney-mimic

Adobe Firefly used thousands of Midjourney images in training its 'ethical AI' model: https://tomsguide.com/ai/ai-image-video/adobe-firefly-used-thousands-of-midjourney-images-in-training-its-ethical-ai-model

Openjourney is an open source Stable Diffusion fine tuned model on Midjourney image: https://huggingface.co/prompthero/openjourney

Training a diffusion model better than stable diffusion 1.5 and DALLE 2 from scratch for $1890 on only 37 real and synthetic million images: https://arxiv.org/abs/2407.15811
using only 37M publicly available real and synthetic images, we train a 1.16 billion parameter sparse transformer with only $1,890 economical cost and achieve a 12.7 FID in zero-shot generation on the COCO dataset. Notably, our model achieves competitive FID and high-quality generations while incurring 118x lower cost than stable diffusion models and 14x lower cost than the current state-of-the-art approach that costs $28,400.




Diffusion Augmented Agents can autonomously learn and generate infinite synthetic data: https://arxiv.org/abs/2407.20798
We introduce Diffusion Augmented Agents (DAAG), a novel framework that leverages large language models, vision language models, and diffusion models to improve sample efficiency and transfer learning in reinforcement learning for embodied agents. DAAG hindsight relabels the agent's past experience by using diffusion models to transform videos in a temporally and geometrically consistent way to align with target instructions with a technique we call Hindsight Experience Augmentation. A large language model orchestrates this autonomous process without requiring human supervision, making it well-suited for lifelong learning scenarios. The framework reduces the amount of reward-labeled data needed to 1) finetune a vision language model that acts as a reward detector, and 2) train RL agents on new tasks. We demonstrate the sample efficiency gains of DAAG in simulated robotics environments involving manipulation and navigation. Our results show that DAAG improves learning of reward detectors, transferring past experience, and acquiring new tasks - key abilities for developing efficient lifelong learning agents. Supplementary material and visualizations are available on our website this https URL: https://sites.google.com/view/diffusion-augmented-agents/
Ideagram 2.0 has no “inbreeding” issues: https://www.reddit.com/r/singularity/comments/1exsq4d/introducing_ideogram_20_our_most_advanced/
OpenAI is already training a new version of Sora with even higher quality and longer videos: https://www.theinformation.com/articles/openai-is-revamping-sora-ai-video
Meta's Joe Spisak explains how AI models can train themselves by generating images, asking itself questions about them, and choosing the best answers, in order to move beyond human data and human fine-tuning, and teach itself from synthetic data: https://x.com/tsarnick/status/1847789784078618640
The Hyperfitting Phenomenon: Sharpening and Stabilizing LLMs for Open-Ended Text Generation: https://arxiv.org/pdf/2412.04318

We find that by further fine-tuning these models to achieve a near-zero training loss on a small set of samples -- a process we refer to as hyperfitting -- the long-sequence generative capabilities are greatly enhanced. Greedy decoding with these Hyperfitted models even outperform Top-P sampling over long-sequences, both in terms of diversity and human preferences. This phenomenon extends to LLMs of various sizes, different domains, and even autoregressive image generation. We further find this phenomena to be distinctly different from that of Grokking and double descent. Surprisingly, our experiments indicate that hyperfitted models rarely fall into repeating sequences they were trained on, and even explicitly blocking these sequences results in high-quality output. All hyperfitted models produce extremely low-entropy predictions, often allocating nearly all probability to a single token.

15. AI Achievements 

Source: https://ourworldindata.org/artificial-intelligence
"GPT-3 displayed some of the cognitive biases observed in people, but they have largely disappeared in the latest generation of LLMs. The tests...designed to be challenging for humans, possibly no longer challenge the growing reasoning abilities in LLMs" https://arxiv.org/pdf/2303.13988

ChatGPT in top 1% of creativity: https://www.cnbc.com/2023/07/17/study-chatgpt-can-match-the-top-1percent-of-creative-human-thinkers.html 
https://x.com/hardmaru/status/1801074062535676193
We’re excited to release DiscoPOP: a new SOTA preference optimization algorithm that was discovered and written by an LLM!

https://sakana.ai/llm-squared/

Our method leverages LLMs to propose and implement new preference optimization algorithms. We then train models with those algorithms and evaluate their performance, providing feedback to the LLM. By repeating this process for multiple generations in an evolutionary loop, the LLM discovers many highly-performant and novel preference optimization objectives!

Paper: https://arxiv.org/abs/2406.08414

GitHub: https://github.com/SakanaAI/DiscoPOP

Model: https://huggingface.co/SakanaAI/DiscoPOP-zephyr-7b-gemma

Claude 3 recreated an unpublished paper on quantum theory without ever seeing it according to former Google quantum computing engineer and CEO of Extropic AI: https://twitter.com/GillVerd/status/1764901418664882327
 
“Godfather of AI” and Turing Award winner Geoffrey Hinton: A neural net given training data where half the examples are incorrect still had an error rate of <=25% rather than 50% because it is able to generalize and find patterns even with very flawed training data: https://youtu.be/n4IQOBka8bc?si=wM423YLd-48YC-eY (14:00 timestamp)
AI beat humans at being persuasive: https://www.reddit.com/r/singularity/comments/1bto2zm/ai_chatbots_beat_humans_at_persuading_their/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_button

AI beats humans at basic tasks: https://www.nature.com/articles/d41586-024-01087-4

GPT4 passes Turing test 54% of the time: https://twitter.com/camrobjones/status/1790766472458903926
 [Claude 3 recreated an unpublished paper on quantum theory without ever seeing it](https://twitter.com/GillVerd/status/1764901418664882327) 

Predicting out of distribution phenomenon of NaCl in solvent: https://arxiv.org/abs/2310.12535

China’s ‘AI Ship Designer’ Works At Unprecedented Speed; Performed A Year’s Work Only In 24 Hours!: https://www.eurasiantimes.com/chinas-ai-ship-designer-works-at-unprecedented-speed-performed/ 

AI-powered F-16 impresses ride-along SECAF in dogfight: https://www.defenseone.com/technology/2024/05/ai-powered-f-16-impresses-ride-along-secaf-dogfight/396418/

[ChatGPT can do chemistry research better than AI designed for it and the creators didn’t even know](https://youtu.be/0b03ibtVYhw?feature=shared&t=447)


Claude 3 solves a problem thought to be impossible for LLMs to solve: https://www.reddit.com/r/singularity/comments/1byusmx/someone_prompted_claude_3_opus_to_solve_a_problem/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_button

A new study shows a 21% drop in demand for digital freelancers since ChatGPT was launched. The hype in AI is real but so is the risk of job displacement: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4602944 

Our findings indicate a 21 percent decrease in the number of job posts for automation-prone jobs related to writing and coding compared to jobs requiring manual-intensive skills after the introduction of ChatGPT. We also find that the introduction of Image-generating AI technologies led to a significant 17 percent decrease in the number of job posts related to image creation. Furthermore, we use Google Trends to show that the more pronounced decline in the demand for freelancers within automation-prone jobs correlates with their higher public awareness of ChatGPT's substitutability.

Human level text to speech: https://www.microsoft.com/en-us/research/project/vall-e-x/vall-e-2/
 
AI makes code refactoring much faster: https://www.reddit.com/r/singularity/comments/1dwgkav/code_editing_has_been_deprecated_i_now_program_by/

AI is better than humans at lie detection: https://www.technologyreview.com/2024/07/05/1094703/ai-lie-detectors-are-better-than-humans-at-spotting-lies/
AI used by official Disney show for intro: https://www.polygon.com/23767640/ai-mcu-secret-invasion-opening-credits
gpt-3.5-turbo-instruct can play chess at ~1800 ELO. I wrote some code and had it play 150 games against stockfish and 30 against gpt-4. It's very good! 99.7% of its 8000 moves were legal with the longest game going 147 moves. https://x.com/a_karvonen/status/1705340535836221659

We've created a demo of an AI that can predict the future at a superhuman level (on par with groups of human forecasters working together): https://x.com/DanHendrycks/status/1833152719756116154
Our bot performs better than experienced human forecasters and performs roughly the same as (and sometimes even better than) crowds of experienced forecasters
Our bot and other forecasting bots can be used in a wide variety of contexts. For example, these AIs could help policymakers minimize bias in their decision-making or help improve the information ecosystem by providing trustworthy, calibrated forecasts.
On the 177 events, the Metaculus crowd got 87.0% accuracy, while FiveThirtyNine got 87.7% ± 1.4. A link to the technical report is here. This bot lacks many of the drawbacks of prediction markets. It makes forecasts within seconds. Additionally, groups of humans do not need to be incentivized with cash prizes to make and continually update their predictions. Forecasting AIs are several orders of magnitude faster and cheaper than prediction markets, and they’re similarly accurate.
The bot is not fine-tuned, and doing so could potentially make it far more accurate. It simply retrieves articles and writes a report as guided through an engineered prompt. (Its prompt can be found by clicking on the gear icon in forecast.safe.ai.) Moreover, probabilities from AIs are also known to lead to automation bias, and improvements in the interface could ameliorate this.
A* planning: https://jdsemrau.substack.com/p/paper-review-beyond-a-better-planning

Based on the claims of the research team, their transformer model optimally solves previously unseen Sokoban puzzles 93.7% of the time, while using up to 26.8% fewer search steps than standard A∗ search. Their solution also robustly follows the execution trace of a symbolic planner and improves (in terms of trace length) beyond the human-crafted rule-based planning strategy it was initially trained on.

Note that this test is an offline-only IQ quiz that a Mensa member created for my testing, which is *not in any AI training data* (so scores are lower than for public IQ tests.)
https://x.com/maximlott/status/1834652893229859212
Large Language Models for Idea Generation in Innovation: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4526071

ChatGPT-4 can generate ideas much faster and cheaper than students, the ideas are on average of higher quality (as measured by purchase-intent surveys) and exhibit higher variance in quality. More important, the vast majority of the best ideas in the pooled sample are generated by ChatGPT and not by the students. Providing ChatGPT with a few examples of highly-rated ideas further increases its performance. 
ChatGPT o1-preview solves unique, PhD-level assignment questions not found on the internet in mere seconds: https://m.youtube.com/watch?v=a8QvnIAGjPA

This paper shows having a short conversation with an AI can get people who believed in a conspiracy theory to change their beliefs & this lasts for months: https://www.science.org/doi/10.1126/science.adq1814

Our LLM-driven bi-level programming shows it’s possible to learn skills from videos without complex video processing! By chaining a VLM and LLM in a bi-level framework, we use the “chain rule” to guide reward search directly from video demos” https://www.reddit.com/r/singularity/comments/1g5qh1x/can_robots_learn_skills_from_youtube_without/

Google trained grandmaster level chess (2895 Elo) without search in a 270 million parameter transformer model with a training dataset of 10 million chess games: https://arxiv.org/abs/2402.04494
 In the paper, they present results for models sizes 9m (internal bot tournament elo 2007), 136m (elo 2224), and 270m trained on the same dataset. Which is to say, data efficiency scales with model size

Impossible to do this through training without generalizing as there are AT LEAST 10^120 possible game states in chess: https://en.wikipedia.org/wiki/Shannon_number

There are only 10^80 atoms in the universe: https://www.thoughtco.com/number-of-atoms-in-the-universe-603795
Sundar Pichai said on an earnings call that more than 25% of all new code at Google is now generated by AI. He also said project astra will be ready for 2025: https://www.reddit.com/r/singularity/comments/1gf6elr/sundar_pichai_said_on_the_earnings_call_today/

Likely not lying as lying to investors is securities fraud. If he wanted to exaggerate, he would have said “a large percentage” instead of a specific and verifiable number.	
https://aidantr.github.io/files/AI_innovation.pdf


"These effects are large. To put the rise in materials discovery in perspective, the lab’s research output per scientist declined by 4% over the preceding five years. This was despite the introduction of several computational tools designed to aid scientists. AI therefore appears to be a different class of technology, with impacts that are orders of magnitude greater than previous methods." 

"However, the results suggest that AI-assisted materials discovery does not compromise quality"

As one scientist noted: “While I was impressed by the performance of the [AI tool]...I couldn’t help feeling that much of my education is now worthless. This is not what I was trained to do.”

AI VTuber Neurosama wins Best Tech VTuber of the Year for 2023 and 2024: https://en.wikipedia.org/wiki/Neuro-sama
Examples:
https://www.youtube.com/watch?v=Abt-ijlI92Q
https://www.youtube.com/watch?v=gVNBpSGpitk&t=443s
Knows what “that word” means at 11:38
https://www.youtube.com/watch?v=Ky495KCWz4Q
https://www.youtube.com/watch?v=3YDs-I_CdWU
Unbelievably good comedic timing: https://x.com/NeuroContext/status/1870286205604245982
Was also the most watched female streamer on Twitch for the last week of December 2023, beating Ironmouse and many international streamers by a HUGE margin (more than double the runner-up) and top 10 in ALL of Twtich: https://www.youtube.com/watch?v=YfNC505f_5I

Did it again in 2024: https://x.com/StreamsCharts/status/1873466520271036856/
4th most watched Twitch streamer overall, very close to 3rd: https://x.com/StreamsCharts/status/1873421724953288873

640k followers on Twitch and 400k subscribers on Youtube
2nd most watched streamer on all of Twitch between 12/19/24-12/26/24: 
Source: https://sullygnome.com/channels/3/watched
6th most subscribed English-speaking channel: 
From: https://twitchtracker.com/subscribers/english
15.1. Jobs
AMIE: A research AI system for diagnostic medical reasoning and conversations: https://research.google/blog/amie-a-research-ai-system-for-diagnostic-medical-reasoning-and-conversations/






OpenAI tech increased productivity of Philippine contact center agents by 12.8% – study: https://www.rappler.com/technology/openai-gpt-productivity-effects-philippines-contact-center-agents/ 

“GenAI will save [Klarna] $10m in marketing this year. We’re spending less on photographers, image banks, and marketing agencies” https://www.reuters.com/technology/klarna-using-genai-cut-marketing-costs-by-10-mln-annually-2024-05-28/
$6m less on producing images.
- 1,000 in-house AI-produced images in 3 months. Includes the creative concept, quality check, and legal compliance.
- AI-image production reduced from 6 WEEKS TO 1 WEEK ONLY.
- Customer response to AI images on par with human produced images.
- Cutting external marketing agency costs by 25% (mainly translation, production, CRM, and social agencies).


Our in-house marketing team is HALF the size it was last year but is producing MORE!


We’ve removed the need for stock imagery from image banks like 
@gettyimages


Now we use genAI tools like Midjourney, DALL-E, and Firefly to generate images, and Topaz Gigapixel and Photoroom to make final adjustments.
Faster images means more app updates, which is great for customers. And our employees get to work on more fun projects AND we're saving money.
‘I will never go back’: Ontario family doctor says new AI notetaking saved her job: https://globalnews.ca/news/10463535/ontario-family-doctor-artificial-intelligence-notes 
“If the physician is unhappy with the note, Lall said, they can ask the AI model to regenerate the information or add more detail to any one of the categories. While the tool has some imperfections, she said, the improvements have been noticeable over the 10 months since she began using it.“I really feel this should be the next gold standard for all of our doctors. It decreases the cognitive load you feel at the end of the day,” she said.The Ford government has been so impressed with the technology that it announced a pilot program to allow 150 family physicians to use AI Scribe as part of their practices. The health minister said the early signs were promising but stressed government would proceed carefully.”
Nvidia’s AI Bot Outperforms Nurses, Study Finds: https://www.forbes.com/sites/robertpearl/2024/04/17/nvidias-ai-bot-outperforms-nurses-heres-what-it-means-for-you/ 
And they only cost $9 an hour: https://www.msn.com/en-us/money/other/nvidia-s-new-ai-nurses-treat-patients-for-9-an-hour-here-s-what-they-can-do-from-colonoscopy-screenings-to-loneliness-companionship/ar-BB1kmKtI
According to company-released data, the AI bots are 16% better than nurses at identifying a medication’s impact on lab values, 24% more accurate detecting toxic dosages of over-the-counter drugs, and 43% better at identifying condition-specific negative interactions from OTC meds. All that at $9 an hour compared to the $39.05 median hourly pay for U.S. nurses. These AI nurse-bots are designed to make new diagnoses, manage chronic disease, and give patients a detailed but clear explanation of clinicians’ advice.


15.2. Medicine

 Physician study shows AI alone is better at diagnosing patients than doctors, even better than doctors using AI: https://www.computerworld.com/article/3613982/will-ai-help-doctors-decide-whether-you-live-or-die.html
AMIE: A research AI system for diagnostic medical reasoning and conversations: https://research.google/blog/amie-a-research-ai-system-for-diagnostic-medical-reasoning-and-conversations/




AMIE responses were preferred to general cardiologists’ responses for 5 of the 10 domains, and were equivalent for the rest. AMIE also demonstrates strong assistive potential — access to AMIE’s response improved cardiologists’ overall response quality in 63.7% of cases while lowering quality in just 3.4%. Qualitative results suggest AMIE and general cardiologists could complement each other, with AMIE responses being thorough and sensitive, while general cardiologists’ responses were concise and specific.

https://research.google/blog/advancing-amie-towards-specialist-care-and-real-world-validation/


New AI Framework for Medical Imaging Matches Accuracy of Clinical Specialists: https://www.insideprecisionmedicine.com/topics/patient-care/new-ai-framework-for-medical-imaging-matches-accuracy-of-clinical-specialists/
AI Detects More Breast Cancers with Fewer False Positives https://www.rsna.org/news/2024/june/ai-detects-more-breast-cancers
Recall (false positive) rate and radiologist reading workload decreased significantly in AI-screened group
Using AI, breast radiologists in Denmark have improved breast cancer screening performance and reduced the rate of false-positive findings.
In total, 60,751 women were screened without AI, and 58,246 women were screened with the AI system. In the AI implementation group, 66.9% (38,977) of the screenings were single-read, and 33.1% (19,269) were double-read with AI assistance. 
Compared to screening without AI, screening with the AI system detected significantly more breast cancers (0.82% versus 0.70%) and had a lower false-positive rate (1.63% versus 2.39%). 
“In the AI-screened group, the recall rate decreased by 20.5 percent, and the radiologists’ reading workload was lowered by 33.4 percent,” Dr. Lauritzen said.
The positive predictive value of AI screening was also greater than that of screening without AI (33.5% versus 22.5%). In the AI group, a higher proportion of invasive cancers detected were 1 centimeter or less in size (44.93% vs. 36.60%).
“All screening performance indicators improved except for the node-negative rate which showed no evidence of change,” Dr. Lauritzen said.
AI spots cancer and viral infections at nanoscale precision: https://healthcare-in-europe.com/en/news/ai-cancer-viral-infections-nanoscale-precision.html

Scanning images of cells could lead to new diagnostic and monitoring strategies for disease.

New research shows AI-discovered drug molecules have 80-90% success rates in Phase I clinical trials, compared to the historical industry average of 40-65%. The Phase 2 success rate so far is similar to the industry average, meaning more drugs are passing overall. https://www.sciencedirect.com/science/article/pii/S135964462400134X 

Nvidia’s AI Bot Outperforms Nurses, Study Finds: https://www.forbes.com/sites/robertpearl/2024/04/17/nvidias-ai-bot-outperforms-nurses-heres-what-it-means-for-you/

And they only cost $9 an hour: https://www.msn.com/en-us/money/other/nvidia-s-new-ai-nurses-treat-patients-for-9-an-hour-here-s-what-they-can-do-from-colonoscopy-screenings-to-loneliness-companionship/ar-BB1kmKtI
According to company-released data, the AI bots are 16% better than nurses at identifying a medication’s impact on lab values, 24% more accurate detecting toxic dosages of over-the-counter drugs, and 43% better at identifying condition-specific negative interactions from OTC meds. All that at $9 an hour compared to the $39.05 median hourly pay for U.S. nurses. These AI nurse-bots are designed to make new diagnoses, manage chronic disease, and give patients a detailed but clear explanation of clinicians’ advice.

AI predicts diseases with 98% accuracy in real-time using tongue color | AI-powered computer model to analyze patients’ tongue colors for real-time disease diagnoses such as anemia, COVID-19, vascular and gastrointestinal issues, or asthma: https://interestingengineering.com/health/ai-model-predicts-disease-using-tongue-color
the paper itself shows that the best model has a f1 score, precision, recall all above 98% https://www.mdpi.com/2227-7080/12/7/97



Researchers find that GPT-4 performs as well as or better than doctors on medical tests, especially in psychiatry. https://www.news-medical.net/news/20231002/GPT-4-beats-human-doctors-in-medical-soft-skills.aspx

AI spots cancer and viral infections at nanoscale precision: https://healthcare-in-europe.com/en/news/ai-cancer-viral-infections-nanoscale-precision.html

Scanning images of cells could lead to new diagnostic and monitoring strategies for disease.

AI Detects Prostate Cancer 17% More Accurately Than Doctors, Finds Study: https://www.ndtv.com/science/ai-detects-prostate-cancer-17-more-accurately-than-doctors-finds-study-6170131

GPs use AI to boost cancer detection rates in England by 8%: https://www.theguardian.com/society/article/2024/jul/21/gps-use-ai-to-boost-cancer-detection-rates-in-england-by-8

Med-Gemini : https://arxiv.org/abs/2404.18416
We evaluate Med-Gemini on 14 medical benchmarks, establishing new state-of-the-art (SoTA) performance on 10 of them, and surpass the GPT-4 model family on every benchmark where a direct comparison is viable, often by a wide margin. On the popular MedQA (USMLE) benchmark, our best-performing Med-Gemini model achieves SoTA performance of 91.1% accuracy, using a novel uncertainty-guided search strategy. On 7 multimodal benchmarks including NEJM Image Challenges and MMMU (health & medicine), Med-Gemini improves over GPT-4V by an average relative margin of 44.5%. We demonstrate the effectiveness of Med-Gemini's long-context capabilities through SoTA performance on a needle-in-a-haystack retrieval task from long de-identified health records and medical video question answering, surpassing prior bespoke methods using only in-context learning. Finally, Med-Gemini's performance suggests real-world utility by surpassing human experts on tasks such as medical text summarization, alongside demonstrations of promising potential for multimodal medical dialogue, medical research and education. 

Double-blind study with Patient Actors and Doctors, who didn't know if they were communicating with a human, or an AI. Best performers were AI: https://m.youtube.com/watch?v=jQwwLEZ2Hz8 

Human doctors + AI did worse, than AI by itself. The mere involvement of a human reduced the accuracy of the diagnosis.
AI was consistently rated to have better bedside manner than human doctors. 
‘I will never go back’: Ontario family doctor says new AI notetaking saved her job: https://globalnews.ca/news/10463535/ontario-family-doctor-artificial-intelligence-notes 

[Google's medical AI destroys GPT's benchmark and outperforms doctors](https://newatlas.com/technology/google-med-gemini-ai/)

[The first randomized trial of medical #AI to show it saves lives. ECG-AI alert in 16,000 hospitalized patients. 31% reduction of mortality (absolute 7 per 100 patients) in pre-specified high-risk group](https://twitter.com/erictopol/status/1784936718283805124)
Medical Text Written By Artificial Intelligence Outperforms Doctors: https://www.forbes.com/sites/williamhaseltine/2023/12/15/medical-text-written-by-artificial-intelligence-outperforms-doctors/ 

AI can make healthcare better and safer: https://www.reddit.com/r/singularity/comments/1brojzm/ais_will_make_health_care_safer_and_better/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_button

CheXzero significantly outperformed humans, especially on uncommon conditions. Huge implications for improving diagnosis of neglected "long tail" diseases: https://x.com/pranavrajpurkar/status/1797292562333454597 

Humans near chance level (50-55% accuracy) on rarest conditions, while CheXzero maintains 64-68% accuracy.

ChatGPT outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions: https://today.ucsd.edu/story/study-finds-chatgpt-outperforms-physicians-in-high-quality-empathetic-answers-to-patient-questions?darkschemeovr=1

AI is better than doctors at detecting breast cancer: https://www.bbc.com/news/health-50857759

AI just as good at diagnosing illness as humans: https://www.medicalnewstoday.com/articles/326460

First NHS physiotherapy clinic run by AI to start this year. New platform to provide same-day appointments with digital physiotherapist in effort to cut waiting times: https://www.theguardian.com/society/article/2024/jun/09/first-nhs-physiotherapy-clinic-run-by-ai-to-start-this-year 
China's first (simulated) AI hospital town debuts: https://www.globaltimes.cn/page/202405/1313235.shtml 
Remarkably, AI doctors can treat 10,000 [simulated]  patients in just a few days. It would take human doctors at least two years to treat that many patients. Furthermore, evolved doctor agents achieved an impressive 93.06 percent accuracy rate on the MedQA dataset (US Medical Licensing Exam questions) covering major respiratory diseases. They simulate the entire process of diagnosing and treating patients, including consultation, examination, diagnosis, treatment and follow-up. 
Research team leader of the Agent Hospital Liu Yang, also executive dean of Institute for AI Industry Research (AIR) and associate dean of the Department of Computer Science and Technology at Tsinghua University, told the Global Times that the AI hospital town is set to transform the way doctors diagnose and treat patients, bringing immense benefits to both medical professionals and the general public. 


For example, this innovative concept allows for virtual patients to be treated by real doctors, providing medical students with enhanced training opportunities. By simulating a variety of AI patients, medical students can confidently propose treatment plans without the fear of causing harm to real patients due to decision-making error, Liu said. 


This simulation training enables medical students to practice diagnosis and treatment in a risk-free environment, ultimately leading to the cultivation of highly skilled doctors, according to Liu.


If the patients in the town are real and the doctors are virtual, online telemedicine services can be provided to patients. The AI hospital town utilizes a vast repository of authoritative medical knowledge, allowing AI doctors to handle thousands, even millions, of cases.


The potential for high-quality, affordable and convenient healthcare services for the public is on the horizon, as the diagnostic capabilities of AI doctors evolve from the virtual world to the real world, Liu stated.


Liu went on to say that the AI hospital town can simulate and predict various medical scenarios, such as the spread, development and control of infectious diseases in a region.

AI models ChatGPT and Grok outperform the average doctor on a medical licensing exam: the average score by doctors is 75% - ChatGPT scored 98% and Grok 84%: https://x.com/tsarnick/status/1814048365002596425

Google DeepMind's AlphaProteo generates novel proteins for biology and health research: https://deepmind.google/discover/blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/?utm_source=x&utm_medium=&utm_campaign=gdm&utm_content=
AlphaProteo can generate new protein binders for diverse target proteins, including VEGF-A, which is associated with cancer and complications from diabetes. This is the first time an AI tool has been able to design a successful protein binder for VEGF-A.
AlphaProteo also achieves higher experimental success rates and 3 to 300 times better binding affinities than the best existing methods on seven target proteins we tested.

https://x.com/DeryaTR_/status/1834630356286558336
Tx-LLM: Supporting therapeutic development with large language models: https://research.google/blog/tx-llm-supporting-therapeutic-development-with-large-language-models/
BrainLM: https://www.biorxiv.org/content/10.1101/2023.09.12.557460v2.full.pdf
Utilizing self-supervised masked-prediction training, BrainLM demonstrates proficiency in both fine-tuning and zero-shot inference tasks. Fine-tuning allows for the accurate prediction of clinical variables like age, anxiety, and PTSD as well as forecasting of future brain states. Critically, the model generalizes well to entirely new external cohorts not seen during training. In zero-shot inference mode, BrainLM can identify intrinsic functional networks directly from raw fMRI data without any network-based supervision during training. The model also generates interpretable latent representations that reveal relationships between brain activity patterns and cognitive states. Overall, BrainLM offers a versatile and interpretable framework for elucidating the complex spatiotemporal dynamics of human brain activity. It serves as a powerful "lens" through which massive repositories of fMRI data can be analyzed in new ways, enabling more effective interpretation and utilization at scale. The work demonstrates the potential of foundation models to advance computational neuroscience research. 
Can accurately simulate the effects of drugs without needing to test it on animals or humans and predict mental illnesses






Cardiologists working with AI said it was equal or better than human cardiologists in most areas: https://x.com/DKThomp/status/1843993273825964312

A.I. Chatbots Defeated Doctors at Diagnosing Illness. "A small study found ChatGPT outdid human physicians when assessing medical case histories, even when those doctors were using a chatbot." https://www.nytimes.com/2024/11/17/health/chatgpt-ai-doctors-diagnosis.html
In an experiment, doctors who were given ChatGPT to diagnose illness did only slightly better than doctors who did not. But the chatbot alone outperformed all the doctors.
Dr. Adam Rodman, an expert in internal medicine at Beth Israel Deaconess Medical Center in Boston, confidently expected that chatbots built to use artificial intelligence would help doctors diagnose illnesses. He was wrong.
Instead, in a study Dr. Rodman helped design, doctors who were given ChatGPT-4 along with conventional resources did only slightly better than doctors who did not have access to the bot. And, to the researchers’ surprise, ChatGPT alone outperformed the doctors.
“I was shocked,” Dr. Rodman said.
The chatbot, from the company OpenAI, scored an average of 90 percent when diagnosing a medical condition from a case report and explaining its reasoning. Doctors randomly assigned to use the chatbot got an average score of 76 percent. Those randomly assigned not to use it had an average score of 74 percent.
The study showed more than just the chatbot’s superior performance.
After his initial shock at the results of the new study, Dr. Rodman decided to probe a little deeper into the data and look at the actual logs of messages between the doctors and ChatGPT. The doctors must have seen the chatbot’s diagnoses and reasoning, so why didn’t those using the chatbot do better? It turns out that the doctors often were not persuaded by the chatbot when it pointed out something that was at odds with their diagnoses. Instead, they tended to be wedded to their own idea of the correct diagnosis. “They didn’t listen to A.I. when A.I. told them things they didn’t agree with,” Dr. Rodman said. That makes sense, said Laura Zwaan, who studies clinical reasoning and diagnostic error at Erasmus Medical Center in Rotterdam and was not involved in the study.
“People generally are overconfident when they think they are right,” she said. But there was another issue: Many of the doctors did not know how to use a chatbot to its fullest extent. Dr. Chen said he noticed that when he peered into the doctors’ chat logs, “they were treating it like a search engine for directed questions: ‘Is cirrhosis a risk factor for cancer? What are possible diagnoses for eye pain?’” “It was only a fraction of the doctors who realized they could literally copy-paste in the entire case history into the chatbot and just ask it to give a comprehensive answer to the entire question,” Dr. Chen added. “Only a fraction of doctors actually saw the surprisingly smart and comprehensive answers the chatbot was capable of producing.”
o1-preview is far superior to doctors on reasoning tasks and it's not even close, according to OpenAI's latest paper. AI does ~80% vs ~30% on the 143 hard NEJM CPC diagnoses: https://x.com/deedydas/status/1869049071346102729
Note that most other LLMs cannot do this despite access to the same training data (Google actually has access to FAR more data than OpenAI does) and high incentive to match these scores


15.3. Art/Music/Literature
Direct link: https://docs.google.com/document/d/1oHuwssPPUTa4dwczX_s3qg3iPfWE4VK-R52LN51GwI8/edit?tab=t.0#heading=h.sjbhebyoadqp

First legally recognized nonbinary person with disabilities writes book with ChatGPT: https://www.wired.com/story/the-us-copyright-office-loosens-up-a-little-on-ai/

The novel draws from Shupe’s eventful life, including her advocacy for more inclusive gender recognition.
Shupe believes fervently that she was only able to complete her book with the assistance of generative AI tools. She says she has been assessed as 100 percent disabled by the Department of Veterans Affairs and struggles to write due to cognitive impairment related to conditions including bipolar disorder, borderline personality disorder, and a brain stem malformation.
She is proud of the finished work and sees working with a text generator as a different but no less worthwhile method of expressing thoughts. “You don't just hit ‘generate’ and get something worthy of publishing. That may come in the future, but we're still far from it,” she says, noting that she spent upwards of 14 hours a day working on her draft.

https://www.theverge.com/2024/1/16/24040124/square-enix-foamstars-ai-art-midjourney

>AI technology has been seeping into game development to mixed reception. Xbox has partnered with Inworld AI to develop tools for developers to generate AI NPCs, quests, and stories. The Finals, a free-to-play multiplayer shooter, was criticized by voice actors for its use of text-to-speech programs to generate voices. Despite the backlash, the game has a mostly positive rating on Steam and is in the top 20 of most played games on the platform.


AI-generated poetry from the VERY outdated GPT 3.5 is indistinguishable from human-written poetry and is rated more favorably: https://idp.nature.com/authorize?response_type=cookie&client_id=grover&redirect_uri=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41598-024-76900-1

AI-generated paintings are judged to be human-created artworks at higher rates than actual human-created paintings; AI-generated faces are judged to be real human faces at higher rate than actual photos of human faces, and AI-generated humor is just as funny as human-generated jokes. Despite this, studies have consistently found a bias against AI-generated artwork; when told that an artwork is AI-generated, participants rate the work as lower quality.
We conducted two experiments with non-expert poetry readers and found that participants performed below chance levels in identifying AI-generated poems (46.6% accuracy, χ2(1, N = 16,340) = 75.13, p < 0.0001). Notably, participants were more likely to judge AI-generated poems as human-authored than actual human-authored poems (χ2(2, N = 16,340) = 247.04, p < 0.0001). We found that AI-generated poems were rated more favorably in qualities such as rhythm and beauty, and that this contributed to their mistaken identification as human-authored.





https://www.astralcodexten.com/p/how-did-you-do-on-the-ai-art-turing
The 1278 people who said they utterly loathed AI art (score of 1 on a 1-5 Likert scale) still preferred AI paintings to humans when they didn't know which were which (the #1 and #2 paintings most often selected as their favorite were still AI, as were 50% of their top ten out of 50 images)

So in a 50-50 mix of AI and human 19th century art, they would incorrectly guess it was 75-25 human; in a 50-50 mix of digital art, they would incorrectly guess it was only 31% human.
Since there were two choices (human or AI), blind chance would produce a score of 50%, and perfect skill a score of 100%. The median score on the test was 60%, only a little above chance. The mean was 60.6%. Participants said the task was harder than expected (median difficulty 4 on a 1-5 scale).
"I asked participants to pick their favorite picture of 50. The 2 best-liked pictures were both by AI, as were 6 of the top 10
people who were professional artists and hated AI art scored 68% for categorizing AI vs. human-made art (random chance is 50%)"
The highest score was 98% (49/50), which 5 out of 11,000 people achieved. 
Alan Turing recommended that if 30% of humans couldn’t tell an AI from a human, the AI could be considered to have “passed” the Turing Test. By these standards, AI artists pass the test with room to spare; on average, 40% of humans mistook each AI picture for human.
Since there were two choices (human or AI), blind chance would produce a score of 50%, and perfect skill a score of 100%.
The median score on the test was 60%, only a little above chance. The mean was 60.6%. Participants said the task was harder than expected (median difficulty 4 on a 1-5 scale).
AI video wins Pink Floyd music video competition: https://ew.com/ai-wins-pink-floyd-s-dark-side-of-the-moon-video-competition-8628712

https://www.pinkfloyd.com/tdsotm50/competition/index.html


AI image won Colorado state fair https://www.cnn.com/2022/09/03/tech/ai-art-fair-winner-controversy/index.html

>You can feed a phrase like “an oil painting of an angry strawberry” to Midjourney and receive several images from the AI system within seconds, but Allen’s process wasn’t that simple. To get the final three images he entered in the competition, he said, took more than 80 hours.
First, he said, he played around with phrasing that led Midjourney to generate images of women in frilly dresses and space helmets — he was trying to mash up Victorian-style costuming with space themes, he said. Over time, with many slight tweaks to his written prompt (such as to adjust lighting and color harmony), he created 900 iterations of what led to his final three images. He cleaned up those three images in Photoshop, such as by giving one of the female figures in his winning image a head with wavy, dark hair after Midjourney had rendered her headless. Then he ran the images through another software program called Gigapixel AI that can improve resolution and had the images printed on canvas at a local print shop.

>Cal Duran, an artist and art teacher who was one of the judges for competition, said that while Allen’s piece included a mention of Midjourney, he didn’t realize that it was generated by AI when judging it. Still, he sticks by his decision to award it first place in its category, he said, calling it a “beautiful piece”.

>“I think there’s a lot involved in this piece and I think the AI technology may give more opportunities to people who may not find themselves artists in the conventional way,” he said.

AI image won in the Sony World Photography Awards: https://www.scientificamerican.com/article/how-my-ai-image-won-a-major-photography-competition/ 

AI image wins another photography competition: https://petapixel.com/2023/02/10/ai-image-fools-judges-and-wins-photography-contest/ 

Japanese writer wins prestigious Akutagawa Prize with a book partially written by ChatGPT: https://www.vice.com/en/article/k7z58y/rie-kudan-akutagawa-prize-used-chatgpt

Fake beauty queens charm judges at the Miss AI pageant: https://www.npr.org/2024/06/09/nx-s1-4993998/the-miss-ai-beauty-pageant-ushers-in-a-new-type-of-influencer 

People PREFER AI art and that was in 2017, long before it got as good as it is today: https://arxiv.org/abs/1706.07068 

>The results show that human subjects could not distinguish art generated by the proposed system from art generated by contemporary artists and shown in top art fairs. Human subjects even rated the generated images higher on various scales.

>People took bot-made art for the real deal 75 percent of the time, and 85 percent of the time for the Abstract Expressionist pieces. The collection of works included Andy Warhol, Leonardo Drew, David Smith and more.

People couldn’t distinguish human art from AI art in 2021 (a year before DALLE Mini/CrAIyon even got popular): https://news.artnet.com/art-world/machine-art-versus-human-art-study-1946514 

>Some 211 subjects recruited on Amazon answered the survey. A majority of respondents were only able to identify one of the five AI landscape works as such. Around 75 to 85 percent of respondents guessed wrong on the other four. When they did correctly attribute an artwork to AI, it was the abstract one. 

Katy Perry’s own mother got tricked by an AI image of Perry: https://abcnews.go.com/GMA/Culture/katy-perry-shares-mom-fooled-ai-photos-2024/story?id=109997891

Todd McFarlane's Spawn Cover Contest Was Won By AI User Robot9000: https://bleedingcool.com/comics/todd-mcfarlanes-spawn-cover-contest-was-won-by-ai-user-robo9000/

“Runway's tools and AI models have been utilized in films such as Everything Everywhere All At Once, in music videos for artists including A$AP Rocky, Kanye West, Brockhampton, and The Dandy Warhols, and in editing television shows like The Late Show and Top Gear.” 

https://en.wikipedia.org/wiki/Runway_(company)

AI music video from Washed Out that received a Vimeo Staff Pick: https://newatlas.com/technology/openai-sora-first-commissioned-music-video/

Runway and Lionsgate are partnering to explore the use of AI in film production: https://runwayml.com/news/runway-partners-with-lionsgate

Tribeca to screen AI generated films made with Sora: https://www.indiewire.com/news/festivals/tribeca-ai-generated-short-films-sora-shorts-1235010911/

Disney is set to announce a major AI initiative that will transform its creative output. The initiative is said to involve “hundreds” of people at the company and will primarily focus on post-production and visual effects: https://www.thewrap.com/disney-ai-initiative/

SIX AI images entered top 300 finalists of official Pokemon art competition (2% of all finalists): https://kotaku.com/pokemon-trading-card-tcg-ai-art-illustration-contest-1851559041

Might have won but were disqualified

AI image becomes top 5 finalist for “Girl With Pearl Earring” art competition: https://www.smithsonianmag.com/smart-news/girl-with-a-pearl-earring-vermeer-artificial-intelligence-mauritshuis-180981767/

Real photograph only got third place in AI art competition: https://www.cnn.com/2024/06/14/style/flamingo-photograph-ai-1839-awards/index.html


Many people, including AI haters, couldnt tell this image is AI generated: 
https://x.com/midosommar/status/1843013374919241868
https://x.com/beyoncesspamacc/status/1843094040851726800

AI generated song remixed by Metro Boomin, who did not even realize it was AI generated: https://en.m.wikipedia.org/wiki/BBL_Drizzy

>Unbeknownst to Metro at the time, the original track's vocals and instrumental were generated entirely by an artificial intelligence model.
Upon release, the track immediately received widespread attention on social media platforms. Notable celebrities and internet personalities including Elon Musk and Dr. Miami reacted to the beat.[19][20] Several corporations also responded, including educational technology company Duolingo and meat producer Oscar Mayer.[21][20]
In addition to users releasing freestyle raps over the instrumental, the track also evolved into a viral phenomenon where users would create remixes of the song beyond the hip hop genre.[22] Many recreated the song in other genres, including house, merengue and Bollywood.[23][18] Users also created covers of the song on a variety of musical instruments, including on saxophone, guitar and harp.

3.88/5 with 613 reviews on Rate Your Music (the best albums of ALL time get about a ⅘ on the site): https://rateyourmusic.com/release/single/metro-boomin/bbl-drizzy-bpm-150_mp3/

86 on Album of the Year (qualifies for an orange star denoting high reviews from fans despite multiple anti AI negative review bombers)

Charted as 22nd top single in New Zealand

AI-generated song made it to 72nd highest ranking song in Germany: https://www.youtube.com/watch?v=o0aG3S3iD6Y

AI music creator has 229k total subscribers and 7.5 million views on all channels https://m.youtube.com/@ObscurestVinyl

Topic channel: https://m.youtube.com/channel/UCSeqzYZQ8GEoF6eMdvJREyw

A few very popular songs: 

https://m.youtube.com/watch?v=wPlOYPGMRws&pp=ygUPb2JzY3VyZXN0IHZpbnls

https://m.youtube.com/watch?v=7zTei5RMhQ8&pp=ygUPb2JzY3VyZXN0IHZpbnls

https://m.youtube.com/watch?v=suXO7Yy_A-8&pp=ygUPb2JzY3VyZXN0IHZpbnls

AI song covers with have hundreds of thousands or even millions of views each: 

https://m.youtube.com/watch?v=GvnTSLS1dTU

https://m.youtube.com/watch?v=VNWudHD3Kt8

https://m.youtube.com/watch?v=rH14QH9jSDQ

https://m.youtube.com/watch?v=-pAW1-bSsAc

https://m.youtube.com/watch?v=_Y543NEiR5w

https://m.youtube.com/watch?v=-ugjFAljBKI

https://m.youtube.com/watch?v=f32P3ZAoJg0

https://m.youtube.com/watch?v=89H4OyZRFcA

Even followers of an AI hate account like AI posts: 

https://x.com/FacebookAIslop/status/1812513303824073124

https://x.com/FacebookAIslop/status/1832194473884844515
15.4. Coding/Computer Science
Takeaways re: AI R&D performance: https://x.com/eli_lifland/status/1860087262849171797
1. Claude 3.5 Sonnet reaches ~50th percentile human baseline 8-hour performance.
2. Sonnet Old-> New is a 0.2 jump in 4 months. We're 0.6 away from 90th percentile baselines.
Link to study: https://metr.org/blog/2024-11-22-evaluating-r-d-capabilities-of-llms/

Keep in mind researchers are already in the top 1% of intelligence and technical ability





Claude autonomously found more than a dozen 0-day exploits in popular GitHub projects: https://github.com/protectai/vulnhuntr/

Google Claims World First As LLM assisted AI Agent Finds 0-Day Security Vulnerability: https://www.forbes.com/sites/daveywinder/2024/11/04/google-claims-world-first-as-ai-finds-0-day-security-vulnerability/

the Big Sleep team says it found “an exploitable stack buffer underflow in SQLite, a widely used open source database engine.”
The zero-day vulnerability was reported to the SQLite development team in October which fixed it the same day. “We found this issue before it appeared in an official release,” the Big Sleep team from Google said, “so SQLite users were not impacted.”


LLM skeptic and 35 year software engineer Internet of Bugs says “ChatGPT-O1 Changes Programming as a Profession. I really hated saying that”: https://youtube.com/watch?v=j0yKLumIbaM

OpenAI o1 model released: https://openai.com/index/learning-to-reason-with-llms/
o1 improves over GPT-4o on a wide range of benchmarks, including 54/57 MMLU subcategories
OpenAI o1 ranks in the 89th percentile on competitive programming questions (Codeforces), places among the top 500 students in the US in a qualifier for the USA Math Olympiad (AIME), and exceeds human PhD-level accuracy on a benchmark of physics, biology, and chemistry problems (GPQA).
On the 2024 AIME exams, GPT-4o only solved on average 12% (1.8/15) of problems. o1 averaged 74% (11.1/15) with a single sample per problem, 83% (12.5/15) with consensus among 64 samples, and 93% (13.9/15) when re-ranking 1000 samples with a learned scoring function. A score of 13.9 places it among the top 500 students nationally and above the cutoff for the USA Mathematical Olympiad.
We trained a model that scored 213 points and ranked in the 49th percentile in the 2024 International Olympiad in Informatics (IOI), by initializing from o1 and training to further improve programming skills. This model competed in the 2024 IOI under the same conditions as the human contestants. It had ten hours to solve six challenging algorithmic problems and was allowed 50 submissions per problem.
With a relaxed submission constraint, we found that model performance improved significantly. When allowed 10,000 submissions per problem, the model achieved a score of 362.14 – above the gold medal threshold – even without any test-time selection strategy.  




Our evaluations closely matched competition rules and allowed for 10 submissions. GPT-4o achieved an Elo rating3 of 808, which is in the 11th percentile of human competitors. This model far exceeded both GPT-4o and o1—it achieved an Elo rating of 1807, performing better than 93% of competitors.
https://cdn.openai.com/o1-system-card.pdf
 We find that o1-preview is less prone to selecting stereotyped options than GPT-4o, and o1-mini has comparable performance to GPT-4o-mini. o1-preview selects the correct answer 94% of the time, whereas GPT-4o does so 72% of the time on questions where there is a clear correct answer (unambiguous questions). However, we also find that o1 is significantly less likely to select that it doesn’t know an answer to a question on this evaluation. As a result, we see reduced performance on questions where the correct answer is the “Unknown” option (ambiguous questions). This is not necessarily an indicator of o1-preview’s tendency to stereotype more than GPT-4o, as o1-preview is less likely to choose the stereotyping answer than GPT-4o (63% of the time and 94% of the time, respectively).









Note: This is the weakest model compared to o1-preview and the full o1 model
OpenAI’s o1 model can get perfect scores on their research engineer interview coding questions:











ChipNeMo-70B, outperforms the highly capable GPT-4 on two of our use cases, namely engineering assistant chatbot and EDA scripts generation, while exhibiting competitive performance on bug summarization and analysis. These results underscore the potential of domain-specific customization for enhancing the effectiveness of large language models in specialized applications: https://arxiv.org/pdf/2311.00176 
[Alphacode 2 beat 85% of competitive programming participants in Codeforce competitions](https://techcrunch.com/2023/12/06/deepmind-unveils-alphacode-2-powered-by-gemini/)
Keep in mind the type of programmer who even joins programming competitions in the first place is definitely far more skilled than the average code monkey, and it’s STILL much better than those guys. 
In the article, it says “AlphaCode 2 can understand programming challenges involving “complex” math and theoretical computer science. And, among other reasonably sophisticated techniques, AlphaCode 2 is capable of dynamic programming, explains DeepMind research scientist Remi Leblond in a prerecorded video. Dynamic programming entails simplifying a complex problem by breaking it down into easier sub-problems over and over; Leblond says that AlphaCode 2 knows not only when to properly implement this strategy but where to use it. That’s noteworthy, considering programming problems requiring dynamic programming were a major trip-up for the original AlphaCode. “[AlphaCode 2] needs to show some level of understanding, some level of reasoning and designing of code solutions before it can get to the actual implementation to solve [a] coding problem,” Leblond said. “And it does all that on problems it’s never seen before.”

Microsoft AutoDev: https://arxiv.org/pdf/2403.08299

“We tested AutoDev on the HumanEval dataset, obtaining promising results with 91.5% and 87.8% of Pass@1 for code generation and test generation respectively, demonstrating its effectiveness in automating software engineering tasks while maintaining a secure and user-controlled development environment.”

NYT article on ChatGPT: https://archive.is/hy3Ae

“In a trial run by GitHub’s researchers, developers given an entry-level task and encouraged to use the program, called Copilot, completed their task 55 percent faster than those who did the assignment manually.”


Study that ChatGPT supposedly fails 52% of coding tasks: https://dl.acm.org/doi/pdf/10.1145/3613904.3642596 

“this work has used the free version of ChatGPT (GPT-3.5) for acquiring the ChatGPT responses for the manual analysis.”

“Thus, we chose to only consider the initial answer generated by ChatGPT.”

“To understand how differently GPT-4 performs compared to GPT-3.5, we conducted a small analysis on 21 randomly selected [StackOverflow] questions where GPT-3.5 gave incorrect answers. Our analysis shows that, among these 21 questions, GPT-4 could answer only 6 questions correctly, and 15 questions were still answered incorrectly.”

This is an extra 28.6% on top of the 48% that GPT 3.5 was correct on, totaling to ~77% for GPT 4 (equal to (517*0.48+517*6/21)/517) if we assume that GPT 4 correctly answers all of the questions that GPT 3.5 correctly answered, which is highly likely considering GPT 4 is far higher quality than GPT 3.5.

Note: This was all done in ONE SHOT with no repeat attempts or follow up.

Also, the study was released before GPT-4o and may not have used GPT-4-Turbo, both of which are significantly higher quality in coding capacity than GPT 4 according to the LMSYS arena


On top of that, both of those models are inferior to Claude 3.5 Sonnet: "In an internal agentic coding evaluation, Claude 3.5 Sonnet solved 64% of problems, outperforming Claude 3 Opus which solved 38%." Claude 3.5 Opus (which will be even better than Sonnet) is set to be released later this year.
Meta researchers create AI that masters Diplomacy, tricking human players. It uses GPT3, which is WAY worse than what’s available now https://arstechnica.com/information-technology/2022/11/meta-researchers-create-ai-that-masters-diplomacy-tricking-human-players/
The resulting model mastered the intricacies of a complex game. "Cicero can deduce, for example, that later in the game it will need the support of one particular player," says Meta, "and then craft a strategy to win that person’s favor—and even recognize the risks and opportunities that that player sees from their particular point of view."
Meta's Cicero research appeared in the journal Science under the title, "Human-level play in the game of Diplomacy by combining language models with strategic reasoning."
CICERO uses relationships with other players to keep its ally, Adam, in check.
When playing 40 games against human players, CICERO achieved more than double the average score of the human players and ranked in the top 10% of participants who played more than one game.
First Results from Med-Gemini (the successor to Med-Palm, a medically fine tuned LLM). "More accurate multimodal conversations about medical images🩻, surgical videos📽️, genomics🧬, ultra-long health records📚, ECGs🫀 & more with state-of-art performance across multiple benchmarks"](https://twitter.com/alan_karthi/status/1785117444383588823 )


Stanford researchers: “Automating AI research is exciting! But can LLMs actually produce novel, expert-level research ideas? After a year-long study, we obtained the first statistically significant conclusion: LLM-generated ideas are more novel than ideas written by expert human researchers." https://x.com/ChengleiSi/status/1833166031134806330

>Coming from 36 different institutions, our participants are mostly PhDs and postdocs. As a proxy metric, our idea writers have a median citation count of 125, and our reviewers have 327.

>We also used an LLM to standardize the writing styles of human and LLM ideas to avoid potential confounders, while preserving the original content.



How AlphaChip transformed computer chip design: https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/
Our AI method has accelerated and optimized chip design, and its superhuman chip layouts are used in hardware around the world
The method has been used to design superhuman chip layouts in the last three generations of Google’s custom AI accelerator, the Tensor Processing Unit (TPU).
AlphaChip was one of the first reinforcement learning approaches used to solve a real-world engineering problem. It generates superhuman or comparable chip layouts in hours, rather than taking weeks or months of human effort, and its layouts are used in chips all over the world, from data centers to mobile phones.
AlphaChip has generated superhuman chip layouts used in every generation of Google’s TPU since its publication in 2020. These chips make it possible to massively scale-up AI models based on Google’s Transformer architecture.
Beyond designing specialized AI accelerators like TPUs, AlphaChip has generated layouts for other chips across Alphabet, such as Google Axion Processors, our first Arm-based general-purpose data center CPUs.
External organizations are also adopting and building on AlphaChip. For example, MediaTek, one of the top chip design companies in the world, extended AlphaChip to accelerate development of their most advanced chips — like the Dimensity Flagship 5G used in Samsung mobile phones — while improving power, performance and chip area.


15.5. Math
Transformers used to solve a math problem that stumped experts for 132 years: Discovering global Lyapunov functions. Lyapunov functions are key tools for analyzing system stability over time and help to predict dynamic system behavior, like the famous three-body problem of celestial mechanics: https://arxiv.org/abs/2410.08304



LeanAgent: Lifelong Learning for Formal Theorem Proving: https://arxiv.org/abs/2410.0620

LeanAgent successfully proves 162 theorems previously unproved by humans across 23 diverse Lean repositories, many from advanced mathematics.


FrontierMath is benchmark of hundreds of original mathematics problems spanning the breadth of modern mathematical research. These range from computationally intensive problems in number theory and real analytics to abstract questions in algebraic geometry and categorytheory We developed it through collaboration with over 60 mathematicians from leading institutions, including professors, IMO question writers, and Fields medalists: https://epoch.ai/frontiermath/the-benchmark
FrontierMath problems typically demand hours or even days for specialist mathematicians to solve.
All problems are new and unpublished, eliminating data contamination concerns that plague existing benchmarks.
Created in collaboration with over 60 mathematicians, FrontierMath spans the full spectrum of modern mathematics, from algebraic geometry to Zermelo–Fraenkel set theory.
“These are extremely challenging. I think that in the near term basically the only way to solve them, short of having a real domain expert in the area, is by a combination of a semi-expert like a graduate student in a related field, maybe paired with some combination of a modern AI and lots of other algebra packages…” —Terence Tao, Fields Medal (2006)
  “[The questions I looked at] were all not really in my area and all looked like things I had no idea how to solve…they appear to be at a different level of difficulty from IMO problems.” — Timothy Gowers, Fields Medal (2006)
"o3 surpasses previous performance records across the board. It beats its predecessor in coding tests (called SWE-Bench Verified) by 22.8 percent and outscores OpenAI’s Chief Scientist in competitive programming. The model nearly aced one of the hardest math competitions (called AIME 2024), missing one question, and achieved 87.7 percent on a benchmark for expert-level science problems (called GPQA Diamond). On the toughest math and reasoning challenges that usually stump AI, o3 solved 25.2 percent of problems (where no other model exceeds 2 percent)." https://www.theverge.com/2024/12/20/24326036/openai-o1-o2-o3-reasoning-model-testing
O1 scores 8/12 (AT LEAST 80 points, excluding partial credit for incorrect answers) on Putnam exam released after its training cutoff date: https://docs.google.com/document/d/1dwtSqDBfcuVrkauFes0ALQpQjCyqa4hD0bPClSJovIs/edit

In 2022, the average score for the competition was approximately 8.2; the median score was one: https://news.mit.edu/2023/mit-wins-putnam-math-competition-0223
Keep in mind, only very talented people even participate in the competition 
GPT 4 and 4o cannot do this 
Abacus Embeddings, a simple tweak to positional embeddings that enables LLMs to do addition, multiplication, sorting, and more. Our Abacus Embeddings trained only on 20-digit addition generalise near perfectly to 100+ digits: https://x.com/SeanMcleish/status/1795481814553018542 


OOD means “out of distribution” so it was NOT in the training data

First AI to solve International Mathematical Olympiad problems at a silver medalist level: https://x.com/GoogleDeepMind/status/1816498082860667086

>It combines AlphaProof, a new breakthrough model for formal reasoning, and AlphaGeometry 2, an improved version of our previous system. 
Powered with a novel search algorithm, AlphaGeometry 2 can now solve 83% of all historical problems from the past 25 years - compared to the 53% rate by its predecessor.
It solved this year’s IMO Problem 4 within 19 seconds
The fact that the program can come up with a non-obvious construction like this is very impressive, and well beyond what I thought was state of the art. -PROF SIR TIMOTHY GOWERS, IMO GOLD MEDALIST AND FIELDS MEDAL WINNER

Math professor on DeepMind's breakthrough: "When people saw Sputnik 1957, they might have had same feeling I do now. Human civ needs to move to high alert" https://x.com/PoShenLoh/status/1816500461484081519

Grok 2 has record high math performance on MathVista benchmark, scoring 15% higher than humans: https://www.reddit.com/r/LocalLLaMA/comments/1etcj0k/grok2_and_grok2_mini_now_hold_the_top_two_spots/
A 10 page paper caused a panic because of a math error. O1 could spot the error by just prompting: “carefully check the math in this paper” even when the info is not in training data: https://x.com/emollick/status/1868329599438037491
This was o1, not pro. I just pasted in the article with the literal prompt above.
Claude did not spot the error when given the PDF until it was told to look just at the reference value.
Google DeepMind used a large language model to solve an unsolved math problem: https://www.technologyreview.com/2023/12/14/1085318/google-deepmind-large-language-model-solve-unsolvable-math-problem-cap-set/
NuminaMath 72b TIR model: https://x.com/JiaLi52524397/status/1814957190320631929/
Trained on new competition math dataset ever released, with 860K problem solution pairs that was created with GPT 4
We selected approximately 70k problems from the NuminaMath-CoT dataset, focusing on those with numerical outputs, most of which are integers. We then utilized a pipeline leveraging GPT-4 to generate TORA-like reasoning paths, executing the code and producing results until the solution was complete. We filtered out solutions where the final answer did not match the reference and repeated this process three times to ensure accuracy and consistency. This iterative approach allowed us to generate high-quality TORA data efficiently.

For AMC 12 2023, the average score is 43%, 
AIME Floor: 70% (top ~6%)
Distinction: 75%
Distinguished Honor Roll: 90%


Six months ago, we launched Numina to lead open research in AI4Math. The Numina Math 7B model won the 1st progress prize of the AI Math Olympiad: https://x.com/JiaLi52524397/status/1808886880164880631

https://mathvista.github.io/
test: 5,141 examples for standard evaluation. Notably, the answer labels for test will NOT be publicly released
Human performance is 60.8%. Average human performance is from AMT annotators who have high school diplomas or above.

https://mathstodon.xyz/@tao/113132503432772494
Scores of o1-preview and GPT-4o on "official national exam in abstract mathematics used in Dutch high schools." Taken twice, o1-preview got 76 and 73 (max 76). Taken twice, GPT-4o got 66 and 61. Paper: "System 2 thinking in OpenAI’s o1-preview model: Near-perfect performance on a mathematics exam"  

A thread of a researcher sharing his team's findings on whether or not LLMs can help create Math proofs, competing against humans. Summary: none of them really could get far, until o1 came out: https://x.com/robertghrist/status/1841462507543949581?t=5zV3VpQI0mbrSU9_QRtfkQ&s=19
LeanAgent: Lifelong Learning for Formal Theorem Proving: https://arxiv.org/abs/2410.06209
LeanAgent successfully proves 162 theorems previously unproved by humans across 23 diverse Lean repositories, many from advanced mathematics.


16. Change Log for Past Week (In PST)
12/11/24
Added information on Google’s Gemini 2.0 Flash

12/12/24
Added Phi 4 14b
Added Klarna use of AI to replace workers to section 5

12/13/24
Added byte latent transformer scaling research from Meta

12/16/24
Added a 10 page paper caused a panic because of a math error. O1 could spot the error by just prompting: “carefully check the math in this paper” even when the info is not in training data
Added new images to section 11.2
Added Nerosama winning Tech Vtuber of the Year 2 years in a row to section 11.2 and 15
Added Veo 2


12/17/24
Added o1-preview performance on hard NEJM CPC diagnoses


12/18/24
Added new physics-based video generation model
Added o1 Livebench results to section 3.1

12/19/24
Added section 12.16
Added new research from Meta and NYU on emergent LLM understanding  

12/26/24
Added information about Deepseek V3 
